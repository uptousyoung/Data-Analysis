{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1>Social Media content-based recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is aimed to build a social media content-based recommendation system to enhance the user experience, which includes recommending or predicting some new items (articles) they will like based on their preference. This project includes the following functions: article classification, article topic keyword extraction, article similarity analysis, article recommendation, user recommendation, user preference analysis, article influence ranking, article influence prediction analysis. We explore the details and meaning of the recommendation system through different angles and methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1>What does the social media platform look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is a text-based social media recommendation system and assumes a platform for article publishing and reading communication, by designing different functions to enhance the user experience and based on user preferences for article analysis and article recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1>What kinds of functions we want to achieve in this project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Article classification and keywords extraction \n",
    "#### 2 Content-based recommendation\n",
    "#### 3 User preference level desigh\n",
    "#### 4 Articles recommendation for a user based on user preference\n",
    "#### 5 Articles influence ranking \n",
    "#### 6 Article influence prediction\n",
    "#### 7 Article tags suggestions\n",
    "#### 8 Frirends recommendation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "import operator\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the datasets from kaggle directly：https://www.kaggle.com/gspmoreira/articles-sharing-reading-from-cit-deskdrop. The two datasets are about  the information of articles sharing and reading from CI&T DeskDrop. Deskdrop is an internal communications platform developed by CI&T, focused in companies using Google G Suite. Among other features, this platform allows companies employees to share relevant articles with their peers, and collaborate around them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing the dataset\n",
    "df_users=pd.read_csv(\"users_interactions.csv\", decimal = ',')\n",
    "\n",
    "\n",
    "df_articles=pd.read_csv(\"shared_articles.csv\", decimal = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>A Glimpse of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 72312\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>personId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userRegion</th>\n",
       "      <th>userCountry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1465413032</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-3499919498720038879</td>\n",
       "      <td>-8845298781299428018</td>\n",
       "      <td>1264196770339959068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1465412560</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>8890720798209849691</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3621737643587579081</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...</td>\n",
       "      <td>NY</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1465416190</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1130272294246983140</td>\n",
       "      <td>2631864456530402479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1465413895</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>344280948527967603</td>\n",
       "      <td>-3167637573980064150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465412290</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-7820640624231356730</td>\n",
       "      <td>-445337111692715325</td>\n",
       "      <td>5611481178424124714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1465413742</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-8763398617720485024</td>\n",
       "      <td>1395789369402380392</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1465415950</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-8864073373672512525</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>1143207167886864524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1465415066</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-1492913151930215984</td>\n",
       "      <td>4254153380739593270</td>\n",
       "      <td>8743229464706506141</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1465413762</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>344280948527967603</td>\n",
       "      <td>-3167637573980064150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1465413771</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>3064370296170038610</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>1143207167886864524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1465413864</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>1143207167886864524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1465415229</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>3460026829794173084</td>\n",
       "      <td>1908339160857512799</td>\n",
       "      <td>9121879357144259163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1465415228</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>3460026829794173084</td>\n",
       "      <td>1908339160857512799</td>\n",
       "      <td>9121879357144259163</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1465415691</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>7763750328910542816</td>\n",
       "      <td>1908339160857512799</td>\n",
       "      <td>9121879357144259163</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1465413171</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>2372438485070148864</td>\n",
       "      <td>7781822014935525018</td>\n",
       "      <td>-8307903816792524795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1465415259</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-348408475077850711</td>\n",
       "      <td>8239286975497580612</td>\n",
       "      <td>8524822173689882396</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1465415623</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>372531153711028286</td>\n",
       "      <td>8239286975497580612</td>\n",
       "      <td>8524822173689882396</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1465412288</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-7820640624231356730</td>\n",
       "      <td>-445337111692715325</td>\n",
       "      <td>5611481178424124714</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1465415693</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>6521856301289868251</td>\n",
       "      <td>2766187446275090740</td>\n",
       "      <td>247949759466213096</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1465415691</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-8142426490949346803</td>\n",
       "      <td>1908339160857512799</td>\n",
       "      <td>9121879357144259163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp eventType            contentId             personId  \\\n",
       "0   1465413032      VIEW -3499919498720038879 -8845298781299428018   \n",
       "1   1465412560      VIEW  8890720798209849691 -1032019229384696495   \n",
       "2   1465416190      VIEW   310515487419366995 -1130272294246983140   \n",
       "3   1465413895    FOLLOW   310515487419366995   344280948527967603   \n",
       "4   1465412290      VIEW -7820640624231356730  -445337111692715325   \n",
       "5   1465413742      VIEW   310515487419366995 -8763398617720485024   \n",
       "6   1465415950      VIEW -8864073373672512525  3609194402293569455   \n",
       "7   1465415066      VIEW -1492913151930215984  4254153380739593270   \n",
       "8   1465413762      VIEW   310515487419366995   344280948527967603   \n",
       "9   1465413771      VIEW  3064370296170038610  3609194402293569455   \n",
       "10  1465413864      VIEW   310515487419366995  3609194402293569455   \n",
       "11  1465415229      VIEW  3460026829794173084  1908339160857512799   \n",
       "12  1465415228      VIEW  3460026829794173084  1908339160857512799   \n",
       "13  1465415691      VIEW  7763750328910542816  1908339160857512799   \n",
       "14  1465413171      VIEW  2372438485070148864  7781822014935525018   \n",
       "15  1465415259      VIEW  -348408475077850711  8239286975497580612   \n",
       "16  1465415623      VIEW   372531153711028286  8239286975497580612   \n",
       "17  1465412288      VIEW -7820640624231356730  -445337111692715325   \n",
       "18  1465415693      VIEW  6521856301289868251  2766187446275090740   \n",
       "19  1465415691      VIEW -8142426490949346803  1908339160857512799   \n",
       "\n",
       "              sessionId                                          userAgent  \\\n",
       "0   1264196770339959068                                                NaN   \n",
       "1   3621737643587579081  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...   \n",
       "2   2631864456530402479                                                NaN   \n",
       "3  -3167637573980064150                                                NaN   \n",
       "4   5611481178424124714                                                NaN   \n",
       "5   1395789369402380392  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "6   1143207167886864524                                                NaN   \n",
       "7   8743229464706506141  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "8  -3167637573980064150                                                NaN   \n",
       "9   1143207167886864524                                                NaN   \n",
       "10  1143207167886864524                                                NaN   \n",
       "11  9121879357144259163                                                NaN   \n",
       "12  9121879357144259163  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "13  9121879357144259163  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "14 -8307903816792524795                                                NaN   \n",
       "15  8524822173689882396  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "16  8524822173689882396  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "17  5611481178424124714  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "18   247949759466213096  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "19  9121879357144259163                                                NaN   \n",
       "\n",
       "   userRegion userCountry  \n",
       "0         NaN         NaN  \n",
       "1          NY          US  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  \n",
       "5          MG          BR  \n",
       "6         NaN         NaN  \n",
       "7          SP          BR  \n",
       "8         NaN         NaN  \n",
       "9         NaN         NaN  \n",
       "10        NaN         NaN  \n",
       "11        NaN         NaN  \n",
       "12         SP          BR  \n",
       "13         SP          BR  \n",
       "14        NaN         NaN  \n",
       "15         SP          BR  \n",
       "16         SP          BR  \n",
       "17         MG          BR  \n",
       "18         MG          BR  \n",
       "19        NaN         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the top 5 rows of the dataset\n",
    "\n",
    "print('rows: %d' % len(df_users))\n",
    "\n",
    "df_users.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 3122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>authorPersonId</th>\n",
       "      <th>authorSessionId</th>\n",
       "      <th>authorUserAgent</th>\n",
       "      <th>authorRegion</th>\n",
       "      <th>authorCountry</th>\n",
       "      <th>contentType</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1459192779</td>\n",
       "      <td>CONTENT REMOVED</td>\n",
       "      <td>-6451309518266745024</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.nytimes.com/2016/03/28/business/dea...</td>\n",
       "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
       "      <td>All of this work is still very early. The firs...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1459193988</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-4110354420726924665</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.nytimes.com/2016/03/28/business/dea...</td>\n",
       "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
       "      <td>All of this work is still very early. The firs...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1459194146</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-7292285110016212249</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://cointelegraph.com/news/bitcoin-future-w...</td>\n",
       "      <td>Bitcoin Future: When GBPcoin of Branson Wins O...</td>\n",
       "      <td>The alarm clock wakes me at 8:00 with stream o...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1459194474</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-6151852268067518688</td>\n",
       "      <td>3891637997717104548</td>\n",
       "      <td>-1457532940883382585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://cloudplatform.googleblog.com/2016/03/G...</td>\n",
       "      <td>Google Data Center 360° Tour</td>\n",
       "      <td>We're excited to share the Google Data Center ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1459194497</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>2448026894306402386</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://bitcoinmagazine.com/articles/ibm-wants...</td>\n",
       "      <td>IBM Wants to \"Evolve the Internet\" With Blockc...</td>\n",
       "      <td>The Aite Group projects the blockchain market ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1459194522</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-2826566343807132236</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.coindesk.com/ieee-blockchain-oxford...</td>\n",
       "      <td>IEEE to Talk Blockchain at Cloud Computing Oxf...</td>\n",
       "      <td>One of the largest and oldest organizations fo...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1459194557</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-2148899391355011268</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.newsbtc.com/2016/03/28/banks-need-c...</td>\n",
       "      <td>Banks Need To Collaborate With Bitcoin and Fin...</td>\n",
       "      <td>It will take time until banks come around to t...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1459194599</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>4119190424078847945</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://bitcoinmagazine.com/articles/blockchai...</td>\n",
       "      <td>Blockchain Technology Could Put Bank Auditors ...</td>\n",
       "      <td>When most people think about computers and rob...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1459194751</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-7926018713416777892</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://news.bitcoin.com/conglomerates-intervi...</td>\n",
       "      <td>Why Decentralized Conglomerates Will Scale Bet...</td>\n",
       "      <td>Bitcoin.com spoke with the OpenLedger CEO, Ron...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1459194842</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>3353902017498793780</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://www.cryptocoinsnews.com/ethereum-rise-...</td>\n",
       "      <td>The Rise And Growth of Ethereum Gets Mainstrea...</td>\n",
       "      <td>Ethereum, considered by many to be the most pr...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1459210504</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-9157338616628196758</td>\n",
       "      <td>5206835909720479405</td>\n",
       "      <td>-7864441319395545950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://economia.ig.com.br/2016-03-27/situacao-...</td>\n",
       "      <td>Situação financeira ruim de varejistas pressio...</td>\n",
       "      <td>A queda nas vendas e a deterioração na situaçã...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1459217624</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>1805789466376069146</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3042342415047984532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://cloud.google.com/compute/docs/load-bal...</td>\n",
       "      <td>Setting Up HTTP(S) Load Balancing</td>\n",
       "      <td>HTTP(S) load balancing provides global load ba...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1459217735</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-2081760549863309770</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3042342415047984532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://cloud.google.com/compute/docs/load-bal...</td>\n",
       "      <td>Setting Up SSL proxy for Google Cloud Load Bal...</td>\n",
       "      <td>Alpha This is an Alpha release of Setting Up S...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1459217994</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-5170198873410718233</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3042342415047984532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://techcrunch.com/2016/03/28/ntt-to-buy-de...</td>\n",
       "      <td>NTT to buy Dell's services division for $3.05 ...</td>\n",
       "      <td>You may know Dell as a computer and server mak...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1459229160</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-3367778232969996503</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3042342415047984532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.salon.com/2016/03/27/good_riddance_...</td>\n",
       "      <td>Good riddance, gig economy: Uber, Ayn Rand and...</td>\n",
       "      <td>The Uber model just doesn't work for other ind...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1459248284</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>4988225165850707692</td>\n",
       "      <td>4670267857749552625</td>\n",
       "      <td>-265833983523746108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://cio.economictimes.indiatimes.com/news/i...</td>\n",
       "      <td>The internet of a billion things | ET CIO</td>\n",
       "      <td>Industrial adoption of IoT dubbed as Industria...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1459248366</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-5917314377186856799</td>\n",
       "      <td>4670267857749552625</td>\n",
       "      <td>-265833983523746108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.senar.org.br/agricultura-precisao/a...</td>\n",
       "      <td>Artigos e Palestras - Programa Agricultura de ...</td>\n",
       "      <td>Artigos e Palestras ARTIGOS / 2015 12/08/2015 ...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1459248432</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>6157037646878010131</td>\n",
       "      <td>4670267857749552625</td>\n",
       "      <td>-265833983523746108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://www.macroprograma1.cnptia.embrapa.br/r...</td>\n",
       "      <td>Rede Agricultura de Precisão II</td>\n",
       "      <td>Do Se Te Qu Qu Se Sa 27 28 29 30 31 Faça downl...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1459251677</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>6023609667389715259</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>-7292854281461484137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://blog.coinfund.io/five-bitcoin-and-ethe...</td>\n",
       "      <td>Five Bitcoin and Ethereum Based Projects to Wa...</td>\n",
       "      <td>Five Bitcoin and Ethereum Based Projects to Wa...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1459251714</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>7905485530310717815</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>-7292854281461484137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.coindesk.com/blockchain-smart-contr...</td>\n",
       "      <td>Blockchain Smart Contracts Startup Selected By...</td>\n",
       "      <td>CommonAccord, a blockchain-based startup for l...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp        eventType            contentId       authorPersonId  \\\n",
       "0   1459192779  CONTENT REMOVED -6451309518266745024  4340306774493623681   \n",
       "1   1459193988   CONTENT SHARED -4110354420726924665  4340306774493623681   \n",
       "2   1459194146   CONTENT SHARED -7292285110016212249  4340306774493623681   \n",
       "3   1459194474   CONTENT SHARED -6151852268067518688  3891637997717104548   \n",
       "4   1459194497   CONTENT SHARED  2448026894306402386  4340306774493623681   \n",
       "5   1459194522   CONTENT SHARED -2826566343807132236  4340306774493623681   \n",
       "6   1459194557   CONTENT SHARED -2148899391355011268  4340306774493623681   \n",
       "7   1459194599   CONTENT SHARED  4119190424078847945  4340306774493623681   \n",
       "8   1459194751   CONTENT SHARED -7926018713416777892  4340306774493623681   \n",
       "9   1459194842   CONTENT SHARED  3353902017498793780  4340306774493623681   \n",
       "10  1459210504   CONTENT SHARED -9157338616628196758  5206835909720479405   \n",
       "11  1459217624   CONTENT SHARED  1805789466376069146 -1032019229384696495   \n",
       "12  1459217735   CONTENT SHARED -2081760549863309770 -1032019229384696495   \n",
       "13  1459217994   CONTENT SHARED -5170198873410718233 -1032019229384696495   \n",
       "14  1459229160   CONTENT SHARED -3367778232969996503 -1032019229384696495   \n",
       "15  1459248284   CONTENT SHARED  4988225165850707692  4670267857749552625   \n",
       "16  1459248366   CONTENT SHARED -5917314377186856799  4670267857749552625   \n",
       "17  1459248432   CONTENT SHARED  6157037646878010131  4670267857749552625   \n",
       "18  1459251677   CONTENT SHARED  6023609667389715259  4340306774493623681   \n",
       "19  1459251714   CONTENT SHARED  7905485530310717815  4340306774493623681   \n",
       "\n",
       "        authorSessionId authorUserAgent authorRegion authorCountry  \\\n",
       "0   8940341205206233829             NaN          NaN           NaN   \n",
       "1   8940341205206233829             NaN          NaN           NaN   \n",
       "2   8940341205206233829             NaN          NaN           NaN   \n",
       "3  -1457532940883382585             NaN          NaN           NaN   \n",
       "4   8940341205206233829             NaN          NaN           NaN   \n",
       "5   8940341205206233829             NaN          NaN           NaN   \n",
       "6   8940341205206233829             NaN          NaN           NaN   \n",
       "7   8940341205206233829             NaN          NaN           NaN   \n",
       "8   8940341205206233829             NaN          NaN           NaN   \n",
       "9   8940341205206233829             NaN          NaN           NaN   \n",
       "10 -7864441319395545950             NaN          NaN           NaN   \n",
       "11  3042342415047984532             NaN          NaN           NaN   \n",
       "12  3042342415047984532             NaN          NaN           NaN   \n",
       "13  3042342415047984532             NaN          NaN           NaN   \n",
       "14  3042342415047984532             NaN          NaN           NaN   \n",
       "15  -265833983523746108             NaN          NaN           NaN   \n",
       "16  -265833983523746108             NaN          NaN           NaN   \n",
       "17  -265833983523746108             NaN          NaN           NaN   \n",
       "18 -7292854281461484137             NaN          NaN           NaN   \n",
       "19 -7292854281461484137             NaN          NaN           NaN   \n",
       "\n",
       "   contentType                                                url  \\\n",
       "0         HTML  http://www.nytimes.com/2016/03/28/business/dea...   \n",
       "1         HTML  http://www.nytimes.com/2016/03/28/business/dea...   \n",
       "2         HTML  http://cointelegraph.com/news/bitcoin-future-w...   \n",
       "3         HTML  https://cloudplatform.googleblog.com/2016/03/G...   \n",
       "4         HTML  https://bitcoinmagazine.com/articles/ibm-wants...   \n",
       "5         HTML  http://www.coindesk.com/ieee-blockchain-oxford...   \n",
       "6         HTML  http://www.newsbtc.com/2016/03/28/banks-need-c...   \n",
       "7         HTML  https://bitcoinmagazine.com/articles/blockchai...   \n",
       "8         HTML  https://news.bitcoin.com/conglomerates-intervi...   \n",
       "9         HTML  https://www.cryptocoinsnews.com/ethereum-rise-...   \n",
       "10        HTML  http://economia.ig.com.br/2016-03-27/situacao-...   \n",
       "11        HTML  https://cloud.google.com/compute/docs/load-bal...   \n",
       "12        HTML  https://cloud.google.com/compute/docs/load-bal...   \n",
       "13        HTML  http://techcrunch.com/2016/03/28/ntt-to-buy-de...   \n",
       "14        HTML  http://www.salon.com/2016/03/27/good_riddance_...   \n",
       "15        HTML  http://cio.economictimes.indiatimes.com/news/i...   \n",
       "16        HTML  http://www.senar.org.br/agricultura-precisao/a...   \n",
       "17        HTML  https://www.macroprograma1.cnptia.embrapa.br/r...   \n",
       "18        HTML  https://blog.coinfund.io/five-bitcoin-and-ethe...   \n",
       "19        HTML  http://www.coindesk.com/blockchain-smart-contr...   \n",
       "\n",
       "                                                title  \\\n",
       "0   Ethereum, a Virtual Currency, Enables Transact...   \n",
       "1   Ethereum, a Virtual Currency, Enables Transact...   \n",
       "2   Bitcoin Future: When GBPcoin of Branson Wins O...   \n",
       "3                        Google Data Center 360° Tour   \n",
       "4   IBM Wants to \"Evolve the Internet\" With Blockc...   \n",
       "5   IEEE to Talk Blockchain at Cloud Computing Oxf...   \n",
       "6   Banks Need To Collaborate With Bitcoin and Fin...   \n",
       "7   Blockchain Technology Could Put Bank Auditors ...   \n",
       "8   Why Decentralized Conglomerates Will Scale Bet...   \n",
       "9   The Rise And Growth of Ethereum Gets Mainstrea...   \n",
       "10  Situação financeira ruim de varejistas pressio...   \n",
       "11                  Setting Up HTTP(S) Load Balancing   \n",
       "12  Setting Up SSL proxy for Google Cloud Load Bal...   \n",
       "13  NTT to buy Dell's services division for $3.05 ...   \n",
       "14  Good riddance, gig economy: Uber, Ayn Rand and...   \n",
       "15          The internet of a billion things | ET CIO   \n",
       "16  Artigos e Palestras - Programa Agricultura de ...   \n",
       "17                    Rede Agricultura de Precisão II   \n",
       "18  Five Bitcoin and Ethereum Based Projects to Wa...   \n",
       "19  Blockchain Smart Contracts Startup Selected By...   \n",
       "\n",
       "                                                 text lang  \n",
       "0   All of this work is still very early. The firs...   en  \n",
       "1   All of this work is still very early. The firs...   en  \n",
       "2   The alarm clock wakes me at 8:00 with stream o...   en  \n",
       "3   We're excited to share the Google Data Center ...   en  \n",
       "4   The Aite Group projects the blockchain market ...   en  \n",
       "5   One of the largest and oldest organizations fo...   en  \n",
       "6   It will take time until banks come around to t...   en  \n",
       "7   When most people think about computers and rob...   en  \n",
       "8   Bitcoin.com spoke with the OpenLedger CEO, Ron...   en  \n",
       "9   Ethereum, considered by many to be the most pr...   en  \n",
       "10  A queda nas vendas e a deterioração na situaçã...   pt  \n",
       "11  HTTP(S) load balancing provides global load ba...   en  \n",
       "12  Alpha This is an Alpha release of Setting Up S...   en  \n",
       "13  You may know Dell as a computer and server mak...   en  \n",
       "14  The Uber model just doesn't work for other ind...   en  \n",
       "15  Industrial adoption of IoT dubbed as Industria...   en  \n",
       "16  Artigos e Palestras ARTIGOS / 2015 12/08/2015 ...   pt  \n",
       "17  Do Se Te Qu Qu Se Sa 27 28 29 30 31 Faça downl...   pt  \n",
       "18  Five Bitcoin and Ethereum Based Projects to Wa...   en  \n",
       "19  CommonAccord, a blockchain-based startup for l...   en  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('rows: %d' % len(df_articles))\n",
    "\n",
    "df_articles.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1> Data Cleaning / Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "   *Check missing values\n",
    "\n",
    "   *remove duplicates\n",
    "\n",
    "   *check data types\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_missing</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>userRegion</th>\n",
       "      <td>15405</td>\n",
       "      <td>21.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userCountry</th>\n",
       "      <td>15394</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userAgent</th>\n",
       "      <td>15394</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             total_missing  percent\n",
       "userRegion           15405    21.30\n",
       "userCountry          15394    21.29\n",
       "userAgent            15394    21.29"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count all the total missing values (not equals to 0)number in each column with the descending order\n",
    "total = df_users.isnull().sum()[df_users.isnull().sum() != 0].sort_values(ascending = False)\n",
    "\n",
    "# Caculate the percantage\n",
    "percent = pd.Series(round(total/len(df_users)*100,2))\n",
    "\n",
    "# Generate a new dataframe for 'total_missing'and'percent'\n",
    "pd.concat([total, percent], axis=1, keys=['total_missing', 'percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_missing</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>authorCountry</th>\n",
       "      <td>2442</td>\n",
       "      <td>78.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorRegion</th>\n",
       "      <td>2442</td>\n",
       "      <td>78.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorUserAgent</th>\n",
       "      <td>2442</td>\n",
       "      <td>78.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 total_missing  percent\n",
       "authorCountry             2442    78.22\n",
       "authorRegion              2442    78.22\n",
       "authorUserAgent           2442    78.22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count all the total missing values (not equals to 0)number in each column with the descending order\n",
    "total = df_articles.isnull().sum()[df_articles.isnull().sum() != 0].sort_values(ascending = False)\n",
    "\n",
    "# Caculate the percantage\n",
    "percent = pd.Series(round(total/len(df_articles)*100,2))\n",
    "\n",
    "# Generate a new dataframe for 'total_missing'and'percent'\n",
    "pd.concat([total, percent], axis=1, keys=['total_missing', 'percent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are too many missing values in these columns: 'userRegion','userCountry','userAgent','authorCountry','authorRegion','authorUserAgent' So we cannot build recommendation system or perform data analysis based on those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows except last occurrence based on all columns are :\n",
      "       timestamp        eventType            contentId       authorPersonId  \\\n",
      "1     1459193988   CONTENT SHARED -4110354420726924665  4340306774493623681   \n",
      "59    1459345029  CONTENT REMOVED  7973573994178035769 -8845298781299428018   \n",
      "84    1459367793  CONTENT REMOVED -7356135999773525293 -1443636648652872475   \n",
      "86    1459367885   CONTENT SHARED  7420742904084384944 -1443636648652872475   \n",
      "87    1459367903  CONTENT REMOVED  7420742904084384944 -1443636648652872475   \n",
      "88    1459368454   CONTENT SHARED  8219310215587599928 -1443636648652872475   \n",
      "89    1459368501   CONTENT SHARED  7748594134538052724 -1443636648652872475   \n",
      "90    1459368576  CONTENT REMOVED  8219310215587599928 -1443636648652872475   \n",
      "210   1459867906  CONTENT REMOVED -6499865726739947794  6003902177042843076   \n",
      "225   1459911539  CONTENT REMOVED -1287202638861144684  1748162647671155552   \n",
      "256   1460035676  CONTENT REMOVED  2293315701090958124  6003902177042843076   \n",
      "307   1460146906  CONTENT REMOVED  6206342468637502921 -1130272294246983140   \n",
      "338   1460459103  CONTENT REMOVED  8160885002406274828   301435144665447655   \n",
      "339   1460459183   CONTENT SHARED -4248528062574538011   301435144665447655   \n",
      "340   1460459213  CONTENT REMOVED -4248528062574538011   301435144665447655   \n",
      "341   1460459237   CONTENT SHARED -3265730906936163775   301435144665447655   \n",
      "342   1460459251  CONTENT REMOVED -3265730906936163775   301435144665447655   \n",
      "348   1460463472   CONTENT SHARED  2824996248683640175 -1387464358334758758   \n",
      "349   1460463527  CONTENT REMOVED  2824996248683640175 -1387464358334758758   \n",
      "381   1460556291  CONTENT REMOVED -8099709040471107382  6003902177042843076   \n",
      "382   1460556333   CONTENT SHARED -1861959619649725543  6003902177042843076   \n",
      "383   1460556380  CONTENT REMOVED -1861959619649725543  6003902177042843076   \n",
      "392   1460568932   CONTENT SHARED -5623496706605874646 -1443636648652872475   \n",
      "402   1460581739   CONTENT SHARED -9153494109165200346  1623838599684589103   \n",
      "403   1460581811  CONTENT REMOVED -9153494109165200346  1623838599684589103   \n",
      "451   1460854706   CONTENT SHARED  5379671084978512851 -8020832670974472349   \n",
      "502   1461172415  CONTENT REMOVED  -389749390447363927 -2623844842607044962   \n",
      "503   1461172599   CONTENT SHARED -2220859822082318562 -2623844842607044962   \n",
      "504   1461172640  CONTENT REMOVED -2220859822082318562 -2623844842607044962   \n",
      "540   1461339090  CONTENT REMOVED   756136904399885845 -2979881261169775358   \n",
      "...          ...              ...                  ...                  ...   \n",
      "1644  1467661682  CONTENT REMOVED   476793294516827044  3217014177234377440   \n",
      "1709  1468001538  CONTENT REMOVED -2377881752614744441  6756039155228175109   \n",
      "1728  1468253803  CONTENT REMOVED -1383778823073811714 -1616903969205976623   \n",
      "1732  1468259766  CONTENT REMOVED  3884256359744615997  3302556033962996625   \n",
      "1812  1468861912  CONTENT REMOVED  4106497696154898573   881856221521045800   \n",
      "1854  1469220488  CONTENT REMOVED  8381798621267347902 -1443636648652872475   \n",
      "1909  1469718901  CONTENT REMOVED  7251252752220327534 -1032019229384696495   \n",
      "1910  1469719009   CONTENT SHARED  1881534532776527237 -1032019229384696495   \n",
      "2159  1471966791  CONTENT REMOVED -5808672937983623398  -709287718034731589   \n",
      "2273  1473193058  CONTENT REMOVED -8083832514395551465 -4432034906943587380   \n",
      "2347  1473947220  CONTENT REMOVED  7944907848226041964 -4125205337625989832   \n",
      "2365  1474051439  CONTENT REMOVED  6690761795935927461 -2525380383541287600   \n",
      "2430  1474914836  CONTENT REMOVED  7216750853471801538 -1387464358334758758   \n",
      "2431  1474915111   CONTENT SHARED  7993526700719577624  6013226412048763966   \n",
      "2432  1474915293   CONTENT SHARED -6400214860728938634  3061273947166110301   \n",
      "2518  1475711742   CONTENT SHARED  2628816849077589497  -709287718034731589   \n",
      "2541  1476122071  CONTENT REMOVED  8416004328454490172 -3643155458357242906   \n",
      "2599  1476918123  CONTENT REMOVED  2847365042071859088  -709287718034731589   \n",
      "2664  1477572285  CONTENT REMOVED   393734797767236089 -1251984896177895077   \n",
      "2665  1477572325   CONTENT SHARED -5011709367955107239 -1251984896177895077   \n",
      "2726  1478641173  CONTENT REMOVED  3399073250354435892  3891637997717104548   \n",
      "2743  1479139626   CONTENT SHARED -3269885695260066314 -1032019229384696495   \n",
      "2769  1479755385  CONTENT REMOVED   319340024738595907  4670267857749552625   \n",
      "2824  1480942004  CONTENT REMOVED  4169374063813159761  2612012348742830907   \n",
      "2874  1481740935  CONTENT REMOVED  8289800212949675494 -8241940599580729220   \n",
      "2942  1484047628  CONTENT REMOVED -5924653357616257702 -4246040813531967142   \n",
      "3008  1485342148  CONTENT REMOVED -7358932766266901263 -8420584158427265596   \n",
      "3009  1485343379   CONTENT SHARED  8550670510357310628 -8420584158427265596   \n",
      "3029  1485770365  CONTENT REMOVED -1138633255366005559 -1863544689523892600   \n",
      "3080  1486984711   CONTENT SHARED -5521549171704079872   301435144665447655   \n",
      "\n",
      "          authorSessionId                                    authorUserAgent  \\\n",
      "1     8940341205206233829                                                NaN   \n",
      "59    3760091107461406486                                                NaN   \n",
      "84    8209530310193218854                                                NaN   \n",
      "86    8209530310193218854                                                NaN   \n",
      "87    8209530310193218854                                                NaN   \n",
      "88    8209530310193218854                                                NaN   \n",
      "89    8209530310193218854                                                NaN   \n",
      "90    8209530310193218854                                                NaN   \n",
      "210   9221043291398421991                                                NaN   \n",
      "225   5860684579527063696                                                NaN   \n",
      "256  -6427127689908138982                                                NaN   \n",
      "307   4579064824853185436                                                NaN   \n",
      "338   7646585100439130925                                                NaN   \n",
      "339   7646585100439130925                                                NaN   \n",
      "340   7646585100439130925                                                NaN   \n",
      "341   7646585100439130925                                                NaN   \n",
      "342   7646585100439130925                                                NaN   \n",
      "348  -3500672065853643491                                                NaN   \n",
      "349  -3500672065853643491                                                NaN   \n",
      "381   8652994095219541250                                                NaN   \n",
      "382   8652994095219541250                                                NaN   \n",
      "383   8652994095219541250                                                NaN   \n",
      "392  -7298018010644449122                                                NaN   \n",
      "402   3184417696659051582                                                NaN   \n",
      "403   3184417696659051582                                                NaN   \n",
      "451   1759315806103391579                                                NaN   \n",
      "502   6736993170665424602                                                NaN   \n",
      "503   6736993170665424602                                                NaN   \n",
      "504   6736993170665424602                                                NaN   \n",
      "540   4821077593310495111                                                NaN   \n",
      "...                   ...                                                ...   \n",
      "1644  2216758203252531925                                                NaN   \n",
      "1709  4392480411901977476                                                NaN   \n",
      "1728 -2163621331757589863                                                NaN   \n",
      "1732  -319088867141743450                                                NaN   \n",
      "1812  7372165047535325487                                                NaN   \n",
      "1854   -65776639285603350                                                NaN   \n",
      "1909  3028199142413699225                                                NaN   \n",
      "1910  3028199142413699225                                                NaN   \n",
      "2159 -8543976727396364315                                                NaN   \n",
      "2273  8771323526822715521                                                NaN   \n",
      "2347 -5379253344898921073                                                NaN   \n",
      "2365 -7246022575664973897                                                NaN   \n",
      "2430 -6409893296920806478                                                NaN   \n",
      "2431  7761905460736875088                                                NaN   \n",
      "2432 -4294318496550281618                                                NaN   \n",
      "2518  5564172872603234737  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1...   \n",
      "2541 -1287220341060068950  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6...   \n",
      "2599 -1719288689557472072  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12) ...   \n",
      "2664 -3411758262273298934  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
      "2665 -3411758262273298934  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
      "2726  1794946588429108409  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
      "2743 -1387563534728594608  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1...   \n",
      "2769  8003062051417116987  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1...   \n",
      "2824 -2359713986954060163  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
      "2874 -4005961876543065182  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
      "2942 -4748637958812360523  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
      "3008 -1843663387254811608  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
      "3009 -1843663387254811608  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
      "3029  9182686286942272997  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
      "3080 -1273834070737970588  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3...   \n",
      "\n",
      "     authorRegion authorCountry contentType  \\\n",
      "1             NaN           NaN        HTML   \n",
      "59            NaN           NaN        HTML   \n",
      "84            NaN           NaN        HTML   \n",
      "86            NaN           NaN        HTML   \n",
      "87            NaN           NaN        HTML   \n",
      "88            NaN           NaN        HTML   \n",
      "89            NaN           NaN        HTML   \n",
      "90            NaN           NaN        HTML   \n",
      "210           NaN           NaN        HTML   \n",
      "225           NaN           NaN        HTML   \n",
      "256           NaN           NaN        HTML   \n",
      "307           NaN           NaN        HTML   \n",
      "338           NaN           NaN        HTML   \n",
      "339           NaN           NaN        HTML   \n",
      "340           NaN           NaN        HTML   \n",
      "341           NaN           NaN        HTML   \n",
      "342           NaN           NaN        HTML   \n",
      "348           NaN           NaN        HTML   \n",
      "349           NaN           NaN        HTML   \n",
      "381           NaN           NaN        HTML   \n",
      "382           NaN           NaN        HTML   \n",
      "383           NaN           NaN        HTML   \n",
      "392           NaN           NaN        HTML   \n",
      "402           NaN           NaN        HTML   \n",
      "403           NaN           NaN        HTML   \n",
      "451           NaN           NaN       VIDEO   \n",
      "502           NaN           NaN        HTML   \n",
      "503           NaN           NaN        HTML   \n",
      "504           NaN           NaN        HTML   \n",
      "540           NaN           NaN        HTML   \n",
      "...           ...           ...         ...   \n",
      "1644          NaN           NaN        HTML   \n",
      "1709          NaN           NaN        HTML   \n",
      "1728          NaN           NaN        HTML   \n",
      "1732          NaN           NaN        HTML   \n",
      "1812          NaN           NaN        HTML   \n",
      "1854          NaN           NaN        HTML   \n",
      "1909          NaN           NaN        HTML   \n",
      "1910          NaN           NaN        HTML   \n",
      "2159          NaN           NaN        HTML   \n",
      "2273          NaN           NaN        HTML   \n",
      "2347          NaN           NaN        HTML   \n",
      "2365          NaN           NaN        HTML   \n",
      "2430          NaN           NaN        HTML   \n",
      "2431          NaN           NaN        HTML   \n",
      "2432          NaN           NaN        HTML   \n",
      "2518           SP            BR        HTML   \n",
      "2541           SP            BR        HTML   \n",
      "2599           SP            BR        HTML   \n",
      "2664           MG            BR        HTML   \n",
      "2665           MG            BR        HTML   \n",
      "2726           SP            BR        HTML   \n",
      "2743           NY            US        HTML   \n",
      "2769           SP            BR        HTML   \n",
      "2824           SP            BR        HTML   \n",
      "2874           MG            BR        HTML   \n",
      "2942           SP            BR        HTML   \n",
      "3008           SP            BR        HTML   \n",
      "3009           SP            BR        HTML   \n",
      "3029           SP            BR        HTML   \n",
      "3080           MG            BR        HTML   \n",
      "\n",
      "                                                    url  \\\n",
      "1     http://www.nytimes.com/2016/03/28/business/dea...   \n",
      "59    http://noticias.uol.com.br/politica/ultimas-no...   \n",
      "84    http://www.popsci.com/byzantine-science-deceiv...   \n",
      "86    http://www.popsci.com/byzantine-science-deceiv...   \n",
      "87    http://www.popsci.com/byzantine-science-deceiv...   \n",
      "88    http://www.popsci.com/byzantine-science-deceiv...   \n",
      "89    http://www.popsci.com/byzantine-science-deceiv...   \n",
      "90    http://www.popsci.com/byzantine-science-deceiv...   \n",
      "210   http://techcrunch.com/2016/04/04/microsofts-mo...   \n",
      "225   https://www.linkedin.com/pulse/eu-n%C3%A3o-pre...   \n",
      "256   http://techcrunch.com/2016/04/07/heres-the-fir...   \n",
      "307   http://www.avozdamarca.com.br/voz-da-marca2-de...   \n",
      "338   https://medium.com/quality-functions/preventin...   \n",
      "339   https://medium.com/quality-functions/preventin...   \n",
      "340   https://medium.com/quality-functions/preventin...   \n",
      "341   https://medium.com/quality-functions/preventin...   \n",
      "342   https://medium.com/quality-functions/preventin...   \n",
      "348   https://medium.com/quality-functions/preventin...   \n",
      "349   https://medium.com/quality-functions/preventin...   \n",
      "381   http://vidaeestilo.terra.com.br/horoscopo/esot...   \n",
      "382   http://vidaeestilo.terra.com.br/horoscopo/esot...   \n",
      "383   http://vidaeestilo.terra.com.br/horoscopo/esot...   \n",
      "392   http://www.theverge.com/2016/4/12/11416472/fac...   \n",
      "402   http://android-developers.blogspot.com/2016/04...   \n",
      "403   http://android-developers.blogspot.com/2016/04...   \n",
      "451   http://www.ted.com/talks/linus_torvalds_the_mi...   \n",
      "502    http://blogdoiphone.com/2016/04/conceito-ios-10/   \n",
      "503    http://blogdoiphone.com/2016/04/conceito-ios-10/   \n",
      "504    http://blogdoiphone.com/2016/04/conceito-ios-10/   \n",
      "540   http://www.kurzweilai.net/you-can-now-be-ident...   \n",
      "...                                                 ...   \n",
      "1644  https://player.fm/series/canaltech-podcast/vis...   \n",
      "1709  https://www.atlassian.com/time-wasting-at-work...   \n",
      "1728  http://exame.abril.com.br/tecnologia/noticias/...   \n",
      "1732  http://www.htmlgoodies.com/tutorials/tables/ar...   \n",
      "1812  https://www.udacity.com/course/learn-swift-pro...   \n",
      "1854  https://www.linkedin.com/pulse/approaching-alm...   \n",
      "1909  http://thecooperreview.com/non-threatening-lea...   \n",
      "1910  http://thecooperreview.com/non-threatening-lea...   \n",
      "2159  http://blog.invisionapp.com/how-netflix-does-a...   \n",
      "2273  http://gitgraphjs.com/examples/gitflowsupport....   \n",
      "2347  http://g1.globo.com/rio-de-janeiro/paralimpiad...   \n",
      "2365                 http://www.matera.com/br/webinars/   \n",
      "2430  https://hbr.org/2016/09/what-science-tells-us-...   \n",
      "2431  https://hbr.org/2016/09/what-science-tells-us-...   \n",
      "2432  https://www.oreilly.com/learning/how-to-build-...   \n",
      "2518  http://www.cultofmac.com/447947/today-apple-hi...   \n",
      "2541  https://realm.io/news/real-world-swift-perform...   \n",
      "2599  http://www.cultofmac.com/449972/ibm-now-uses-m...   \n",
      "2664  http://jcrs.uol.com.br/_conteudo/2016/10/econo...   \n",
      "2665  http://jcrs.uol.com.br/_conteudo/2016/10/econo...   \n",
      "2726  http://lightning.acquia.com/blog/introducing-w...   \n",
      "2743  https://hbr.org/2016/11/the-competitive-landsc...   \n",
      "2769  http://www.webmotors.com.br/comprar/mitsubishi...   \n",
      "2824  http://noticias.uol.com.br/politica/ultimas-no...   \n",
      "2874  http://making.duolingo.com/which-countries-stu...   \n",
      "2942  http://exame.abril.com.br/tecnologia/robo-da-i...   \n",
      "3008  http://www.coindesk.com/three-smart-contract-m...   \n",
      "3009  http://www.coindesk.com/three-smart-contract-m...   \n",
      "3029  http://thinkolga.com/2015/02/02/kaol-porfirio-...   \n",
      "3080  https://blog.google/products/g-suite/introduci...   \n",
      "\n",
      "                                                  title  \\\n",
      "1     Ethereum, a Virtual Currency, Enables Transact...   \n",
      "59    Governo Dilma é desaprovado por 69% e aprovado...   \n",
      "84                                  Fooling The Machine   \n",
      "86                                  Fooling The Machine   \n",
      "87                                  Fooling The Machine   \n",
      "88                                  Fooling The Machine   \n",
      "89                                  Fooling The Machine   \n",
      "90                                  Fooling The Machine   \n",
      "210   Microsoft's mobile problem may not be a proble...   \n",
      "225   Eu não preciso de Unicórnios, preciso de Malam...   \n",
      "256   Here's the first full trailer for the next Sta...   \n",
      "307   Como contar histórias para marcas - Podcast A ...   \n",
      "338   Preventing Software Bugs from Ever Occurring -...   \n",
      "339   Preventing Software Bugs from Ever Occurring -...   \n",
      "340   Preventing Software Bugs from Ever Occurring -...   \n",
      "341   Preventing Software Bugs from Ever Occurring -...   \n",
      "342   Preventing Software Bugs from Ever Occurring -...   \n",
      "348   Preventing Software Bugs from Ever Occurring -...   \n",
      "349   Preventing Software Bugs from Ever Occurring -...   \n",
      "381    Vidente reflete sobre os desafios contemporâneos   \n",
      "382    Vidente reflete sobre os desafios contemporâneos   \n",
      "383    Vidente reflete sobre os desafios contemporâneos   \n",
      "392   Facebook's new Messenger bots are the slowest ...   \n",
      "402   Android N Developer Preview 2, out today! | An...   \n",
      "403   Android N Developer Preview 2, out today! | An...   \n",
      "451               Linus Torvalds: The mind behind Linux   \n",
      "502   Conceito mostra ideias que adoraríamos ver no ...   \n",
      "503   Conceito mostra ideias que adoraríamos ver no ...   \n",
      "504   Conceito mostra ideias que adoraríamos ver no ...   \n",
      "540   You can now be identified by your 'brainprint'...   \n",
      "...                                                 ...   \n",
      "1644  [Podcast] Visa: de olho no futuro do mercado f...   \n",
      "1709            Certeza que devemos marcar uma reunião?   \n",
      "1728  Swatch lança relógio para pagamentos em parcer...   \n",
      "1732                         So, You Want A Table, Huh?   \n",
      "1812           Learn Swift Programming Syntax | Udacity   \n",
      "1854  Approaching (Almost) Any Machine Learning Problem   \n",
      "1909  9 Non-Threatening Leadership Strategies for Women   \n",
      "1910  9 Non-Threatening Leadership Strategies for Women   \n",
      "2159       How Netflix does A/B testing - InVision Blog   \n",
      "2273                              git flow with support   \n",
      "2347  Cego é destaque entre os fotógrafos que regist...   \n",
      "2365                          Webinars | MATERA Systems   \n",
      "2430   What Science Tells Us About Leadership Potential   \n",
      "2431   What Science Tells Us About Leadership Potential   \n",
      "2432  How to build a robot that \"sees\" with $100 and...   \n",
      "2518  Today in Apple history: Steve Jobs passes away...   \n",
      "2541                       Real World Swift Performance   \n",
      "2599  IBM now uses more Macs than any other company ...   \n",
      "2664  Vale reverte prejuízo e tem lucro de R$ 1,8 bi...   \n",
      "2665  Vale reverte prejuízo e tem lucro de R$ 1,8 bi...   \n",
      "2726  Introducing the Workspace Preview System | Acq...   \n",
      "2743  The Competitive Landscape for Machine Intellig...   \n",
      "2769  MITSUBISHI ASX 2.0 4X4 AWD 16V GASOLINA 4P AUT...   \n",
      "2824  Brasil gasta R$ 16,4 mi ao ano com aposentador...   \n",
      "2874  Which countries study which languages, and wha...   \n",
      "2942  Robô da IBM substitui 34 funcionários de empre...   \n",
      "3008  Why Many Smart Contract Use Cases Are Simply I...   \n",
      "3009  Why Many Smart Contract Use Cases Are Simply I...   \n",
      "3029   Kaol Porfírio luta como uma garota! - Think Olga   \n",
      "3080  Introducing Google Cloud Search: Bringing the ...   \n",
      "\n",
      "                                                   text lang  \n",
      "1     All of this work is still very early. The firs...   en  \n",
      "59    Pesquisa Ibope encomendada pela Confederação N...   pt  \n",
      "84    Two groups, one at Berkeley University and ano...   en  \n",
      "86    Two groups, one at Berkeley University and ano...   en  \n",
      "87    Two groups, one at Berkeley University and ano...   en  \n",
      "88    Two groups, one at Berkeley University and ano...   en  \n",
      "89    Two groups, one at Berkeley University and ano...   en  \n",
      "90    Two groups, one at Berkeley University and ano...   en  \n",
      "210   When Microsoft announced its Windows 10 strate...   en  \n",
      "225   ... afinal, Unicórnios não existem, não é mesm...   pt  \n",
      "256   Hey. You. On the computer. You heard about thi...   en  \n",
      "307   Veja como é simples contratar conteúdo de qual...   pt  \n",
      "338   Bug Type 3: Missing Specifications Description...   en  \n",
      "339   Bug Type 3: Missing Specifications Description...   en  \n",
      "340   Bug Type 3: Missing Specifications Description...   en  \n",
      "341   Bug Type 3: Missing Specifications Description...   en  \n",
      "342   Bug Type 3: Missing Specifications Description...   en  \n",
      "348   Bug Type 3: Missing Specifications Description...   en  \n",
      "349   Bug Type 3: Missing Specifications Description...   en  \n",
      "381   Como vidente, aprendo todo dia a separar os do...   pt  \n",
      "382   Como vidente, aprendo todo dia a separar os do...   pt  \n",
      "383   Como vidente, aprendo todo dia a separar os do...   pt  \n",
      "392   Today, Facebook announced a bold new bot initi...   en  \n",
      "402   Posted by Dave Burke, VP of Engineering Last m...   en  \n",
      "403   Posted by Dave Burke, VP of Engineering Last m...   en  \n",
      "451   Linus Torvalds transformed technology twice --...   en  \n",
      "502   O iOS 10 já tem data para ser apresentado: dia...   pt  \n",
      "503   O iOS 10 já tem data para ser apresentado: dia...   pt  \n",
      "504   O iOS 10 já tem data para ser apresentado: dia...   pt  \n",
      "540   Binghamton University researchers have develop...   en  \n",
      "...                                                 ...  ...  \n",
      "1644  Welcome to Player FM What if radio played only...   en  \n",
      "1709  Just because you're at work doesn't mean you'r...   en  \n",
      "1728  São Paulo - A Swatch e a Visa se uniram para l...   pt  \n",
      "1732  Use these links to jump around or read it all....   en  \n",
      "1812  Lesson 1: Swift Basics In this lesson, you'll ...   en  \n",
      "1854  An average data scientist deals with loads of ...   en  \n",
      "1909  In this fast-paced business world, female lead...   en  \n",
      "1910  In this fast-paced business world, female lead...   en  \n",
      "2159  A couple of weeks ago, I attended a Designers ...   en  \n",
      "2273  Lorem ipsum dolor sit amet, consectetur adipis...   la  \n",
      "2347  Em meio à aglomeração de fotógrafos que fazem ...   pt  \n",
      "2365  APRENDENDO NA PRÁTICA COM TESTING DOJO Data : ...   pt  \n",
      "2430  Although the scientific study of leadership is...   en  \n",
      "2431  Although the scientific study of leadership is...   en  \n",
      "2432  Eye of Providence. (source: Bureau of Engravin...   en  \n",
      "2518  A portrait of Steve created by artist Jeremy M...   en  \n",
      "2541  Lots of things can make your application slow....   en  \n",
      "2599  IBM is on track to deploy 100,000 Macs by earl...   en  \n",
      "2664  Investimentos da mineradora no período caíram ...   pt  \n",
      "2665  Investimentos da mineradora no período caíram ...   pt  \n",
      "2726  It's here! The Workspace Preview System (WPS) ...   en  \n",
      "2743  Three years ago, our venture capital firm bega...   en  \n",
      "2769  Opcionais Airbag, Alarme, Ar condicionado, Ar ...   pt  \n",
      "2824  iStock Uso do cargo para beneficiar loja maçôn...   pt  \n",
      "2874  To find out which languages are the most popul...   en  \n",
      "2942  São Paulo - O Watson, que a empresa define com...   pt  \n",
      "3008  Dr Gideon Greenspan is the founder and CEO of ...   en  \n",
      "3009  Dr Gideon Greenspan is the founder and CEO of ...   en  \n",
      "3029  Entrevistas Kaol Porfírio luta como uma garota...   pt  \n",
      "3080  Every day, people around the globe rely on the...   en  \n",
      "\n",
      "[96 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# checking duplicates\n",
    "\n",
    "duplicateRowsDF = df_articles[df_articles.duplicated(['title','text'])]\n",
    "print(\"Duplicate Rows except last occurrence based on all columns are :\")\n",
    "print(duplicateRowsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>authorPersonId</th>\n",
       "      <th>authorSessionId</th>\n",
       "      <th>authorUserAgent</th>\n",
       "      <th>authorRegion</th>\n",
       "      <th>authorCountry</th>\n",
       "      <th>contentType</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1459193988</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-4110354420726924665</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.nytimes.com/2016/03/28/business/dea...</td>\n",
       "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
       "      <td>All of this work is still very early. The firs...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1459194146</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-7292285110016212249</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://cointelegraph.com/news/bitcoin-future-w...</td>\n",
       "      <td>Bitcoin Future: When GBPcoin of Branson Wins O...</td>\n",
       "      <td>The alarm clock wakes me at 8:00 with stream o...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1459194474</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-6151852268067518688</td>\n",
       "      <td>3891637997717104548</td>\n",
       "      <td>-1457532940883382585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://cloudplatform.googleblog.com/2016/03/G...</td>\n",
       "      <td>Google Data Center 360° Tour</td>\n",
       "      <td>We're excited to share the Google Data Center ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1459194497</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>2448026894306402386</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://bitcoinmagazine.com/articles/ibm-wants...</td>\n",
       "      <td>IBM Wants to \"Evolve the Internet\" With Blockc...</td>\n",
       "      <td>The Aite Group projects the blockchain market ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1459194522</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-2826566343807132236</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.coindesk.com/ieee-blockchain-oxford...</td>\n",
       "      <td>IEEE to Talk Blockchain at Cloud Computing Oxf...</td>\n",
       "      <td>One of the largest and oldest organizations fo...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1459194557</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-2148899391355011268</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.newsbtc.com/2016/03/28/banks-need-c...</td>\n",
       "      <td>Banks Need To Collaborate With Bitcoin and Fin...</td>\n",
       "      <td>It will take time until banks come around to t...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1459194599</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>4119190424078847945</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://bitcoinmagazine.com/articles/blockchai...</td>\n",
       "      <td>Blockchain Technology Could Put Bank Auditors ...</td>\n",
       "      <td>When most people think about computers and rob...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1459194751</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-7926018713416777892</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://news.bitcoin.com/conglomerates-intervi...</td>\n",
       "      <td>Why Decentralized Conglomerates Will Scale Bet...</td>\n",
       "      <td>Bitcoin.com spoke with the OpenLedger CEO, Ron...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1459194842</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>3353902017498793780</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>8940341205206233829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://www.cryptocoinsnews.com/ethereum-rise-...</td>\n",
       "      <td>The Rise And Growth of Ethereum Gets Mainstrea...</td>\n",
       "      <td>Ethereum, considered by many to be the most pr...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1459210504</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-9157338616628196758</td>\n",
       "      <td>5206835909720479405</td>\n",
       "      <td>-7864441319395545950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://economia.ig.com.br/2016-03-27/situacao-...</td>\n",
       "      <td>Situação financeira ruim de varejistas pressio...</td>\n",
       "      <td>A queda nas vendas e a deterioração na situaçã...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1459217624</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>1805789466376069146</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3042342415047984532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://cloud.google.com/compute/docs/load-bal...</td>\n",
       "      <td>Setting Up HTTP(S) Load Balancing</td>\n",
       "      <td>HTTP(S) load balancing provides global load ba...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1459217735</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-2081760549863309770</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3042342415047984532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://cloud.google.com/compute/docs/load-bal...</td>\n",
       "      <td>Setting Up SSL proxy for Google Cloud Load Bal...</td>\n",
       "      <td>Alpha This is an Alpha release of Setting Up S...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1459217994</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-5170198873410718233</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3042342415047984532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://techcrunch.com/2016/03/28/ntt-to-buy-de...</td>\n",
       "      <td>NTT to buy Dell's services division for $3.05 ...</td>\n",
       "      <td>You may know Dell as a computer and server mak...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1459229160</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-3367778232969996503</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3042342415047984532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.salon.com/2016/03/27/good_riddance_...</td>\n",
       "      <td>Good riddance, gig economy: Uber, Ayn Rand and...</td>\n",
       "      <td>The Uber model just doesn't work for other ind...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1459248284</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>4988225165850707692</td>\n",
       "      <td>4670267857749552625</td>\n",
       "      <td>-265833983523746108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://cio.economictimes.indiatimes.com/news/i...</td>\n",
       "      <td>The internet of a billion things | ET CIO</td>\n",
       "      <td>Industrial adoption of IoT dubbed as Industria...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1459248366</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-5917314377186856799</td>\n",
       "      <td>4670267857749552625</td>\n",
       "      <td>-265833983523746108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.senar.org.br/agricultura-precisao/a...</td>\n",
       "      <td>Artigos e Palestras - Programa Agricultura de ...</td>\n",
       "      <td>Artigos e Palestras ARTIGOS / 2015 12/08/2015 ...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1459248432</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>6157037646878010131</td>\n",
       "      <td>4670267857749552625</td>\n",
       "      <td>-265833983523746108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://www.macroprograma1.cnptia.embrapa.br/r...</td>\n",
       "      <td>Rede Agricultura de Precisão II</td>\n",
       "      <td>Do Se Te Qu Qu Se Sa 27 28 29 30 31 Faça downl...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1459251677</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>6023609667389715259</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>-7292854281461484137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://blog.coinfund.io/five-bitcoin-and-ethe...</td>\n",
       "      <td>Five Bitcoin and Ethereum Based Projects to Wa...</td>\n",
       "      <td>Five Bitcoin and Ethereum Based Projects to Wa...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1459251714</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>7905485530310717815</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>-7292854281461484137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.coindesk.com/blockchain-smart-contr...</td>\n",
       "      <td>Blockchain Smart Contracts Startup Selected By...</td>\n",
       "      <td>CommonAccord, a blockchain-based startup for l...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1459251799</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>8194079557551008273</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>-7292854281461484137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://bitcoinist.net/using-gamified-hacking-c...</td>\n",
       "      <td>Using Gamified Hacking Challenges To Attract N...</td>\n",
       "      <td>The blockchain ecosystem is always in need of ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1459251851</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-1672166631728511207</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>-7292854281461484137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://www.coinbr.net/blog/america-latina-apr...</td>\n",
       "      <td>O potencial do bitcoin na América Latina</td>\n",
       "      <td>28/03/2016 | por Safiri Felix | em Economia As...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1459251889</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-4374331682165863764</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>-7292854281461484137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.bbc.com/news/business-35890616</td>\n",
       "      <td>From fine wine to lotteries: Blockchain tech t...</td>\n",
       "      <td>Imagine a world where you can vote in an elect...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1459257477</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>5714314286511882372</td>\n",
       "      <td>1895326251577378793</td>\n",
       "      <td>6290959012079283980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://www.sympla.com.br/como-startups-e-gran...</td>\n",
       "      <td>Como Startups e Grandes Empresas podem colabor...</td>\n",
       "      <td>Muito tem se falado sobre como grandes empresa...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1459257584</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-8141818108252244664</td>\n",
       "      <td>1895326251577378793</td>\n",
       "      <td>6290959012079283980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://www.sympla.com.br/pimp-my-pitch-como-f...</td>\n",
       "      <td>Pimp My Pitch: como fazer um Pitch poderoso</td>\n",
       "      <td>Descrição do evento Qual horário? 14h00min às ...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1459257924</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-8939172344092554931</td>\n",
       "      <td>-1443636648652872475</td>\n",
       "      <td>-9071650721576979280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://kotaku.com/google-deepmind-is-now-analy...</td>\n",
       "      <td>Google DeepMind Is Now Analysing Magic And Hea...</td>\n",
       "      <td>With retro games and Go well-conquered , where...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1459258094</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-1591454024897803197</td>\n",
       "      <td>-8606085472606356565</td>\n",
       "      <td>7660662789565329118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://recruitingdaily.com/how-okcupid-changed...</td>\n",
       "      <td>How OKCupid Changed Hiring Forever.</td>\n",
       "      <td>Twenty years ago, if you wanted to find a spec...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1459259981</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-6874540813378776198</td>\n",
       "      <td>-108842214936804958</td>\n",
       "      <td>770918631519434453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://medium.com/greylock-perspectives/the-h...</td>\n",
       "      <td>The Hierarchy of Engagement - Greylock Perspec...</td>\n",
       "      <td>The Hierarchy of Engagement The Fuel to Build ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1459268727</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-3173020603774823976</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3042342415047984532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://nodejs.org/en/blog/announcements/welco...</td>\n",
       "      <td>Welcome Google Cloud Platform!</td>\n",
       "      <td>Google Cloud Platform joined the Node.js Found...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1459268965</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-9107331682787867601</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3042342415047984532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://techcrunch.com/2016/03/29/hopper-raises...</td>\n",
       "      <td>Hopper raises $16 million for a travel app tha...</td>\n",
       "      <td>Hopper , the makers of a handy travel applicat...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1459269196</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-1021685224930603833</td>\n",
       "      <td>4670267857749552625</td>\n",
       "      <td>-265833983523746108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.telequest.com.br/portal/index.php/o...</td>\n",
       "      <td>Indústria 4.0: desafios e oportunidades</td>\n",
       "      <td>*Igor Schiewig 25/03/2016 - A Indústria 4.0 é ...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>1487154848</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>8729086959762650511</td>\n",
       "      <td>7645894863578715801</td>\n",
       "      <td>7395860765143290921</td>\n",
       "      <td>Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:51....</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://martinfowler.com/articles/201701-event...</td>\n",
       "      <td>What do you mean by \"Event-Driven\"?</td>\n",
       "      <td>Towards the end of last year I attended a work...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>1487157951</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-6623581327558800021</td>\n",
       "      <td>599868086167624974</td>\n",
       "      <td>-6471874325422590486</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://www.wired.com/2017/02/spanner-google-d...</td>\n",
       "      <td>Spanner, the Google Database That Mastered Tim...</td>\n",
       "      <td>About a decade ago, a handful of Google's most...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>1487178123</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-5845411843260276924</td>\n",
       "      <td>5660542693104786364</td>\n",
       "      <td>7452795821770584842</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://www.uk.capgemini-consulting.com/blog/r...</td>\n",
       "      <td>Lean and banking: the pot of gold waiting to b...</td>\n",
       "      <td>Banks are identifying areas for efficiency gai...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>1487184049</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-8473322535064919980</td>\n",
       "      <td>-8845298781299428018</td>\n",
       "      <td>3264443726869427854</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://techcrunch.com/2017/02/15/ibms-bringin...</td>\n",
       "      <td>IBM wants to bring machine learning to the mai...</td>\n",
       "      <td>IBM wants to bring machine learning to its tra...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>1487246811</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-4029704725707465084</td>\n",
       "      <td>6013226412048763966</td>\n",
       "      <td>-6569695881431984742</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.cnbc.com/2016/12/21/former-google-c...</td>\n",
       "      <td>Former Google career coach shares a visual tri...</td>\n",
       "      <td>If you want 2017 to be an exciting year, desig...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>1487257346</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-8627051188605351707</td>\n",
       "      <td>-4465926797008424436</td>\n",
       "      <td>-5996702544087841012</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://dev.to/gonedark/when-to-make-a-git-commit</td>\n",
       "      <td>When to make a Git Commit</td>\n",
       "      <td>You don't have to look through too many commit...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>1487263968</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>3618205920179577598</td>\n",
       "      <td>5660542693104786364</td>\n",
       "      <td>-7424898710963348430</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://cantarinobrasileiro.com.br/blog/aplicat...</td>\n",
       "      <td>Aplicativo Celcoin oferece a possibilidade de ...</td>\n",
       "      <td>O CEO e fundador do Celcoin, Marcelo França, e...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>1487339269</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>6831941111848480366</td>\n",
       "      <td>5660542693104786364</td>\n",
       "      <td>-4042309088759228835</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.bankingtech.com/735552/amazon-looki...</td>\n",
       "      <td>Amazon looking to buy Capital One? \" Banking T...</td>\n",
       "      <td>Amazon is rumoured to be pondering the acquisi...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>1487342224</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>6244532954645766056</td>\n",
       "      <td>5660542693104786364</td>\n",
       "      <td>-4042309088759228835</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.coindesk.com/3-big-blockchain-ideas...</td>\n",
       "      <td>3 Big Blockchain Ideas MIT is Working on Right...</td>\n",
       "      <td>When one of the world's most prestigious unive...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>1487345705</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>2277184202014276839</td>\n",
       "      <td>-5706287032724665714</td>\n",
       "      <td>1536755170726159771</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://medium.freecodecamp.com/how-to-build-c...</td>\n",
       "      <td>How to build cross-platform mobile apps using ...</td>\n",
       "      <td>For the past few months, I've been working on ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>1487353335</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-5160830061297425098</td>\n",
       "      <td>-3203894957285229214</td>\n",
       "      <td>-6451643644744208210</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>ON</td>\n",
       "      <td>CA</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://aws.amazon.com/blogs/aws/amazon-ebs-up...</td>\n",
       "      <td>Amazon EBS Update - New Elastic Volumes Change...</td>\n",
       "      <td>It is always interesting to speak with our cus...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>1487596721</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>7021353262177009708</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>-2941135241517914970</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://startupi.com.br/2017/02/udacity-abre-c...</td>\n",
       "      <td>Udacity abre código de simulador de carro autô...</td>\n",
       "      <td>Várias empresas automotivas já estão desenvolv...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>1487597538</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-6872546942144599345</td>\n",
       "      <td>-1393866732742189886</td>\n",
       "      <td>-6350745898785551312</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://medium.com/@husayn.hakeem/my-experienc...</td>\n",
       "      <td>My experience with Google's Associate Android ...</td>\n",
       "      <td>In this article I talk about my personal exper...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>1487601781</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-5605799891597699962</td>\n",
       "      <td>-7410485589492665094</td>\n",
       "      <td>7463073430234613325</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://philippe.kruchten.com/2017/02/14/concr...</td>\n",
       "      <td>Concrete things you can do about your technica...</td>\n",
       "      <td>\"Technical debt, yes we have some of this, but...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>1487608017</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>7631327570702153011</td>\n",
       "      <td>3302556033962996625</td>\n",
       "      <td>2863165998245027705</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://medium.com/upday-devs/optimizing-the-p...</td>\n",
       "      <td>Optimizing the Performance of Vector Drawables...</td>\n",
       "      <td>While some mobile platforms have been supporti...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>1487608245</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-7264217791213422584</td>\n",
       "      <td>6013226412048763966</td>\n",
       "      <td>7817933231113759598</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://vocerh.uol.com.br/noticias/legislacao/q...</td>\n",
       "      <td>Qual é o valor da área de T&amp;D na sua empresa?</td>\n",
       "      <td>É fundamental que o departamento de Recursos H...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>1487608319</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-2402288292108892893</td>\n",
       "      <td>-4465926797008424436</td>\n",
       "      <td>-8412615285329455721</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://www.codeatest.com/como-testar-excecoes-...</td>\n",
       "      <td>Como testar exceções em Java com o JUnit - Cod...</td>\n",
       "      <td>Introdução Neste post vou mostrar de forma suc...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>1487616054</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-624901815223005993</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>-2941135241517914970</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://googlediscovery.com/2017/02/20/i-duet-...</td>\n",
       "      <td>A.I. Duet, crie melodias usando o aprendizado ...</td>\n",
       "      <td>O Google lançou o AI Duet , um novo experiment...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>1487681005</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-6340141548068597572</td>\n",
       "      <td>-1393866732742189886</td>\n",
       "      <td>7540353649241449090</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>http://insurancethoughtleadership.com/top-10-i...</td>\n",
       "      <td>Top 10 Insurtech Trends for 2017 - Insurance T...</td>\n",
       "      <td>Summary: This list isn't just about what is ne...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>1487692411</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-8591127493017117985</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>7126320888094993255</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://startupi.com.br/2017/02/ibm-e-visa-tra...</td>\n",
       "      <td>IBM e Visa transformam automóveis, eletrodomés...</td>\n",
       "      <td>A IBM e a Visa anunciaram a primeira colaboraç...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>1487777120</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-5953227649059336919</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>-1382987583323397219</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://www.matthewbarby.com/chatbot-marketing/</td>\n",
       "      <td>Life Beyond Email: Chatbot Marketing</td>\n",
       "      <td>Every marketing channel suffers from fatigue a...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>1487782326</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-3201623914150480647</td>\n",
       "      <td>-534549863526737439</td>\n",
       "      <td>-8470437783673120049</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://security.googleblog.com/2017/02/anothe...</td>\n",
       "      <td>Another option for file sharing</td>\n",
       "      <td>Existing mechanisms for file sharing are so fr...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>1487783149</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-4132331404553626868</td>\n",
       "      <td>9109075639526981934</td>\n",
       "      <td>9068765379852494896</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://www.gartner.com/doc/reprints?id=1-3TYE...</td>\n",
       "      <td>Gartner Reprint</td>\n",
       "      <td>Gartner redesigned the Magic Quadrant for BI a...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>1487860157</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>1908114740148100507</td>\n",
       "      <td>-1393866732742189886</td>\n",
       "      <td>-7684196451423283583</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://hackernoon.com/macbook-my-command-line...</td>\n",
       "      <td>Command-line utilities</td>\n",
       "      <td>Introduction I've talked previously about my i...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116</th>\n",
       "      <td>1487939756</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>4675505028897335428</td>\n",
       "      <td>-1393866732742189886</td>\n",
       "      <td>-1729556941184852519</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://medium.mybridge.co/swift-top-10-articl...</td>\n",
       "      <td>Swift Top 10 Articles For The Past Year (v.2017)</td>\n",
       "      <td>For the past year , we've ranked nearly 9,000 ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>1487946604</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>9213260650272029784</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>7144190892417579456</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://startupi.com.br/2017/02/liga-ventures-...</td>\n",
       "      <td>Conheça a Liga IoT, plataforma de inovação abe...</td>\n",
       "      <td>A Liga Ventures, aceleradora de startups espec...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118</th>\n",
       "      <td>1487947067</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>-3295913657316686039</td>\n",
       "      <td>6960073744377754728</td>\n",
       "      <td>-8193630595542572738</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3...</td>\n",
       "      <td>GA</td>\n",
       "      <td>US</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://thenextweb.com/apps/2017/02/14/amazon-...</td>\n",
       "      <td>Amazon takes on Skype and GoToMeeting with its...</td>\n",
       "      <td>Amazon has launched Chime, a video conferencin...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>1488223224</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>3618271604906293310</td>\n",
       "      <td>1908339160857512799</td>\n",
       "      <td>-183341653743161643</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://code.org/about/2016</td>\n",
       "      <td>Code.org 2016 Annual Report</td>\n",
       "      <td>February 9, 2017 - We begin each year with a l...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>1488300719</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>6607431762270322325</td>\n",
       "      <td>-1393866732742189886</td>\n",
       "      <td>2367029511384577082</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://www.bloomberg.com/news/articles/2017-0...</td>\n",
       "      <td>JPMorgan Software Does in Seconds What Took La...</td>\n",
       "      <td>At JPMorgan Chase &amp; Co., a learning machine is...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>1488307871</td>\n",
       "      <td>CONTENT SHARED</td>\n",
       "      <td>4109618890343020064</td>\n",
       "      <td>3891637997717104548</td>\n",
       "      <td>-7416795577834806518</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>HTML</td>\n",
       "      <td>https://www.acquia.com/blog/partner/2017-acqui...</td>\n",
       "      <td>The 2017 Acquia Partners of the Year</td>\n",
       "      <td>The Acquia Partner Awards Program is comprised...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3011 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp       eventType            contentId       authorPersonId  \\\n",
       "1     1459193988  CONTENT SHARED -4110354420726924665  4340306774493623681   \n",
       "2     1459194146  CONTENT SHARED -7292285110016212249  4340306774493623681   \n",
       "3     1459194474  CONTENT SHARED -6151852268067518688  3891637997717104548   \n",
       "4     1459194497  CONTENT SHARED  2448026894306402386  4340306774493623681   \n",
       "5     1459194522  CONTENT SHARED -2826566343807132236  4340306774493623681   \n",
       "6     1459194557  CONTENT SHARED -2148899391355011268  4340306774493623681   \n",
       "7     1459194599  CONTENT SHARED  4119190424078847945  4340306774493623681   \n",
       "8     1459194751  CONTENT SHARED -7926018713416777892  4340306774493623681   \n",
       "9     1459194842  CONTENT SHARED  3353902017498793780  4340306774493623681   \n",
       "10    1459210504  CONTENT SHARED -9157338616628196758  5206835909720479405   \n",
       "11    1459217624  CONTENT SHARED  1805789466376069146 -1032019229384696495   \n",
       "12    1459217735  CONTENT SHARED -2081760549863309770 -1032019229384696495   \n",
       "13    1459217994  CONTENT SHARED -5170198873410718233 -1032019229384696495   \n",
       "14    1459229160  CONTENT SHARED -3367778232969996503 -1032019229384696495   \n",
       "15    1459248284  CONTENT SHARED  4988225165850707692  4670267857749552625   \n",
       "16    1459248366  CONTENT SHARED -5917314377186856799  4670267857749552625   \n",
       "17    1459248432  CONTENT SHARED  6157037646878010131  4670267857749552625   \n",
       "18    1459251677  CONTENT SHARED  6023609667389715259  4340306774493623681   \n",
       "19    1459251714  CONTENT SHARED  7905485530310717815  4340306774493623681   \n",
       "20    1459251799  CONTENT SHARED  8194079557551008273  4340306774493623681   \n",
       "21    1459251851  CONTENT SHARED -1672166631728511207  4340306774493623681   \n",
       "22    1459251889  CONTENT SHARED -4374331682165863764  4340306774493623681   \n",
       "23    1459257477  CONTENT SHARED  5714314286511882372  1895326251577378793   \n",
       "24    1459257584  CONTENT SHARED -8141818108252244664  1895326251577378793   \n",
       "25    1459257924  CONTENT SHARED -8939172344092554931 -1443636648652872475   \n",
       "26    1459258094  CONTENT SHARED -1591454024897803197 -8606085472606356565   \n",
       "27    1459259981  CONTENT SHARED -6874540813378776198  -108842214936804958   \n",
       "28    1459268727  CONTENT SHARED -3173020603774823976 -1032019229384696495   \n",
       "29    1459268965  CONTENT SHARED -9107331682787867601 -1032019229384696495   \n",
       "30    1459269196  CONTENT SHARED -1021685224930603833  4670267857749552625   \n",
       "...          ...             ...                  ...                  ...   \n",
       "3092  1487154848  CONTENT SHARED  8729086959762650511  7645894863578715801   \n",
       "3093  1487157951  CONTENT SHARED -6623581327558800021   599868086167624974   \n",
       "3094  1487178123  CONTENT SHARED -5845411843260276924  5660542693104786364   \n",
       "3095  1487184049  CONTENT SHARED -8473322535064919980 -8845298781299428018   \n",
       "3096  1487246811  CONTENT SHARED -4029704725707465084  6013226412048763966   \n",
       "3097  1487257346  CONTENT SHARED -8627051188605351707 -4465926797008424436   \n",
       "3098  1487263968  CONTENT SHARED  3618205920179577598  5660542693104786364   \n",
       "3099  1487339269  CONTENT SHARED  6831941111848480366  5660542693104786364   \n",
       "3100  1487342224  CONTENT SHARED  6244532954645766056  5660542693104786364   \n",
       "3101  1487345705  CONTENT SHARED  2277184202014276839 -5706287032724665714   \n",
       "3102  1487353335  CONTENT SHARED -5160830061297425098 -3203894957285229214   \n",
       "3103  1487596721  CONTENT SHARED  7021353262177009708  3609194402293569455   \n",
       "3104  1487597538  CONTENT SHARED -6872546942144599345 -1393866732742189886   \n",
       "3105  1487601781  CONTENT SHARED -5605799891597699962 -7410485589492665094   \n",
       "3106  1487608017  CONTENT SHARED  7631327570702153011  3302556033962996625   \n",
       "3107  1487608245  CONTENT SHARED -7264217791213422584  6013226412048763966   \n",
       "3108  1487608319  CONTENT SHARED -2402288292108892893 -4465926797008424436   \n",
       "3109  1487616054  CONTENT SHARED  -624901815223005993  3609194402293569455   \n",
       "3110  1487681005  CONTENT SHARED -6340141548068597572 -1393866732742189886   \n",
       "3111  1487692411  CONTENT SHARED -8591127493017117985  3609194402293569455   \n",
       "3112  1487777120  CONTENT SHARED -5953227649059336919  3609194402293569455   \n",
       "3113  1487782326  CONTENT SHARED -3201623914150480647  -534549863526737439   \n",
       "3114  1487783149  CONTENT SHARED -4132331404553626868  9109075639526981934   \n",
       "3115  1487860157  CONTENT SHARED  1908114740148100507 -1393866732742189886   \n",
       "3116  1487939756  CONTENT SHARED  4675505028897335428 -1393866732742189886   \n",
       "3117  1487946604  CONTENT SHARED  9213260650272029784  3609194402293569455   \n",
       "3118  1487947067  CONTENT SHARED -3295913657316686039  6960073744377754728   \n",
       "3119  1488223224  CONTENT SHARED  3618271604906293310  1908339160857512799   \n",
       "3120  1488300719  CONTENT SHARED  6607431762270322325 -1393866732742189886   \n",
       "3121  1488307871  CONTENT SHARED  4109618890343020064  3891637997717104548   \n",
       "\n",
       "          authorSessionId                                    authorUserAgent  \\\n",
       "1     8940341205206233829                                                NaN   \n",
       "2     8940341205206233829                                                NaN   \n",
       "3    -1457532940883382585                                                NaN   \n",
       "4     8940341205206233829                                                NaN   \n",
       "5     8940341205206233829                                                NaN   \n",
       "6     8940341205206233829                                                NaN   \n",
       "7     8940341205206233829                                                NaN   \n",
       "8     8940341205206233829                                                NaN   \n",
       "9     8940341205206233829                                                NaN   \n",
       "10   -7864441319395545950                                                NaN   \n",
       "11    3042342415047984532                                                NaN   \n",
       "12    3042342415047984532                                                NaN   \n",
       "13    3042342415047984532                                                NaN   \n",
       "14    3042342415047984532                                                NaN   \n",
       "15    -265833983523746108                                                NaN   \n",
       "16    -265833983523746108                                                NaN   \n",
       "17    -265833983523746108                                                NaN   \n",
       "18   -7292854281461484137                                                NaN   \n",
       "19   -7292854281461484137                                                NaN   \n",
       "20   -7292854281461484137                                                NaN   \n",
       "21   -7292854281461484137                                                NaN   \n",
       "22   -7292854281461484137                                                NaN   \n",
       "23    6290959012079283980                                                NaN   \n",
       "24    6290959012079283980                                                NaN   \n",
       "25   -9071650721576979280                                                NaN   \n",
       "26    7660662789565329118                                                NaN   \n",
       "27     770918631519434453                                                NaN   \n",
       "28    3042342415047984532                                                NaN   \n",
       "29    3042342415047984532                                                NaN   \n",
       "30    -265833983523746108                                                NaN   \n",
       "...                   ...                                                ...   \n",
       "3092  7395860765143290921  Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:51....   \n",
       "3093 -6471874325422590486  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "3094  7452795821770584842  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "3095  3264443726869427854  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3...   \n",
       "3096 -6569695881431984742  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
       "3097 -5996702544087841012  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
       "3098 -7424898710963348430  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "3099 -4042309088759228835  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "3100 -4042309088759228835  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "3101  1536755170726159771  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3...   \n",
       "3102 -6451643644744208210  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "3103 -2941135241517914970  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "3104 -6350745898785551312  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "3105  7463073430234613325  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3...   \n",
       "3106  2863165998245027705  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "3107  7817933231113759598  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
       "3108 -8412615285329455721  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
       "3109 -2941135241517914970  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "3110  7540353649241449090  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "3111  7126320888094993255  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "3112 -1382987583323397219  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "3113 -8470437783673120049  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3...   \n",
       "3114  9068765379852494896  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
       "3115 -7684196451423283583  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "3116 -1729556941184852519  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "3117  7144190892417579456  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "3118 -8193630595542572738  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3...   \n",
       "3119  -183341653743161643  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0...   \n",
       "3120  2367029511384577082  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "3121 -7416795577834806518  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "\n",
       "     authorRegion authorCountry contentType  \\\n",
       "1             NaN           NaN        HTML   \n",
       "2             NaN           NaN        HTML   \n",
       "3             NaN           NaN        HTML   \n",
       "4             NaN           NaN        HTML   \n",
       "5             NaN           NaN        HTML   \n",
       "6             NaN           NaN        HTML   \n",
       "7             NaN           NaN        HTML   \n",
       "8             NaN           NaN        HTML   \n",
       "9             NaN           NaN        HTML   \n",
       "10            NaN           NaN        HTML   \n",
       "11            NaN           NaN        HTML   \n",
       "12            NaN           NaN        HTML   \n",
       "13            NaN           NaN        HTML   \n",
       "14            NaN           NaN        HTML   \n",
       "15            NaN           NaN        HTML   \n",
       "16            NaN           NaN        HTML   \n",
       "17            NaN           NaN        HTML   \n",
       "18            NaN           NaN        HTML   \n",
       "19            NaN           NaN        HTML   \n",
       "20            NaN           NaN        HTML   \n",
       "21            NaN           NaN        HTML   \n",
       "22            NaN           NaN        HTML   \n",
       "23            NaN           NaN        HTML   \n",
       "24            NaN           NaN        HTML   \n",
       "25            NaN           NaN        HTML   \n",
       "26            NaN           NaN        HTML   \n",
       "27            NaN           NaN        HTML   \n",
       "28            NaN           NaN        HTML   \n",
       "29            NaN           NaN        HTML   \n",
       "30            NaN           NaN        HTML   \n",
       "...           ...           ...         ...   \n",
       "3092           SP            BR        HTML   \n",
       "3093           MG            BR        HTML   \n",
       "3094           SP            BR        HTML   \n",
       "3095           SP            BR        HTML   \n",
       "3096           SP            BR        HTML   \n",
       "3097           SP            BR        HTML   \n",
       "3098           SP            BR        HTML   \n",
       "3099           SP            BR        HTML   \n",
       "3100           SP            BR        HTML   \n",
       "3101           SP            BR        HTML   \n",
       "3102           ON            CA        HTML   \n",
       "3103           SP            BR        HTML   \n",
       "3104           MG            BR        HTML   \n",
       "3105           MG            BR        HTML   \n",
       "3106           SP            BR        HTML   \n",
       "3107           SP            BR        HTML   \n",
       "3108           SP            BR        HTML   \n",
       "3109           SP            BR        HTML   \n",
       "3110           MG            BR        HTML   \n",
       "3111           SP            BR        HTML   \n",
       "3112           SP            BR        HTML   \n",
       "3113           MG            BR        HTML   \n",
       "3114           MG            BR        HTML   \n",
       "3115           MG            BR        HTML   \n",
       "3116           MG            BR        HTML   \n",
       "3117           SP            BR        HTML   \n",
       "3118           GA            US        HTML   \n",
       "3119           SP            BR        HTML   \n",
       "3120           MG            BR        HTML   \n",
       "3121           SP            BR        HTML   \n",
       "\n",
       "                                                    url  \\\n",
       "1     http://www.nytimes.com/2016/03/28/business/dea...   \n",
       "2     http://cointelegraph.com/news/bitcoin-future-w...   \n",
       "3     https://cloudplatform.googleblog.com/2016/03/G...   \n",
       "4     https://bitcoinmagazine.com/articles/ibm-wants...   \n",
       "5     http://www.coindesk.com/ieee-blockchain-oxford...   \n",
       "6     http://www.newsbtc.com/2016/03/28/banks-need-c...   \n",
       "7     https://bitcoinmagazine.com/articles/blockchai...   \n",
       "8     https://news.bitcoin.com/conglomerates-intervi...   \n",
       "9     https://www.cryptocoinsnews.com/ethereum-rise-...   \n",
       "10    http://economia.ig.com.br/2016-03-27/situacao-...   \n",
       "11    https://cloud.google.com/compute/docs/load-bal...   \n",
       "12    https://cloud.google.com/compute/docs/load-bal...   \n",
       "13    http://techcrunch.com/2016/03/28/ntt-to-buy-de...   \n",
       "14    http://www.salon.com/2016/03/27/good_riddance_...   \n",
       "15    http://cio.economictimes.indiatimes.com/news/i...   \n",
       "16    http://www.senar.org.br/agricultura-precisao/a...   \n",
       "17    https://www.macroprograma1.cnptia.embrapa.br/r...   \n",
       "18    https://blog.coinfund.io/five-bitcoin-and-ethe...   \n",
       "19    http://www.coindesk.com/blockchain-smart-contr...   \n",
       "20    http://bitcoinist.net/using-gamified-hacking-c...   \n",
       "21    https://www.coinbr.net/blog/america-latina-apr...   \n",
       "22            http://www.bbc.com/news/business-35890616   \n",
       "23    https://www.sympla.com.br/como-startups-e-gran...   \n",
       "24    https://www.sympla.com.br/pimp-my-pitch-como-f...   \n",
       "25    http://kotaku.com/google-deepmind-is-now-analy...   \n",
       "26    http://recruitingdaily.com/how-okcupid-changed...   \n",
       "27    https://medium.com/greylock-perspectives/the-h...   \n",
       "28    https://nodejs.org/en/blog/announcements/welco...   \n",
       "29    http://techcrunch.com/2016/03/29/hopper-raises...   \n",
       "30    http://www.telequest.com.br/portal/index.php/o...   \n",
       "...                                                 ...   \n",
       "3092  https://martinfowler.com/articles/201701-event...   \n",
       "3093  https://www.wired.com/2017/02/spanner-google-d...   \n",
       "3094  https://www.uk.capgemini-consulting.com/blog/r...   \n",
       "3095  https://techcrunch.com/2017/02/15/ibms-bringin...   \n",
       "3096  http://www.cnbc.com/2016/12/21/former-google-c...   \n",
       "3097  https://dev.to/gonedark/when-to-make-a-git-commit   \n",
       "3098  http://cantarinobrasileiro.com.br/blog/aplicat...   \n",
       "3099  http://www.bankingtech.com/735552/amazon-looki...   \n",
       "3100  http://www.coindesk.com/3-big-blockchain-ideas...   \n",
       "3101  https://medium.freecodecamp.com/how-to-build-c...   \n",
       "3102  https://aws.amazon.com/blogs/aws/amazon-ebs-up...   \n",
       "3103  https://startupi.com.br/2017/02/udacity-abre-c...   \n",
       "3104  https://medium.com/@husayn.hakeem/my-experienc...   \n",
       "3105  https://philippe.kruchten.com/2017/02/14/concr...   \n",
       "3106  https://medium.com/upday-devs/optimizing-the-p...   \n",
       "3107  http://vocerh.uol.com.br/noticias/legislacao/q...   \n",
       "3108  http://www.codeatest.com/como-testar-excecoes-...   \n",
       "3109  https://googlediscovery.com/2017/02/20/i-duet-...   \n",
       "3110  http://insurancethoughtleadership.com/top-10-i...   \n",
       "3111  https://startupi.com.br/2017/02/ibm-e-visa-tra...   \n",
       "3112    https://www.matthewbarby.com/chatbot-marketing/   \n",
       "3113  https://security.googleblog.com/2017/02/anothe...   \n",
       "3114  https://www.gartner.com/doc/reprints?id=1-3TYE...   \n",
       "3115  https://hackernoon.com/macbook-my-command-line...   \n",
       "3116  https://medium.mybridge.co/swift-top-10-articl...   \n",
       "3117  https://startupi.com.br/2017/02/liga-ventures-...   \n",
       "3118  https://thenextweb.com/apps/2017/02/14/amazon-...   \n",
       "3119                        https://code.org/about/2016   \n",
       "3120  https://www.bloomberg.com/news/articles/2017-0...   \n",
       "3121  https://www.acquia.com/blog/partner/2017-acqui...   \n",
       "\n",
       "                                                  title  \\\n",
       "1     Ethereum, a Virtual Currency, Enables Transact...   \n",
       "2     Bitcoin Future: When GBPcoin of Branson Wins O...   \n",
       "3                          Google Data Center 360° Tour   \n",
       "4     IBM Wants to \"Evolve the Internet\" With Blockc...   \n",
       "5     IEEE to Talk Blockchain at Cloud Computing Oxf...   \n",
       "6     Banks Need To Collaborate With Bitcoin and Fin...   \n",
       "7     Blockchain Technology Could Put Bank Auditors ...   \n",
       "8     Why Decentralized Conglomerates Will Scale Bet...   \n",
       "9     The Rise And Growth of Ethereum Gets Mainstrea...   \n",
       "10    Situação financeira ruim de varejistas pressio...   \n",
       "11                    Setting Up HTTP(S) Load Balancing   \n",
       "12    Setting Up SSL proxy for Google Cloud Load Bal...   \n",
       "13    NTT to buy Dell's services division for $3.05 ...   \n",
       "14    Good riddance, gig economy: Uber, Ayn Rand and...   \n",
       "15            The internet of a billion things | ET CIO   \n",
       "16    Artigos e Palestras - Programa Agricultura de ...   \n",
       "17                      Rede Agricultura de Precisão II   \n",
       "18    Five Bitcoin and Ethereum Based Projects to Wa...   \n",
       "19    Blockchain Smart Contracts Startup Selected By...   \n",
       "20    Using Gamified Hacking Challenges To Attract N...   \n",
       "21             O potencial do bitcoin na América Latina   \n",
       "22    From fine wine to lotteries: Blockchain tech t...   \n",
       "23    Como Startups e Grandes Empresas podem colabor...   \n",
       "24          Pimp My Pitch: como fazer um Pitch poderoso   \n",
       "25    Google DeepMind Is Now Analysing Magic And Hea...   \n",
       "26                  How OKCupid Changed Hiring Forever.   \n",
       "27    The Hierarchy of Engagement - Greylock Perspec...   \n",
       "28                       Welcome Google Cloud Platform!   \n",
       "29    Hopper raises $16 million for a travel app tha...   \n",
       "30              Indústria 4.0: desafios e oportunidades   \n",
       "...                                                 ...   \n",
       "3092                What do you mean by \"Event-Driven\"?   \n",
       "3093  Spanner, the Google Database That Mastered Tim...   \n",
       "3094  Lean and banking: the pot of gold waiting to b...   \n",
       "3095  IBM wants to bring machine learning to the mai...   \n",
       "3096  Former Google career coach shares a visual tri...   \n",
       "3097                          When to make a Git Commit   \n",
       "3098  Aplicativo Celcoin oferece a possibilidade de ...   \n",
       "3099  Amazon looking to buy Capital One? \" Banking T...   \n",
       "3100  3 Big Blockchain Ideas MIT is Working on Right...   \n",
       "3101  How to build cross-platform mobile apps using ...   \n",
       "3102  Amazon EBS Update - New Elastic Volumes Change...   \n",
       "3103  Udacity abre código de simulador de carro autô...   \n",
       "3104  My experience with Google's Associate Android ...   \n",
       "3105  Concrete things you can do about your technica...   \n",
       "3106  Optimizing the Performance of Vector Drawables...   \n",
       "3107      Qual é o valor da área de T&D na sua empresa?   \n",
       "3108  Como testar exceções em Java com o JUnit - Cod...   \n",
       "3109  A.I. Duet, crie melodias usando o aprendizado ...   \n",
       "3110  Top 10 Insurtech Trends for 2017 - Insurance T...   \n",
       "3111  IBM e Visa transformam automóveis, eletrodomés...   \n",
       "3112               Life Beyond Email: Chatbot Marketing   \n",
       "3113                    Another option for file sharing   \n",
       "3114                                    Gartner Reprint   \n",
       "3115                             Command-line utilities   \n",
       "3116   Swift Top 10 Articles For The Past Year (v.2017)   \n",
       "3117  Conheça a Liga IoT, plataforma de inovação abe...   \n",
       "3118  Amazon takes on Skype and GoToMeeting with its...   \n",
       "3119                        Code.org 2016 Annual Report   \n",
       "3120  JPMorgan Software Does in Seconds What Took La...   \n",
       "3121               The 2017 Acquia Partners of the Year   \n",
       "\n",
       "                                                   text lang  \n",
       "1     All of this work is still very early. The firs...   en  \n",
       "2     The alarm clock wakes me at 8:00 with stream o...   en  \n",
       "3     We're excited to share the Google Data Center ...   en  \n",
       "4     The Aite Group projects the blockchain market ...   en  \n",
       "5     One of the largest and oldest organizations fo...   en  \n",
       "6     It will take time until banks come around to t...   en  \n",
       "7     When most people think about computers and rob...   en  \n",
       "8     Bitcoin.com spoke with the OpenLedger CEO, Ron...   en  \n",
       "9     Ethereum, considered by many to be the most pr...   en  \n",
       "10    A queda nas vendas e a deterioração na situaçã...   pt  \n",
       "11    HTTP(S) load balancing provides global load ba...   en  \n",
       "12    Alpha This is an Alpha release of Setting Up S...   en  \n",
       "13    You may know Dell as a computer and server mak...   en  \n",
       "14    The Uber model just doesn't work for other ind...   en  \n",
       "15    Industrial adoption of IoT dubbed as Industria...   en  \n",
       "16    Artigos e Palestras ARTIGOS / 2015 12/08/2015 ...   pt  \n",
       "17    Do Se Te Qu Qu Se Sa 27 28 29 30 31 Faça downl...   pt  \n",
       "18    Five Bitcoin and Ethereum Based Projects to Wa...   en  \n",
       "19    CommonAccord, a blockchain-based startup for l...   en  \n",
       "20    The blockchain ecosystem is always in need of ...   en  \n",
       "21    28/03/2016 | por Safiri Felix | em Economia As...   pt  \n",
       "22    Imagine a world where you can vote in an elect...   en  \n",
       "23    Muito tem se falado sobre como grandes empresa...   pt  \n",
       "24    Descrição do evento Qual horário? 14h00min às ...   pt  \n",
       "25    With retro games and Go well-conquered , where...   en  \n",
       "26    Twenty years ago, if you wanted to find a spec...   en  \n",
       "27    The Hierarchy of Engagement The Fuel to Build ...   en  \n",
       "28    Google Cloud Platform joined the Node.js Found...   en  \n",
       "29    Hopper , the makers of a handy travel applicat...   en  \n",
       "30    *Igor Schiewig 25/03/2016 - A Indústria 4.0 é ...   pt  \n",
       "...                                                 ...  ...  \n",
       "3092  Towards the end of last year I attended a work...   en  \n",
       "3093  About a decade ago, a handful of Google's most...   en  \n",
       "3094  Banks are identifying areas for efficiency gai...   en  \n",
       "3095  IBM wants to bring machine learning to its tra...   en  \n",
       "3096  If you want 2017 to be an exciting year, desig...   en  \n",
       "3097  You don't have to look through too many commit...   en  \n",
       "3098  O CEO e fundador do Celcoin, Marcelo França, e...   pt  \n",
       "3099  Amazon is rumoured to be pondering the acquisi...   en  \n",
       "3100  When one of the world's most prestigious unive...   en  \n",
       "3101  For the past few months, I've been working on ...   en  \n",
       "3102  It is always interesting to speak with our cus...   en  \n",
       "3103  Várias empresas automotivas já estão desenvolv...   pt  \n",
       "3104  In this article I talk about my personal exper...   en  \n",
       "3105  \"Technical debt, yes we have some of this, but...   en  \n",
       "3106  While some mobile platforms have been supporti...   en  \n",
       "3107  É fundamental que o departamento de Recursos H...   pt  \n",
       "3108  Introdução Neste post vou mostrar de forma suc...   pt  \n",
       "3109  O Google lançou o AI Duet , um novo experiment...   pt  \n",
       "3110  Summary: This list isn't just about what is ne...   en  \n",
       "3111  A IBM e a Visa anunciaram a primeira colaboraç...   pt  \n",
       "3112  Every marketing channel suffers from fatigue a...   en  \n",
       "3113  Existing mechanisms for file sharing are so fr...   en  \n",
       "3114  Gartner redesigned the Magic Quadrant for BI a...   en  \n",
       "3115  Introduction I've talked previously about my i...   en  \n",
       "3116  For the past year , we've ranked nearly 9,000 ...   en  \n",
       "3117  A Liga Ventures, aceleradora de startups espec...   pt  \n",
       "3118  Amazon has launched Chime, a video conferencin...   en  \n",
       "3119  February 9, 2017 - We begin each year with a l...   en  \n",
       "3120  At JPMorgan Chase & Co., a learning machine is...   en  \n",
       "3121  The Acquia Partner Awards Program is comprised...   en  \n",
       "\n",
       "[3011 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate by a column name\n",
    " \n",
    "df_articles=df_articles.drop_duplicates(['title'], keep='last')\n",
    "\n",
    "df_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp       int64\n",
       "eventType      object\n",
       "contentId       int64\n",
       "personId        int64\n",
       "sessionId       int64\n",
       "userAgent      object\n",
       "userRegion     object\n",
       "userCountry    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp           int64\n",
       "eventType          object\n",
       "contentId           int64\n",
       "authorPersonId      int64\n",
       "authorSessionId     int64\n",
       "authorUserAgent    object\n",
       "authorRegion       object\n",
       "authorCountry      object\n",
       "contentType        object\n",
       "url                object\n",
       "title              object\n",
       "text               object\n",
       "lang               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1> Text Classification Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function, we apply two different method to to discover what are the main topics of the shared articles and generate the classification automatically. The Latent Dirichlet Allocation method is used, implemented in Gensim framework for the topic classification. And the TF-IDF method is used for the keywords extraction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visualization of Intelligent topic classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import logging\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filtering only English articles\n",
    "english_articles_df = df_articles[df_articles['lang'] == 'en']\n",
    "#Concatenating the articles titles and bodies\n",
    "english_articles_content = (english_articles_df['title'] + ' ' + english_articles_df['text']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading a set of English stopwords\n",
    "english_stopset = set(stopwords.words('english')).union(\n",
    "                  {\"things\", \"that's\", \"something\", \"take\", \"don't\", \"may\", \"want\", \"you're\", \n",
    "                   \"set\", \"might\", \"says\", \"including\", \"lot\", \"much\", \"said\", \"know\", \n",
    "                   \"good\", \"step\", \"often\", \"going\", \"thing\", \"things\", \"think\",\n",
    "                  \"back\", \"actually\", \"better\", \"look\", \"find\", \"right\", \"example\", \n",
    "                   \"verb\", \"verbs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tokenizing words of articles\n",
    "tokenizer = RegexpTokenizer(r\"(?u)[\\b\\#a-zA-Z][\\w&-_]+\\b\")\n",
    "english_articles_tokens = list(map(lambda d: [token for token in tokenizer.tokenize(d.lower()) if token not in english_stopset], english_articles_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "#Processing bigrams from unigrams (sets of two works frequently together in the corpus)\n",
    "bigram_transformer = models.Phrases(english_articles_tokens)\n",
    "english_articles_unigrams_bigrams_tokens = list(bigram_transformer[english_articles_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(16126 unique tokens: ['actual', 'advocates', 'agreed_upon', 'agreements', 'aim']...)\n"
     ]
    }
   ],
   "source": [
    "#Creating a dictionary and filtering out too rare and too common tokens\n",
    "english_dictionary = corpora.Dictionary(english_articles_unigrams_bigrams_tokens)\n",
    "english_dictionary.filter_extremes(no_below=5, no_above=0.4, keep_n=None)\n",
    "english_dictionary.compactify()\n",
    "print(english_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Processing Bag-of-Words (BoW) for each article\n",
    "english_articles_bow = [english_dictionary.doc2bow(doc) for doc in english_articles_unigrams_bigrams_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training the LDA topic model on English articles\n",
    "lda_model = models.LdaModel(english_articles_bow, id2word=english_dictionary, num_topics=30, passes=10, iterations=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Processing the topics for each article\n",
    "english_articles_lda = lda_model[english_articles_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topics_top_words(model, max_words):\n",
    "    all_topics = model.show_topics(-1, max_words*2, False, False)\n",
    "    topics = []\n",
    "    for topic in all_topics:    \n",
    "        min_score_word = float(abs(topic[1][0][1])) / 2.\n",
    "        top_positive_words = list(map(lambda y: y[0].replace('_',' '), filter(lambda x: x[1] > min_score_word, topic[1])))[0:max_words]\n",
    "        topics.append('[' + ', '.join(top_positive_words) + ']')\n",
    "    return topics\n",
    "\n",
    "#Computing the main topic of each article\n",
    "topics_top_words = get_topics_top_words(lda_model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[learning, computer science, year, company, st...</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[ai, technology]</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[team]</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[company, companies, technology]</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[api, google, google cloud, service, cloud]</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[google]</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[digital, customers, business, companies, orga...</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[product, growth, users]</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[slack, platform, app]</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[blockchain, service, services, bitcoin, proce...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[build, run, server, event, mongodb]</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[code, java]</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[apple]</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[app, bot, facebook, page, email]</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[users, user, browser, performance, page]</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[drupal]</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[image, size, constraints]</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[php]</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[kotlin, security, support, distribution]</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[api, tensorflow, track, report]</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[content]</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[machine learning, data science, elasticsearch...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[docker, architecture]</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[elements, layout, view, items, json]</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[terminal, commands, command, girls, history]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[google analytics, site, tracking, analytics, ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[event, database, events]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[feature, commit, changes, commits, git]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[team, project, software]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                topic  count\n",
       "28  [learning, computer science, year, company, st...    302\n",
       "27                                   [ai, technology]    238\n",
       "26                                             [team]    178\n",
       "25                   [company, companies, technology]    174\n",
       "24        [api, google, google cloud, service, cloud]    153\n",
       "23                                           [google]    140\n",
       "22  [digital, customers, business, companies, orga...    130\n",
       "21                           [product, growth, users]    129\n",
       "20                             [slack, platform, app]     87\n",
       "19  [blockchain, service, services, bitcoin, proce...     76\n",
       "18               [build, run, server, event, mongodb]     67\n",
       "17                                       [code, java]     66\n",
       "16                                            [apple]     64\n",
       "15                  [app, bot, facebook, page, email]     61\n",
       "14          [users, user, browser, performance, page]     55\n",
       "13                                           [drupal]     39\n",
       "12                         [image, size, constraints]     35\n",
       "11                                              [php]     32\n",
       "10          [kotlin, security, support, distribution]     22\n",
       "9                    [api, tensorflow, track, report]     22\n",
       "8                                           [content]     21\n",
       "7   [machine learning, data science, elasticsearch...     20\n",
       "6                              [docker, architecture]     15\n",
       "5               [elements, layout, view, items, json]     13\n",
       "4       [terminal, commands, command, girls, history]      9\n",
       "3   [google analytics, site, tracking, analytics, ...      9\n",
       "2                           [event, database, events]      9\n",
       "1            [feature, commit, changes, commits, git]      6\n",
       "0                           [team, project, software]      6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_main_topics(corpus_lda, topics_labels):\n",
    "    min_strength = (1.0 / float(len(topics_labels))) + 0.01\n",
    "    main_topics = map(lambda ts: sorted(ts, key=lambda t: -t[1])[0][0] if sorted(ts, key=lambda t: -t[1])[0][1] > min_strength else None, corpus_lda)\n",
    "    main_topics_labels = map(lambda x: topics_labels[x] if x != None else '', main_topics)\n",
    "    return list(main_topics_labels)\n",
    "\n",
    "#Return the discovered topics, sorted by popularity\n",
    "corpus_main_topics = get_main_topics(english_articles_lda, topics_top_words)\n",
    "\n",
    "main_topics_df = pd.DataFrame(corpus_main_topics, columns=['topic']).groupby('topic').size().sort_values(ascending=True).reset_index()\n",
    "main_topics_df.columns = ['topic','count']\n",
    "main_topics_df.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a355cceb8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAARuCAYAAABUVEELAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9OMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a356f2748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_topics_df.plot(kind='barh', x='topic', y='count', figsize=(8,20), title='Main topics on shared English articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Keyword Extraction with TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bitcoin future when gbpcoin of branson wins over usdcoin of trumpthe alarm clock wakes me at with stream of advert free broadcasting charged at one satoshi per second the current btc exchange rate makes that snooze button a costly proposition so i get up make coffee and go to my computer to check the overnight performance of my bots tradebot earns me on trump and branson tradebot which allocates funds between the main chain and various national currency side chains generated a lucrative btc return tradebot has been reliably profitable ever since i set it to trade usdcoin according to political prediction market data as expected the latest poll numbers came in as highly supportive of trump s re election as usdcoin ceo trump s resistance to de anonymizing public spending by moving usdcoin off the confidential transactions layer continues to erode his coin s credibility in his latest speech trump maintains that full ct privacy is essential to combatting cnycoin s sinister ring signature scheming i make a note to increase my long position in gbpcoin following ceo branson s memo to the effect that government finances and national banks be brought into compliance with the public blockchain british corruption indices have flatlined as the first national econmy to go light britain leads the global recovery from the great debt default of happy with the goatdata project i check teachbot and note that it s performing in line with expectations teachbot serves as an autonomous info agent between various contracting ais and data providers the btc bounty it awarded to a team of sherpas to outfit a herd of tibetan mountain goats with full motion sensing rigs has already been repaid i check the latest figures four times over my best teachbot strategy to date the goatdata project provides valuable data to winterhoof the artificial general intelligence in charge of the swiss military s quadripedal robotics program at this rate i ll soon have enough btc to retire to satoshi city on mars '"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"</?.*?>\",\" <> \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "dfText = pd.DataFrame()\n",
    "dfText['text'] = df_articles['title'] + df_articles['text']\n",
    "dfText['text'] = dfText['text'].apply(lambda x:pre_process(x))\n",
    "\n",
    "#show the first 'text'\n",
    "dfText['text'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the IDF\n",
    "### CountVectorizer to create a vocabulary and generate word counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to start the counting process. We can use the CountVectorizer to create a vocabulary from all the text in our dfText['text'] and generate counts for each row in dfText['text']. The result of the last two lines is a sparse matrix representation of the counts, meaning each column represents a word in the vocabulary and each row represents the document in our dataset where the values are the word counts. Note that with this representation, counts of some words could be 0 if the word did not appear in the corresponding document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "def get_stop_words(stop_file_path):\n",
    "    \"\"\"load stop words \"\"\"\n",
    "    \n",
    "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "        return frozenset(stop_set)\n",
    "\n",
    "#load a set of stop words\n",
    "stopwords=get_stop_words(\"stopwords.txt\")\n",
    "\n",
    "#get the text column \n",
    "docs=dfText['text'].tolist()\n",
    "\n",
    "#create a vocabulary of words, \n",
    "#ignore words that appear in 85% of documents, \n",
    "#eliminate stop words\n",
    "cv=CountVectorizer(max_df=0.85,stop_words=stopwords)\n",
    "word_count_vector=cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3011, 72004)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the shape of the resulting vector. Notice that the shape below is (3011, 72004) because we have 3011 documents in our dataset (the rows) and the vocabulary size is 72004 meaning we have 149391 unique words (the columns) in our dataset minus the stopwords. In some of the text mining applications, such as clustering and text classification we limit the size of the vocabulary. It's really easy to do this by setting max_features=vocab_size when instantiating CountVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "limit our vocabulary size to 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3011, 10000)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(max_df=0.85,stop_words=stopwords,max_features=10000)\n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ethereum',\n",
       " 'virtual',\n",
       " 'currency',\n",
       " 'enables',\n",
       " 'transactions',\n",
       " 'rival',\n",
       " 'bitcoin',\n",
       " 'work',\n",
       " 'still',\n",
       " 'early']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv.vocabulary_.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['consumes',\n",
       " 'consumidor',\n",
       " 'consumidores',\n",
       " 'consuming',\n",
       " 'consumir',\n",
       " 'consumo',\n",
       " 'consumption',\n",
       " 'consórcio',\n",
       " 'conta',\n",
       " 'contact',\n",
       " 'contacted',\n",
       " 'contactless',\n",
       " 'contacts',\n",
       " 'contain',\n",
       " 'contained']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv.get_feature_names())[2000:2015]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfTransformer to Compute Inverse Document Frequency (IDF)¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we are essentially taking the sparse matrix from CountVectorizer to generate the IDF when you invoke fit. An extremely important point to note here is that the IDF should be based on a large corpora and should be representative of texts you would be using to extract keywords. I've seen several articles on the Web that compute the IDF using a handful of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the IDF values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.40092168, 4.19817523, 5.83230576, ..., 4.82070485, 5.83230576,\n",
       "       5.51385203])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to compute the tf-idf value for a given document in our test set by invoking tfidf_transformer.transform(...). This generates a vector of tf-idf scores. Next, we sort the words in the vector in descending order of tf-idf values and then iterate over to extract the top-n items with the corresponding feature names, In the example below, we are extracting keywords for the first document in our test set.\n",
    "\n",
    "The sort_coo(...) method essentially sorts the values in the vector while preserving the column index. Once you have the column index then its really easy to look-up the corresponding word value as you would see in extract_topn_from_vector(...) where we do feature_vals.append(feature_names[idx])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Title=====\n",
      "Setting Up SSL proxy for Google Cloud Load Balancing\n",
      "\n",
      "=====Body=====\n",
      "Alpha This is an Alpha release of Setting Up SSL proxy for Google Cloud Load Balancing. This feature might be changed in backward-incompatible ways and is not recommended for production use. It is not subject to any SLA or deprecation policy. Request to be whitelisted to use this feature . Google Cloud SSL proxy terminates user SSL (TLS) connections at the global load balancing layer, then balances the connections across your instances via SSL or TCP. Cloud SSL proxy is intended for non-HTTP(S) traffic. For HTTP(S) traffic, HTTP(S) load balancing is recommended instead. Contents Google Cloud Load Balancing with SSL proxy Setting up SSL load balancing Configure instance groups and backend services Configure frontend services Additional Commands Listing target SSL proxies Describe target SSL proxies Delete target SSL proxy Update a backend service for the target SSL proxy Update the SSL certificates for the target SSL proxy Update PROXY protocol header for the proxy PROXY protocol for retaining client connection information Recommendations Troubleshooting Pages fail to load from load balancer IP Alpha Limitations FAQ When should I use HTTPS load balancing instead of SSL proxy load balancing? Can I view the original IP address of the connection to the global load balancing layer? Overview We are excited to introduce SSL (TLS) proxying for your SSL traffic. With SSL proxy, you can terminate your customers' SSL sessions at the global load balancing layer, then forward the traffic to your virtual machine instances using SSL (recommended) or TCP. SSL proxy is a global load balancing service. You can deploy your instances in multiple regions, and global load balancing will automatically direct traffic to the region closest to the user. If a region is at capacity, the load balancer automatically directs new connections to another region with available capacity. Existing user connections to remain in the current region. We recommend use of end-to-end encryption for your SSL proxy deployment by configuring your backend service to accept traffic over SSL ( backend-services --protocol SSL ). This ensures that the client traffic decrypted at the SSL proxy layer is encrypted again before being sent to the backend instances. This end-to-end encryption requires you to provision certificates and keys on your instances so they can perform SSL processing. The advantages of managed SSL proxy are as follows: Intelligent routing - the load balancer can route requests to backend locations where there is capacity. In contrast, an L3/L4 load balancer must route to regional backends without paying attention to capacity. Use of smarter routing allows provisioning at N+1 or N+2 instead of x*N. Better utilization of the back-end servers - SSL processing can be very CPU intensive if the ciphers used are not CPU efficient. In order to maximize CPU performance, use ECDSA SSL certs,TLS1.2 and prefer the ECDHE-ECDSA-AES128-GCM-SHA256 cipher suite for SSL between the load balancer and your instances. Certificate management - You only need to update your customer facing certificate in one place when you need to switch certs. You can also reduce the management overhead for your instances by using self-signed certificates. Security patching - If vulnerabilities arise in the SSL or TCP stack, we will apply patches at the load balancer automatically in order to keep your instances safe. Notes: While choosing to send the traffic over unencrypted TCP ( backend-services --protocol TCP ) between the global load balancing layer and instances enables you to manage your SSL certificates at one place and offload SSL processing from your instances, it also comes with reduced security between your global load balancing layer and instances and is therefore not recommended. SSL proxy can handle HTTPS, but this is not recommended. You should instead use HTTP(S) load balancing for HTTPS traffic. See the FAQ for details. We now describe how SSL proxy works and walk you through configuring an SSL proxy for load balancing traffic to some instances. Google Cloud Load Balancing with SSL proxy With SSL proxy at the global load balancing layer, traffic coming over an SSL connection is terminated at the global layer then proxied to the closest available instance group. In this example, the traffic from the users in Iowa and Boston is terminated at the global load balancing layer, and a separate connection is established to the selected backend instance. Google Cloud Load Balancing with SSL termination (click to enlarge) Setting up SSL load balancing This example demonstrates setting up global SSL load balancing for a simple service that exists in two regions: us-central1 and us-east1 . We will configure the following: Instance groups for holding the instances A pair of instances for each instance group A health check for verifying instance health A backend service, which monitors instances in groups and prevents them from exceeding configured usage The SSL proxy itself with its SSL certificate A public static IP address and forwarding rule that sends user traffic to the proxy A firewall rule for the load balancer IP address After that, we'll test our configuration. Configure instance groups and backend services This section shows how to create simple instance groups, add instances to them, then add those instances to a backend service with a health check. A production system would normally use managed instance groups based on instance templates , but this setup is quicker for initial testing. Backend configuration (click to enlarge) Create an instance group for each zone gcloud compute instance-groups unmanaged create us-ig1 --zone us-central1-b Created [ [PROJECT_ID]/zones/us-central1-b/instanceGroups/us-ig1]. NAME ZONE NETWORK MANAGED INSTANCES us-ig1 us-central1-b 0 gcloud compute instance-groups unmanaged create us-ig2 --zone us-east1-b Created [ [PROJECT_ID]/zones/us-east1-b/instanceGroups/us-ig2]. NAME ZONE NETWORK MANAGED INSTANCES us-ig2 us-east1-b 0 Create two instances in each zone For testing purposes, we'll install Apache on each instance. Normally, you wouldn't use SSL load balancing for HTTP traffic, but Apache is commonly used and is easy to set up for testing. These instance are all being created with a tag of ssl-lb . This tag is used later by the firewall rule. Add instances to the instance groups Add ig-us-central1-1 and ig-us-central1-2 to us-ig1 gcloud compute instance-groups unmanaged add-instances us-ig1 \\ --instances ig-us-central1-1,ig-us-central1-2 \\ --zone us-central1-b Updated [ [PROJECT_ID]/zones/us-central1-b/instanceGroups/us-ig1]. Add ig-us-east1-1 and ig-us-east1-2 to us-ig2 gcloud compute instance-groups unmanaged add-instances us-ig2 \\ --instances ig-us-east1-1,ig-us-east1-2 \\ --zone us-east1-b Updated [ [PROJECT_ID]/zones/us-east1-b/instanceGroups/us-ig2]. You now have an instance group in two different regions, each with two instances. When we create a backend service, we have to specify a health check, so we'll create the health check next. Create a health check You can configure either an SSL or TCP health check for determining the health of your instances. If you are using SSL between the load balancer and the instances, use an SSL health check. If you are using plain TCP between the load balancer and the instances, use a TCP health check. Once configured, health checks are sent on a regular basis to the specified port on all the instances in the configured instance groups. If the health check fails, the instance is marked as UNHEALTHY and the load balancer stops sending new connections to that instance until the instance becomes healthy again. Existing connections are allowed to continue. In this example, we're creating a simple SSL health check that we'll use with our backend service. This health check does a simple SSL handshake with each instance on port 443 to determine health. If the handshake succeeds twice in a row (the default), the new instance is marked HEALTHY . If the handshake fails twice in a row (the default) on a HEALTHY instance, the instance is marked UNHEALTHY . If the handshake is again successful twice in a row, the instance is marked as HEALTHY again. See the Health checks section for more information and options. gcloud alpha compute health-checks create ssl my-ssl-health-check --port 443 Created [ [PROJECT_ID]/global/healthChecks/my-ssl-health-check]. NAME PROTOCOL my-ssl-health-check SSL Create a backend service A backend service defines the capacity, max utilization, and health check of the instance groups it contains. Backend services direct incoming traffic to one or more attached backends (depending on the load balancing mode, discussed later). Each backend consists of an instance group and additional configuration to balance traffic among the instances in the instance group. Each instance group is composed of one or more instances. Each backend service also specifies which health checks will be performed for the instances in an all the instance groups added to the backend service. The duration of idle SSL proxy connections through the load balancer is limited by the backend service timeout. In this example we'll add a backend service that connects to instances over SSL. This only governs connections between the load balancer and the instance, not the connections between users and the load balancer. gcloud alpha compute backend-services create my-backend-service \\ --protocol SSL \\ --health-check my-ssl-health-check \\ --timeout 5m Created [ [PROJECT_ID]/global/backendServices/my-backend-service]. NAME BACKENDS PROTOCOL my-backend-service SSL Alternatively you could configure unencrypted communication between from the load balancer to the instances with --protocol TCP . Configure your backend service When you configure a backend service, you must add instance groups and specify a balancing mode that determines how much traffic the load balancer can send to instances in each instance group. Once the limit is reached for a particular instance group, additional requests are sent to an instance group that is next closest to the user, as long as it has capacity. SSL proxy supports the following balancing mode: UTILIZATION (default): instances can accept traffic as long as the average current CPU utilization of the instance group is below an indicated value. To set this value, use the --max-utilization parameter and pass a value between 0.0 (0%) and 1.0 (100%). Default is 0.8 (80%). For this example, we'll add both instance groups to the same backend service and set the balancing mode to send traffic to instance groups that have not reached 80% utilization. gcloud alpha compute backend-services add-backend my-backend-service \\ --instance-group us-ig1 \\ --zone us-central1-b \\ --balancing-mode UTILIZATION \\ --max-utilization 0.8 Updated [ [PROJECT_ID]/global/backendServices/my-backend-service]. gcloud alpha compute backend-services add-backend my-backend-service \\ --instance-group us-ig2 \\ --zone us-east1-b \\ --balancing-mode UTILIZATION \\ --max-utilization 0.8 Updated [ [PROJECT_ID]/global/backendServices/my-backend-service]. Configure frontend services This section shows how to create the following frontend resources: an SslCertificate resource to use with the load balancer an SSL proxy load balancer a static external IP address and a forwarding rule to use with that address a firewall rule that allows traffic from the load balancer and the health checker to reach the instances Frontend configuration (click to enlarge) Configure an SSL certificate and key If you don't have a private key and signed certificate, you can create and use a self-signed certificate for testing purposes, or get real certificate from an authority. See SSL Certificates for further information. You should not use a self-signed certificate on the load balancer for production purposes. This step takes your certificate and key and creates an SSL certificate resource that you will assign to your SSL proxy in the next step. gcloud compute ssl-certificates create my-ssl-cert \\ --certificate [CRT_FILE_PATH] \\ --private-key [KEY_FILE_PATH] Created [ [PROJECT_ID]/global/sslCertificates/ssl-cert1]. NAME CREATION_TIMESTAMP ssl-cert1 2016-02-20T20:53:33.584-08:00 Configure a target SSL proxy The target SSL proxy receives the packets from the user and sends them to the backend service. When you create the target SSL proxy, you associate your backend service and SSL certificate with that resource. If you want to enable insertion of PROXY protocol version 1 header, you can configure the command above with --proxy-header PROXY_V1 . For more information on PROXY protocol, see Update proxy protocol header for the proxy . gcloud alpha compute target-ssl-proxies create my-target-ssl-proxy \\ --backend-service my-backend-service \\ --ssl-certificate my-ssl-cert \\ --proxy-header NONE Created [ [PROJECT_ID]/global/targetSslProxies/my-target-ssl-proxy]. NAME PROXY_HEADER SERVICE SSL_CERTIFICATES my-target-ssl-proxy NONE my-backend-service ssl-cert1 Reserve a global static IP address Now we need to create a global reserved static IP address for your service. This IP address is the one your customers will use to access your load balanced service. gcloud compute addresses create ssl-lb-static-ip --global Created [ [PROJECT_ID]/global/addresses/ssl-lb-static-ip]. NAME REGION ADDRESS STATUS ssl-lb-static-ip [LB_STATIC_IP] RESERVED Configure a global forwarding rule Create a global forwarding rule to forward specific IPs and ports to the target SSL proxy. When customer traffic arrives at your external IP address, this forwarding rule tells the network to send that traffic to your SSL proxy. To create a global forwarding rule associated with the target proxy, replace LB_STATIC_IP with the IP address you generated in the prior step. gcloud alpha compute forwarding-rules create my-global-forwarding-rule \\ --global \\ --target-ssl-proxy my-target-ssl-proxy \\ --address [LB_STATIC_IP] \\ --port-range 443 Created [ [PROJECT_ID]/global/forwardingRules/my-global-forwarding-rule]. NAME REGION IP_ADDRESS IP_PROTOCOL TARGET my-global-forwarding-rule [LB_STATIC_IP] TCP my-target-ssl-proxy Create a firewall rule for the SSL load balancer Configure the firewall to allow traffic from the load balancer and health checker to the instances. gcloud compute firewall-rules create allow-ssl-130-211-0-0-22 \\ --source-ranges 130.211.0.0/22 \\ --target-tags ssl-lb \\ --allow tcp:443 Created [ [PROJECT_ID]/global/firewalls/allow-ssl-130-211-0-0-22]. NAME NETWORK SRC_RANGES RULES SRC_TAGS TARGET_TAGS allow-ssl-130-211-0-0-22 default 130.211.0.0/22 tcp:443 ssl-lb Test your load balancer In your web browser, connect to your static IP address via HTTPS. In this test setup, the instances are using self-signed certificates. Therefore, you will see a warning in your browser the first time you access a page. Click through the warning to see the actual page. You should see one of the hosts from the region closest to you. Reload the page until you see the other instance in that region. To see instances from the other region, either stop the instances in the closest region or disable Apache on those instances. Alternatively, you can use curl from the your local machine's command line. If you are using a self-signed certificate on the SSL proxy, you must also specify -k . curl -k [LB_STATIC_IP] Additional Commands Listing target SSL proxies gcloud alpha compute target-ssl-proxies list NAME PROXY_HEADER SERVICE SSL_CERTIFICATES my-target-ssl-proxy NONE my-backend-service ssl-cert1 Describe target SSL proxies gcloud alpha compute target-ssl-proxies describe my-target-ssl-proxy creationTimestamp: '2016-02-20T20:55:17.633-08:00' id: '9208913598676794842' kind: compute#targetSslProxy name: my-target-ssl-proxy proxyHeader: NONE selfLink: [PROJECT_ID]/global/targetSslProxies/my-target-ssl-proxy service: [PROJECT_ID]/global/backendServices/my-backend-service sslCertificates: - [PROJECT_ID]/global/sslCertificates/ssl-cert1 Delete target SSL proxy To delete a target proxy, you must first delete any global forwarding rules that reference it. You can use the update command to point your SSL proxy at a different backend service. In this example, we'll create a new backend service and point the proxy at it. We'll then point back to the original proxy. Use this command to replace the SSL certificate on the SSL proxy. You must already have created a second SSL certificate resource. gcloud alpha compute target-ssl-proxies update my-target-ssl-proxy \\ --ssl-certificate ssl-cert2 Updated [ [PROJECT_ID]/global/targetSslProxies/my-target-ssl-proxy]. Use this command to change the PROXY protocol header for an existing target SSL proxy. gcloud alpha compute target-ssl-proxies update my-target-ssl-proxy \\ --proxy-header [NONE | PROXY_V1] Updated [ [PROJECT_ID]/global/targetSslProxies/my-target-ssl-proxy]. PROXY protocol for retaining client connection information Google Cloud Load Balancing with SSL proxy terminates SSL connections from the client and creates new connections to the instances, hence the original client IP and port information is not preserved by default. If you would like to preserve and send this information to your instances, then you will need to enable PROXY protocol (version 1) where an additional header containing the original connection information including source IP address, destination IP address, and port numbers is added and sent to the instance as a part of the request. The PROXY protocol header will typically be a single line of user-readable text with the following format: PROXY TCP4 <client IP> <load balancing IP> <source port> <dest port>\\r\\n An example of the PROXY protocol is show below: PROXY TCP4 192.0.2.1 198.51.100.1 15221 443\\r\\n Where client IP is 192.0.2.1 , load balancing IP is 198.51.100.1 , client port is 15221 and the destination port is 443 . In cases where the client IP is not known, the load balancer will generate a PROXY protocol header in the following format: PROXY UNKNOWN\\r\\n Health checks Health checks determine which instances can receive new connections. The health checker polls instances at specified intervals. Instances that fail the check are marked as UNHEALTHY . However, the health checker continues to poll unhealthy instances. If an instance passes its health check, it is marked HEALTHY . You can configure either an SSL or TCP health check to determine the health of your backend instances. If you are using SSL between the load balancer and the instances, use an SSL health check. If you are using plain TCP between the load balancer and the instances, use a TCP health check. Once configured, health checks will be sent on a regular basis on the specified port to all the instances in the configured instance groups. When you configure the health check to be of type SSL , an SSL connection is opened to each of your instances. When you configure the health check to be of type TCP , a TCP connection is opened. The health check itself can use one of the following checks: Simple handshake health check (default): the health checker attempts a simple TCP or SSL handshake. If it is successful, the instance passes. Request/response health check : you provide a request string for the health checker to send after completing the TCP or SSL handshake. If the instance returns the response string you've configured, the instance is marked as HEALTHY . Both the request and response strings can be up to 1024 bytes. If the check succeeds twice in a row (the default) on a new instance, the instance is marked HEALTHY . If the check fails twice in a row (the default) on a HEALTHY instance, the instance is marked UNHEALTHY . If the check is again successful twice in a row (default), the instance is marked as HEALTHY again. Existing connections are allowed to continue on instances that have failed their health check. Create a health check gcloud alpha compute health-checks create [tcp | ssl] my-ssl-health-check \\ [--port PORT ] \\ ...other options If you are encrypting traffic between the load balancer and your instances, use an SSL health check. If the traffic is unencrypted, use a TCP health check. Health check create options --check-interval [CHECK_INTERVAL]; default= 5s How often to perform a health check for an instance. For example, specifying 10s will run the check every 10 seconds. Valid units for this flag are s for seconds and m for minutes. --description [DESCRIPTION] An optional textual description for the health check. Must be surrounded by quotes if the string contains spaces. --healthy-threshold [HEALTHY_THRESHOLD]; default= 2 The number of consecutive successful health checks before an unhealthy instance is marked as HEALTHY . --port [PORT]; default= 80 for TCP, 443 for SSL The TCP port number that this health check monitors. --request An optional string of up to 1024 characters that the health checker can send to the instance. The health checker then looks for a reply from the instance of the string provided in the --response field. If --response is not configured, the health checker does not wait for a response and regards the check as successful if the TCP or SSL handshake was successful. --response An optional string of up to 1024 characters that the health checker expects to receive from the instance. If the response is not received exactly, the health check fails. If --response is configured, but not --request , the health checker will wait for a response anyway. Unless your system automatically sends out a message in response to a successful handshake, always configure --response to match an explicit --request . --timeout [TIMEOUT]; default= 5s If the health checker doesn't receive valid response from the instance within this interval, the check is considered a failure. For example, specifying 10s will cause the check to wait for 10 seconds before considering the request a failure. Valid units for this flag are s for seconds and m for minutes. --unhealthy-threshold [UNHEALTHY_THRESHOLD]; default= 2 The number of consecutive health check failures before a healthy instance is marked as UNHEALTHY . List health checks Lists all the health checks in the current project. gcloud alpha compute health-checks list NAME PROTOCOL my-ssl-health-check SSL Describe a health check Provides detailed information about a specific health check. gcloud alpha compute health-checks describe my-ssl-health-check checkIntervalSec: 5 creationTimestamp: '2016-02-20T20:47:26.034-08:00' description: '' healthyThreshold: 2 id: '1423984233044836273' kind: compute#healthCheck name: my-ssl-health-check selfLink: [PROJECT_ID]/global/healthChecks/my-ssl-health-check sslHealthCheck: port: 443 timeoutSec: 5 type: SSL unhealthyThreshold: 2 To modify a parameter in a health check, run the following command and pass in any of the create parameters. Any specified parameters will be changed. All unspecified parameters will be left the same. gcloud alpha compute health-checks [tcp|ssl] update [--options] Example: gcloud alpha compute health-checks update ssl my-ssl-health-check \\ --description \"SSL health check\" Updated [ [PROJECT_ID]/global/healthChecks/my-ssl-health-check]. Recommendations You should configure the load balancer to prepend a PROXY protocol version 1 header if you need to retain the client connection information. If your traffic is HTTPS, then you should use HTTPS Load Balancing and not SSL proxy for load balancing. Troubleshooting Pages fail to load from load balancer IP Verify the health of instances Verify that the instances are HEALTHY. gcloud alpha compute backend-services get-health my-backend-service --- backend: [PROJECT_ID]/zones/us-central1-b/resourceViews/us-ig1 status: kind: compute#backendServiceGroupHealth --- backend: [PROJECT_ID]/zones/us-east1-b/instanceGroups/us-ig2 status: kind: compute#backendServiceGroupHealth Confirm that your firewall rule is correct Both the health checker and the load balancer need 130.211.0.0/22 to be open If you are doing SSL between the load balancer and the instances, you should do an SSL health check. In that case, tcp:443 must be allowed by the firewall from 130.211.0.0/22 . If you are doing TCP to the instances, do a TCP health check and open tcp:80 from 130.211.0.0/22 instead. If you are leveraging instance tags, make sure the tag is listed as under TARGET_TAGS in the firewall rule, and make sure all your instances have that tag. In this example, instances are tagged with ssl-lb . gcloud compute firewall-rules list NAME NETWORK SRC_RANGES RULES SRC_TAGS TARGET_TAGS allow-ssl-130-211-0-0-22 default 130.211.0.0/22 tcp:443 ssl-lb Try to reach individual instances Temporarily set a firewall rule that allows you to access your instances individually, then try to load a page from a specific instance. Then access one or more of your instances directly from your browser. [EXTERNAL_IP] Alpha Limitations The PROXY protocol header is currently only allowed if the protocol between the load balancer and the instance is set to TCP. This will be fixed for protocol SSL by Beta timeframe. FAQ When should I use HTTPS load balancing instead of SSL proxy load balancing? Though SSL proxy can handle HTTPS traffic, HTTPS Load Balancing has additional features that make it a better choice in most cases. HTTPS load balancing has the following additional functionality: Negotiates HTTP/2 and SPDY/3.1 Rejects invalid HTTP requests or responses Forwards requests to different instance groups based on URL host and path Integrates with Cloud CDN . Spreads the request load more evenly among instances, providing better instance utilization. HTTPS load balances each request separately, whereas SSL proxy sends all bytes from the same SSL or TCP connection to the same instance. SSL proxy for Google Cloud Load Balancing can be used for other protocols that use SSL, such as Websockets and IMAP over SSL. Can I view the original IP address of the connection to the global load balancing layer? Yes. You can configure the load balancer to prepend a PROXY protocol version 1 header to retain the original connection information. See Update proxy protocol header for the proxy for details.\n",
      "\n",
      "===Keywords===\n",
      "dell 0.868\n",
      "billion 0.19\n",
      "division 0.144\n",
      "systems 0.13\n",
      "acquired 0.124\n",
      "acquisition 0.121\n",
      "foreign 0.095\n",
      "expanding 0.085\n",
      "company 0.083\n",
      "finance 0.082\n"
     ]
    }
   ],
   "source": [
    "\n",
    "docs_title = df_articles['title']\n",
    "\n",
    "docs_body = df_articles['text']\n",
    "\n",
    "feature_names=cv.get_feature_names()\n",
    "\n",
    "# get the document that we want to extract keywords from\n",
    "doc=dfText['text'].iloc[12]\n",
    "\n",
    "#generate tf-idf for the given document\n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
    "\n",
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "#extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "\n",
    "# now print the results\n",
    "print(\"\\n=====Title=====\")\n",
    "print(docs_title[12])\n",
    "print(\"\\n=====Body=====\")\n",
    "print(docs_body[12])\n",
    "print(\"\\n===Keywords===\")\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Use the simple function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Setting Up SSL proxy for Google Cloud Load Balancing'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles['title'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "text_tmp = df_articles['title'][12] + ' ' + df_articles['text'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Setting Up SSL proxy for Google Cloud Load Balancing Alpha This is an Alpha release of Setting Up SSL proxy for Google Cloud Load Balancing. This feature might be changed in backward-incompatible ways and is not recommended for production use. It is not subject to any SLA or deprecation policy. Request to be whitelisted to use this feature . Google Cloud SSL proxy terminates user SSL (TLS) connections at the global load balancing layer, then balances the connections across your instances via SSL or TCP. Cloud SSL proxy is intended for non-HTTP(S) traffic. For HTTP(S) traffic, HTTP(S) load balancing is recommended instead. Contents Google Cloud Load Balancing with SSL proxy Setting up SSL load balancing Configure instance groups and backend services Configure frontend services Additional Commands Listing target SSL proxies Describe target SSL proxies Delete target SSL proxy Update a backend service for the target SSL proxy Update the SSL certificates for the target SSL proxy Update PROXY protocol header for the proxy PROXY protocol for retaining client connection information Recommendations Troubleshooting Pages fail to load from load balancer IP Alpha Limitations FAQ When should I use HTTPS load balancing instead of SSL proxy load balancing? Can I view the original IP address of the connection to the global load balancing layer? Overview We are excited to introduce SSL (TLS) proxying for your SSL traffic. With SSL proxy, you can terminate your customers\\' SSL sessions at the global load balancing layer, then forward the traffic to your virtual machine instances using SSL (recommended) or TCP. SSL proxy is a global load balancing service. You can deploy your instances in multiple regions, and global load balancing will automatically direct traffic to the region closest to the user. If a region is at capacity, the load balancer automatically directs new connections to another region with available capacity. Existing user connections to remain in the current region. We recommend use of end-to-end encryption for your SSL proxy deployment by configuring your backend service to accept traffic over SSL ( backend-services --protocol SSL ). This ensures that the client traffic decrypted at the SSL proxy layer is encrypted again before being sent to the backend instances. This end-to-end encryption requires you to provision certificates and keys on your instances so they can perform SSL processing. The advantages of managed SSL proxy are as follows: Intelligent routing - the load balancer can route requests to backend locations where there is capacity. In contrast, an L3/L4 load balancer must route to regional backends without paying attention to capacity. Use of smarter routing allows provisioning at N+1 or N+2 instead of x*N. Better utilization of the back-end servers - SSL processing can be very CPU intensive if the ciphers used are not CPU efficient. In order to maximize CPU performance, use ECDSA SSL certs,TLS1.2 and prefer the ECDHE-ECDSA-AES128-GCM-SHA256 cipher suite for SSL between the load balancer and your instances. Certificate management - You only need to update your customer facing certificate in one place when you need to switch certs. You can also reduce the management overhead for your instances by using self-signed certificates. Security patching - If vulnerabilities arise in the SSL or TCP stack, we will apply patches at the load balancer automatically in order to keep your instances safe. Notes: While choosing to send the traffic over unencrypted TCP ( backend-services --protocol TCP ) between the global load balancing layer and instances enables you to manage your SSL certificates at one place and offload SSL processing from your instances, it also comes with reduced security between your global load balancing layer and instances and is therefore not recommended. SSL proxy can handle HTTPS, but this is not recommended. You should instead use HTTP(S) load balancing for HTTPS traffic. See the FAQ for details. We now describe how SSL proxy works and walk you through configuring an SSL proxy for load balancing traffic to some instances. Google Cloud Load Balancing with SSL proxy With SSL proxy at the global load balancing layer, traffic coming over an SSL connection is terminated at the global layer then proxied to the closest available instance group. In this example, the traffic from the users in Iowa and Boston is terminated at the global load balancing layer, and a separate connection is established to the selected backend instance. Google Cloud Load Balancing with SSL termination (click to enlarge) Setting up SSL load balancing This example demonstrates setting up global SSL load balancing for a simple service that exists in two regions: us-central1 and us-east1 . We will configure the following: Instance groups for holding the instances A pair of instances for each instance group A health check for verifying instance health A backend service, which monitors instances in groups and prevents them from exceeding configured usage The SSL proxy itself with its SSL certificate A public static IP address and forwarding rule that sends user traffic to the proxy A firewall rule for the load balancer IP address After that, we\\'ll test our configuration. Configure instance groups and backend services This section shows how to create simple instance groups, add instances to them, then add those instances to a backend service with a health check. A production system would normally use managed instance groups based on instance templates , but this setup is quicker for initial testing. Backend configuration (click to enlarge) Create an instance group for each zone gcloud compute instance-groups unmanaged create us-ig1 --zone us-central1-b Created [ [PROJECT_ID]/zones/us-central1-b/instanceGroups/us-ig1]. NAME ZONE NETWORK MANAGED INSTANCES us-ig1 us-central1-b 0 gcloud compute instance-groups unmanaged create us-ig2 --zone us-east1-b Created [ [PROJECT_ID]/zones/us-east1-b/instanceGroups/us-ig2]. NAME ZONE NETWORK MANAGED INSTANCES us-ig2 us-east1-b 0 Create two instances in each zone For testing purposes, we\\'ll install Apache on each instance. Normally, you wouldn\\'t use SSL load balancing for HTTP traffic, but Apache is commonly used and is easy to set up for testing. These instance are all being created with a tag of ssl-lb . This tag is used later by the firewall rule. Add instances to the instance groups Add ig-us-central1-1 and ig-us-central1-2 to us-ig1 gcloud compute instance-groups unmanaged add-instances us-ig1 \\\\ --instances ig-us-central1-1,ig-us-central1-2 \\\\ --zone us-central1-b Updated [ [PROJECT_ID]/zones/us-central1-b/instanceGroups/us-ig1]. Add ig-us-east1-1 and ig-us-east1-2 to us-ig2 gcloud compute instance-groups unmanaged add-instances us-ig2 \\\\ --instances ig-us-east1-1,ig-us-east1-2 \\\\ --zone us-east1-b Updated [ [PROJECT_ID]/zones/us-east1-b/instanceGroups/us-ig2]. You now have an instance group in two different regions, each with two instances. When we create a backend service, we have to specify a health check, so we\\'ll create the health check next. Create a health check You can configure either an SSL or TCP health check for determining the health of your instances. If you are using SSL between the load balancer and the instances, use an SSL health check. If you are using plain TCP between the load balancer and the instances, use a TCP health check. Once configured, health checks are sent on a regular basis to the specified port on all the instances in the configured instance groups. If the health check fails, the instance is marked as UNHEALTHY and the load balancer stops sending new connections to that instance until the instance becomes healthy again. Existing connections are allowed to continue. In this example, we\\'re creating a simple SSL health check that we\\'ll use with our backend service. This health check does a simple SSL handshake with each instance on port 443 to determine health. If the handshake succeeds twice in a row (the default), the new instance is marked HEALTHY . If the handshake fails twice in a row (the default) on a HEALTHY instance, the instance is marked UNHEALTHY . If the handshake is again successful twice in a row, the instance is marked as HEALTHY again. See the Health checks section for more information and options. gcloud alpha compute health-checks create ssl my-ssl-health-check --port 443 Created [ [PROJECT_ID]/global/healthChecks/my-ssl-health-check]. NAME PROTOCOL my-ssl-health-check SSL Create a backend service A backend service defines the capacity, max utilization, and health check of the instance groups it contains. Backend services direct incoming traffic to one or more attached backends (depending on the load balancing mode, discussed later). Each backend consists of an instance group and additional configuration to balance traffic among the instances in the instance group. Each instance group is composed of one or more instances. Each backend service also specifies which health checks will be performed for the instances in an all the instance groups added to the backend service. The duration of idle SSL proxy connections through the load balancer is limited by the backend service timeout. In this example we\\'ll add a backend service that connects to instances over SSL. This only governs connections between the load balancer and the instance, not the connections between users and the load balancer. gcloud alpha compute backend-services create my-backend-service \\\\ --protocol SSL \\\\ --health-check my-ssl-health-check \\\\ --timeout 5m Created [ [PROJECT_ID]/global/backendServices/my-backend-service]. NAME BACKENDS PROTOCOL my-backend-service SSL Alternatively you could configure unencrypted communication between from the load balancer to the instances with --protocol TCP . Configure your backend service When you configure a backend service, you must add instance groups and specify a balancing mode that determines how much traffic the load balancer can send to instances in each instance group. Once the limit is reached for a particular instance group, additional requests are sent to an instance group that is next closest to the user, as long as it has capacity. SSL proxy supports the following balancing mode: UTILIZATION (default): instances can accept traffic as long as the average current CPU utilization of the instance group is below an indicated value. To set this value, use the --max-utilization parameter and pass a value between 0.0 (0%) and 1.0 (100%). Default is 0.8 (80%). For this example, we\\'ll add both instance groups to the same backend service and set the balancing mode to send traffic to instance groups that have not reached 80% utilization. gcloud alpha compute backend-services add-backend my-backend-service \\\\ --instance-group us-ig1 \\\\ --zone us-central1-b \\\\ --balancing-mode UTILIZATION \\\\ --max-utilization 0.8 Updated [ [PROJECT_ID]/global/backendServices/my-backend-service]. gcloud alpha compute backend-services add-backend my-backend-service \\\\ --instance-group us-ig2 \\\\ --zone us-east1-b \\\\ --balancing-mode UTILIZATION \\\\ --max-utilization 0.8 Updated [ [PROJECT_ID]/global/backendServices/my-backend-service]. Configure frontend services This section shows how to create the following frontend resources: an SslCertificate resource to use with the load balancer an SSL proxy load balancer a static external IP address and a forwarding rule to use with that address a firewall rule that allows traffic from the load balancer and the health checker to reach the instances Frontend configuration (click to enlarge) Configure an SSL certificate and key If you don\\'t have a private key and signed certificate, you can create and use a self-signed certificate for testing purposes, or get real certificate from an authority. See SSL Certificates for further information. You should not use a self-signed certificate on the load balancer for production purposes. This step takes your certificate and key and creates an SSL certificate resource that you will assign to your SSL proxy in the next step. gcloud compute ssl-certificates create my-ssl-cert \\\\ --certificate [CRT_FILE_PATH] \\\\ --private-key [KEY_FILE_PATH] Created [ [PROJECT_ID]/global/sslCertificates/ssl-cert1]. NAME CREATION_TIMESTAMP ssl-cert1 2016-02-20T20:53:33.584-08:00 Configure a target SSL proxy The target SSL proxy receives the packets from the user and sends them to the backend service. When you create the target SSL proxy, you associate your backend service and SSL certificate with that resource. If you want to enable insertion of PROXY protocol version 1 header, you can configure the command above with --proxy-header PROXY_V1 . For more information on PROXY protocol, see Update proxy protocol header for the proxy . gcloud alpha compute target-ssl-proxies create my-target-ssl-proxy \\\\ --backend-service my-backend-service \\\\ --ssl-certificate my-ssl-cert \\\\ --proxy-header NONE Created [ [PROJECT_ID]/global/targetSslProxies/my-target-ssl-proxy]. NAME PROXY_HEADER SERVICE SSL_CERTIFICATES my-target-ssl-proxy NONE my-backend-service ssl-cert1 Reserve a global static IP address Now we need to create a global reserved static IP address for your service. This IP address is the one your customers will use to access your load balanced service. gcloud compute addresses create ssl-lb-static-ip --global Created [ [PROJECT_ID]/global/addresses/ssl-lb-static-ip]. NAME REGION ADDRESS STATUS ssl-lb-static-ip [LB_STATIC_IP] RESERVED Configure a global forwarding rule Create a global forwarding rule to forward specific IPs and ports to the target SSL proxy. When customer traffic arrives at your external IP address, this forwarding rule tells the network to send that traffic to your SSL proxy. To create a global forwarding rule associated with the target proxy, replace LB_STATIC_IP with the IP address you generated in the prior step. gcloud alpha compute forwarding-rules create my-global-forwarding-rule \\\\ --global \\\\ --target-ssl-proxy my-target-ssl-proxy \\\\ --address [LB_STATIC_IP] \\\\ --port-range 443 Created [ [PROJECT_ID]/global/forwardingRules/my-global-forwarding-rule]. NAME REGION IP_ADDRESS IP_PROTOCOL TARGET my-global-forwarding-rule [LB_STATIC_IP] TCP my-target-ssl-proxy Create a firewall rule for the SSL load balancer Configure the firewall to allow traffic from the load balancer and health checker to the instances. gcloud compute firewall-rules create allow-ssl-130-211-0-0-22 \\\\ --source-ranges 130.211.0.0/22 \\\\ --target-tags ssl-lb \\\\ --allow tcp:443 Created [ [PROJECT_ID]/global/firewalls/allow-ssl-130-211-0-0-22]. NAME NETWORK SRC_RANGES RULES SRC_TAGS TARGET_TAGS allow-ssl-130-211-0-0-22 default 130.211.0.0/22 tcp:443 ssl-lb Test your load balancer In your web browser, connect to your static IP address via HTTPS. In this test setup, the instances are using self-signed certificates. Therefore, you will see a warning in your browser the first time you access a page. Click through the warning to see the actual page. You should see one of the hosts from the region closest to you. Reload the page until you see the other instance in that region. To see instances from the other region, either stop the instances in the closest region or disable Apache on those instances. Alternatively, you can use curl from the your local machine\\'s command line. If you are using a self-signed certificate on the SSL proxy, you must also specify -k . curl -k [LB_STATIC_IP] Additional Commands Listing target SSL proxies gcloud alpha compute target-ssl-proxies list NAME PROXY_HEADER SERVICE SSL_CERTIFICATES my-target-ssl-proxy NONE my-backend-service ssl-cert1 Describe target SSL proxies gcloud alpha compute target-ssl-proxies describe my-target-ssl-proxy creationTimestamp: \\'2016-02-20T20:55:17.633-08:00\\' id: \\'9208913598676794842\\' kind: compute#targetSslProxy name: my-target-ssl-proxy proxyHeader: NONE selfLink: [PROJECT_ID]/global/targetSslProxies/my-target-ssl-proxy service: [PROJECT_ID]/global/backendServices/my-backend-service sslCertificates: - [PROJECT_ID]/global/sslCertificates/ssl-cert1 Delete target SSL proxy To delete a target proxy, you must first delete any global forwarding rules that reference it. You can use the update command to point your SSL proxy at a different backend service. In this example, we\\'ll create a new backend service and point the proxy at it. We\\'ll then point back to the original proxy. Use this command to replace the SSL certificate on the SSL proxy. You must already have created a second SSL certificate resource. gcloud alpha compute target-ssl-proxies update my-target-ssl-proxy \\\\ --ssl-certificate ssl-cert2 Updated [ [PROJECT_ID]/global/targetSslProxies/my-target-ssl-proxy]. Use this command to change the PROXY protocol header for an existing target SSL proxy. gcloud alpha compute target-ssl-proxies update my-target-ssl-proxy \\\\ --proxy-header [NONE | PROXY_V1] Updated [ [PROJECT_ID]/global/targetSslProxies/my-target-ssl-proxy]. PROXY protocol for retaining client connection information Google Cloud Load Balancing with SSL proxy terminates SSL connections from the client and creates new connections to the instances, hence the original client IP and port information is not preserved by default. If you would like to preserve and send this information to your instances, then you will need to enable PROXY protocol (version 1) where an additional header containing the original connection information including source IP address, destination IP address, and port numbers is added and sent to the instance as a part of the request. The PROXY protocol header will typically be a single line of user-readable text with the following format: PROXY TCP4 <client IP> <load balancing IP> <source port> <dest port>\\\\r\\\\n An example of the PROXY protocol is show below: PROXY TCP4 192.0.2.1 198.51.100.1 15221 443\\\\r\\\\n Where client IP is 192.0.2.1 , load balancing IP is 198.51.100.1 , client port is 15221 and the destination port is 443 . In cases where the client IP is not known, the load balancer will generate a PROXY protocol header in the following format: PROXY UNKNOWN\\\\r\\\\n Health checks Health checks determine which instances can receive new connections. The health checker polls instances at specified intervals. Instances that fail the check are marked as UNHEALTHY . However, the health checker continues to poll unhealthy instances. If an instance passes its health check, it is marked HEALTHY . You can configure either an SSL or TCP health check to determine the health of your backend instances. If you are using SSL between the load balancer and the instances, use an SSL health check. If you are using plain TCP between the load balancer and the instances, use a TCP health check. Once configured, health checks will be sent on a regular basis on the specified port to all the instances in the configured instance groups. When you configure the health check to be of type SSL , an SSL connection is opened to each of your instances. When you configure the health check to be of type TCP , a TCP connection is opened. The health check itself can use one of the following checks: Simple handshake health check (default): the health checker attempts a simple TCP or SSL handshake. If it is successful, the instance passes. Request/response health check : you provide a request string for the health checker to send after completing the TCP or SSL handshake. If the instance returns the response string you\\'ve configured, the instance is marked as HEALTHY . Both the request and response strings can be up to 1024 bytes. If the check succeeds twice in a row (the default) on a new instance, the instance is marked HEALTHY . If the check fails twice in a row (the default) on a HEALTHY instance, the instance is marked UNHEALTHY . If the check is again successful twice in a row (default), the instance is marked as HEALTHY again. Existing connections are allowed to continue on instances that have failed their health check. Create a health check gcloud alpha compute health-checks create [tcp | ssl] my-ssl-health-check \\\\ [--port PORT ] \\\\ ...other options If you are encrypting traffic between the load balancer and your instances, use an SSL health check. If the traffic is unencrypted, use a TCP health check. Health check create options --check-interval [CHECK_INTERVAL]; default= 5s How often to perform a health check for an instance. For example, specifying 10s will run the check every 10 seconds. Valid units for this flag are s for seconds and m for minutes. --description [DESCRIPTION] An optional textual description for the health check. Must be surrounded by quotes if the string contains spaces. --healthy-threshold [HEALTHY_THRESHOLD]; default= 2 The number of consecutive successful health checks before an unhealthy instance is marked as HEALTHY . --port [PORT]; default= 80 for TCP, 443 for SSL The TCP port number that this health check monitors. --request An optional string of up to 1024 characters that the health checker can send to the instance. The health checker then looks for a reply from the instance of the string provided in the --response field. If --response is not configured, the health checker does not wait for a response and regards the check as successful if the TCP or SSL handshake was successful. --response An optional string of up to 1024 characters that the health checker expects to receive from the instance. If the response is not received exactly, the health check fails. If --response is configured, but not --request , the health checker will wait for a response anyway. Unless your system automatically sends out a message in response to a successful handshake, always configure --response to match an explicit --request . --timeout [TIMEOUT]; default= 5s If the health checker doesn\\'t receive valid response from the instance within this interval, the check is considered a failure. For example, specifying 10s will cause the check to wait for 10 seconds before considering the request a failure. Valid units for this flag are s for seconds and m for minutes. --unhealthy-threshold [UNHEALTHY_THRESHOLD]; default= 2 The number of consecutive health check failures before a healthy instance is marked as UNHEALTHY . List health checks Lists all the health checks in the current project. gcloud alpha compute health-checks list NAME PROTOCOL my-ssl-health-check SSL Describe a health check Provides detailed information about a specific health check. gcloud alpha compute health-checks describe my-ssl-health-check checkIntervalSec: 5 creationTimestamp: \\'2016-02-20T20:47:26.034-08:00\\' description: \\'\\' healthyThreshold: 2 id: \\'1423984233044836273\\' kind: compute#healthCheck name: my-ssl-health-check selfLink: [PROJECT_ID]/global/healthChecks/my-ssl-health-check sslHealthCheck: port: 443 timeoutSec: 5 type: SSL unhealthyThreshold: 2 To modify a parameter in a health check, run the following command and pass in any of the create parameters. Any specified parameters will be changed. All unspecified parameters will be left the same. gcloud alpha compute health-checks [tcp|ssl] update [--options] Example: gcloud alpha compute health-checks update ssl my-ssl-health-check \\\\ --description \"SSL health check\" Updated [ [PROJECT_ID]/global/healthChecks/my-ssl-health-check]. Recommendations You should configure the load balancer to prepend a PROXY protocol version 1 header if you need to retain the client connection information. If your traffic is HTTPS, then you should use HTTPS Load Balancing and not SSL proxy for load balancing. Troubleshooting Pages fail to load from load balancer IP Verify the health of instances Verify that the instances are HEALTHY. gcloud alpha compute backend-services get-health my-backend-service --- backend: [PROJECT_ID]/zones/us-central1-b/resourceViews/us-ig1 status: kind: compute#backendServiceGroupHealth --- backend: [PROJECT_ID]/zones/us-east1-b/instanceGroups/us-ig2 status: kind: compute#backendServiceGroupHealth Confirm that your firewall rule is correct Both the health checker and the load balancer need 130.211.0.0/22 to be open If you are doing SSL between the load balancer and the instances, you should do an SSL health check. In that case, tcp:443 must be allowed by the firewall from 130.211.0.0/22 . If you are doing TCP to the instances, do a TCP health check and open tcp:80 from 130.211.0.0/22 instead. If you are leveraging instance tags, make sure the tag is listed as under TARGET_TAGS in the firewall rule, and make sure all your instances have that tag. In this example, instances are tagged with ssl-lb . gcloud compute firewall-rules list NAME NETWORK SRC_RANGES RULES SRC_TAGS TARGET_TAGS allow-ssl-130-211-0-0-22 default 130.211.0.0/22 tcp:443 ssl-lb Try to reach individual instances Temporarily set a firewall rule that allows you to access your instances individually, then try to load a page from a specific instance. Then access one or more of your instances directly from your browser. [EXTERNAL_IP] Alpha Limitations The PROXY protocol header is currently only allowed if the protocol between the load balancer and the instance is set to TCP. This will be fixed for protocol SSL by Beta timeframe. FAQ When should I use HTTPS load balancing instead of SSL proxy load balancing? Though SSL proxy can handle HTTPS traffic, HTTPS Load Balancing has additional features that make it a better choice in most cases. HTTPS load balancing has the following additional functionality: Negotiates HTTP/2 and SPDY/3.1 Rejects invalid HTTP requests or responses Forwards requests to different instance groups based on URL host and path Integrates with Cloud CDN . Spreads the request load more evenly among instances, providing better instance utilization. HTTPS load balances each request separately, whereas SSL proxy sends all bytes from the same SSL or TCP connection to the same instance. SSL proxy for Google Cloud Load Balancing can be used for other protocols that use SSL, such as Websockets and IMAP over SSL. Can I view the original IP address of the connection to the global load balancing layer? Yes. You can configure the load balancer to prepend a PROXY protocol version 1 header to retain the original connection information. See Update proxy protocol header for the proxy for details.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setting up ssl', 'google cloud load balancing alpha', 'alpha', 'setting up ssl', 'google cloud load balancing', 'backward-incompatible ways', 'production use', 'sla', 'deprecation policy', 'request', 'google cloud ssl', 'proxy terminates user', 'ssl', 'tls', 'global load', 'ssl', 'tcp', 'cloud ssl', 'http', 'http', 'contents google cloud load balancing', 'ssl', 'setting', 'ssl', 'configure', 'instance groups', 'backend services', 'configure', 'frontend services', 'additional commands listing', 'ssl', 'describe', 'ssl', 'delete', 'ssl', 'update', 'backend service', 'ssl', 'update', 'ssl', 'ssl', 'update proxy', 'protocol header', 'proxy', 'client connection information', 'recommendations troubleshooting pages', 'load balancer', 'ip alpha limitations faq', 'https', 'ssl', 'proxy load', 'ip', 'global load', 'overview', 'ssl', 'tls', 'ssl', 'ssl', 'ssl', 'global load', 'virtual machine instances', 'ssl', 'tcp', 'ssl', 'global load', 'multiple regions', 'global load', 'direct traffic', 'load balancer', 'new connections', 'available capacity', 'existing', 'user connections', 'current region', 'end-to-end encryption', 'ssl', 'proxy deployment', 'backend service', 'ssl', 'ssl', 'client traffic', 'ssl', 'proxy layer', 'backend instances', 'end-to-end encryption', 'provision certificates', 'ssl', 'ssl', 'intelligent', 'load balancer', 'route requests', 'backend locations', 'l3/l4', 'load balancer', 'regional backends', 'n+1', 'n+2', 'back-end servers', 'ssl', 'cpu', 'cpu', 'cpu', 'ecdsa ssl', 'tls1.2', 'ecdhe-ecdsa-aes128-gcm-sha256', 'cipher suite', 'ssl', 'load balancer', 'certificate', 'switch certs', 'management overhead', 'ssl', 'tcp', 'load balancer', 'notes', 'tcp', 'tcp', 'global load', 'ssl', 'ssl', 'global load', 'ssl', 'https', 'http', 'https', 'faq', 'ssl', 'ssl', 'google cloud load balancing', 'ssl', 'ssl', 'global load', 'ssl', 'global layer', 'available instance group', 'iowa', 'boston', 'global load', 'separate connection', 'backend instance', 'google cloud load balancing', 'ssl', 'setting', 'ssl', 'example demonstrates setting', 'ssl', 'simple service', 'instance', 'instance group', 'health check', 'instance health', 'backend service', 'monitors instances', 'ssl', 'ssl', 'public static', 'ip', 'sends user traffic', 'firewall rule', 'load balancer', 'ip', \"'ll test\", 'configure', 'instance groups', 'backend services', 'section shows', 'simple instance groups', 'backend service', 'health check', 'production system', 'instance groups', 'instance templates', 'backend', 'create', 'instance group', 'zone gcloud compute instance-groups', 'zone us-central1-b', 'created', '[ [', 'project_id', '] /zones/us-central1-b/instancegroups/us-ig1 ]', 'name zone network managed instances', 'us-ig1 us-central1-b', 'gcloud compute instance-groups', 'zone us-east1-b', 'created', '[ [', 'project_id', '] /zones/us-east1-b/instancegroups/us-ig2 ]', 'name zone network managed instances', 'us-ig2 us-east1-b', 'create', \"'ll install\", 'apache', 'normally', \"n't use\", 'ssl', 'http', 'apache', 'firewall rule', 'instance groups', 'us-ig1 gcloud compute instance-groups', 'add-instances us-ig1 \\\\', 'instances ig-us-central1-1', 'ig-us-central1-2 \\\\', 'zone us-central1-b', 'updated', '[ [', 'project_id', '] /zones/us-central1-b/instancegroups/us-ig1 ]', 'us-ig2 gcloud compute instance-groups', 'add-instances us-ig2 \\\\', 'instances ig-us-east1-1', 'ig-us-east1-2 \\\\', 'zone us-east1-b', 'updated', '[ [', 'project_id', '] /zones/us-east1-b/instancegroups/us-ig2 ]', 'instance group', 'different regions', 'backend service', 'health check', 'health check', 'create', 'health check', 'ssl', 'tcp', 'health check', 'ssl', 'load balancer', 'ssl', 'health check', 'tcp', 'load balancer', 'tcp', 'health check', 'health checks', 'regular basis', 'instance groups', 'health check', 'unhealthy', 'load balancer stops', 'new connections', 'existing', 'ssl', 'health check', \"'ll use\", 'backend service', 'health check', 'ssl', 'new instance', 'healthy', 'healthy', 'unhealthy', 'healthy', 'health checks section', 'gcloud alpha compute health-checks', 'ssl my-ssl-health-check', 'created', '[ [', 'project_id', '] /global/healthchecks/my-ssl-health-check ]', 'name protocol', 'ssl create', 'backend service', 'backend service defines', 'max utilization', 'health check', 'instance groups', 'backend', 'instance group', 'additional configuration', 'balance traffic', 'instance group', 'instance group', 'backend service', 'health checks', 'instance groups', 'backend service', 'ssl', 'proxy connections', 'load balancer', 'backend service timeout', 'backend service', 'ssl', 'load balancer', 'load balancer', 'gcloud alpha compute backend-services', 'my-backend-service \\\\', 'ssl', 'health-check my-ssl-health-check \\\\', 'timeout 5m', 'created', '[ [', 'project_id', '] /global/backendservices/my-backend-service ]', 'name backends protocol', 'ssl alternatively', 'load balancer', 'tcp', 'configure', 'backend service', 'backend service', 'instance groups', 'load balancer', 'instance group', 'particular instance group', 'additional requests', 'instance group', 'ssl', 'proxy supports', 'utilization', 'cpu', 'instance group', 'max-utilization parameter', 'default', 'instance groups', 'backend service', 'instance groups', '% utilization', 'gcloud alpha compute backend-services add-backend my-backend-service \\\\', 'instance-group us-ig1 \\\\', 'zone us-central1-b \\\\', 'utilization', 'updated', '[ [', 'project_id', '] /global/backendservices/my-backend-service ]', 'gcloud alpha compute backend-services add-backend my-backend-service \\\\', 'instance-group us-ig2 \\\\', 'zone us-east1-b \\\\', 'utilization', 'updated', '[ [', 'project_id', '] /global/backendservices/my-backend-service ]', 'configure', 'frontend services', 'section shows', 'frontend resources', 'sslcertificate', 'load balancer', 'ssl', 'proxy load balancer', 'static external', 'ip', 'firewall rule', 'load balancer', 'health checker', 'frontend', 'configure', 'ssl', 'private key', 'real certificate', 'ssl certificates', 'load balancer', 'production purposes', 'ssl', 'certificate resource', 'ssl', 'gcloud compute ssl-certificates', 'my-ssl-cert \\\\', 'certificate [', 'crt_file_path', '] \\\\', 'private-key [', 'key_file_path', 'created', '[ [', 'project_id', '] /global/sslcertificates/ssl-cert1 ]', 'name creation_timestamp', 'ssl-cert1 2016-02-20t20:53:33.584-08:00', 'configure', 'ssl', 'ssl', 'backend service', 'ssl', 'backend service', 'ssl', 'enable insertion', 'proxy', 'protocol version', 'proxy_v1', 'proxy', 'update', 'proxy protocol header', 'gcloud alpha compute target-ssl-proxies', 'my-target-ssl-proxy \\\\', 'backend-service my-backend-service \\\\', 'ssl-certificate my-ssl-cert \\\\', 'none created', '[ [', 'project_id', '] /global/targetsslproxies/my-target-ssl-proxy ]', 'name proxy_header service ssl_certificates', 'none', 'my-backend-service ssl-cert1 reserve', 'global static', 'ip', 'ip', 'ip', 'gcloud compute addresses', 'created', '[ [', 'project_id', '] /global/addresses/ssl-lb-static-ip ]', 'name region address status', 'ssl-lb-static-ip [', 'lb_static_ip', 'reserved configure', 'create', 'ips', 'ssl', 'customer traffic arrives', 'ip', 'ssl', 'target proxy', 'lb_static_ip', 'ip', 'gcloud alpha compute forwarding-rules', 'my-global-forwarding-rule \\\\', 'global \\\\', 'target-ssl-proxy my-target-ssl-proxy \\\\', 'address [', 'lb_static_ip', '] \\\\', 'created', '[ [', 'project_id', '] /global/forwardingrules/my-global-forwarding-rule ]', 'name region ip_address ip_protocol target', 'my-global-forwarding-rule [', 'lb_static_ip', 'tcp', 'create', 'firewall rule', 'ssl', 'load balancer', 'configure', 'load balancer', 'health checker', 'gcloud compute firewall-rules', 'allow-ssl-130-211-0-0-22 \\\\', 'source-ranges 130.211.0.0/22 \\\\', 'target-tags ssl-lb \\\\', 'created', '[ [', 'project_id', '] /global/firewalls/allow-ssl-130-211-0-0-22 ]', 'name network src_ranges rules src_tags target_tags', 'allow-ssl-130-211-0-0-22 default 130.211.0.0/22 tcp:443 ssl-lb', 'test', 'load balancer', 'web browser', 'ip', 'https', 'test setup', 'click', 'actual page', 'reload', 'apache', 'alternatively', \"local machine 's command line\", 'ssl', 'specify -k', 'curl -k [', 'lb_static_ip', 'additional commands listing', 'ssl', 'proxies gcloud alpha compute target-ssl-proxies list', 'name proxy_header service ssl_certificates', 'none', 'my-backend-service ssl-cert1', 'describe', 'ssl', 'proxies gcloud alpha compute target-ssl-proxies describe my-target-ssl-proxy creationtimestamp', 'compute # targetsslproxy name', 'my-target-ssl-proxy proxyheader', 'none', 'project_id', '] /global/targetsslproxies/my-target-ssl-proxy service', 'project_id', '] /global/backendservices/my-backend-service sslcertificates', 'project_id', '] /global/sslcertificates/ssl-cert1', 'delete', 'ssl', 'target proxy', 'update command', 'ssl', 'different backend service', 'new backend service', 'original proxy', 'ssl', 'ssl', 'ssl', 'certificate resource', 'gcloud alpha compute target-ssl-proxies update my-target-ssl-proxy \\\\', 'ssl-certificate ssl-cert2', 'updated', '[ [', 'project_id', '] /global/targetsslproxies/my-target-ssl-proxy ]', 'proxy', 'protocol header', 'ssl', 'gcloud alpha compute target-ssl-proxies update my-target-ssl-proxy \\\\', 'proxy-header [', 'none', 'proxy_v1', 'updated', '[ [', 'project_id', '] /global/targetsslproxies/my-target-ssl-proxy ]', 'proxy', 'client connection information', 'google cloud load balancing', 'ssl', 'proxy terminates', 'ssl', 'new connections', 'original client', 'ip', 'port information', 'proxy', 'additional header', 'original connection information', 'ip', 'ip', 'port numbers', 'proxy', 'protocol header', 'user-readable text', 'proxy tcp4', '< client', 'ip', '> < load', 'ip', '> < source port > < dest port > \\\\r\\\\n', 'proxy', 'proxy tcp4', '192.0.2.1 198.51.100.1', 'ip', 'ip', 'client port', 'destination port', 'ip', 'load balancer', 'proxy', 'protocol header', 'proxy unknown\\\\r\\\\n', 'health checks health checks', 'new connections', 'health checker polls instances', 'instances', 'unhealthy', 'health checker', 'poll unhealthy instances', 'health check', 'healthy', 'ssl', 'tcp', 'health check', 'backend instances', 'ssl', 'load balancer', 'ssl', 'health check', 'tcp', 'load balancer', 'tcp', 'health check', 'health checks', 'regular basis', 'instance groups', 'health check', 'ssl', 'ssl', 'health check', 'tcp', 'tcp', 'health check', 'simple', 'handshake health check', 'health checker attempts', 'tcp', 'ssl', 'request/response', 'health check', 'request string', 'health checker', 'tcp', 'ssl', 'instance returns', 'response string', 'healthy', 'response strings', 'new instance', 'healthy', 'healthy', 'unhealthy', 'healthy', 'existing', 'health check', 'create', 'health check gcloud alpha compute health-checks', '[ tcp | ssl ] my-ssl-health-check \\\\ [', 'port', '] \\\\ ...', 'load balancer', 'ssl', 'health check', 'tcp', 'health check', 'health check', 'check-interval [', 'check_interval', 'default= 5s', 'health check', 'valid', 'description [', 'description', 'optional textual description', 'health check', 'string contains spaces', 'healthy-threshold [', 'healthy_threshold', 'consecutive successful health checks', 'unhealthy instance', 'healthy', 'port [', 'port', 'tcp', 'ssl', 'tcp', 'port number', 'health check monitors', 'optional string', 'health checker', 'health checker', 'response field', 'health checker', 'tcp', 'ssl', 'optional string', 'health checker', 'health check', 'health checker', 'unless', 'successful handshake', 'timeout [', 'timeout', 'default= 5s', 'health checker', 'valid response', 'valid', 'unhealthy-threshold [', 'unhealthy_threshold', 'consecutive health check failures', 'healthy instance', 'unhealthy', 'list', 'health checks', 'lists', 'health checks', 'current project', 'gcloud alpha compute health-checks list', 'name protocol', 'ssl describe', 'health check', 'provides', 'specific health check', 'gcloud alpha compute health-checks describe my-ssl-health-check checkintervalsec', 'compute # healthcheck name', 'my-ssl-health-check selflink', 'project_id', '] /global/healthchecks/my-ssl-health-check sslhealthcheck', 'ssl', 'health check', 'unspecified parameters', 'gcloud alpha compute health-checks [ tcp|ssl ] update [', 'options ]', 'example', 'gcloud alpha compute health-checks update ssl my-ssl-health-check \\\\', 'ssl', 'health check', 'updated', '[ [', 'project_id', '] /global/healthchecks/my-ssl-health-check ]', 'recommendations', 'load balancer', 'proxy', 'protocol version', 'client connection information', 'https', 'https load balancing', 'ssl', 'troubleshooting pages', 'load balancer', 'ip verify', 'verify', 'healthy', 'gcloud alpha compute backend-services get-health my-backend-service', 'project_id', '] /zones/us-central1-b/resourceviews/us-ig1 status', 'compute # backendservicegrouphealth', 'project_id', '] /zones/us-east1-b/instancegroups/us-ig2 status', 'compute # backendservicegrouphealth', 'confirm', 'firewall rule', 'health checker', 'load balancer need 130.211.0.0/22', 'ssl', 'load balancer', 'ssl', 'health check', 'tcp', 'tcp', 'health check', 'instance tags', 'target_tags', 'firewall rule', 'gcloud compute firewall-rules list', 'name network src_ranges rules src_tags target_tags', 'allow-ssl-130-211-0-0-22 default 130.211.0.0/22 tcp:443 ssl-lb', 'try', 'individual instances', 'temporarily', 'firewall rule', 'specific instance', 'external_ip', 'alpha limitations', 'proxy', 'protocol header', 'load balancer', 'tcp', 'ssl', 'beta', 'faq', 'https', 'ssl', 'proxy load', 'ssl', 'https', 'https load balancing', 'additional features', 'https', 'additional functionality', 'negotiates http/2', 'spdy/3.1 rejects', 'http', 'forwards', 'different instance groups', 'url', 'integrates', 'cloud cdn', 'spreads', 'request load', 'instance utilization', 'https', 'load balances', 'ssl', 'proxy sends', 'ssl', 'tcp', 'ssl', 'google cloud load balancing', 'ssl', 'websockets', 'imap', 'ssl', 'ip', 'global load', 'load balancer', 'proxy', 'protocol version', 'original connection information', 'update', 'proxy protocol header']\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(text_tmp)\n",
    "\n",
    "\n",
    "print(blob.noun_phrases)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SSL', 'proxy', 'Google', 'Cloud', 'Load', 'Balancing', 'Alpha', 'Alpha', 'release', 'SSL', 'proxy', 'Google', 'Cloud', 'Load', 'Balancing', 'feature', 'ways', 'production', 'use', 'SLA', 'deprecation', 'policy', 'feature', 'Google', 'Cloud', 'SSL', 'proxy', 'SSL', 'TLS', 'connections', 'load', 'layer', 'connections', 'instances', 'SSL', 'TCP', 'Cloud', 'SSL', 'proxy', 'non-HTTP', 'S', 'traffic', 'HTTP', 'S', 'traffic', 'HTTP', 'S', 'load', 'balancing', 'Contents', 'Google', 'Cloud', 'Load', 'Balancing', 'SSL', 'proxy', 'SSL', 'load', 'Configure', 'instance', 'groups', 'services', 'Configure', 'services', 'Additional', 'Commands', 'Listing', 'target', 'SSL', 'Describe', 'target', 'SSL', 'Delete', 'target', 'SSL', 'proxy', 'Update', 'backend', 'service', 'target', 'SSL', 'proxy', 'Update', 'SSL', 'certificates', 'target', 'SSL', 'proxy', 'Update', 'PROXY', 'protocol', 'header', 'PROXY', 'protocol', 'client', 'connection', 'information', 'Recommendations', 'Troubleshooting', 'Pages', 'balancer', 'IP', 'Alpha', 'Limitations', 'FAQ', 'HTTPS', 'load', 'SSL', 'proxy', 'load', 'IP', 'address', 'connection', 'load', 'layer', 'SSL', 'TLS', 'SSL', 'traffic', 'SSL', 'proxy', 'customers', 'SSL', 'sessions', 'load', 'layer', 'traffic', 'machine', 'instances', 'SSL', 'TCP', 'SSL', 'proxy', 'load', 'service', 'instances', 'regions', 'load', 'balancing', 'traffic', 'region', 'closest', 'user', 'region', 'capacity', 'load', 'balancer', 'connections', 'region', 'capacity', 'connections', 'region', 'use', 'encryption', 'SSL', 'proxy', 'deployment', 'backend', 'service', 'traffic', 'SSL', 'backend-services', 'SSL', 'client', 'traffic', 'SSL', 'proxy', 'layer', 'backend', 'encryption', 'provision', 'certificates', 'keys', 'instances', 'SSL', 'processing', 'advantages', 'SSL', 'proxy', 'Intelligent', 'load', 'balancer', 'requests', 'locations', 'capacity', 'contrast', 'L3/L4', 'load', 'balancer', 'backends', 'attention', 'capacity', 'Use', 'smarter', 'allows', 'N+1', 'N+2', 'x*N.', 'Better', 'utilization', 'servers', 'SSL', 'processing', 'CPU', 'ciphers', 'CPU', 'efficient', 'order', 'CPU', 'performance', 'use', 'ECDSA', 'SSL', 'certs', 'TLS1.2', 'ECDHE-ECDSA-AES128-GCM-SHA256', 'cipher', 'suite', 'SSL', 'load', 'balancer', 'instances', 'Certificate', 'management', 'customer', 'certificate', 'place', 'certs', 'management', 'overhead', 'instances', 'certificates', 'Security', 'vulnerabilities', 'SSL', 'TCP', 'stack', 'patches', 'load', 'balancer', 'order', 'instances', 'Notes', 'traffic', 'TCP', 'backend-services', 'TCP', 'load', 'layer', 'instances', 'SSL', 'certificates', 'place', 'offload', 'SSL', 'processing', 'instances', 'security', 'load', 'layer', 'instances', 'SSL', 'proxy', 'HTTPS', 'HTTP', 'S', 'load', 'HTTPS', 'traffic', 'FAQ', 'details', 'SSL', 'proxy', 'works', 'walk', 'SSL', 'proxy', 'load', 'traffic', 'instances', 'Google', 'Cloud', 'Load', 'Balancing', 'SSL', 'proxy', 'SSL', 'proxy', 'load', 'layer', 'traffic', 'SSL', 'connection', 'layer', 'closest', 'instance', 'group', 'example', 'traffic', 'users', 'Iowa', 'Boston', 'load', 'layer', 'connection', 'backend', 'instance', 'Google', 'Cloud', 'Load', 'Balancing', 'SSL', 'termination', 'SSL', 'load', 'example', 'SSL', 'load', 'service', 'regions', 'following', 'Instance', 'groups', 'instances', 'A', 'pair', 'instances', 'instance', 'group', 'A', 'health', 'check', 'instance', 'health', 'A', 'backend', 'service', 'instances', 'groups', 'prevents', 'SSL', 'SSL', 'certificate', 'A', 'IP', 'address', 'forwarding', 'rule', 'traffic', 'proxy', 'A', 'firewall', 'rule', 'load', 'balancer', 'IP', 'address', 'configuration', 'Configure', 'instance', 'groups', 'services', 'section', 'instance', 'groups', 'instances', 'instances', 'backend', 'service', 'health', 'check', 'production', 'system', 'instance', 'groups', 'instance', 'templates', 'setup', 'testing', 'configuration', 'Create', 'instance', 'group', 'compute', 'instance-groups', 'Created', '[', '[', 'PROJECT_ID', ']', ']', 'NAME', 'ZONE', 'NETWORK', 'MANAGED', 'INSTANCES', 'compute', 'instance-groups', 'Created', '[', '[', 'PROJECT_ID', ']', ']', 'NAME', 'ZONE', 'NETWORK', 'MANAGED', 'INSTANCES', 'Create', 'instances', 'zone', 'purposes', 'Apache', 'instance', 'SSL', 'load', 'HTTP', 'traffic', 'Apache', 'instance', 'tag', 'ssl-lb', 'tag', 'firewall', 'rule', 'Add', 'instance', 'groups', 'Add', 'compute', 'instance-groups', 'add-instances', '\\\\', '\\\\', 'Updated', '[', '[', 'PROJECT_ID', ']', ']', 'Add', 'compute', 'instance-groups', 'add-instances', '\\\\', '\\\\', 'Updated', '[', '[', 'PROJECT_ID', ']', ']', 'instance', 'group', 'regions', 'instances', 'backend', 'service', 'health', 'check', 'health', 'check', 'health', 'check', 'SSL', 'TCP', 'health', 'check', 'health', 'instances', 'SSL', 'load', 'balancer', 'instances', 'SSL', 'health', 'check', 'plain', 'TCP', 'load', 'balancer', 'instances', 'TCP', 'health', 'check', 'health', 'checks', 'basis', 'port', 'instances', 'instance', 'groups', 'health', 'check', 'fails', 'instance', 'UNHEALTHY', 'load', 'balancer', 'connections', 'instance', 'instance', 'connections', 'example', 'SSL', 'health', 'check', 'backend', 'service', 'health', 'check', 'SSL', 'handshake', 'instance', 'port', 'health', 'handshake', 'row', 'default', 'instance', 'HEALTHY', 'handshake', 'row', 'default', 'HEALTHY', 'instance', 'instance', 'UNHEALTHY', 'handshake', 'row', 'instance', 'HEALTHY', 'Health', 'checks', 'section', 'information', 'options', 'compute', 'health-checks', 'my-ssl-health-check', 'port', 'Created', '[', '[', 'PROJECT_ID', ']', ']', 'NAME', 'PROTOCOL', 'my-ssl-health-check', 'SSL', 'Create', 'service', 'A', 'backend', 'service', 'capacity', 'utilization', 'health', 'check', 'instance', 'groups', 'Backend', 'services', 'traffic', 'backends', 'load', 'mode', 'backend', 'instance', 'group', 'configuration', 'traffic', 'instances', 'instance', 'group', 'instance', 'group', 'instances', 'backend', 'service', 'health', 'checks', 'instances', 'instance', 'groups', 'backend', 'service', 'duration', 'SSL', 'proxy', 'connections', 'load', 'balancer', 'backend', 'service', 'timeout', 'example', 'service', 'instances', 'SSL', 'connections', 'load', 'balancer', 'instance', 'connections', 'users', 'load', 'balancer', 'compute', 'backend-services', '\\\\', 'protocol', 'SSL', '\\\\', '\\\\', 'Created', '[', '[', 'PROJECT_ID', ']', ']', 'NAME', 'BACKENDS', 'PROTOCOL', 'my-backend-service', 'SSL', 'Alternatively', 'communication', 'load', 'balancer', 'instances', 'protocol', 'TCP', 'backend', 'service', 'backend', 'service', 'instance', 'groups', 'balancing', 'mode', 'traffic', 'load', 'balancer', 'instances', 'instance', 'group', 'limit', 'instance', 'group', 'requests', 'instance', 'group', 'closest', 'user', 'capacity', 'SSL', 'proxy', 'balancing', 'mode', 'UTILIZATION', 'default', 'instances', 'traffic', 'CPU', 'utilization', 'instance', 'group', 'value', 'value', 'max-utilization', 'parameter', 'pass', 'value', '%', '%', 'Default', '%', 'example', 'instance', 'groups', 'backend', 'service', 'mode', 'traffic', 'instance', 'groups', '%', 'utilization', 'backend-services', '\\\\', '\\\\', '\\\\', 'UTILIZATION', '\\\\', '[', '[', 'PROJECT_ID', ']', ']', 'gcloud', 'backend-services', '\\\\', '\\\\', '\\\\', 'UTILIZATION', '\\\\', '[', '[', 'PROJECT_ID', ']', ']', 'Configure', 'frontend', 'services', 'section', 'resources', 'SslCertificate', 'resource', 'load', 'SSL', 'proxy', 'load', 'balancer', 'IP', 'address', 'forwarding', 'rule', 'address', 'firewall', 'rule', 'traffic', 'load', 'balancer', 'health', 'checker', 'instances', 'Frontend', 'configuration', 'Configure', 'SSL', 'certificate', 'key', 'certificate', 'certificate', 'purposes', 'certificate', 'authority', 'SSL', 'Certificates', 'information', 'certificate', 'load', 'balancer', 'production', 'purposes', 'step', 'certificate', 'key', 'SSL', 'certificate', 'resource', 'SSL', 'proxy', 'step', 'ssl-certificates', '\\\\', 'certificate', 'CRT_FILE_PATH', ']', '\\\\', 'KEY_FILE_PATH', ']', 'Created', '[', '[', 'PROJECT_ID', ']', ']', 'NAME', 'CREATION_TIMESTAMP', 'Configure', 'target', 'SSL', 'target', 'SSL', 'proxy', 'packets', 'user', 'backend', 'service', 'target', 'SSL', 'proxy', 'backend', 'service', 'SSL', 'certificate', 'resource', 'insertion', 'PROXY', 'protocol', 'version', 'header', 'command', 'PROXY_V1', 'information', 'PROXY', 'protocol', 'Update', 'proxy', 'protocol', 'header', 'proxy', 'compute', 'target-ssl-proxies', '\\\\', '\\\\', '\\\\', 'NONE', '[', '[', 'PROJECT_ID', ']', ']', 'NAME', 'PROXY_HEADER', 'SERVICE', 'SSL_CERTIFICATES', 'NONE', 'my-backend-service', 'ssl-cert1', 'Reserve', 'IP', 'address', 'IP', 'address', 'service', 'IP', 'address', 'customers', 'access', 'load', 'service', 'compute', 'addresses', 'Created', '[', '[', 'PROJECT_ID', ']', ']', 'NAME', 'REGION', 'ADDRESS', 'STATUS', '[', 'LB_STATIC_IP', ']', 'RESERVED', 'Configure', 'forwarding', 'rule', 'Create', 'forwarding', 'rule', 'IPs', 'ports', 'target', 'SSL', 'proxy', 'customer', 'traffic', 'IP', 'address', 'forwarding', 'rule', 'network', 'traffic', 'SSL', 'proxy', 'forwarding', 'rule', 'target', 'proxy', 'LB_STATIC_IP', 'IP', 'address', 'step', 'compute', 'create', '\\\\', '\\\\', '\\\\', 'LB_STATIC_IP', ']', '\\\\', 'Created', '[', '[', 'PROJECT_ID', ']', ']', 'NAME', 'REGION', 'IP_ADDRESS', 'IP_PROTOCOL', 'TARGET', '[', 'LB_STATIC_IP', ']', 'TCP', 'Create', 'rule', 'SSL', 'load', 'balancer', 'Configure', 'firewall', 'traffic', 'load', 'balancer', 'health', 'checker', 'instances', 'firewall-rules', '\\\\', '\\\\', 'Created', '[', '[', 'PROJECT_ID', ']', ']', 'NAME', 'NETWORK', 'SRC_RANGES', 'RULES', 'SRC_TAGS', 'TARGET_TAGS', 'default', 'Test', 'load', 'balancer', 'web', 'browser', 'IP', 'address', 'HTTPS', 'test', 'setup', 'instances', 'certificates', 'warning', 'browser', 'time', 'access', 'page', 'Click', 'warning', 'page', 'hosts', 'region', 'closest', 'page', 'instance', 'region', 'instances', 'region', 'instances', 'region', 'Apache', 'instances', 'curl', 'machine', 'command', 'line', 'certificate', 'SSL', 'proxy', '-k', 'curl', '[', 'LB_STATIC_IP', ']', 'Additional', 'Commands', 'Listing', 'target', 'SSL', 'target-ssl-proxies', 'list', 'NAME', 'PROXY_HEADER', 'SERVICE', 'SSL_CERTIFICATES', 'NONE', 'my-backend-service', 'ssl-cert1', 'Describe', 'target', 'SSL', 'target-ssl-proxies', 'creationTimestamp', 'id', 'kind', 'compute', 'name', 'proxyHeader', 'NONE', 'selfLink', 'PROJECT_ID', ']', 'service', 'PROJECT_ID', ']', 'sslCertificates', '[', 'PROJECT_ID', ']', 'Delete', 'target', 'SSL', 'proxy', 'target', 'proxy', 'forwarding', 'rules', 'command', 'SSL', 'proxy', 'backend', 'service', 'example', 'backend', 'service', 'proxy', 'proxy', 'command', 'SSL', 'certificate', 'SSL', 'proxy', 'SSL', 'certificate', 'resource', 'compute', 'target-ssl-proxies', '\\\\', '[', 'PROJECT_ID', ']', ']', 'command', 'PROXY', 'protocol', 'header', 'target', 'SSL', 'proxy', 'compute', 'target-ssl-proxies', '\\\\', '[', 'NONE', '|', 'PROXY_V1', ']', 'Updated', '[', '[', 'PROJECT_ID', ']', ']', 'PROXY', 'protocol', 'client', 'connection', 'information', 'Google', 'Cloud', 'Load', 'Balancing', 'SSL', 'proxy', 'SSL', 'connections', 'client', 'connections', 'instances', 'client', 'IP', 'port', 'information', 'default', 'information', 'instances', 'PROXY', 'protocol', 'version', 'header', 'connection', 'information', 'source', 'IP', 'address', 'destination', 'IP', 'address', 'port', 'numbers', 'instance', 'part', 'request', 'PROXY', 'protocol', 'header', 'line', 'text', 'format', 'PROXY', 'TCP4', '<', 'client', 'IP', '>', '<', 'load', 'IP', '>', '<', 'source', 'port', '>', '<', 'port', '>', 'example', 'PROXY', 'protocol', 'PROXY', 'TCP4', 'client', 'IP', 'load', 'IP', 'client', 'port', 'destination', 'port', 'cases', 'client', 'IP', 'load', 'balancer', 'PROXY', 'protocol', 'header', 'format', 'PROXY', 'UNKNOWN\\\\r\\\\n', 'Health', 'checks', 'Health', 'checks', 'instances', 'connections', 'health', 'checker', 'polls', 'instances', 'intervals', 'Instances', 'check', 'UNHEALTHY', 'health', 'checker', 'instances', 'instance', 'health', 'check', 'HEALTHY', 'SSL', 'TCP', 'health', 'check', 'health', 'backend', 'instances', 'SSL', 'load', 'balancer', 'instances', 'SSL', 'health', 'check', 'plain', 'TCP', 'load', 'balancer', 'instances', 'TCP', 'health', 'check', 'health', 'checks', 'basis', 'port', 'instances', 'instance', 'groups', 'health', 'check', 'SSL', 'SSL', 'connection', 'instances', 'health', 'check', 'TCP', 'TCP', 'connection', 'health', 'checks', 'Simple', 'health', 'check', 'default', 'health', 'checker', 'TCP', 'SSL', 'instance', 'passes', 'Request/response', 'health', 'check', 'request', 'string', 'health', 'checker', 'TCP', 'SSL', 'instance', 'response', 'string', 'instance', 'HEALTHY', 'request', 'response', 'strings', 'bytes', 'check', 'row', 'default', 'instance', 'instance', 'HEALTHY', 'check', 'row', 'default', 'HEALTHY', 'instance', 'instance', 'UNHEALTHY', 'check', 'row', 'default', 'instance', 'HEALTHY', 'connections', 'instances', 'health', 'check', 'health', 'check', 'gcloud', 'health-checks', 'tcp', '|', 'ssl', ']', 'my-ssl-health-check', '\\\\', '[', 'port', 'PORT', ']', '\\\\', 'options', 'traffic', 'load', 'balancer', 'instances', 'SSL', 'health', 'check', 'traffic', 'TCP', 'health', 'check', 'Health', 'check', 'create', 'options', 'CHECK_INTERVAL', ']', 'How', 'health', 'check', 'instance', 'example', 'check', 'seconds', 'Valid', 'units', 'flag', 'seconds', 'm', 'minutes', 'description', 'DESCRIPTION', ']', 'description', 'health', 'check', 'Must', 'quotes', 'string', 'spaces', '[', 'HEALTHY_THRESHOLD', ']', 'number', 'health', 'checks', 'instance', 'HEALTHY', 'port', 'PORT', ']', 'TCP', 'SSL', 'TCP', 'port', 'number', 'health', 'check', 'monitors', 'string', 'characters', 'health', 'checker', 'instance', 'health', 'checker', 'reply', 'instance', 'string', 'response', 'field', 'response', 'health', 'checker', 'response', 'check', 'TCP', 'SSL', 'handshake', 'response', 'string', 'characters', 'health', 'checker', 'instance', 'response', 'health', 'check', 'fails', 'response', 'health', 'checker', 'response', 'system', 'message', 'response', 'handshake', 'configure', 'response', 'explicit', 'request', '[', 'TIMEOUT', ']', 'health', 'checker', 'response', 'instance', 'interval', 'check', 'failure', 'example', 'check', 'seconds', 'request', 'failure', 'units', 'flag', 'seconds', 'm', 'minutes', '[', 'UNHEALTHY_THRESHOLD', ']', 'number', 'health', 'check', 'failures', 'instance', 'UNHEALTHY', 'List', 'health', 'checks', 'health', 'checks', 'project', 'compute', 'health-checks', 'list', 'NAME', 'PROTOCOL', 'my-ssl-health-check', 'SSL', 'Describe', 'health', 'check', 'Provides', 'information', 'health', 'check', 'compute', 'health-checks', 'checkIntervalSec', 'creationTimestamp', 'description', 'healthyThreshold', 'id', 'kind', 'compute', 'healthCheck', 'name', 'selfLink', 'PROJECT_ID', ']', 'sslHealthCheck', 'port', 'timeoutSec', 'type', 'SSL', 'parameter', 'health', 'check', 'command', 'pass', 'create', 'parameters', 'parameters', 'parameters', 'compute', 'health-checks', '[', 'tcp|ssl', ']', 'update', '[', 'options', 'Example', 'gcloud', 'health-checks', 'my-ssl-health-check', '\\\\', 'description', 'SSL', 'health', 'check', '[', '[', 'PROJECT_ID', ']', ']', 'Recommendations', 'load', 'balancer', 'PROXY', 'protocol', 'version', 'header', 'client', 'connection', 'information', 'traffic', 'HTTPS', 'HTTPS', 'Load', 'Balancing', 'SSL', 'proxy', 'load', 'balancing', 'Pages', 'balancer', 'IP', 'Verify', 'health', 'instances', 'Verify', 'instances', 'HEALTHY', 'backend-services', 'my-backend-service', 'backend', 'PROJECT_ID', ']', 'status', 'kind', 'compute', 'backendServiceGroupHealth', 'backend', 'PROJECT_ID', ']', 'status', 'kind', 'compute', 'backendServiceGroupHealth', 'Confirm', 'firewall', 'rule', 'Both', 'health', 'checker', 'load', 'balancer', 'SSL', 'load', 'balancer', 'instances', 'SSL', 'health', 'check', 'case', 'tcp:443', 'firewall', 'TCP', 'instances', 'TCP', 'health', 'check', 'tcp:80', 'instance', 'tags', 'tag', 'TARGET_TAGS', 'firewall', 'rule', 'instances', 'tag', 'example', 'instances', 'firewall-rules', 'list', 'NAME', 'NETWORK', 'SRC_RANGES', 'RULES', 'SRC_TAGS', 'TARGET_TAGS', 'default', 'tcp:443', 'Try', 'instances', 'firewall', 'rule', 'access', 'instances', 'page', 'instance', 'access', 'instances', 'browser', 'EXTERNAL_IP', ']', 'Alpha', 'Limitations', 'PROXY', 'protocol', 'header', 'protocol', 'load', 'balancer', 'instance', 'TCP', 'protocol', 'SSL', 'Beta', 'timeframe', 'FAQ', 'HTTPS', 'load', 'SSL', 'proxy', 'load', 'SSL', 'proxy', 'HTTPS', 'traffic', 'HTTPS', 'Load', 'Balancing', 'features', 'choice', 'cases', 'HTTPS', 'load', 'balancing', 'functionality', 'Negotiates', 'HTTP/2', 'SPDY/3.1', 'Rejects', 'HTTP', 'requests', 'responses', 'Forwards', 'requests', 'instance', 'groups', 'URL', 'host', 'path', 'Integrates', 'Cloud', 'CDN', 'request', 'load', 'instances', 'instance', 'utilization', 'HTTPS', 'load', 'balances', 'request', 'whereas', 'SSL', 'proxy', 'bytes', 'SSL', 'TCP', 'connection', 'instance', 'SSL', 'proxy', 'Google', 'Cloud', 'Load', 'Balancing', 'protocols', 'SSL', 'Websockets', 'IMAP', 'SSL', 'IP', 'address', 'connection', 'load', 'layer', 'load', 'balancer', 'PROXY', 'protocol', 'version', 'header', 'connection', 'information', 'Update', 'protocol', 'header', 'proxy', 'details']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "# function to test if something is a noun\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "# do the nlp stuff\n",
    "tokenized = nltk.word_tokenize(text_tmp)\n",
    "nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)] \n",
    "\n",
    "print (nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'SSL': 103, 'instance': 61, 'health': 60, 'load': 59, 'instances': 57, ']': 55, 'proxy': 46, 'check': 44, '[': 42, 'balancer': 31, '\\\\': 31, 'traffic': 27, 'TCP': 25, 'service': 24, 'backend': 23, 'PROJECT_ID': 22, 'IP': 21, 'protocol': 19, 'compute': 18, 'PROXY': 16, 'groups': 15, 'target': 15, 'address': 14, 'certificate': 14, 'port': 14, 'connections': 13, 'rule': 13, 'checker': 13, 'connection': 12, 'NAME': 12, 'response': 12, 'header': 11, 'information': 11, 'HTTPS': 11, 'group': 11, 'Cloud': 10, 'layer': 10, 'client': 10, 'example': 10, 'checks': 10, 'default': 10, 'HEALTHY': 10, 'Load': 9, 'Balancing': 9, 'Google': 8, 'Configure': 8, 'region': 8, 'firewall': 8, 'Created': 8, 'forwarding': 7, 'request': 7, 'balancing': 6, 'capacity': 6, 'backend-services': 6, 'A': 6, 'handshake': 6, 'row': 6, 'health-checks': 6, 'command': 6, 'string': 6, 'HTTP': 5, 'services': 5, 'Update': 5, 'certificates': 5, 'utilization': 5, 'Create': 5, 'UNHEALTHY': 5, 'my-ssl-health-check': 5, 'target-ssl-proxies': 5, 'NONE': 5, 'LB_STATIC_IP': 5, 'Alpha': 4, 'S': 4, 'closest': 4, 'requests': 4, 'CPU': 4, 'configuration': 4, 'instance-groups': 4, 'NETWORK': 4, 'tag': 4, 'Health': 4, 'options': 4, 'mode': 4, 'my-backend-service': 4, '%': 4, 'resource': 4, 'version': 4, 'access': 4, 'page': 4, 'kind': 4, '<': 4, '>': 4, 'seconds': 4, 'description': 4, 'production': 3, 'use': 3, 'Describe': 3, 'FAQ': 3, 'regions': 3, 'user': 3, 'processing': 3, 'section': 3, 'purposes': 3, 'Apache': 3, 'Add': 3, 'Updated': 3, 'PROTOCOL': 3, 'UTILIZATION': 3, 'value': 3, 'gcloud': 3, 'step': 3, 'create': 3, 'TARGET_TAGS': 3, 'browser': 3, 'list': 3, 'number': 3, 'parameters': 3, 'feature': 2, 'TLS': 2, 'Additional': 2, 'Commands': 2, 'Listing': 2, 'Delete': 2, 'Recommendations': 2, 'Pages': 2, 'Limitations': 2, 'customers': 2, 'machine': 2, 'encryption': 2, 'backends': 2, 'order': 2, 'certs': 2, 'management': 2, 'customer': 2, 'place': 2, 'details': 2, 'users': 2, 'system': 2, 'setup': 2, 'ZONE': 2, 'MANAGED': 2, 'INSTANCES': 2, 'add-instances': 2, 'plain': 2, 'basis': 2, 'fails': 2, 'parameter': 2, 'pass': 2, 'key': 2, 'PROXY_V1': 2, 'PROXY_HEADER': 2, 'SERVICE': 2, 'SSL_CERTIFICATES': 2, 'ssl-cert1': 2, 'REGION': 2, 'firewall-rules': 2, 'SRC_RANGES': 2, 'RULES': 2, 'SRC_TAGS': 2, 'warning': 2, 'curl': 2, 'line': 2, 'creationTimestamp': 2, 'id': 2, 'name': 2, 'selfLink': 2, '|': 2, 'source': 2, 'destination': 2, 'format': 2, 'TCP4': 2, 'cases': 2, 'bytes': 2, 'PORT': 2, 'units': 2, 'flag': 2, 'm': 2, 'minutes': 2, 'characters': 2, 'failure': 2, 'Verify': 2, 'status': 2, 'backendServiceGroupHealth': 2, 'tcp:443': 2, 'release': 1, 'ways': 1, 'SLA': 1, 'deprecation': 1, 'policy': 1, 'non-HTTP': 1, 'Contents': 1, 'Troubleshooting': 1, 'sessions': 1, 'deployment': 1, 'provision': 1, 'keys': 1, 'advantages': 1, 'Intelligent': 1, 'locations': 1, 'contrast': 1, 'L3/L4': 1, 'attention': 1, 'Use': 1, 'smarter': 1, 'allows': 1, 'N+1': 1, 'N+2': 1, 'x*N.': 1, 'Better': 1, 'servers': 1, 'ciphers': 1, 'efficient': 1, 'performance': 1, 'ECDSA': 1, 'TLS1.2': 1, 'ECDHE-ECDSA-AES128-GCM-SHA256': 1, 'cipher': 1, 'suite': 1, 'Certificate': 1, 'overhead': 1, 'Security': 1, 'vulnerabilities': 1, 'stack': 1, 'patches': 1, 'Notes': 1, 'offload': 1, 'security': 1, 'works': 1, 'walk': 1, 'Iowa': 1, 'Boston': 1, 'termination': 1, 'following': 1, 'Instance': 1, 'pair': 1, 'prevents': 1, 'templates': 1, 'testing': 1, 'zone': 1, 'ssl-lb': 1, 'Backend': 1, 'duration': 1, 'timeout': 1, 'BACKENDS': 1, 'Alternatively': 1, 'communication': 1, 'limit': 1, 'max-utilization': 1, 'Default': 1, 'frontend': 1, 'resources': 1, 'SslCertificate': 1, 'Frontend': 1, 'authority': 1, 'Certificates': 1, 'ssl-certificates': 1, 'CRT_FILE_PATH': 1, 'KEY_FILE_PATH': 1, 'CREATION_TIMESTAMP': 1, 'packets': 1, 'insertion': 1, 'Reserve': 1, 'addresses': 1, 'ADDRESS': 1, 'STATUS': 1, 'RESERVED': 1, 'IPs': 1, 'ports': 1, 'network': 1, 'IP_ADDRESS': 1, 'IP_PROTOCOL': 1, 'TARGET': 1, 'Test': 1, 'web': 1, 'test': 1, 'time': 1, 'Click': 1, 'hosts': 1, '-k': 1, 'proxyHeader': 1, 'sslCertificates': 1, 'rules': 1, 'numbers': 1, 'part': 1, 'text': 1, 'UNKNOWN\\\\r\\\\n': 1, 'polls': 1, 'intervals': 1, 'Instances': 1, 'Simple': 1, 'passes': 1, 'Request/response': 1, 'strings': 1, 'tcp': 1, 'ssl': 1, 'CHECK_INTERVAL': 1, 'How': 1, 'Valid': 1, 'DESCRIPTION': 1, 'Must': 1, 'quotes': 1, 'spaces': 1, 'HEALTHY_THRESHOLD': 1, 'monitors': 1, 'reply': 1, 'field': 1, 'message': 1, 'configure': 1, 'explicit': 1, 'TIMEOUT': 1, 'interval': 1, 'UNHEALTHY_THRESHOLD': 1, 'failures': 1, 'List': 1, 'project': 1, 'Provides': 1, 'checkIntervalSec': 1, 'healthyThreshold': 1, 'healthCheck': 1, 'sslHealthCheck': 1, 'timeoutSec': 1, 'type': 1, 'tcp|ssl': 1, 'update': 1, 'Example': 1, 'Confirm': 1, 'Both': 1, 'case': 1, 'tcp:80': 1, 'tags': 1, 'Try': 1, 'EXTERNAL_IP': 1, 'Beta': 1, 'timeframe': 1, 'features': 1, 'choice': 1, 'functionality': 1, 'Negotiates': 1, 'HTTP/2': 1, 'SPDY/3.1': 1, 'Rejects': 1, 'responses': 1, 'Forwards': 1, 'URL': 1, 'host': 1, 'path': 1, 'Integrates': 1, 'CDN': 1, 'balances': 1, 'whereas': 1, 'protocols': 1, 'Websockets': 1, 'IMAP': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(nouns)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1>  content-based reccommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     All of this work is still very early. The firs...\n",
       "2     The alarm clock wakes me at 8:00 with stream o...\n",
       "3     We're excited to share the Google Data Center ...\n",
       "4     The Aite Group projects the blockchain market ...\n",
       "5     One of the largest and oldest organizations fo...\n",
       "6     It will take time until banks come around to t...\n",
       "7     When most people think about computers and rob...\n",
       "8     Bitcoin.com spoke with the OpenLedger CEO, Ron...\n",
       "9     Ethereum, considered by many to be the most pr...\n",
       "10    A queda nas vendas e a deterioração na situaçã...\n",
       "11    HTTP(S) load balancing provides global load ba...\n",
       "12    Alpha This is an Alpha release of Setting Up S...\n",
       "13    You may know Dell as a computer and server mak...\n",
       "14    The Uber model just doesn't work for other ind...\n",
       "15    Industrial adoption of IoT dubbed as Industria...\n",
       "16    Artigos e Palestras ARTIGOS / 2015 12/08/2015 ...\n",
       "17    Do Se Te Qu Qu Se Sa 27 28 29 30 31 Faça downl...\n",
       "18    Five Bitcoin and Ethereum Based Projects to Wa...\n",
       "19    CommonAccord, a blockchain-based startup for l...\n",
       "20    The blockchain ecosystem is always in need of ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check texts\n",
    "df_articles['text'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3011, 72314)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature extraction\n",
    "\n",
    "#Import TfIdfVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "#Replace NaN with an empty string\n",
    "df_articles['text'] = df_articles['text'].fillna('')\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(df_articles['text'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Construct a reverse map of indices and movie titles\n",
    "indices = pd.Series(df_articles.index, index=df_articles['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that takes in movie title as input and outputs most similar movies\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the movie that matches the title\n",
    "    \n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    article_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return df_articles['title'].iloc[article_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make our first recommendation based on content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
       "      <td>All of this work is still very early. The firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bitcoin Future: When GBPcoin of Branson Wins O...</td>\n",
       "      <td>The alarm clock wakes me at 8:00 with stream o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google Data Center 360° Tour</td>\n",
       "      <td>We're excited to share the Google Data Center ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBM Wants to \"Evolve the Internet\" With Blockc...</td>\n",
       "      <td>The Aite Group projects the blockchain market ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IEEE to Talk Blockchain at Cloud Computing Oxf...</td>\n",
       "      <td>One of the largest and oldest organizations fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Banks Need To Collaborate With Bitcoin and Fin...</td>\n",
       "      <td>It will take time until banks come around to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blockchain Technology Could Put Bank Auditors ...</td>\n",
       "      <td>When most people think about computers and rob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Why Decentralized Conglomerates Will Scale Bet...</td>\n",
       "      <td>Bitcoin.com spoke with the OpenLedger CEO, Ron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Rise And Growth of Ethereum Gets Mainstrea...</td>\n",
       "      <td>Ethereum, considered by many to be the most pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Situação financeira ruim de varejistas pressio...</td>\n",
       "      <td>A queda nas vendas e a deterioração na situaçã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Setting Up HTTP(S) Load Balancing</td>\n",
       "      <td>HTTP(S) load balancing provides global load ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Setting Up SSL proxy for Google Cloud Load Bal...</td>\n",
       "      <td>Alpha This is an Alpha release of Setting Up S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NTT to buy Dell's services division for $3.05 ...</td>\n",
       "      <td>You may know Dell as a computer and server mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Good riddance, gig economy: Uber, Ayn Rand and...</td>\n",
       "      <td>The Uber model just doesn't work for other ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The internet of a billion things | ET CIO</td>\n",
       "      <td>Industrial adoption of IoT dubbed as Industria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Artigos e Palestras - Programa Agricultura de ...</td>\n",
       "      <td>Artigos e Palestras ARTIGOS / 2015 12/08/2015 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Rede Agricultura de Precisão II</td>\n",
       "      <td>Do Se Te Qu Qu Se Sa 27 28 29 30 31 Faça downl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Five Bitcoin and Ethereum Based Projects to Wa...</td>\n",
       "      <td>Five Bitcoin and Ethereum Based Projects to Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Blockchain Smart Contracts Startup Selected By...</td>\n",
       "      <td>CommonAccord, a blockchain-based startup for l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Using Gamified Hacking Challenges To Attract N...</td>\n",
       "      <td>The blockchain ecosystem is always in need of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "1   Ethereum, a Virtual Currency, Enables Transact...   \n",
       "2   Bitcoin Future: When GBPcoin of Branson Wins O...   \n",
       "3                        Google Data Center 360° Tour   \n",
       "4   IBM Wants to \"Evolve the Internet\" With Blockc...   \n",
       "5   IEEE to Talk Blockchain at Cloud Computing Oxf...   \n",
       "6   Banks Need To Collaborate With Bitcoin and Fin...   \n",
       "7   Blockchain Technology Could Put Bank Auditors ...   \n",
       "8   Why Decentralized Conglomerates Will Scale Bet...   \n",
       "9   The Rise And Growth of Ethereum Gets Mainstrea...   \n",
       "10  Situação financeira ruim de varejistas pressio...   \n",
       "11                  Setting Up HTTP(S) Load Balancing   \n",
       "12  Setting Up SSL proxy for Google Cloud Load Bal...   \n",
       "13  NTT to buy Dell's services division for $3.05 ...   \n",
       "14  Good riddance, gig economy: Uber, Ayn Rand and...   \n",
       "15          The internet of a billion things | ET CIO   \n",
       "16  Artigos e Palestras - Programa Agricultura de ...   \n",
       "17                    Rede Agricultura de Precisão II   \n",
       "18  Five Bitcoin and Ethereum Based Projects to Wa...   \n",
       "19  Blockchain Smart Contracts Startup Selected By...   \n",
       "20  Using Gamified Hacking Challenges To Attract N...   \n",
       "\n",
       "                                                 text  \n",
       "1   All of this work is still very early. The firs...  \n",
       "2   The alarm clock wakes me at 8:00 with stream o...  \n",
       "3   We're excited to share the Google Data Center ...  \n",
       "4   The Aite Group projects the blockchain market ...  \n",
       "5   One of the largest and oldest organizations fo...  \n",
       "6   It will take time until banks come around to t...  \n",
       "7   When most people think about computers and rob...  \n",
       "8   Bitcoin.com spoke with the OpenLedger CEO, Ron...  \n",
       "9   Ethereum, considered by many to be the most pr...  \n",
       "10  A queda nas vendas e a deterioração na situaçã...  \n",
       "11  HTTP(S) load balancing provides global load ba...  \n",
       "12  Alpha This is an Alpha release of Setting Up S...  \n",
       "13  You may know Dell as a computer and server mak...  \n",
       "14  The Uber model just doesn't work for other ind...  \n",
       "15  Industrial adoption of IoT dubbed as Industria...  \n",
       "16  Artigos e Palestras ARTIGOS / 2015 12/08/2015 ...  \n",
       "17  Do Se Te Qu Qu Se Sa 27 28 29 30 31 Faça downl...  \n",
       "18  Five Bitcoin and Ethereum Based Projects to Wa...  \n",
       "19  CommonAccord, a blockchain-based startup for l...  \n",
       "20  The blockchain ecosystem is always in need of ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles[['title','text']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2378    Are you a bitcoin denialist? - Chris Skinner's...\n",
       "375          Blockchain won't kill banks: Bitcoin pioneer\n",
       "181     Venture Capitalists Inject Nearly Half a Billi...\n",
       "334     Our Goal is to Replace Your Need for a Bank, S...\n",
       "932      Confused by blockchains? Revolution vs Evolution\n",
       "227     IBM Watson is Working to Bring AI to the Block...\n",
       "22      From fine wine to lotteries: Blockchain tech t...\n",
       "2328    Banks find blockchain hard to put into practic...\n",
       "928                      The Blockchain is the new Google\n",
       "50      Blockstream Among 10 New Firms to Join Hyperle...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('Google Data Center 360° Tour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1>User Preference\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different interaction types represent different levels of like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Preference_level = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 3.0, \n",
    "   'FOLLOW': 4.0,\n",
    "   'COMMENT CREATED': 5.0,  \n",
    "}\n",
    "\n",
    "df_users['Preference_level'] = df_users['eventType'].apply(lambda x: Preference_level[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>personId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userRegion</th>\n",
       "      <th>userCountry</th>\n",
       "      <th>Preference_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1465413032</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-3499919498720038879</td>\n",
       "      <td>-8845298781299428018</td>\n",
       "      <td>1264196770339959068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1465412560</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>8890720798209849691</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3621737643587579081</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...</td>\n",
       "      <td>NY</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1465416190</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1130272294246983140</td>\n",
       "      <td>2631864456530402479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1465413895</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>344280948527967603</td>\n",
       "      <td>-3167637573980064150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465412290</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-7820640624231356730</td>\n",
       "      <td>-445337111692715325</td>\n",
       "      <td>5611481178424124714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1465413742</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-8763398617720485024</td>\n",
       "      <td>1395789369402380392</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1465415950</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-8864073373672512525</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>1143207167886864524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1465415066</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-1492913151930215984</td>\n",
       "      <td>4254153380739593270</td>\n",
       "      <td>8743229464706506141</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1465413762</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>344280948527967603</td>\n",
       "      <td>-3167637573980064150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1465413771</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>3064370296170038610</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>1143207167886864524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp eventType            contentId             personId  \\\n",
       "0  1465413032      VIEW -3499919498720038879 -8845298781299428018   \n",
       "1  1465412560      VIEW  8890720798209849691 -1032019229384696495   \n",
       "2  1465416190      VIEW   310515487419366995 -1130272294246983140   \n",
       "3  1465413895    FOLLOW   310515487419366995   344280948527967603   \n",
       "4  1465412290      VIEW -7820640624231356730  -445337111692715325   \n",
       "5  1465413742      VIEW   310515487419366995 -8763398617720485024   \n",
       "6  1465415950      VIEW -8864073373672512525  3609194402293569455   \n",
       "7  1465415066      VIEW -1492913151930215984  4254153380739593270   \n",
       "8  1465413762      VIEW   310515487419366995   344280948527967603   \n",
       "9  1465413771      VIEW  3064370296170038610  3609194402293569455   \n",
       "\n",
       "             sessionId                                          userAgent  \\\n",
       "0  1264196770339959068                                                NaN   \n",
       "1  3621737643587579081  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...   \n",
       "2  2631864456530402479                                                NaN   \n",
       "3 -3167637573980064150                                                NaN   \n",
       "4  5611481178424124714                                                NaN   \n",
       "5  1395789369402380392  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "6  1143207167886864524                                                NaN   \n",
       "7  8743229464706506141  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "8 -3167637573980064150                                                NaN   \n",
       "9  1143207167886864524                                                NaN   \n",
       "\n",
       "  userRegion userCountry  Preference_level  \n",
       "0        NaN         NaN               1.0  \n",
       "1         NY          US               1.0  \n",
       "2        NaN         NaN               1.0  \n",
       "3        NaN         NaN               4.0  \n",
       "4        NaN         NaN               1.0  \n",
       "5         MG          BR               1.0  \n",
       "6        NaN         NaN               1.0  \n",
       "7         SP          BR               1.0  \n",
       "8        NaN         NaN               1.0  \n",
       "9        NaN         NaN               1.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61086, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>personId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userRegion</th>\n",
       "      <th>userCountry</th>\n",
       "      <th>Preference_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1465413032</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-3499919498720038879</td>\n",
       "      <td>-8845298781299428018</td>\n",
       "      <td>1264196770339959068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1465412560</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>8890720798209849691</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3621737643587579081</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...</td>\n",
       "      <td>NY</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1465416190</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1130272294246983140</td>\n",
       "      <td>2631864456530402479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465412290</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-7820640624231356730</td>\n",
       "      <td>-445337111692715325</td>\n",
       "      <td>5611481178424124714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1465413742</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-8763398617720485024</td>\n",
       "      <td>1395789369402380392</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp eventType            contentId             personId  \\\n",
       "0  1465413032      VIEW -3499919498720038879 -8845298781299428018   \n",
       "1  1465412560      VIEW  8890720798209849691 -1032019229384696495   \n",
       "2  1465416190      VIEW   310515487419366995 -1130272294246983140   \n",
       "4  1465412290      VIEW -7820640624231356730  -445337111692715325   \n",
       "5  1465413742      VIEW   310515487419366995 -8763398617720485024   \n",
       "\n",
       "             sessionId                                          userAgent  \\\n",
       "0  1264196770339959068                                                NaN   \n",
       "1  3621737643587579081  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...   \n",
       "2  2631864456530402479                                                NaN   \n",
       "4  5611481178424124714                                                NaN   \n",
       "5  1395789369402380392  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "\n",
       "  userRegion userCountry  Preference_level  \n",
       "0        NaN         NaN               1.0  \n",
       "1         NY          US               1.0  \n",
       "2        NaN         NaN               1.0  \n",
       "4        NaN         NaN               1.0  \n",
       "5         MG          BR               1.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventtypes=['VIEW']\n",
    "\n",
    "eventType_View = df_users[df_users.eventType.isin(eventtypes)]\n",
    "\n",
    "print(eventType_View.shape)\n",
    "\n",
    "eventType_View.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5745, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>personId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userRegion</th>\n",
       "      <th>userCountry</th>\n",
       "      <th>Preference_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1465415756</td>\n",
       "      <td>LIKE</td>\n",
       "      <td>-8142426490949346803</td>\n",
       "      <td>1908339160857512799</td>\n",
       "      <td>9121879357144259163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1465413867</td>\n",
       "      <td>LIKE</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>1143207167886864524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1465413845</td>\n",
       "      <td>LIKE</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>344280948527967603</td>\n",
       "      <td>-3167637573980064150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1465413946</td>\n",
       "      <td>LIKE</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-8763398617720485024</td>\n",
       "      <td>1395789369402380392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1465413763</td>\n",
       "      <td>LIKE</td>\n",
       "      <td>-1492913151930215984</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>1143207167886864524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp eventType            contentId             personId  \\\n",
       "33  1465415756      LIKE -8142426490949346803  1908339160857512799   \n",
       "36  1465413867      LIKE   310515487419366995  3609194402293569455   \n",
       "40  1465413845      LIKE   310515487419366995   344280948527967603   \n",
       "43  1465413946      LIKE   310515487419366995 -8763398617720485024   \n",
       "56  1465413763      LIKE -1492913151930215984  3609194402293569455   \n",
       "\n",
       "              sessionId userAgent userRegion userCountry  Preference_level  \n",
       "33  9121879357144259163       NaN        NaN         NaN               2.0  \n",
       "36  1143207167886864524       NaN        NaN         NaN               2.0  \n",
       "40 -3167637573980064150       NaN        NaN         NaN               2.0  \n",
       "43  1395789369402380392       NaN        NaN         NaN               2.0  \n",
       "56  1143207167886864524       NaN        NaN         NaN               2.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventtypes=['LIKE']\n",
    "\n",
    "eventType_Like = df_users[df_users.eventType.isin(eventtypes)]\n",
    "\n",
    "\n",
    "print(eventType_Like.shape)\n",
    "\n",
    "eventType_Like.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2463, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>personId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userRegion</th>\n",
       "      <th>userCountry</th>\n",
       "      <th>Preference_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1465413879</td>\n",
       "      <td>BOOKMARK</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>1143207167886864524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1465413954</td>\n",
       "      <td>BOOKMARK</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-8763398617720485024</td>\n",
       "      <td>1395789369402380392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1465413873</td>\n",
       "      <td>BOOKMARK</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>344280948527967603</td>\n",
       "      <td>-3167637573980064150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1460567399</td>\n",
       "      <td>BOOKMARK</td>\n",
       "      <td>-5557505576293652420</td>\n",
       "      <td>-2772844562500836582</td>\n",
       "      <td>-4457986168060768634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1465846305</td>\n",
       "      <td>BOOKMARK</td>\n",
       "      <td>1415230502586719648</td>\n",
       "      <td>3636910968448833585</td>\n",
       "      <td>9055424356075682444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp eventType            contentId             personId  \\\n",
       "25   1465413879  BOOKMARK   310515487419366995  3609194402293569455   \n",
       "27   1465413954  BOOKMARK   310515487419366995 -8763398617720485024   \n",
       "37   1465413873  BOOKMARK   310515487419366995   344280948527967603   \n",
       "107  1460567399  BOOKMARK -5557505576293652420 -2772844562500836582   \n",
       "178  1465846305  BOOKMARK  1415230502586719648  3636910968448833585   \n",
       "\n",
       "               sessionId userAgent userRegion userCountry  Preference_level  \n",
       "25   1143207167886864524       NaN        NaN         NaN               3.0  \n",
       "27   1395789369402380392       NaN        NaN         NaN               3.0  \n",
       "37  -3167637573980064150       NaN        NaN         NaN               3.0  \n",
       "107 -4457986168060768634       NaN        NaN         NaN               3.0  \n",
       "178  9055424356075682444       NaN        NaN         NaN               3.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventtypes=['BOOKMARK']\n",
    "\n",
    "eventType_Bookmark = df_users[df_users.eventType.isin(eventtypes)]\n",
    "\n",
    "print(eventType_Bookmark.shape)\n",
    "\n",
    "eventType_Bookmark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1407, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>personId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userRegion</th>\n",
       "      <th>userCountry</th>\n",
       "      <th>Preference_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1465413895</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>344280948527967603</td>\n",
       "      <td>-3167637573980064150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1466034457</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-4205346868684833897</td>\n",
       "      <td>-1387464358334758758</td>\n",
       "      <td>5111485313337394011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1460566517</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>4761910285123871012</td>\n",
       "      <td>-108842214936804958</td>\n",
       "      <td>-9137723263631808218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1463360064</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-6255158415883847921</td>\n",
       "      <td>6013226412048763966</td>\n",
       "      <td>7846471679835395183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1463357802</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-5181489804915739633</td>\n",
       "      <td>-1443636648652872475</td>\n",
       "      <td>-2256095188093371416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp eventType            contentId             personId  \\\n",
       "3    1465413895    FOLLOW   310515487419366995   344280948527967603   \n",
       "69   1466034457    FOLLOW -4205346868684833897 -1387464358334758758   \n",
       "78   1460566517    FOLLOW  4761910285123871012  -108842214936804958   \n",
       "257  1463360064    FOLLOW -6255158415883847921  6013226412048763966   \n",
       "259  1463357802    FOLLOW -5181489804915739633 -1443636648652872475   \n",
       "\n",
       "               sessionId userAgent userRegion userCountry  Preference_level  \n",
       "3   -3167637573980064150       NaN        NaN         NaN               4.0  \n",
       "69   5111485313337394011       NaN        NaN         NaN               4.0  \n",
       "78  -9137723263631808218       NaN        NaN         NaN               4.0  \n",
       "257  7846471679835395183       NaN        NaN         NaN               4.0  \n",
       "259 -2256095188093371416       NaN        NaN         NaN               4.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventtypes=['FOLLOW']\n",
    "\n",
    "eventType_Follow = df_users[df_users.eventType.isin(eventtypes)]\n",
    "\n",
    "print(eventType_Follow.shape)\n",
    "\n",
    "eventType_Follow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>personId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userRegion</th>\n",
       "      <th>userCountry</th>\n",
       "      <th>Preference_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1466034456</td>\n",
       "      <td>COMMENT CREATED</td>\n",
       "      <td>-4205346868684833897</td>\n",
       "      <td>-1387464358334758758</td>\n",
       "      <td>5111485313337394011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1466034895</td>\n",
       "      <td>COMMENT CREATED</td>\n",
       "      <td>-4205346868684833897</td>\n",
       "      <td>-1387464358334758758</td>\n",
       "      <td>5111485313337394011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1466034818</td>\n",
       "      <td>COMMENT CREATED</td>\n",
       "      <td>-4205346868684833897</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>-5537786999103108189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1460569522</td>\n",
       "      <td>COMMENT CREATED</td>\n",
       "      <td>-2261845840076552387</td>\n",
       "      <td>4340306774493623681</td>\n",
       "      <td>6173407106018486716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1460568099</td>\n",
       "      <td>COMMENT CREATED</td>\n",
       "      <td>5688279681867464747</td>\n",
       "      <td>-108842214936804958</td>\n",
       "      <td>-9137723263631808218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp        eventType            contentId             personId  \\\n",
       "61   1466034456  COMMENT CREATED -4205346868684833897 -1387464358334758758   \n",
       "62   1466034895  COMMENT CREATED -4205346868684833897 -1387464358334758758   \n",
       "71   1466034818  COMMENT CREATED -4205346868684833897 -1032019229384696495   \n",
       "122  1460569522  COMMENT CREATED -2261845840076552387  4340306774493623681   \n",
       "124  1460568099  COMMENT CREATED  5688279681867464747  -108842214936804958   \n",
       "\n",
       "               sessionId userAgent userRegion userCountry  Preference_level  \n",
       "61   5111485313337394011       NaN        NaN         NaN               5.0  \n",
       "62   5111485313337394011       NaN        NaN         NaN               5.0  \n",
       "71  -5537786999103108189       NaN        NaN         NaN               5.0  \n",
       "122  6173407106018486716       NaN        NaN         NaN               5.0  \n",
       "124 -9137723263631808218       NaN        NaN         NaN               5.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventtypes=['COMMENT CREATED']\n",
    "\n",
    "eventType_Comment = df_users[df_users.eventType.isin(eventtypes)]\n",
    "\n",
    "print(eventType_Comment.shape)\n",
    "\n",
    "eventType_Comment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11226, 9)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventtypes=['LIKE','BOOKMARK','FOLLOW','COMMENT CREATED']\n",
    "\n",
    "eventType_more_than_view = df_users[df_users.eventType.isin(eventtypes)]\n",
    "\n",
    "eventType_more_than_view.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1>Articles Recommendation for a user based on user preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Recommend_user_preference(n):\n",
    "    \n",
    "\n",
    "    tmp_1 =df_users.loc[df_users['personId'] == n].sort_values(by='Preference_level', ascending=False)\n",
    "\n",
    "    content_ID = tmp_1['contentId'].iloc[0]\n",
    "    \n",
    "    tmp_2 = df_articles.loc[df_articles['contentId'] == content_ID]\n",
    "\n",
    "    title_content = tmp_2['title'].iloc[0]\n",
    "   \n",
    "    articles_results = get_recommendations(title_content)\n",
    "    \n",
    "    df_tmp = df_articles.loc[df_articles['title'].isin(articles_results)]\n",
    "    \n",
    "    articles_id = df_tmp['contentId']\n",
    "    \n",
    "    articles_tmp = df_users.loc[df_users['personId'] == n]\n",
    "    \n",
    "    recommendation_results = articles_id.loc[~articles_id.isin(articles_tmp['contentId'])]\n",
    "    \n",
    "    return recommendation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function to recommend new articles to a sepcific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263     -788035419968530567\n",
       "498     4307023751244532288\n",
       "804     3751305746867503759\n",
       "1044     240943776326872028\n",
       "1255   -3405516291669853723\n",
       "1382   -7009536306337650657\n",
       "1752    4313871021753084020\n",
       "1807     123378787151399958\n",
       "1925   -8968101771604200516\n",
       "2457   -6761163882540291832\n",
       "Name: contentId, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recommend_user_preference(-8763398617720485024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1>Influence Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contentId</th>\n",
       "      <th>Preference_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9222795471790223670</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9216926795620865886</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9194572880052200111</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9192549002213406534</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9190737901804729417</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             contentId  Preference_level\n",
       "0 -9222795471790223670              49.0\n",
       "1 -9216926795620865886              33.0\n",
       "2 -9194572880052200111              44.0\n",
       "3 -9192549002213406534              65.0\n",
       "4 -9190737901804729417              10.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_users.groupby('contentId', as_index=False).agg({\"Preference_level\": \"sum\"})\n",
    "\n",
    "df1.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contentId\n",
       "-9222795471790223670    26\n",
       "-9216926795620865886    21\n",
       "-9194572880052200111    29\n",
       "-9192549002213406534    56\n",
       "-9190737901804729417     9\n",
       "Name: contentId, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 =  df_users.groupby('contentId').contentId.count()\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Views\n",
       "0     26\n",
       "1     21\n",
       "2     29\n",
       "3     56\n",
       "4      9"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(np.array(df2))\n",
    "df2.columns=['Views']\n",
    "\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -3499919498720038879\n",
       "1    8890720798209849691\n",
       "2     310515487419366995\n",
       "3     310515487419366995\n",
       "4   -7820640624231356730\n",
       "Name: contentId, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=df_users['contentId']\n",
    "df3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contentId</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3499919498720038879</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8890720798209849691</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7820640624231356730</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             contentId  Views\n",
       "0 -3499919498720038879   26.0\n",
       "1  8890720798209849691   21.0\n",
       "2   310515487419366995   29.0\n",
       "3   310515487419366995   56.0\n",
       "4 -7820640624231356730    9.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.concat([df3,df2],axis=1, ignore_index=True)\n",
    "df4.columns=['contentId','Views']\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles_influence= pd.concat([df1, df2], axis=1)\n",
    "articles_influence.columns=['contentId','Popularity','Views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contentId</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9222795471790223670</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9216926795620865886</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9194572880052200111</td>\n",
       "      <td>44.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9192549002213406534</td>\n",
       "      <td>65.0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9190737901804729417</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-9189659052158407108</td>\n",
       "      <td>41.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-9184137057748005562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-9176143510534135851</td>\n",
       "      <td>45.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-9172673334835262304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-9171475473795142532</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-9166778629773133902</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-9161596996229760398</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-9160910454530522563</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-9157338616628196758</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-9153494109165200346</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-9152398073968262186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-9147114693160126293</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-9137036168156595470</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-9128741757954228992</td>\n",
       "      <td>52.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-9128652074338368262</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              contentId  Popularity  Views\n",
       "0  -9222795471790223670        49.0     26\n",
       "1  -9216926795620865886        33.0     21\n",
       "2  -9194572880052200111        44.0     29\n",
       "3  -9192549002213406534        65.0     56\n",
       "4  -9190737901804729417        10.0      9\n",
       "5  -9189659052158407108        41.0     36\n",
       "6  -9184137057748005562         1.0      1\n",
       "7  -9176143510534135851        45.0     33\n",
       "8  -9172673334835262304         1.0      1\n",
       "9  -9171475473795142532         7.0      5\n",
       "10 -9166778629773133902         5.0      5\n",
       "11 -9161596996229760398        26.0     15\n",
       "12 -9160910454530522563        37.0     37\n",
       "13 -9157338616628196758         5.0      5\n",
       "14 -9153494109165200346         2.0      2\n",
       "15 -9152398073968262186         1.0      1\n",
       "16 -9147114693160126293         8.0      8\n",
       "17 -9137036168156595470        12.0     10\n",
       "18 -9128741757954228992        52.0     45\n",
       "19 -9128652074338368262        25.0     19"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_influence.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contentId</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4110354420726924665</td>\n",
       "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
       "      <td>All of this work is still very early. The firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7292285110016212249</td>\n",
       "      <td>Bitcoin Future: When GBPcoin of Branson Wins O...</td>\n",
       "      <td>The alarm clock wakes me at 8:00 with stream o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6151852268067518688</td>\n",
       "      <td>Google Data Center 360° Tour</td>\n",
       "      <td>We're excited to share the Google Data Center ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2448026894306402386</td>\n",
       "      <td>IBM Wants to \"Evolve the Internet\" With Blockc...</td>\n",
       "      <td>The Aite Group projects the blockchain market ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2826566343807132236</td>\n",
       "      <td>IEEE to Talk Blockchain at Cloud Computing Oxf...</td>\n",
       "      <td>One of the largest and oldest organizations fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             contentId                                              title  \\\n",
       "1 -4110354420726924665  Ethereum, a Virtual Currency, Enables Transact...   \n",
       "2 -7292285110016212249  Bitcoin Future: When GBPcoin of Branson Wins O...   \n",
       "3 -6151852268067518688                       Google Data Center 360° Tour   \n",
       "4  2448026894306402386  IBM Wants to \"Evolve the Internet\" With Blockc...   \n",
       "5 -2826566343807132236  IEEE to Talk Blockchain at Cloud Computing Oxf...   \n",
       "\n",
       "                                                text  \n",
       "1  All of this work is still very early. The firs...  \n",
       "2  The alarm clock wakes me at 8:00 with stream o...  \n",
       "3  We're excited to share the Google Data Center ...  \n",
       "4  The Aite Group projects the blockchain market ...  \n",
       "5  One of the largest and oldest organizations fo...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=df_articles[['contentId','title','text']]\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contentId</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4110354420726924665</td>\n",
       "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
       "      <td>All of this work is still very early. The firs...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7292285110016212249</td>\n",
       "      <td>Bitcoin Future: When GBPcoin of Branson Wins O...</td>\n",
       "      <td>The alarm clock wakes me at 8:00 with stream o...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6151852268067518688</td>\n",
       "      <td>Google Data Center 360° Tour</td>\n",
       "      <td>We're excited to share the Google Data Center ...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2826566343807132236</td>\n",
       "      <td>IEEE to Talk Blockchain at Cloud Computing Oxf...</td>\n",
       "      <td>One of the largest and oldest organizations fo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4119190424078847945</td>\n",
       "      <td>Blockchain Technology Could Put Bank Auditors ...</td>\n",
       "      <td>When most people think about computers and rob...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             contentId                                              title  \\\n",
       "0 -4110354420726924665  Ethereum, a Virtual Currency, Enables Transact...   \n",
       "1 -7292285110016212249  Bitcoin Future: When GBPcoin of Branson Wins O...   \n",
       "2 -6151852268067518688                       Google Data Center 360° Tour   \n",
       "3 -2826566343807132236  IEEE to Talk Blockchain at Cloud Computing Oxf...   \n",
       "4  4119190424078847945  Blockchain Technology Could Put Bank Auditors ...   \n",
       "\n",
       "                                                text  Popularity  Views  \n",
       "0  All of this work is still very early. The firs...         1.0      1  \n",
       "1  The alarm clock wakes me at 8:00 with stream o...         1.0      1  \n",
       "2  We're excited to share the Google Data Center ...        16.0     13  \n",
       "3  One of the largest and oldest organizations fo...         2.0      2  \n",
       "4  When most people think about computers and rob...         1.0      1  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles_influence = pd.merge(df5, articles_influence, on=['contentId'])\n",
    "df_articles_influence.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Influence ranking based on the popularity of each content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contentId</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>-4029704725707465084</td>\n",
       "      <td>Former Google career coach shares a visual tri...</td>\n",
       "      <td>If you want 2017 to be an exciting year, desig...</td>\n",
       "      <td>550.0</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>-6783772548752091658</td>\n",
       "      <td>Livro: Retrospectivas Divertidas</td>\n",
       "      <td>Neste livro, nós fornecemos um conjunto de fer...</td>\n",
       "      <td>415.0</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>-2358756719610361882</td>\n",
       "      <td>Custo do Erro - Cinco motivos para investir em...</td>\n",
       "      <td>Atualmente, o custo de manutenção de software ...</td>\n",
       "      <td>412.0</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>8657408509986329668</td>\n",
       "      <td>Pull request first - Practical Blend</td>\n",
       "      <td>Pull request first After two years of working ...</td>\n",
       "      <td>381.0</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>-8208801367848627943</td>\n",
       "      <td>Ray Kurzweil: The world isn't getting worse - ...</td>\n",
       "      <td>Ray Kurzweil, the author, inventor, computer s...</td>\n",
       "      <td>363.0</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>-133139342397538859</td>\n",
       "      <td>Novo workaholic trabalha, pratica esportes e t...</td>\n",
       "      <td>Novo workaholic não abre mão do esporte e da f...</td>\n",
       "      <td>363.0</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>-1633984990770981161</td>\n",
       "      <td>UX ou UI?</td>\n",
       "      <td>UX ou UI? Tenho escutado essa pergunta com fre...</td>\n",
       "      <td>360.0</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>-6843047699859121724</td>\n",
       "      <td>Ganhe 6 meses de acesso ao Pluralsight, maior ...</td>\n",
       "      <td>Ganhe 6 meses de acesso ao Pluralsight, maior ...</td>\n",
       "      <td>360.0</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>2857117417189640073</td>\n",
       "      <td>Running GV sprints inside corporates - learn f...</td>\n",
       "      <td>Running GV sprints inside corporates - learn f...</td>\n",
       "      <td>349.0</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>8224860111193157980</td>\n",
       "      <td>Psicóloga de Harvard diz que as pessoas julgam...</td>\n",
       "      <td>As pessoas avaliam você em segundos, mas o que...</td>\n",
       "      <td>347.0</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>-1297580205670251233</td>\n",
       "      <td>A minha viagem à Maternidade #tetodomundo</td>\n",
       "      <td>Já fazia uma semana, desde o dia 26 de dezembr...</td>\n",
       "      <td>339.0</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>2581138407738454418</td>\n",
       "      <td>10 Modern Software Over-Engineering Mistakes</td>\n",
       "      <td>10 Modern Software Over-Engineering Mistakes F...</td>\n",
       "      <td>338.0</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>-6156751702010469220</td>\n",
       "      <td>The Broken Window Theory</td>\n",
       "      <td>In a previous entry , I touched on the broken ...</td>\n",
       "      <td>321.0</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>-330801551666885085</td>\n",
       "      <td>AWS vs Packet.net Why we left AWS Benchmarking...</td>\n",
       "      <td>If this sounds like a glowing review of Packet...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>3367026768872537336</td>\n",
       "      <td>Seja esperto no trabalho: Melhore a comunicaçã...</td>\n",
       "      <td>Seja Esperto no Trabalho: Melhore a Comunicaçã...</td>\n",
       "      <td>297.0</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>7507067965574797372</td>\n",
       "      <td>Um bilhão de arquivos mostram quem vence a dis...</td>\n",
       "      <td>Esta é uma das maiores batalhas já travadas en...</td>\n",
       "      <td>294.0</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>-5002383425685129595</td>\n",
       "      <td>Changing change management</td>\n",
       "      <td>Research tells us that most change efforts fai...</td>\n",
       "      <td>273.0</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>1854874463930846880</td>\n",
       "      <td>O dia em que tive mais medo de estar errada.</td>\n",
       "      <td>Passei meu sábado em Belém do Pará, mais espec...</td>\n",
       "      <td>260.0</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>1469580151036142903</td>\n",
       "      <td>Don't document your code. Code your documentat...</td>\n",
       "      <td>This is one of the great discussions among dev...</td>\n",
       "      <td>259.0</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>5238119115012015307</td>\n",
       "      <td>Embracing Agile</td>\n",
       "      <td>Idea in Brief The Problem Agile methods such a...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                contentId                                              title  \\\n",
       "2918 -4029704725707465084  Former Google career coach shares a visual tri...   \n",
       "1673 -6783772548752091658                   Livro: Retrospectivas Divertidas   \n",
       "2157 -2358756719610361882  Custo do Erro - Cinco motivos para investir em...   \n",
       "1199  8657408509986329668               Pull request first - Practical Blend   \n",
       "1758 -8208801367848627943  Ray Kurzweil: The world isn't getting worse - ...   \n",
       "1537  -133139342397538859  Novo workaholic trabalha, pratica esportes e t...   \n",
       "1948 -1633984990770981161                                          UX ou UI?   \n",
       "532  -6843047699859121724  Ganhe 6 meses de acesso ao Pluralsight, maior ...   \n",
       "1054  2857117417189640073  Running GV sprints inside corporates - learn f...   \n",
       "1732  8224860111193157980  Psicóloga de Harvard diz que as pessoas julgam...   \n",
       "1588 -1297580205670251233          A minha viagem à Maternidade #tetodomundo   \n",
       "1795  2581138407738454418       10 Modern Software Over-Engineering Mistakes   \n",
       "1853 -6156751702010469220                           The Broken Window Theory   \n",
       "1239  -330801551666885085  AWS vs Packet.net Why we left AWS Benchmarking...   \n",
       "2199  3367026768872537336  Seja esperto no trabalho: Melhore a comunicaçã...   \n",
       "2115  7507067965574797372  Um bilhão de arquivos mostram quem vence a dis...   \n",
       "1428 -5002383425685129595                         Changing change management   \n",
       "1289  1854874463930846880       O dia em que tive mais medo de estar errada.   \n",
       "2914  1469580151036142903  Don't document your code. Code your documentat...   \n",
       "525   5238119115012015307                                    Embracing Agile   \n",
       "\n",
       "                                                   text  Popularity  Views  \n",
       "2918  If you want 2017 to be an exciting year, desig...       550.0    433  \n",
       "1673  Neste livro, nós fornecemos um conjunto de fer...       415.0    294  \n",
       "2157  Atualmente, o custo de manutenção de software ...       412.0    280  \n",
       "1199  Pull request first After two years of working ...       381.0    294  \n",
       "1758  Ray Kurzweil, the author, inventor, computer s...       363.0    266  \n",
       "1537  Novo workaholic não abre mão do esporte e da f...       363.0    315  \n",
       "1948  UX ou UI? Tenho escutado essa pergunta com fre...       360.0    249  \n",
       "532   Ganhe 6 meses de acesso ao Pluralsight, maior ...       360.0    281  \n",
       "1054  Running GV sprints inside corporates - learn f...       349.0    241  \n",
       "1732  As pessoas avaliam você em segundos, mas o que...       347.0    236  \n",
       "1588  Já fazia uma semana, desde o dia 26 de dezembr...       339.0    253  \n",
       "1795  10 Modern Software Over-Engineering Mistakes F...       338.0    255  \n",
       "1853  In a previous entry , I touched on the broken ...       321.0    221  \n",
       "1239  If this sounds like a glowing review of Packet...       299.0    122  \n",
       "2199  Seja Esperto no Trabalho: Melhore a Comunicaçã...       297.0    247  \n",
       "2115  Esta é uma das maiores batalhas já travadas en...       294.0    233  \n",
       "1428  Research tells us that most change efforts fai...       273.0    190  \n",
       "1289  Passei meu sábado em Belém do Pará, mais espec...       260.0    165  \n",
       "2914  This is one of the great discussions among dev...       259.0    209  \n",
       "525   Idea in Brief The Problem Agile methods such a...       256.0    182  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles_influence.sort_values(by='Popularity', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Influence ranking based on how many views each content got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contentId</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>-4029704725707465084</td>\n",
       "      <td>Former Google career coach shares a visual tri...</td>\n",
       "      <td>If you want 2017 to be an exciting year, desig...</td>\n",
       "      <td>550.0</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>-133139342397538859</td>\n",
       "      <td>Novo workaholic trabalha, pratica esportes e t...</td>\n",
       "      <td>Novo workaholic não abre mão do esporte e da f...</td>\n",
       "      <td>363.0</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>-6783772548752091658</td>\n",
       "      <td>Livro: Retrospectivas Divertidas</td>\n",
       "      <td>Neste livro, nós fornecemos um conjunto de fer...</td>\n",
       "      <td>415.0</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>8657408509986329668</td>\n",
       "      <td>Pull request first - Practical Blend</td>\n",
       "      <td>Pull request first After two years of working ...</td>\n",
       "      <td>381.0</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>-6843047699859121724</td>\n",
       "      <td>Ganhe 6 meses de acesso ao Pluralsight, maior ...</td>\n",
       "      <td>Ganhe 6 meses de acesso ao Pluralsight, maior ...</td>\n",
       "      <td>360.0</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>-2358756719610361882</td>\n",
       "      <td>Custo do Erro - Cinco motivos para investir em...</td>\n",
       "      <td>Atualmente, o custo de manutenção de software ...</td>\n",
       "      <td>412.0</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>-8208801367848627943</td>\n",
       "      <td>Ray Kurzweil: The world isn't getting worse - ...</td>\n",
       "      <td>Ray Kurzweil, the author, inventor, computer s...</td>\n",
       "      <td>363.0</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>2581138407738454418</td>\n",
       "      <td>10 Modern Software Over-Engineering Mistakes</td>\n",
       "      <td>10 Modern Software Over-Engineering Mistakes F...</td>\n",
       "      <td>338.0</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>-1297580205670251233</td>\n",
       "      <td>A minha viagem à Maternidade #tetodomundo</td>\n",
       "      <td>Já fazia uma semana, desde o dia 26 de dezembr...</td>\n",
       "      <td>339.0</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>-1633984990770981161</td>\n",
       "      <td>UX ou UI?</td>\n",
       "      <td>UX ou UI? Tenho escutado essa pergunta com fre...</td>\n",
       "      <td>360.0</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>3367026768872537336</td>\n",
       "      <td>Seja esperto no trabalho: Melhore a comunicaçã...</td>\n",
       "      <td>Seja Esperto no Trabalho: Melhore a Comunicaçã...</td>\n",
       "      <td>297.0</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>2857117417189640073</td>\n",
       "      <td>Running GV sprints inside corporates - learn f...</td>\n",
       "      <td>Running GV sprints inside corporates - learn f...</td>\n",
       "      <td>349.0</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>8224860111193157980</td>\n",
       "      <td>Psicóloga de Harvard diz que as pessoas julgam...</td>\n",
       "      <td>As pessoas avaliam você em segundos, mas o que...</td>\n",
       "      <td>347.0</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>7507067965574797372</td>\n",
       "      <td>Um bilhão de arquivos mostram quem vence a dis...</td>\n",
       "      <td>Esta é uma das maiores batalhas já travadas en...</td>\n",
       "      <td>294.0</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>-6156751702010469220</td>\n",
       "      <td>The Broken Window Theory</td>\n",
       "      <td>In a previous entry , I touched on the broken ...</td>\n",
       "      <td>321.0</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>1469580151036142903</td>\n",
       "      <td>Don't document your code. Code your documentat...</td>\n",
       "      <td>This is one of the great discussions among dev...</td>\n",
       "      <td>259.0</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>-4333957157636611418</td>\n",
       "      <td>Why Programmers Want Private Offices</td>\n",
       "      <td>Ask any of your employees or coworkers what th...</td>\n",
       "      <td>237.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>880612740433495828</td>\n",
       "      <td>O que você deve fazer para se tornar um líder ...</td>\n",
       "      <td>Para ser um grande coach, você deve fazer mais...</td>\n",
       "      <td>232.0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>-5002383425685129595</td>\n",
       "      <td>Changing change management</td>\n",
       "      <td>Research tells us that most change efforts fai...</td>\n",
       "      <td>273.0</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>6044362651232258738</td>\n",
       "      <td>Cinco competências comportamentais para você s...</td>\n",
       "      <td>escritório | Crédito: pixabay Por que algumas ...</td>\n",
       "      <td>232.0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                contentId                                              title  \\\n",
       "2918 -4029704725707465084  Former Google career coach shares a visual tri...   \n",
       "1537  -133139342397538859  Novo workaholic trabalha, pratica esportes e t...   \n",
       "1673 -6783772548752091658                   Livro: Retrospectivas Divertidas   \n",
       "1199  8657408509986329668               Pull request first - Practical Blend   \n",
       "532  -6843047699859121724  Ganhe 6 meses de acesso ao Pluralsight, maior ...   \n",
       "2157 -2358756719610361882  Custo do Erro - Cinco motivos para investir em...   \n",
       "1758 -8208801367848627943  Ray Kurzweil: The world isn't getting worse - ...   \n",
       "1795  2581138407738454418       10 Modern Software Over-Engineering Mistakes   \n",
       "1588 -1297580205670251233          A minha viagem à Maternidade #tetodomundo   \n",
       "1948 -1633984990770981161                                          UX ou UI?   \n",
       "2199  3367026768872537336  Seja esperto no trabalho: Melhore a comunicaçã...   \n",
       "1054  2857117417189640073  Running GV sprints inside corporates - learn f...   \n",
       "1732  8224860111193157980  Psicóloga de Harvard diz que as pessoas julgam...   \n",
       "2115  7507067965574797372  Um bilhão de arquivos mostram quem vence a dis...   \n",
       "1853 -6156751702010469220                           The Broken Window Theory   \n",
       "2914  1469580151036142903  Don't document your code. Code your documentat...   \n",
       "2468 -4333957157636611418               Why Programmers Want Private Offices   \n",
       "1101   880612740433495828  O que você deve fazer para se tornar um líder ...   \n",
       "1428 -5002383425685129595                         Changing change management   \n",
       "544   6044362651232258738  Cinco competências comportamentais para você s...   \n",
       "\n",
       "                                                   text  Popularity  Views  \n",
       "2918  If you want 2017 to be an exciting year, desig...       550.0    433  \n",
       "1537  Novo workaholic não abre mão do esporte e da f...       363.0    315  \n",
       "1673  Neste livro, nós fornecemos um conjunto de fer...       415.0    294  \n",
       "1199  Pull request first After two years of working ...       381.0    294  \n",
       "532   Ganhe 6 meses de acesso ao Pluralsight, maior ...       360.0    281  \n",
       "2157  Atualmente, o custo de manutenção de software ...       412.0    280  \n",
       "1758  Ray Kurzweil, the author, inventor, computer s...       363.0    266  \n",
       "1795  10 Modern Software Over-Engineering Mistakes F...       338.0    255  \n",
       "1588  Já fazia uma semana, desde o dia 26 de dezembr...       339.0    253  \n",
       "1948  UX ou UI? Tenho escutado essa pergunta com fre...       360.0    249  \n",
       "2199  Seja Esperto no Trabalho: Melhore a Comunicaçã...       297.0    247  \n",
       "1054  Running GV sprints inside corporates - learn f...       349.0    241  \n",
       "1732  As pessoas avaliam você em segundos, mas o que...       347.0    236  \n",
       "2115  Esta é uma das maiores batalhas já travadas en...       294.0    233  \n",
       "1853  In a previous entry , I touched on the broken ...       321.0    221  \n",
       "2914  This is one of the great discussions among dev...       259.0    209  \n",
       "2468  Ask any of your employees or coworkers what th...       237.0    192  \n",
       "1101  Para ser um grande coach, você deve fazer mais...       232.0    191  \n",
       "1428  Research tells us that most change efforts fai...       273.0    190  \n",
       "544   escritório | Crédito: pixabay Por que algumas ...       232.0    184  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles_influence.sort_values(by='Views', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1>Article Influence prediction and Evaluation\n",
    "(How many views I will probably get? / What's the popularity score I will probably get?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity \n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentim_analyzer = SentimentAnalyzer()\n",
    "vectorizer = TfidfVectorizer(\"english\") ### check tf-idf theory, input: arr of string, output: feature arr, column: tf-idf feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineer steps\n",
    "#### 1 insight\n",
    "#### 2 summarization\n",
    "#### 3 remove puntucation\n",
    "#### 4 remove stop words\n",
    "#### 5 remove stemmization, lemmatization\n",
    "\n",
    "#### 6 dimension reduction\n",
    "#### 7 train test split\n",
    "\n",
    "###### others features: n-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def pre_process(text):\n",
    "    \n",
    "    ### Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    ### Remove stops words\n",
    "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
    "    ### Remove lemmatization\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    text = list(map(lambda x:wnl.lemmatize(x),text))\n",
    "    ### Remove stemmization\n",
    "    words = \"\"\n",
    "    for i in text:\n",
    "            stemmer = SnowballStemmer(\"english\")\n",
    "            words += (stemmer.stem(i))+\" \"\n",
    "    print('done')\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article_texts = df_articles_influence.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The alarm clock wakes me at 8:00 with stream of advert-free broadcasting, charged at one satoshi per second. The current BTC exchange rate makes that snooze button a costly proposition! So I get up, make coffee and go to my computer to check the overnight performance of my bots. TradeBot earns me on Trump and Branson TradeBot, which allocates funds between the main chain and various national currency side-chains, generated a lucrative 0.24 BTC return. TradeBot has been reliably profitable ever since I set it to trade USDcoin according to political prediction market data. As expected, the latest poll numbers came in as highly supportive of Trump\\'s re-election as USDcoin CEO. Trump\\'s resistance to de-anonymizing public spending, by moving USDcoin off the Confidential Transactions layer, continues to erode his coin\\'s credibility. In his latest speech, Trump maintains that full CT-privacy is essential to \"combatting CNYcoin\\'s sinister ring-signature scheming.\" I make a note to increase my long position in GBPcoin. Following CEO Branson\\'s memo to the effect that government finances and national banks be brought into compliance with the public blockchain , British corruption indices have flatlined. As the first national econmy to \"go light,\" Britain leads the global recovery from the Great Debt Default of \\'20. Happy with the GoatData Project I check TeachBot and note that it\\'s performing in-line with expectations. TeachBot serves as an autonomous info-agent between various contracting AIs and data providers. The 0.5 BTC bounty it awarded to a team of Sherpas to outfit a herd of Tibetan mountain goats with full motion-sensing rigs has already been repaid...I check the latest figures... four times over! My best TeachBot strategy to date, the GoatData project provides valuable data to WinterHoof, the Artificial General Intelligence in charge of the Swiss military\\'s quadripedal robotics program. At this rate, I\\'ll soon have enough BTC to retire to Satoshi City on Mars!'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "article_texts = np.array(list(map(lambda x:pre_process(x),article_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2944, 67394)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = vectorizer.fit_transform(article_texts)\n",
    "features.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text summarization refers to the technique of shortening long pieces of text. The intention is to create a coherent and fluent summary having only the main points outlined in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.summarization.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alarm clock wake 800 stream advertfre broadcast charg one satoshi per second current btc exchang rate make snooz button cost proposit get make coffe go comput check overnight perform bot tradebot earn trump branson tradebot alloc fund main chain various nation currenc sidechain generat lucrat 024 btc return tradebot reliabl profit ever sinc set trade usdcoin accord polit predict market data expect latest poll number came high support trump reelect usdcoin ceo trump resist deanonym public spend move usdcoin confidenti transact layer continu erod coin credibl latest speech trump maintain full ctprivaci essenti combat cnycoin sinist ringsignatur scheme make note increas long posit gbpcoin follow ceo branson memo effect govern financ nation bank brought complianc public blockchain british corrupt index flatlin first nation econmi go light britain lead global recoveri great debt default 20 happi goatdata project check teachbot note perform inlin expect teachbot serf autonom infoag various contract ai data provid 05 btc bounti award team sherpa outfit herd tibetan mountain goat full motionsens rig alreadi repaidi check latest figur four time best teachbot strategi date goatdata project provid valuabl data winterhoof artifici general intellig charg swiss militari quadriped robot program rate ill soon enough btc retir satoshi citi mar '"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 16:57:53,543 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 16:57:53,551 : INFO : built Dictionary(148 unique tokens: ['advert', 'alarm', 'broadcast', 'charg', 'clock']...) from 16 documents (total 182 corpus positions)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"TradeBot earns me on Trump and Branson TradeBot, which allocates funds between the main chain and various national currency side-chains, generated a lucrative 0.24 BTC return.\\nAs expected, the latest poll numbers came in as highly supportive of Trump's re-election as USDcoin CEO.\\nHappy with the GoatData Project I check TeachBot and note that it's performing in-line with expectations.\""
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(df_articles_influence['text'].values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary(string,**kwargs):\n",
    "    try:\n",
    "        summarized = summarize(string,**kwargs)\n",
    "    except:\n",
    "        return string\n",
    "    return summarized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:36,628 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:36,633 : INFO : built Dictionary(307 unique tokens: ['earli', 'work', 'bitcoin', 'ethereum', 'face']...) from 45 documents (total 505 corpus positions)\n",
      "2019-04-24 17:00:36,657 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:36,659 : INFO : built Dictionary(148 unique tokens: ['advert', 'alarm', 'broadcast', 'charg', 'clock']...) from 16 documents (total 182 corpus positions)\n",
      "2019-04-24 17:00:36,668 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:36,671 : INFO : built Dictionary(86 unique tokens: ['center', 'data', 'excit', 'give', 'googl']...) from 11 documents (total 135 corpus positions)\n",
      "2019-04-24 17:00:36,679 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:36,681 : INFO : built Dictionary(107 unique tokens: ['annual', 'attract', 'blockchain', 'cloud', 'comput']...) from 11 documents (total 154 corpus positions)\n",
      "2019-04-24 17:00:36,692 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:36,696 : INFO : built Dictionary(220 unique tokens: ['amazon', 'awai', 'cashier', 'come', 'comput']...) from 32 documents (total 351 corpus positions)\n",
      "2019-04-24 17:00:36,728 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:36,733 : INFO : built Dictionary(395 unique tokens: ['bitcoin', 'boes', 'bring', 'ceo', 'challeng']...) from 77 documents (total 794 corpus positions)\n",
      "2019-04-24 17:00:36,785 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:36,788 : INFO : built Dictionary(248 unique tokens: ['altcoin', 'attent', 'consid', 'ethereum', 'grab']...) from 45 documents (total 420 corpus positions)\n",
      "2019-04-24 17:00:36,817 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:36,821 : INFO : built Dictionary(352 unique tokens: ['alguma', 'custo', 'da', 'deterioração', 'do']...) from 34 documents (total 600 corpus positions)\n",
      "2019-04-24 17:00:36,860 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:36,867 : INFO : built Dictionary(292 unique tokens: ['balanc', 'destin', 'global', 'http', 'instanc']...) from 99 documents (total 1044 corpus positions)\n",
      "2019-04-24 17:00:36,973 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:36,980 : INFO : built Dictionary(386 unique tokens: ['alpha', 'balanc', 'cloud', 'googl', 'load']...) from 185 documents (total 2444 corpus positions)\n",
      "2019-04-24 17:00:37,225 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,227 : INFO : built Dictionary(76 unique tokens: ['dell', 'divis', 'know', 'maker', 'oper']...) from 17 documents (total 132 corpus positions)\n",
      "2019-04-24 17:00:37,253 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,257 : INFO : built Dictionary(631 unique tokens: ['industri', 'model', 'uber', 'work', 'call']...) from 74 documents (total 1100 corpus positions)\n",
      "2019-04-24 17:00:37,320 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,323 : INFO : built Dictionary(293 unique tokens: ['adopt', 'ascend', 'dub', 'iiot', 'industri']...) from 47 documents (total 513 corpus positions)\n",
      "2019-04-24 17:00:37,345 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,348 : INFO : built Dictionary(191 unique tokens: ['adoção', 'agricultura', 'agronegócio', 'alberto', 'alimentar']...) from 15 documents (total 315 corpus positions)\n",
      "2019-04-24 17:00:37,377 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,383 : INFO : built Dictionary(844 unique tokens: ['agricultura', 'conhec', 'download', 'embrapa', 'faça']...) from 75 documents (total 1753 corpus positions)\n",
      "2019-04-24 17:00:37,464 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,468 : INFO : built Dictionary(286 unique tokens: ['allow', 'automat', 'base', 'bitcoin', 'bounti']...) from 35 documents (total 433 corpus positions)\n",
      "2019-04-24 17:00:37,485 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:37,488 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,490 : INFO : built Dictionary(82 unique tokens: ['acceler', 'ateli', 'base', 'blockchain', 'bnp']...) from 9 documents (total 113 corpus positions)\n",
      "2019-04-24 17:00:37,493 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:37,504 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,508 : INFO : built Dictionary(190 unique tokens: ['blockchain', 'concept', 'develop', 'distribut', 'ecosystem']...) from 26 documents (total 293 corpus positions)\n",
      "2019-04-24 17:00:37,526 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,529 : INFO : built Dictionary(302 unique tokens: ['américa', 'animadora', 'economia', 'felix', 'latina']...) from 30 documents (total 483 corpus positions)\n",
      "2019-04-24 17:00:37,557 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,560 : INFO : built Dictionary(337 unique tokens: ['bui', 'cash', 'elect', 'exist', 'hour']...) from 45 documents (total 507 corpus positions)\n",
      "2019-04-24 17:00:37,580 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:37,583 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,586 : INFO : built Dictionary(49 unique tokens: ['alavancar', 'aproveitando', 'aproveitar', 'como', 'discutido']...) from 4 documents (total 85 corpus positions)\n",
      "2019-04-24 17:00:37,590 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:37,593 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:37,598 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,602 : INFO : built Dictionary(156 unique tokens: ['descrição', 'evento', 'horário', 'qual', 'access']...) from 12 documents (total 211 corpus positions)\n",
      "2019-04-24 17:00:37,614 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,617 : INFO : built Dictionary(179 unique tokens: ['artifici', 'conquer', 'deepmind', 'game', 'googl']...) from 24 documents (total 267 corpus positions)\n",
      "2019-04-24 17:00:37,636 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,640 : INFO : built Dictionary(295 unique tokens: ['ago', 'counterpart', 'employe', 'expect', 'futur']...) from 47 documents (total 455 corpus positions)\n",
      "2019-04-24 17:00:37,661 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,664 : INFO : built Dictionary(86 unique tokens: ['billion', 'build', 'busi', 'compani', 'consum']...) from 15 documents (total 140 corpus positions)\n",
      "2019-04-24 17:00:37,674 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,677 : INFO : built Dictionary(98 unique tokens: ['cloud', 'foundat', 'googl', 'join', 'node']...) from 12 documents (total 157 corpus positions)\n",
      "2019-04-24 17:00:37,692 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,695 : INFO : built Dictionary(228 unique tokens: ['addit', 'applic', 'best', 'busi', 'capit']...) from 31 documents (total 393 corpus positions)\n",
      "2019-04-24 17:00:37,712 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:37,715 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,717 : INFO : built Dictionary(70 unique tokens: ['coisa', 'como', 'computação', 'da', 'igor']...) from 5 documents (total 89 corpus positions)\n",
      "2019-04-24 17:00:37,720 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:37,729 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,733 : INFO : built Dictionary(166 unique tokens: ['affect', 'bitcoin', 'circul', 'differ', 'healthcar']...) from 24 documents (total 266 corpus positions)\n",
      "2019-04-24 17:00:37,747 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,750 : INFO : built Dictionary(202 unique tokens: ['announc', 'citi', 'claim', 'coinfest', 'contin']...) from 21 documents (total 337 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:37,763 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:37,766 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,767 : INFO : built Dictionary(66 unique tokens: ['bitcoin', 'combat', 'commend', 'crime', 'currenc']...) from 5 documents (total 87 corpus positions)\n",
      "2019-04-24 17:00:37,770 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:37,777 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,780 : INFO : built Dictionary(119 unique tokens: ['attia', 'bomb', 'ceo', 'demand', 'economi']...) from 17 documents (total 196 corpus positions)\n",
      "2019-04-24 17:00:37,793 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,797 : INFO : built Dictionary(117 unique tokens: ['automat', 'consum', 'contact', 'duplic', 'featur']...) from 14 documents (total 243 corpus positions)\n",
      "2019-04-24 17:00:37,807 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,810 : INFO : built Dictionary(126 unique tokens: ['come', 'divers', 'find', 'hear', 'long']...) from 12 documents (total 188 corpus positions)\n",
      "2019-04-24 17:00:37,843 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:37,849 : INFO : built Dictionary(642 unique tokens: ['anim', 'cofound', 'compani', 'creat', 'featur']...) from 214 documents (total 1473 corpus positions)\n",
      "2019-04-24 17:00:38,027 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,030 : INFO : built Dictionary(275 unique tokens: ['cb', 'david', 'even', 'excel', 'interview']...) from 84 documents (total 569 corpus positions)\n",
      "2019-04-24 17:00:38,066 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:38,068 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,071 : INFO : built Dictionary(75 unique tokens: ['android', 'aplicativo', 'appl', 'autoatendimento', 'client']...) from 7 documents (total 93 corpus positions)\n",
      "2019-04-24 17:00:38,072 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:38,082 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,085 : INFO : built Dictionary(283 unique tokens: ['atla', 'biped', 'boston', 'box', 'door']...) from 38 documents (total 377 corpus positions)\n",
      "2019-04-24 17:00:38,100 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,103 : INFO : built Dictionary(141 unique tokens: ['analyz', 'artifici', 'card', 'deepmind', 'gather']...) from 16 documents (total 199 corpus positions)\n",
      "2019-04-24 17:00:38,125 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,128 : INFO : built Dictionary(460 unique tokens: ['bay', 'know', 'rule', 'learn', 'machin']...) from 132 documents (total 1014 corpus positions)\n",
      "2019-04-24 17:00:38,198 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,200 : INFO : built Dictionary(175 unique tokens: ['chatbot', 'deep', 'devolv', 'horrifi', 'japan']...) from 15 documents (total 255 corpus positions)\n",
      "2019-04-24 17:00:38,222 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,227 : INFO : built Dictionary(436 unique tokens: ['corbi', 'core', 'creat', 'finland', 'helsinki']...) from 108 documents (total 910 corpus positions)\n",
      "2019-04-24 17:00:38,287 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,290 : INFO : built Dictionary(149 unique tokens: ['congest', 'elbidul', 'expans', 'expens', 'imag']...) from 16 documents (total 210 corpus positions)\n",
      "2019-04-24 17:00:38,301 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,304 : INFO : built Dictionary(218 unique tokens: ['chatbot', 'epithet', 'microsoft', 'nazi', 'rogu']...) from 47 documents (total 334 corpus positions)\n",
      "2019-04-24 17:00:38,328 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,331 : INFO : built Dictionary(343 unique tokens: ['enigma', 'learn', 'machin', 'algorithm', 'complex']...) from 63 documents (total 725 corpus positions)\n",
      "2019-04-24 17:00:38,370 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,373 : INFO : built Dictionary(193 unique tokens: ['bitcoin', 'brazil', 'infrastructur', 'lead', 'provid']...) from 26 documents (total 326 corpus positions)\n",
      "2019-04-24 17:00:38,386 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,389 : INFO : built Dictionary(123 unique tokens: ['bitcoin', 'blockchain', 'blockstream', 'compani', 'develop']...) from 11 documents (total 179 corpus positions)\n",
      "2019-04-24 17:00:38,426 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,433 : INFO : built Dictionary(924 unique tokens: ['demand', 'digit', 'disrupt', 'guid', 'suppli']...) from 180 documents (total 2229 corpus positions)\n",
      "2019-04-24 17:00:38,638 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,641 : INFO : built Dictionary(216 unique tokens: ['absolut', 'better', 'blog', 'character', 'contain']...) from 39 documents (total 371 corpus positions)\n",
      "2019-04-24 17:00:38,663 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,666 : INFO : built Dictionary(117 unique tokens: ['abl', 'accord', 'canon', 'compani', 'linux']...) from 28 documents (total 202 corpus positions)\n",
      "2019-04-24 17:00:38,687 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,691 : INFO : built Dictionary(237 unique tokens: ['question', 'integr', 'user', 'want', 'car']...) from 47 documents (total 427 corpus positions)\n",
      "2019-04-24 17:00:38,721 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,724 : INFO : built Dictionary(205 unique tokens: ['comput', 'enslav', 'get', 'human', 'know']...) from 22 documents (total 290 corpus positions)\n",
      "2019-04-24 17:00:38,737 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,741 : INFO : built Dictionary(89 unique tokens: ['control', 'design', 'especi', 'interfac', 'menu']...) from 19 documents (total 150 corpus positions)\n",
      "2019-04-24 17:00:38,757 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,761 : INFO : built Dictionary(278 unique tokens: ['abil', 'app', 'break', 'facebook', 'fast']...) from 54 documents (total 536 corpus positions)\n",
      "2019-04-24 17:00:38,790 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:38,793 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,796 : INFO : built Dictionary(49 unique tokens: ['aponta', 'avaliam', 'brasileiro', 'como', 'confederação']...) from 5 documents (total 58 corpus positions)\n",
      "2019-04-24 17:00:38,799 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:38,816 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,819 : INFO : built Dictionary(322 unique tokens: ['basement', 'call', 'caus', 'data', 'good']...) from 55 documents (total 650 corpus positions)\n",
      "2019-04-24 17:00:38,854 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,857 : INFO : built Dictionary(184 unique tokens: ['aren', 'best', 'despit', 'effort', 'great']...) from 29 documents (total 293 corpus positions)\n",
      "2019-04-24 17:00:38,873 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,876 : INFO : built Dictionary(112 unique tokens: ['app', 'commiser', 'commun', 'earlier', 'peopl']...) from 16 documents (total 153 corpus positions)\n",
      "2019-04-24 17:00:38,887 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,891 : INFO : built Dictionary(137 unique tokens: ['access', 'addit', 'capabl', 'cloud', 'give']...) from 27 documents (total 295 corpus positions)\n",
      "2019-04-24 17:00:38,909 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,913 : INFO : built Dictionary(217 unique tokens: ['busi', 'cloud', 'comput', 'googl', 'prowess']...) from 37 documents (total 353 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:38,944 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,949 : INFO : built Dictionary(321 unique tokens: ['complic', 'develop', 'web', 'beginn', 'biggest']...) from 48 documents (total 634 corpus positions)\n",
      "2019-04-24 17:00:38,975 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:38,978 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:38,983 : INFO : built Dictionary(91 unique tokens: ['api', 'dai', 'develop', 'googl', 'hundr']...) from 9 documents (total 153 corpus positions)\n",
      "2019-04-24 17:00:38,988 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:39,004 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:39,009 : INFO : built Dictionary(213 unique tokens: ['announc', 'app', 'asana', 'compani', 'enterpris']...) from 16 documents (total 305 corpus positions)\n",
      "2019-04-24 17:00:39,028 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:39,032 : INFO : built Dictionary(231 unique tokens: ['app', 'applic', 'content', 'featur', 'menu']...) from 52 documents (total 424 corpus positions)\n",
      "2019-04-24 17:00:39,056 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:39,059 : INFO : built Dictionary(125 unique tokens: ['content', 'creation', 'new', 'overview', 'paragraph']...) from 21 documents (total 234 corpus positions)\n",
      "2019-04-24 17:00:39,079 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:39,082 : INFO : built Dictionary(317 unique tokens: ['configur', 'drupal', 'go', 'imag', 'option']...) from 76 documents (total 686 corpus positions)\n",
      "2019-04-24 17:00:39,125 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:39,127 : INFO : built Dictionary(100 unique tokens: ['activ', 'contribut', 'highlight', 'lot', 'marketplac']...) from 16 documents (total 176 corpus positions)\n",
      "2019-04-24 17:00:39,140 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:39,143 : INFO : built Dictionary(130 unique tokens: ['ago', 'blog', 'code', 'confus', 'jump']...) from 25 documents (total 309 corpus positions)\n",
      "2019-04-24 17:00:39,164 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:39,167 : INFO : built Dictionary(322 unique tokens: ['bitcoin', 'bring', 'march', 'mine', 'price']...) from 61 documents (total 612 corpus positions)\n",
      "2019-04-24 17:00:39,198 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:39,201 : INFO : built Dictionary(72 unique tokens: ['base', 'blockchain', 'com', 'creat', 'develop']...) from 11 documents (total 100 corpus positions)\n",
      "2019-04-24 17:00:39,208 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:39,211 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:39,214 : INFO : built Dictionary(96 unique tokens: ['bitcoin', 'continu', 'mainstream', 'tech', 'attend']...) from 8 documents (total 111 corpus positions)\n",
      "2019-04-24 17:00:39,216 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:39,224 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:39,226 : INFO : built Dictionary(94 unique tokens: ['annual', 'award', 'blockchain', 'center', 'coin']...) from 12 documents (total 131 corpus positions)\n",
      "2019-04-24 17:00:39,234 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:39,237 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:39,239 : INFO : built Dictionary(77 unique tokens: ['applic', 'augment', 'base', 'build', 'contextu']...) from 7 documents (total 113 corpus positions)\n",
      "2019-04-24 17:00:39,241 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:39,252 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:39,255 : INFO : built Dictionary(199 unique tokens: ['andi', 'challeng', 'cloud', 'googl', 'imag']...) from 35 documents (total 366 corpus positions)\n",
      "2019-04-24 17:00:39,284 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:39,288 : INFO : built Dictionary(343 unique tokens: ['action', 'artist', 'client', 'event', 'inform']...) from 96 documents (total 899 corpus positions)\n",
      "2019-04-24 17:00:39,397 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:39,404 : INFO : built Dictionary(959 unique tokens: ['cloud', 'host', 'larg', 'legaci', 'migrat']...) from 342 documents (total 3524 corpus positions)\n",
      "2019-04-24 17:00:40,108 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:40,111 : INFO : built Dictionary(265 unique tokens: ['abl', 'announc', 'applic', 'blockchain', 'build']...) from 36 documents (total 483 corpus positions)\n",
      "2019-04-24 17:00:40,175 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:40,183 : INFO : built Dictionary(717 unique tokens: ['amazon', 'aw', 'cloud', 'concept', 'design']...) from 362 documents (total 3662 corpus positions)\n",
      "2019-04-24 17:00:41,119 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,122 : INFO : built Dictionary(287 unique tokens: ['algorithm', 'assist', 'berkelei', 'burst', 'command']...) from 43 documents (total 473 corpus positions)\n",
      "2019-04-24 17:00:41,142 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:41,144 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,147 : INFO : built Dictionary(97 unique tokens: ['anunciaram', 'aérea', 'com', 'como', 'companhia']...) from 8 documents (total 123 corpus positions)\n",
      "2019-04-24 17:00:41,150 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:41,162 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,165 : INFO : built Dictionary(141 unique tokens: ['dai', 'calcul', 'digit', 'infinit', 'irration']...) from 17 documents (total 356 corpus positions)\n",
      "2019-04-24 17:00:41,198 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,203 : INFO : built Dictionary(696 unique tokens: ['abil', 'commun', 'embed', 'gain', 'object']...) from 110 documents (total 1505 corpus positions)\n",
      "2019-04-24 17:00:41,306 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,313 : INFO : built Dictionary(126 unique tokens: ['agora', 'automatizada', 'colheita', 'era', 'fazenda']...) from 15 documents (total 158 corpus positions)\n",
      "2019-04-24 17:00:41,329 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:41,332 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,335 : INFO : built Dictionary(56 unique tokens: ['announc', 'appl', 'browser', 'new', 'sort']...) from 8 documents (total 76 corpus positions)\n",
      "2019-04-24 17:00:41,338 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:41,355 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,359 : INFO : built Dictionary(236 unique tokens: ['billion', 'googl', 'year', 'dog', 'match']...) from 38 documents (total 399 corpus positions)\n",
      "2019-04-24 17:00:41,398 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,403 : INFO : built Dictionary(450 unique tokens: ['bot', 'come', 'build', 'call', 'develop']...) from 95 documents (total 877 corpus positions)\n",
      "2019-04-24 17:00:41,480 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,483 : INFO : built Dictionary(211 unique tokens: ['cloud', 'compani', 'dai', 'grown', 'home']...) from 28 documents (total 360 corpus positions)\n",
      "2019-04-24 17:00:41,500 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,503 : INFO : built Dictionary(112 unique tokens: ['content', 'contribut', 'deliv', 'drupal', 'function']...) from 16 documents (total 173 corpus positions)\n",
      "2019-04-24 17:00:41,514 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,517 : INFO : built Dictionary(127 unique tokens: ['build', 'dai', 'anniversari', 'come', 'featur']...) from 20 documents (total 231 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:41,535 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,540 : INFO : built Dictionary(285 unique tokens: ['build', 'hello', 'anniversari', 'celebr', 'continu']...) from 55 documents (total 638 corpus positions)\n",
      "2019-04-24 17:00:41,572 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,575 : INFO : built Dictionary(195 unique tokens: ['announc', 'compani', 'effort', 'hololen', 'home']...) from 26 documents (total 355 corpus positions)\n",
      "2019-04-24 17:00:41,598 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,601 : INFO : built Dictionary(166 unique tokens: ['ago', 'client', 'contact', 'decommiss', 'drupal']...) from 33 documents (total 364 corpus positions)\n",
      "2019-04-24 17:00:41,617 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:41,619 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,622 : INFO : built Dictionary(20 unique tokens: ['best', 'check', 'code', 'coder', 'drupal']...) from 3 documents (total 29 corpus positions)\n",
      "2019-04-24 17:00:41,624 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:41,629 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:41,631 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:41,633 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,635 : INFO : built Dictionary(40 unique tokens: ['billion', 'come', 'compani', 'convert', 'deal']...) from 2 documents (total 43 corpus positions)\n",
      "2019-04-24 17:00:41,638 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:41,640 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:41,642 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:41,646 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,649 : INFO : built Dictionary(70 unique tokens: ['advoc', 'applic', 'build', 'develop', 'excit']...) from 12 documents (total 97 corpus positions)\n",
      "2019-04-24 17:00:41,661 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,664 : INFO : built Dictionary(256 unique tokens: ['access', 'billion', 'facebook', 'help', 'internet']...) from 28 documents (total 402 corpus positions)\n",
      "2019-04-24 17:00:41,682 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,685 : INFO : built Dictionary(185 unique tokens: ['announc', 'bot', 'build', 'compani', 'confer']...) from 25 documents (total 346 corpus positions)\n",
      "2019-04-24 17:00:41,701 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,704 : INFO : built Dictionary(171 unique tokens: ['brows', 'command', 'cool', 'develop', 'end']...) from 41 documents (total 323 corpus positions)\n",
      "2019-04-24 17:00:41,721 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:41,724 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,726 : INFO : built Dictionary(93 unique tokens: ['announc', 'avail', 'consensi', 'contract', 'develop']...) from 6 documents (total 140 corpus positions)\n",
      "2019-04-24 17:00:41,729 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:41,741 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,744 : INFO : built Dictionary(263 unique tokens: ['clear', 'corp', 'depositori', 'trust', 'center']...) from 29 documents (total 512 corpus positions)\n",
      "2019-04-24 17:00:41,766 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,770 : INFO : built Dictionary(267 unique tokens: ['action', 'bitcoin', 'control', 'entitl', 'focus']...) from 29 documents (total 412 corpus positions)\n",
      "2019-04-24 17:00:41,788 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,791 : INFO : built Dictionary(195 unique tokens: ['base', 'bitcoin', 'bitit', 'launch', 'locat']...) from 31 documents (total 338 corpus positions)\n",
      "2019-04-24 17:00:41,813 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,817 : INFO : built Dictionary(260 unique tokens: ['associ', 'bitcoin', 'energi', 'focu', 'lot']...) from 45 documents (total 512 corpus positions)\n",
      "2019-04-24 17:00:41,844 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:41,846 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,849 : INFO : built Dictionary(28 unique tokens: ['achiev', 'adopt', 'ago', 'appar', 'bitcoin']...) from 2 documents (total 30 corpus positions)\n",
      "2019-04-24 17:00:41,851 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:41,853 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:41,856 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:41,863 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,866 : INFO : built Dictionary(108 unique tokens: ['eth', 'ether', 'exchang', 'includ', 'kei']...) from 20 documents (total 210 corpus positions)\n",
      "2019-04-24 17:00:41,876 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:41,878 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,880 : INFO : built Dictionary(37 unique tokens: ['brown', 'burnt', 'butter', 'candi', 'color']...) from 3 documents (total 49 corpus positions)\n",
      "2019-04-24 17:00:41,883 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:41,885 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:41,889 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:41,904 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,911 : INFO : built Dictionary(230 unique tokens: ['avail', 'develop', 'enabl', 'extens', 'linux']...) from 62 documents (total 518 corpus positions)\n",
      "2019-04-24 17:00:41,951 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,955 : INFO : built Dictionary(100 unique tokens: ['attende', 'build', 'hand', 'lot', 'microsoft']...) from 12 documents (total 156 corpus positions)\n",
      "2019-04-24 17:00:41,966 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,971 : INFO : built Dictionary(169 unique tokens: ['augment', 'come', 'develop', 'futur', 'hijink']...) from 15 documents (total 230 corpus positions)\n",
      "2019-04-24 17:00:41,987 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:41,991 : INFO : built Dictionary(278 unique tokens: ['aaron', 'conveni', 'decid', 'director', 'home']...) from 32 documents (total 446 corpus positions)\n",
      "2019-04-24 17:00:42,016 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,021 : INFO : built Dictionary(193 unique tokens: ['accept', 'anger', 'associ', 'bargain', 'busi']...) from 19 documents (total 301 corpus positions)\n",
      "2019-04-24 17:00:42,039 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,042 : INFO : built Dictionary(228 unique tokens: ['common', 'commun', 'degre', 'docker', 'familiar']...) from 47 documents (total 411 corpus positions)\n",
      "2019-04-24 17:00:42,064 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:42,067 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,070 : INFO : built Dictionary(79 unique tokens: ['até', 'bilhõ', 'capturar', 'carteira', 'cartõ']...) from 5 documents (total 97 corpus positions)\n",
      "2019-04-24 17:00:42,073 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:42,085 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,088 : INFO : built Dictionary(226 unique tokens: ['api', 'applic', 'browser', 'core', 'devic']...) from 33 documents (total 442 corpus positions)\n",
      "2019-04-24 17:00:42,107 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,110 : INFO : built Dictionary(90 unique tokens: ['approach', 'bank', 'blockchain', 'comptrol', 'currenc']...) from 10 documents (total 139 corpus positions)\n",
      "2019-04-24 17:00:42,119 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,122 : INFO : built Dictionary(125 unique tokens: ['bitcoin', 'card', 'contactless', 'debit', 'launch']...) from 17 documents (total 244 corpus positions)\n",
      "2019-04-24 17:00:42,135 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,138 : INFO : built Dictionary(147 unique tokens: ['ad', 'blockchain', 'currenc', 'digit', 'earlier']...) from 20 documents (total 253 corpus positions)\n",
      "2019-04-24 17:00:42,168 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,174 : INFO : built Dictionary(395 unique tokens: ['angularj', 'built', 'develop', 'framework', 'great']...) from 139 documents (total 1289 corpus positions)\n",
      "2019-04-24 17:00:42,304 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,307 : INFO : built Dictionary(226 unique tokens: ['characterist', 'goal', 'organ', 'process', 'special']...) from 43 documents (total 465 corpus positions)\n",
      "2019-04-24 17:00:42,336 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,340 : INFO : built Dictionary(124 unique tokens: ['cada', 'como', 'encontramo', 'esta', 'fica']...) from 14 documents (total 162 corpus positions)\n",
      "2019-04-24 17:00:42,369 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,374 : INFO : built Dictionary(552 unique tokens: ['busi', 'clear', 'compani', 'emphasi', 'forward']...) from 76 documents (total 1175 corpus positions)\n",
      "2019-04-24 17:00:42,425 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:42,427 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,429 : INFO : built Dictionary(65 unique tokens: ['book', 'came', 'chang', 'context', 'deepli']...) from 5 documents (total 80 corpus positions)\n",
      "2019-04-24 17:00:42,432 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:42,444 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,448 : INFO : built Dictionary(221 unique tokens: ['actual', 'blog', 'com', 'exercis', 'go']...) from 68 documents (total 452 corpus positions)\n",
      "2019-04-24 17:00:42,488 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,492 : INFO : built Dictionary(302 unique tokens: ['dai', 'excit', 'microsoft', 'team', 'todai']...) from 62 documents (total 761 corpus positions)\n",
      "2019-04-24 17:00:42,531 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,535 : INFO : built Dictionary(78 unique tokens: ['button', 'eject', 'email', 'great', 'hit']...) from 13 documents (total 101 corpus positions)\n",
      "2019-04-24 17:00:42,545 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,549 : INFO : built Dictionary(136 unique tokens: ['api', 'beta', 'broader', 'cloud', 'commun']...) from 18 documents (total 181 corpus positions)\n",
      "2019-04-24 17:00:42,558 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:42,561 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,563 : INFO : built Dictionary(66 unique tokens: ['digitai', 'do', 'el', 'física', 'livro']...) from 8 documents (total 78 corpus positions)\n",
      "2019-04-24 17:00:42,565 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:42,582 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,586 : INFO : built Dictionary(358 unique tokens: ['attende', 'build', 'center', 'chanc', 'cloud']...) from 52 documents (total 654 corpus positions)\n",
      "2019-04-24 17:00:42,617 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,621 : INFO : built Dictionary(130 unique tokens: ['best', 'cloud', 'compani', 'engin', 'francisco']...) from 17 documents (total 232 corpus positions)\n",
      "2019-04-24 17:00:42,639 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,643 : INFO : built Dictionary(393 unique tokens: ['amigo', 'com', 'concorrendo', 'conversava', 'dia']...) from 44 documents (total 818 corpus positions)\n",
      "2019-04-24 17:00:42,680 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,683 : INFO : built Dictionary(147 unique tokens: ['post', 'titl', 'typo', 'correctli', 'read']...) from 19 documents (total 287 corpus positions)\n",
      "2019-04-24 17:00:42,699 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,702 : INFO : built Dictionary(135 unique tokens: ['applic', 'cloud', 'databas', 'datastor', 'googl']...) from 35 documents (total 334 corpus positions)\n",
      "2019-04-24 17:00:42,719 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,723 : INFO : built Dictionary(73 unique tokens: ['concern', 'docker', 'hub', 'pass', 'proud']...) from 12 documents (total 118 corpus positions)\n",
      "2019-04-24 17:00:42,731 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,735 : INFO : built Dictionary(91 unique tokens: ['commun', 'hous', 'machin', 'bodi', 'technolog']...) from 16 documents (total 132 corpus positions)\n",
      "2019-04-24 17:00:42,743 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:42,746 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,749 : INFO : built Dictionary(76 unique tokens: ['activ', 'android', 'app', 'billion', 'distribut']...) from 7 documents (total 110 corpus positions)\n",
      "2019-04-24 17:00:42,752 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:42,759 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,764 : INFO : built Dictionary(140 unique tokens: ['acordo', 'automação', 'citi', 'com', 'está']...) from 12 documents (total 197 corpus positions)\n",
      "2019-04-24 17:00:42,776 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,781 : INFO : built Dictionary(309 unique tokens: ['algum', 'atend', 'banco', 'capacidad', 'client']...) from 27 documents (total 507 corpus positions)\n",
      "2019-04-24 17:00:42,819 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,826 : INFO : built Dictionary(627 unique tokens: ['ago', 'ceo', 'clear', 'indra', 'nooyi']...) from 197 documents (total 1243 corpus positions)\n",
      "2019-04-24 17:00:42,978 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:42,986 : INFO : built Dictionary(212 unique tokens: ['acquisit', 'close', 'march', 'microsoft', 'offici']...) from 35 documents (total 398 corpus positions)\n",
      "2019-04-24 17:00:43,050 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,056 : INFO : built Dictionary(816 unique tokens: ['amaz', 'collabor', 'commun', 'docker', 'month']...) from 183 documents (total 2261 corpus positions)\n",
      "2019-04-24 17:00:43,252 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,255 : INFO : built Dictionary(112 unique tokens: ['billion', 'busi', 'compani', 'confirm', 'messag']...) from 12 documents (total 145 corpus positions)\n",
      "2019-04-24 17:00:43,270 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,274 : INFO : built Dictionary(360 unique tokens: ['artifici', 'beat', 'board', 'champion', 'complex']...) from 53 documents (total 566 corpus positions)\n",
      "2019-04-24 17:00:43,302 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,304 : INFO : built Dictionary(114 unique tokens: ['gallup', 'getti', 'histor', 'middl', 'moment']...) from 15 documents (total 185 corpus positions)\n",
      "2019-04-24 17:00:43,318 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,322 : INFO : built Dictionary(272 unique tokens: ['compani', 'entrepreneur', 'focus', 'leader', 'master']...) from 40 documents (total 427 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:43,348 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,351 : INFO : built Dictionary(277 unique tokens: ['axl', 'dynam', 'forc', 'gear', 'mechan']...) from 45 documents (total 523 corpus positions)\n",
      "2019-04-24 17:00:43,377 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,380 : INFO : built Dictionary(217 unique tokens: ['articl', 'chanc', 'etsi', 'familiar', 'mayb']...) from 23 documents (total 370 corpus positions)\n",
      "2019-04-24 17:00:43,399 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,402 : INFO : built Dictionary(299 unique tokens: ['artifici', 'develop', 'faster', 'intellig', 'thought']...) from 40 documents (total 502 corpus positions)\n",
      "2019-04-24 17:00:43,432 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,436 : INFO : built Dictionary(430 unique tokens: ['amazon', 'chiu', 'dave', 'doubt', 'echo']...) from 67 documents (total 833 corpus positions)\n",
      "2019-04-24 17:00:43,484 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,487 : INFO : built Dictionary(164 unique tokens: ['ago', 'chromebox', 'devic', 'easi', 'enjoi']...) from 21 documents (total 265 corpus positions)\n",
      "2019-04-24 17:00:43,502 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,507 : INFO : built Dictionary(216 unique tokens: ['barket', 'brad', 'cool', 'facebook', 'getti']...) from 33 documents (total 359 corpus positions)\n",
      "2019-04-24 17:00:43,530 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,534 : INFO : built Dictionary(220 unique tokens: ['applic', 'explos', 'learn', 'machin', 'potenti']...) from 38 documents (total 406 corpus positions)\n",
      "2019-04-24 17:00:43,551 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,555 : INFO : built Dictionary(122 unique tokens: ['arriv', 'appear', 'april', 'come', 'lilli']...) from 18 documents (total 155 corpus positions)\n",
      "2019-04-24 17:00:43,570 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,574 : INFO : built Dictionary(288 unique tokens: ['advantag', 'bigger', 'build', 'busi', 'give']...) from 51 documents (total 484 corpus positions)\n",
      "2019-04-24 17:00:43,601 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:43,603 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,606 : INFO : built Dictionary(180 unique tokens: ['aggreg', 'break', 'bucket', 'bug', 'chang']...) from 9 documents (total 298 corpus positions)\n",
      "2019-04-24 17:00:43,609 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:43,619 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,622 : INFO : built Dictionary(237 unique tokens: ['adotar', 'baxter', 'berlim', 'bex', 'bristol']...) from 17 documents (total 339 corpus positions)\n",
      "2019-04-24 17:00:43,659 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,665 : INFO : built Dictionary(526 unique tokens: ['box', 'introduct', 'learn', 'librari', 'machin']...) from 100 documents (total 1671 corpus positions)\n",
      "2019-04-24 17:00:43,758 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,761 : INFO : built Dictionary(98 unique tokens: ['ag', 'danger', 'drone', 'golden', 'live']...) from 10 documents (total 121 corpus positions)\n",
      "2019-04-24 17:00:43,775 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,778 : INFO : built Dictionary(192 unique tokens: ['biolog', 'devis', 'engin', 'function', 'languag']...) from 33 documents (total 376 corpus positions)\n",
      "2019-04-24 17:00:43,802 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,806 : INFO : built Dictionary(249 unique tokens: ['abil', 'app', 'bot', 'english', 'fast']...) from 38 documents (total 511 corpus positions)\n",
      "2019-04-24 17:00:43,837 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,841 : INFO : built Dictionary(148 unique tokens: ['actual', 'attent', 'best', 'better', 'calori']...) from 23 documents (total 218 corpus positions)\n",
      "2019-04-24 17:00:43,853 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,857 : INFO : built Dictionary(146 unique tokens: ['alta', 'andré', 'ano', 'carioca', 'convidado']...) from 15 documents (total 223 corpus positions)\n",
      "2019-04-24 17:00:43,868 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,871 : INFO : built Dictionary(113 unique tokens: ['accord', 'compani', 'competitor', 'contain', 'coreo']...) from 11 documents (total 171 corpus positions)\n",
      "2019-04-24 17:00:43,879 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:43,882 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,885 : INFO : built Dictionary(69 unique tokens: ['amor', 'cor', 'diverso', 'etnia', 'fotógrafo']...) from 5 documents (total 86 corpus positions)\n",
      "2019-04-24 17:00:43,887 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:43,894 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,897 : INFO : built Dictionary(42 unique tokens: ['class', 'creat', 'free', 'game', 'like']...) from 12 documents (total 64 corpus positions)\n",
      "2019-04-24 17:00:43,906 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,909 : INFO : built Dictionary(145 unique tokens: ['announc', 'applic', 'bank', 'blockchain', 'chase']...) from 11 documents (total 219 corpus positions)\n",
      "2019-04-24 17:00:43,922 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,925 : INFO : built Dictionary(215 unique tokens: ['athlet', 'billionair', 'dictat', 'drug', 'erupt']...) from 30 documents (total 336 corpus positions)\n",
      "2019-04-24 17:00:43,941 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,948 : INFO : built Dictionary(128 unique tokens: ['banner', 'certainli', 'folk', 'tesla', 'week']...) from 20 documents (total 159 corpus positions)\n",
      "2019-04-24 17:00:43,960 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,963 : INFO : built Dictionary(160 unique tokens: ['bitcoin', 'come', 'compani', 'ecosystem', 'fund']...) from 19 documents (total 234 corpus positions)\n",
      "2019-04-24 17:00:43,976 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,979 : INFO : built Dictionary(110 unique tokens: ['bitcoin', 'ethereum', 'fact', 'ignor', 'lot']...) from 19 documents (total 184 corpus positions)\n",
      "2019-04-24 17:00:43,992 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:43,995 : INFO : built Dictionary(197 unique tokens: ['bitcoin', 'cybersecur', 'discuss', 'ethereum', 'execut']...) from 18 documents (total 266 corpus positions)\n",
      "2019-04-24 17:00:44,010 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,013 : INFO : built Dictionary(225 unique tokens: ['abil', 'aim', 'announc', 'bank', 'base']...) from 14 documents (total 309 corpus positions)\n",
      "2019-04-24 17:00:44,026 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,029 : INFO : built Dictionary(189 unique tokens: ['advisor', 'bitcoin', 'blockchain', 'continu', 'countri']...) from 27 documents (total 331 corpus positions)\n",
      "2019-04-24 17:00:44,044 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,047 : INFO : built Dictionary(115 unique tokens: ['began', 'carefulli', 'countri', 'earlier', 'expect']...) from 14 documents (total 146 corpus positions)\n",
      "2019-04-24 17:00:44,057 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,061 : INFO : built Dictionary(127 unique tokens: ['mainnet', 'openbazaar', 'readi', 'real', 'releas']...) from 23 documents (total 210 corpus positions)\n",
      "2019-04-24 17:00:44,075 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,078 : INFO : built Dictionary(144 unique tokens: ['american', 'darl', 'happen', 'meet', 'scene']...) from 15 documents (total 194 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:44,089 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:44,092 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,094 : INFO : built Dictionary(62 unique tokens: ['awar', 'googl', 'impress', 'learn', 'machin']...) from 9 documents (total 92 corpus positions)\n",
      "2019-04-24 17:00:44,096 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:44,108 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,111 : INFO : built Dictionary(159 unique tokens: ['cluster', 'docker', 'edit', 'follow', 'instruct']...) from 20 documents (total 361 corpus positions)\n",
      "2019-04-24 17:00:44,125 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,129 : INFO : built Dictionary(193 unique tokens: ['began', 'burger', 'cal', 'commun', 'expect']...) from 34 documents (total 318 corpus positions)\n",
      "2019-04-24 17:00:44,158 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,162 : INFO : built Dictionary(606 unique tokens: ['build', 'conferência', 'desenvolvedor', 'durant', 'eua']...) from 72 documents (total 991 corpus positions)\n",
      "2019-04-24 17:00:44,212 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:44,216 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,218 : INFO : built Dictionary(39 unique tokens: ['earth', 'know', 'lot', 'surfac', 'want']...) from 5 documents (total 45 corpus positions)\n",
      "2019-04-24 17:00:44,220 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:44,228 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,233 : INFO : built Dictionary(121 unique tokens: ['announc', 'cloud', 'databas', 'datastor', 'googl']...) from 20 documents (total 233 corpus positions)\n",
      "2019-04-24 17:00:44,251 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,254 : INFO : built Dictionary(208 unique tokens: ['applic', 'blog', 'cloud', 'creat', 'develop']...) from 21 documents (total 402 corpus positions)\n",
      "2019-04-24 17:00:44,287 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,294 : INFO : built Dictionary(406 unique tokens: ['robert', 'articl', 'aspect', 'bloat', 'latest']...) from 103 documents (total 1434 corpus positions)\n",
      "2019-04-24 17:00:44,384 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,388 : INFO : built Dictionary(295 unique tokens: ['analysi', 'collect', 'come', 'conduct', 'cours']...) from 33 documents (total 687 corpus positions)\n",
      "2019-04-24 17:00:44,441 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,450 : INFO : built Dictionary(292 unique tokens: ['public', 'nielsen', 'der', 'shin', 'vaidyanathan']...) from 105 documents (total 1144 corpus positions)\n",
      "2019-04-24 17:00:44,500 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,503 : INFO : built Dictionary(106 unique tokens: ['acquir', 'chees', 'design', 'develop', 'hard']...) from 12 documents (total 186 corpus positions)\n",
      "2019-04-24 17:00:44,524 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,527 : INFO : built Dictionary(367 unique tokens: ['ag', 'api', 'base', 'cloud', 'enter']...) from 71 documents (total 784 corpus positions)\n",
      "2019-04-24 17:00:44,577 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,580 : INFO : built Dictionary(182 unique tokens: ['bitcoin', 'dai', 'disrupt', 'entrepreneur', 'financi']...) from 22 documents (total 283 corpus positions)\n",
      "2019-04-24 17:00:44,594 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,598 : INFO : built Dictionary(163 unique tokens: ['ahead', 'alphabet', 'amazon', 'blockchain', 'busi']...) from 19 documents (total 236 corpus positions)\n",
      "2019-04-24 17:00:44,621 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,625 : INFO : built Dictionary(435 unique tokens: ['biggest', 'contain', 'coupl', 'daniel', 'document']...) from 58 documents (total 811 corpus positions)\n",
      "2019-04-24 17:00:44,660 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,663 : INFO : built Dictionary(152 unique tokens: ['auka', 'bank', 'bird', 'complianc', 'custom']...) from 16 documents (total 225 corpus positions)\n",
      "2019-04-24 17:00:44,677 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,681 : INFO : built Dictionary(373 unique tokens: ['aplaudido', 'começava', 'el', 'gai', 'minha']...) from 44 documents (total 677 corpus positions)\n",
      "2019-04-24 17:00:44,711 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,714 : INFO : built Dictionary(206 unique tokens: ['announc', 'bring', 'doldrum', 'drive', 'final']...) from 29 documents (total 348 corpus positions)\n",
      "2019-04-24 17:00:44,731 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,734 : INFO : built Dictionary(191 unique tokens: ['capa', 'colocamo', 'consegu', 'essa', 'imagem']...) from 12 documents (total 268 corpus positions)\n",
      "2019-04-24 17:00:44,746 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,749 : INFO : built Dictionary(210 unique tokens: ['access', 'googl', 'healthcar', 'help', 'increas']...) from 23 documents (total 323 corpus positions)\n",
      "2019-04-24 17:00:44,763 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,766 : INFO : built Dictionary(158 unique tokens: ['adesão', 'amazônia', 'demissão', 'divulgado', 'empresa']...) from 14 documents (total 216 corpus positions)\n",
      "2019-04-24 17:00:44,782 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,786 : INFO : built Dictionary(309 unique tokens: ['bug', 'count', 'easi', 'good', 'low']...) from 70 documents (total 538 corpus positions)\n",
      "2019-04-24 17:00:44,834 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,839 : INFO : built Dictionary(449 unique tokens: ['career', 'framework', 'individu', 'launch', 'path']...) from 110 documents (total 990 corpus positions)\n",
      "2019-04-24 17:00:44,913 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:44,916 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,919 : INFO : built Dictionary(106 unique tokens: ['come', 'ikea', 'leav', 'meatbal', 'realiti']...) from 9 documents (total 129 corpus positions)\n",
      "2019-04-24 17:00:44,921 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:44,937 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,945 : INFO : built Dictionary(293 unique tokens: ['america', 'app', 'bare', 'billion', 'bot']...) from 46 documents (total 547 corpus positions)\n",
      "2019-04-24 17:00:44,985 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:44,989 : INFO : built Dictionary(223 unique tokens: ['aim', 'announc', 'assist', 'blockchain', 'concept']...) from 27 documents (total 418 corpus positions)\n",
      "2019-04-24 17:00:45,021 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,028 : INFO : built Dictionary(223 unique tokens: ['bring', 'desktop', 'exasper', 'featur', 'final']...) from 60 documents (total 552 corpus positions)\n",
      "2019-04-24 17:00:45,065 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,068 : INFO : built Dictionary(149 unique tokens: ['aplicativo', 'enviar', 'está', 'instalada', 'mai']...) from 13 documents (total 214 corpus positions)\n",
      "2019-04-24 17:00:45,080 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,083 : INFO : built Dictionary(231 unique tokens: ['banco', 'bank', 'como', 'dado', 'data']...) from 25 documents (total 385 corpus positions)\n",
      "2019-04-24 17:00:45,110 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,113 : INFO : built Dictionary(340 unique tokens: ['depend', 'hypothes', 'improv', 'market', 'potenti']...) from 91 documents (total 894 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:45,178 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,182 : INFO : built Dictionary(460 unique tokens: ['fly', 'gui', 'like', 'non', 'stop']...) from 65 documents (total 863 corpus positions)\n",
      "2019-04-24 17:00:45,219 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,222 : INFO : built Dictionary(257 unique tokens: ['afin', 'existem', 'mesmo', 'não', 'unicórnio']...) from 25 documents (total 452 corpus positions)\n",
      "2019-04-24 17:00:45,243 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,247 : INFO : built Dictionary(242 unique tokens: ['approach', 'brave', 'browser', 'complet', 'differ']...) from 36 documents (total 438 corpus positions)\n",
      "2019-04-24 17:00:45,272 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,276 : INFO : built Dictionary(247 unique tokens: ['artifici', 'attempt', 'blockchain', 'current', 'ibm']...) from 29 documents (total 436 corpus positions)\n",
      "2019-04-24 17:00:45,300 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,304 : INFO : built Dictionary(323 unique tokens: ['blockchain', 'face', 'government', 'humanitarian', 'innov']...) from 62 documents (total 548 corpus positions)\n",
      "2019-04-24 17:00:45,334 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,337 : INFO : built Dictionary(172 unique tokens: ['attack', 'base', 'design', 'individu', 'network']...) from 28 documents (total 287 corpus positions)\n",
      "2019-04-24 17:00:45,356 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,359 : INFO : built Dictionary(218 unique tokens: ['accord', 'anthoni', 'blockchain', 'cap', 'coin']...) from 32 documents (total 466 corpus positions)\n",
      "2019-04-24 17:00:45,385 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,388 : INFO : built Dictionary(264 unique tokens: ['com', 'draw', 'drop', 'let', 'site']...) from 89 documents (total 510 corpus positions)\n",
      "2019-04-24 17:00:45,436 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,445 : INFO : built Dictionary(270 unique tokens: ['color', 'comment', 'equidist', 'find', 'hsv']...) from 63 documents (total 504 corpus positions)\n",
      "2019-04-24 17:00:45,493 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,496 : INFO : built Dictionary(150 unique tokens: ['comput', 'deal', 'deep', 'dream', 'experi']...) from 19 documents (total 202 corpus positions)\n",
      "2019-04-24 17:00:45,517 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,521 : INFO : built Dictionary(306 unique tokens: ['busi', 'deserv', 'design', 'futur', 'newberi']...) from 55 documents (total 609 corpus positions)\n",
      "2019-04-24 17:00:45,558 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,561 : INFO : built Dictionary(68 unique tokens: ['affluenc', 'consum', 'live', 'million', 'societi']...) from 15 documents (total 80 corpus positions)\n",
      "2019-04-24 17:00:45,573 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,577 : INFO : built Dictionary(117 unique tokens: ['devic', 'goal', 'help', 'microsoft', 'mind']...) from 21 documents (total 221 corpus positions)\n",
      "2019-04-24 17:00:45,591 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:45,593 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,598 : INFO : built Dictionary(94 unique tokens: ['amiabl', 'awaken', 'ball', 'cat', 'exist']...) from 7 documents (total 114 corpus positions)\n",
      "2019-04-24 17:00:45,601 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:45,611 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,615 : INFO : built Dictionary(182 unique tokens: ['acesso', 'aparelho', 'brasileiro', 'celular', 'dado']...) from 25 documents (total 351 corpus positions)\n",
      "2019-04-24 17:00:45,630 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:45,633 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,637 : INFO : built Dictionary(66 unique tokens: ['animai', 'apena', 'card', 'cliqu', 'com']...) from 5 documents (total 84 corpus positions)\n",
      "2019-04-24 17:00:45,641 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:45,662 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,665 : INFO : built Dictionary(223 unique tokens: ['angular', 'common', 'develop', 'duplic', 'export']...) from 68 documents (total 749 corpus positions)\n",
      "2019-04-24 17:00:45,715 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:45,717 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,721 : INFO : built Dictionary(22 unique tokens: ['minut', 'shouldn', 'survei', 'builder', 'care']...) from 3 documents (total 27 corpus positions)\n",
      "2019-04-24 17:00:45,724 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:45,727 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:45,729 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:45,740 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,744 : INFO : built Dictionary(220 unique tokens: ['agenc', 'feel', 'like', 'luxuri', 'research']...) from 43 documents (total 446 corpus positions)\n",
      "2019-04-24 17:00:45,768 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,771 : INFO : built Dictionary(153 unique tokens: ['agronegócio', 'artificiai', 'aumento', 'busca', 'caminho']...) from 13 documents (total 261 corpus positions)\n",
      "2019-04-24 17:00:45,781 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,784 : INFO : built Dictionary(91 unique tokens: ['atuem', 'banco', 'bnde', 'brasil', 'busca']...) from 10 documents (total 118 corpus positions)\n",
      "2019-04-24 17:00:45,805 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,810 : INFO : built Dictionary(406 unique tokens: ['googl', 'need', 'time', 'wasn', 'happen']...) from 77 documents (total 786 corpus positions)\n",
      "2019-04-24 17:00:45,867 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,871 : INFO : built Dictionary(519 unique tokens: ['android', 'começar', 'desenvolvendo', 'ond', 'por']...) from 77 documents (total 1204 corpus positions)\n",
      "2019-04-24 17:00:45,941 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,949 : INFO : built Dictionary(93 unique tokens: ['center', 'data', 'design', 'googl', 'happen']...) from 11 documents (total 124 corpus positions)\n",
      "2019-04-24 17:00:45,970 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:45,974 : INFO : built Dictionary(349 unique tokens: ['app', 'begin', 'cloud', 'comput', 'engin']...) from 63 documents (total 823 corpus positions)\n",
      "2019-04-24 17:00:46,043 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,047 : INFO : built Dictionary(207 unique tokens: ['featur', 'import', 'mobil', 'notif', 'platform']...) from 31 documents (total 339 corpus positions)\n",
      "2019-04-24 17:00:46,064 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,067 : INFO : built Dictionary(120 unique tokens: ['analyt', 'app', 'data', 'develop', 'gener']...) from 13 documents (total 187 corpus positions)\n",
      "2019-04-24 17:00:46,109 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,116 : INFO : built Dictionary(673 unique tokens: ['advisor', 'daniel', 'data', 'instacart', 'jeremi']...) from 206 documents (total 2052 corpus positions)\n",
      "2019-04-24 17:00:46,491 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,493 : INFO : built Dictionary(134 unique tokens: ['abil', 'anniversari', 'announc', 'bash', 'build']...) from 12 documents (total 235 corpus positions)\n",
      "2019-04-24 17:00:46,502 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:46,504 : INFO : built Dictionary(77 unique tokens: ['align', 'css', 'justifi', 'smart', 'smartli']...) from 20 documents (total 165 corpus positions)\n",
      "2019-04-24 17:00:46,513 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:46,515 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,517 : INFO : built Dictionary(55 unique tokens: ['app', 'battl', 'best', 'book', 'clash']...) from 6 documents (total 77 corpus positions)\n",
      "2019-04-24 17:00:46,519 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:46,524 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,526 : INFO : built Dictionary(62 unique tokens: ['hei', 'heard', 'star', 'thing', 'war']...) from 12 documents (total 88 corpus positions)\n",
      "2019-04-24 17:00:46,542 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,546 : INFO : built Dictionary(536 unique tokens: ['amigo', 'com', 'concepção', 'contam', 'desenvolvimento']...) from 47 documents (total 1113 corpus positions)\n",
      "2019-04-24 17:00:46,583 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,586 : INFO : built Dictionary(221 unique tokens: ['aren', 'chanc', 'content', 'familiar', 'good']...) from 46 documents (total 351 corpus positions)\n",
      "2019-04-24 17:00:46,614 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,620 : INFO : built Dictionary(449 unique tokens: ['complex', 'coverag', 'fee', 'includ', 'insur']...) from 63 documents (total 828 corpus positions)\n",
      "2019-04-24 17:00:46,666 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,669 : INFO : built Dictionary(217 unique tokens: ['abril', 'auditório', 'aumenta', 'brasil', 'campina']...) from 17 documents (total 368 corpus positions)\n",
      "2019-04-24 17:00:46,680 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,682 : INFO : built Dictionary(119 unique tokens: ['app', 'messag', 'smartphon', 'social', 'us']...) from 18 documents (total 201 corpus positions)\n",
      "2019-04-24 17:00:46,694 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,697 : INFO : built Dictionary(187 unique tokens: ['attempt', 'blockchain', 'bridg', 'financ', 'gap']...) from 23 documents (total 340 corpus positions)\n",
      "2019-04-24 17:00:46,714 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,720 : INFO : built Dictionary(443 unique tokens: ['anim', 'causa', 'desd', 'encantamento', 'força']...) from 43 documents (total 754 corpus positions)\n",
      "2019-04-24 17:00:46,749 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,753 : INFO : built Dictionary(274 unique tokens: ['brand', 'discuss', 'facebook', 'go', 'googl']...) from 60 documents (total 562 corpus positions)\n",
      "2019-04-24 17:00:46,787 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,791 : INFO : built Dictionary(112 unique tokens: ['apresent', 'esta', 'mai', 'notebook', 'novo']...) from 11 documents (total 162 corpus positions)\n",
      "2019-04-24 17:00:46,799 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,802 : INFO : built Dictionary(199 unique tokens: ['apresentada', 'client', 'como', 'ela', 'fazem']...) from 16 documents (total 264 corpus positions)\n",
      "2019-04-24 17:00:46,813 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,816 : INFO : built Dictionary(249 unique tokens: ['accentur', 'analyt', 'brasileiro', 'braço', 'client']...) from 20 documents (total 349 corpus positions)\n",
      "2019-04-24 17:00:46,836 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,841 : INFO : built Dictionary(396 unique tokens: ['announc', 'bank', 'blockchain', 'consortium', 'develop']...) from 60 documents (total 920 corpus positions)\n",
      "2019-04-24 17:00:46,881 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,885 : INFO : built Dictionary(121 unique tokens: ['base', 'cach', 'call', 'compani', 'creat']...) from 14 documents (total 172 corpus positions)\n",
      "2019-04-24 17:00:46,898 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,901 : INFO : built Dictionary(283 unique tokens: ['author', 'bitcoin', 'btc', 'chri', 'express']...) from 31 documents (total 533 corpus positions)\n",
      "2019-04-24 17:00:46,915 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:46,918 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,919 : INFO : built Dictionary(30 unique tokens: ['agenda', 'appli', 'basic', 'brain', 'choos']...) from 2 documents (total 31 corpus positions)\n",
      "2019-04-24 17:00:46,921 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:46,923 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:46,925 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:46,932 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,935 : INFO : built Dictionary(194 unique tokens: ['anim', 'anuncia', 'brasil', 'cargil', 'client']...) from 19 documents (total 368 corpus positions)\n",
      "2019-04-24 17:00:46,963 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:46,967 : INFO : built Dictionary(427 unique tokens: ['android', 'begin', 'develop', 'jump', 'web']...) from 135 documents (total 1145 corpus positions)\n",
      "2019-04-24 17:00:47,057 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,060 : INFO : built Dictionary(138 unique tokens: ['app', 'inform', 'need', 'place', 'comput']...) from 34 documents (total 244 corpus positions)\n",
      "2019-04-24 17:00:47,085 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,089 : INFO : built Dictionary(432 unique tokens: ['interest', 'learn', 'machin', 'dai', 'get']...) from 67 documents (total 831 corpus positions)\n",
      "2019-04-24 17:00:47,133 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,135 : INFO : built Dictionary(193 unique tokens: ['capabl', 'comput', 'human', 'lifetim', 'misconcept']...) from 21 documents (total 272 corpus positions)\n",
      "2019-04-24 17:00:47,156 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,159 : INFO : built Dictionary(347 unique tokens: ['coolest', 'featur', 'java', 'start', 'todai']...) from 60 documents (total 664 corpus positions)\n",
      "2019-04-24 17:00:47,198 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,202 : INFO : built Dictionary(268 unique tokens: ['android', 'app', 'auto', 'build', 'eason']...) from 59 documents (total 747 corpus positions)\n",
      "2019-04-24 17:00:47,240 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,243 : INFO : built Dictionary(342 unique tokens: ['encount', 'rememb', 'smp', 'vividli', 'dual']...) from 77 documents (total 671 corpus positions)\n",
      "2019-04-24 17:00:47,272 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,274 : INFO : built Dictionary(60 unique tokens: ['card', 'googl', 'look', 'new', 'pai']...) from 12 documents (total 92 corpus positions)\n",
      "2019-04-24 17:00:47,280 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,282 : INFO : built Dictionary(85 unique tokens: ['ad', 'differ', 'familiar', 'listen', 'network']...) from 10 documents (total 108 corpus positions)\n",
      "2019-04-24 17:00:47,292 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,294 : INFO : built Dictionary(166 unique tokens: ['applic', 'cloud', 'databas', 'datastax', 'enterpris']...) from 28 documents (total 312 corpus positions)\n",
      "2019-04-24 17:00:47,309 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,312 : INFO : built Dictionary(228 unique tokens: ['abl', 'app', 'compani', 'giant', 'mobil']...) from 29 documents (total 393 corpus positions)\n",
      "2019-04-24 17:00:47,356 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,361 : INFO : built Dictionary(628 unique tokens: ['asset', 'busi', 'compon', 'consum', 'critic']...) from 144 documents (total 2434 corpus positions)\n",
      "2019-04-24 17:00:47,570 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:47,572 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,574 : INFO : built Dictionary(65 unique tokens: ['atom', 'awai', 'bank', 'big', 'britain']...) from 6 documents (total 93 corpus positions)\n",
      "2019-04-24 17:00:47,576 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:47,581 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:47,583 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,586 : INFO : built Dictionary(59 unique tokens: ['announc', 'dutch', 'ecosystem', 'fintech', 'holland']...) from 6 documents (total 88 corpus positions)\n",
      "2019-04-24 17:00:47,588 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:47,611 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,616 : INFO : built Dictionary(602 unique tokens: ['area', 'bank', 'busi', 'digit', 'help']...) from 95 documents (total 1338 corpus positions)\n",
      "2019-04-24 17:00:47,695 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,699 : INFO : built Dictionary(148 unique tokens: ['activ', 'fintech', 'follow', 'invest', 'month']...) from 27 documents (total 264 corpus positions)\n",
      "2019-04-24 17:00:47,716 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,718 : INFO : built Dictionary(277 unique tokens: ['bag', 'buck', 'bui', 'ga', 'groceri']...) from 31 documents (total 470 corpus positions)\n",
      "2019-04-24 17:00:47,735 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,738 : INFO : built Dictionary(192 unique tokens: ['australian', 'bank', 'behemoth', 'chang', 'explor']...) from 22 documents (total 324 corpus positions)\n",
      "2019-04-24 17:00:47,750 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,752 : INFO : built Dictionary(93 unique tokens: ['activ', 'appl', 'bank', 'barclai', 'deadlin']...) from 10 documents (total 142 corpus positions)\n",
      "2019-04-24 17:00:47,760 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,764 : INFO : built Dictionary(158 unique tokens: ['best', 'big', 'box', 'bui', 'card']...) from 23 documents (total 268 corpus positions)\n",
      "2019-04-24 17:00:47,775 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,778 : INFO : built Dictionary(128 unique tokens: ['announc', 'auth', 'braintre', 'checkout', 'entri']...) from 17 documents (total 258 corpus positions)\n",
      "2019-04-24 17:00:47,789 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,792 : INFO : built Dictionary(153 unique tokens: ['adopt', 'amazon', 'announc', 'morn', 'parti']...) from 18 documents (total 253 corpus positions)\n",
      "2019-04-24 17:00:47,804 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,807 : INFO : built Dictionary(226 unique tokens: ['attent', 'banker', 'barclai', 'busi', 'compani']...) from 27 documents (total 390 corpus positions)\n",
      "2019-04-24 17:00:47,828 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,836 : INFO : built Dictionary(317 unique tokens: ['abraçar', 'ainda', 'comentado', 'como', 'decol']...) from 31 documents (total 446 corpus positions)\n",
      "2019-04-24 17:00:47,861 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,865 : INFO : built Dictionary(311 unique tokens: ['app', 'card', 'cluster', 'combin', 'dai']...) from 59 documents (total 614 corpus positions)\n",
      "2019-04-24 17:00:47,893 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,898 : INFO : built Dictionary(213 unique tokens: ['blomfield', 'histor', 'moment', 'tom', 'account']...) from 35 documents (total 334 corpus positions)\n",
      "2019-04-24 17:00:47,922 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,925 : INFO : built Dictionary(286 unique tokens: ['abril', 'agora', 'agência', 'cavalletti', 'claro']...) from 34 documents (total 477 corpus positions)\n",
      "2019-04-24 17:00:47,943 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,946 : INFO : built Dictionary(164 unique tokens: ['alphago', 'ceo', 'chip', 'chipmak', 'gold']...) from 24 documents (total 231 corpus positions)\n",
      "2019-04-24 17:00:47,960 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,963 : INFO : built Dictionary(279 unique tokens: ['app', 'design', 'diabet', 'healthier', 'help']...) from 41 documents (total 501 corpus positions)\n",
      "2019-04-24 17:00:47,981 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,985 : INFO : built Dictionary(89 unique tokens: ['battl', 'cloud', 'learn', 'machin', 'new']...) from 15 documents (total 136 corpus positions)\n",
      "2019-04-24 17:00:47,993 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:47,996 : INFO : built Dictionary(169 unique tokens: ['aluno', 'ano', 'apó', 'assunto', 'barbacena']...) from 25 documents (total 263 corpus positions)\n",
      "2019-04-24 17:00:48,004 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:48,005 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,007 : INFO : built Dictionary(37 unique tokens: ['olá', 'persona', 'apresentar', 'central', 'como']...) from 3 documents (total 40 corpus positions)\n",
      "2019-04-24 17:00:48,008 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:48,011 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:48,014 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,016 : INFO : built Dictionary(85 unique tokens: ['abordagem', 'aprenda', 'como', 'conceitu', 'contar']...) from 11 documents (total 116 corpus positions)\n",
      "2019-04-24 17:00:48,024 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,026 : INFO : built Dictionary(126 unique tokens: ['applic', 'error', 'excit', 'help', 'introduc']...) from 18 documents (total 187 corpus positions)\n",
      "2019-04-24 17:00:48,035 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,037 : INFO : built Dictionary(167 unique tokens: ['decis', 'farmer', 'make', 'right', 'success']...) from 19 documents (total 274 corpus positions)\n",
      "2019-04-24 17:00:48,046 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,049 : INFO : built Dictionary(108 unique tokens: ['addit', 'compani', 'instant', 'preview', 'promin']...) from 11 documents (total 158 corpus positions)\n",
      "2019-04-24 17:00:48,058 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,061 : INFO : built Dictionary(241 unique tokens: ['actual', 'augment', 'compani', 'high', 'hint']...) from 30 documents (total 373 corpus positions)\n",
      "2019-04-24 17:00:48,072 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:48,074 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,076 : INFO : built Dictionary(80 unique tokens: ['better', 'chang', 'compon', 'dai', 'envis']...) from 7 documents (total 100 corpus positions)\n",
      "2019-04-24 17:00:48,079 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:48,091 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,094 : INFO : built Dictionary(417 unique tokens: ['imagen', 'originalment', 'publicado', 'site', 'texto']...) from 122 documents (total 822 corpus positions)\n",
      "2019-04-24 17:00:48,166 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,169 : INFO : built Dictionary(511 unique tokens: ['bee', 'amber', 'arrai', 'cell', 'cross']...) from 88 documents (total 990 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:48,222 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,225 : INFO : built Dictionary(93 unique tokens: ['algorithm', 'code', 'end', 'later', 'programm']...) from 10 documents (total 132 corpus positions)\n",
      "2019-04-24 17:00:48,241 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,245 : INFO : built Dictionary(294 unique tokens: ['futur', 'misunderstood', 'wide', 'aren', 'expect']...) from 57 documents (total 565 corpus positions)\n",
      "2019-04-24 17:00:48,273 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,276 : INFO : built Dictionary(138 unique tokens: ['abl', 'app', 'atom', 'bank', 'interact']...) from 15 documents (total 201 corpus positions)\n",
      "2019-04-24 17:00:48,288 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,291 : INFO : built Dictionary(209 unique tokens: ['activ', 'artifici', 'deal', 'high', 'hit']...) from 48 documents (total 308 corpus positions)\n",
      "2019-04-24 17:00:48,306 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,309 : INFO : built Dictionary(108 unique tokens: ['afternoon', 'coupl', 'feedback', 'got', 'issu']...) from 21 documents (total 174 corpus positions)\n",
      "2019-04-24 17:00:48,319 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,325 : INFO : built Dictionary(159 unique tokens: ['base', 'benefit', 'bitcoin', 'blockchain', 'compani']...) from 11 documents (total 226 corpus positions)\n",
      "2019-04-24 17:00:48,354 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,360 : INFO : built Dictionary(303 unique tokens: ['annual', 'averag', 'capita', 'compar', 'countri']...) from 51 documents (total 848 corpus positions)\n",
      "2019-04-24 17:00:48,391 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,394 : INFO : built Dictionary(129 unique tokens: ['data', 'earth', 'final', 'fourth', 'googl']...) from 39 documents (total 286 corpus positions)\n",
      "2019-04-24 17:00:48,424 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,429 : INFO : built Dictionary(536 unique tokens: ['comic', 'hate', 'love', 'san', 'ban']...) from 99 documents (total 1112 corpus positions)\n",
      "2019-04-24 17:00:48,502 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,506 : INFO : built Dictionary(397 unique tokens: ['amadurecimento', 'criam', 'crítica', 'da', 'design']...) from 50 documents (total 805 corpus positions)\n",
      "2019-04-24 17:00:48,544 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,547 : INFO : built Dictionary(204 unique tokens: ['acquir', 'awar', 'believ', 'best', 'discuss']...) from 39 documents (total 471 corpus positions)\n",
      "2019-04-24 17:00:48,567 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:48,570 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,572 : INFO : built Dictionary(38 unique tokens: ['common', 'eat', 'factor', 'look', 'offic']...) from 4 documents (total 41 corpus positions)\n",
      "2019-04-24 17:00:48,574 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:48,579 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:48,582 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:48,585 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,587 : INFO : built Dictionary(97 unique tokens: ['com', 'constantement', 'da', 'do', 'espaço']...) from 5 documents (total 128 corpus positions)\n",
      "2019-04-24 17:00:48,589 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:48,598 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,601 : INFO : built Dictionary(213 unique tokens: ['bitcoin', 'cointelegraph', 'con', 'employe', 'freelanc']...) from 31 documents (total 324 corpus positions)\n",
      "2019-04-24 17:00:48,614 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,617 : INFO : built Dictionary(122 unique tokens: ['blockchain', 'come', 'disnei', 'intern', 'privat']...) from 16 documents (total 188 corpus positions)\n",
      "2019-04-24 17:00:48,625 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,628 : INFO : built Dictionary(131 unique tokens: ['announc', 'beta', 'cloud', 'lab', 'offici']...) from 12 documents (total 189 corpus positions)\n",
      "2019-04-24 17:00:48,643 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,646 : INFO : built Dictionary(324 unique tokens: ['ask', 'blockchain', 'cari', 'ceo', 'cointelegraph']...) from 54 documents (total 616 corpus positions)\n",
      "2019-04-24 17:00:48,686 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,691 : INFO : built Dictionary(532 unique tokens: ['app', 'bank', 'destin', 'dy', 'experi']...) from 182 documents (total 1322 corpus positions)\n",
      "2019-04-24 17:00:48,831 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,834 : INFO : built Dictionary(165 unique tokens: ['earn', 'hadn', 'heard', 'men', 'monei']...) from 13 documents (total 235 corpus positions)\n",
      "2019-04-24 17:00:48,843 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,850 : INFO : built Dictionary(109 unique tokens: ['arcadehero', 'come', 'common', 'float', 'game']...) from 10 documents (total 136 corpus positions)\n",
      "2019-04-24 17:00:48,862 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,865 : INFO : built Dictionary(178 unique tokens: ['librari', 'libunwind', 'nativ', 'perform', 'portabl']...) from 29 documents (total 418 corpus positions)\n",
      "2019-04-24 17:00:48,907 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:48,912 : INFO : built Dictionary(511 unique tokens: ['benefici', 'decis', 'design', 'extrem', 'know']...) from 166 documents (total 1080 corpus positions)\n",
      "2019-04-24 17:00:49,032 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,037 : INFO : built Dictionary(144 unique tokens: ['bug', 'descript', 'implement', 'miss', 'specif']...) from 27 documents (total 189 corpus positions)\n",
      "2019-04-24 17:00:49,050 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:49,053 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,055 : INFO : built Dictionary(110 unique tokens: ['breve', 'definição', 'dicionário', 'família', 'houaiss']...) from 9 documents (total 145 corpus positions)\n",
      "2019-04-24 17:00:49,057 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:49,068 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,071 : INFO : built Dictionary(251 unique tokens: ['backplan', 'buckl', 'buzz', 'caus', 'earli']...) from 30 documents (total 378 corpus positions)\n",
      "2019-04-24 17:00:49,091 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,094 : INFO : built Dictionary(161 unique tokens: ['acredit', 'ainda', 'ano', 'crescimento', 'espaço']...) from 11 documents (total 216 corpus positions)\n",
      "2019-04-24 17:00:49,106 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,110 : INFO : built Dictionary(192 unique tokens: ['machin', 'superintellig', 'aim', 'artifici', 'condens']...) from 19 documents (total 292 corpus positions)\n",
      "2019-04-24 17:00:49,127 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,131 : INFO : built Dictionary(435 unique tokens: ['anunciada', 'até', 'bbc', 'chamada', 'com']...) from 50 documents (total 789 corpus positions)\n",
      "2019-04-24 17:00:49,161 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,164 : INFO : built Dictionary(181 unique tokens: ['attract', 'aviv', 'backer', 'bosch', 'cropx']...) from 19 documents (total 268 corpus positions)\n",
      "2019-04-24 17:00:49,173 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:49,175 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:49,177 : INFO : built Dictionary(115 unique tokens: ['bem', 'bovespa', 'brasil', 'com', 'criar']...) from 9 documents (total 182 corpus positions)\n",
      "2019-04-24 17:00:49,179 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:49,184 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:49,186 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,188 : INFO : built Dictionary(34 unique tokens: ['billion', 'button', 'creat', 'dai', 'design']...) from 2 documents (total 37 corpus positions)\n",
      "2019-04-24 17:00:49,190 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:49,192 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:49,194 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:49,198 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,201 : INFO : built Dictionary(91 unique tokens: ['center', 'cloud', 'collect', 'data', 'network']...) from 13 documents (total 138 corpus positions)\n",
      "2019-04-24 17:00:49,213 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,216 : INFO : built Dictionary(169 unique tokens: ['access', 'cloud', 'control', 'defin', 'iam']...) from 57 documents (total 572 corpus positions)\n",
      "2019-04-24 17:00:49,251 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,255 : INFO : built Dictionary(207 unique tokens: ['addit', 'charg', 'cloud', 'data', 'disk']...) from 87 documents (total 1039 corpus positions)\n",
      "2019-04-24 17:00:49,321 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,323 : INFO : built Dictionary(141 unique tokens: ['agil', 'busi', 'cloud', 'develop', 'drive']...) from 24 documents (total 229 corpus positions)\n",
      "2019-04-24 17:00:49,342 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,345 : INFO : built Dictionary(166 unique tokens: ['analysi', 'api', 'cloud', 'content', 'deriv']...) from 32 documents (total 377 corpus positions)\n",
      "2019-04-24 17:00:49,375 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,379 : INFO : built Dictionary(477 unique tokens: ['announc', 'api', 'cluster', 'depth', 'editor']...) from 97 documents (total 1227 corpus positions)\n",
      "2019-04-24 17:00:49,447 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,449 : INFO : built Dictionary(101 unique tokens: ['cloud', 'event', 'exchang', 'fi', 'financi']...) from 10 documents (total 167 corpus positions)\n",
      "2019-04-24 17:00:49,458 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,460 : INFO : built Dictionary(141 unique tokens: ['compani', 'logist', 'particularli', 'transport', 'travel']...) from 18 documents (total 216 corpus positions)\n",
      "2019-04-24 17:00:49,473 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,477 : INFO : built Dictionary(435 unique tokens: ['algo', 'alguém', 'borbulhava', 'cabeça', 'contá']...) from 53 documents (total 783 corpus positions)\n",
      "2019-04-24 17:00:49,511 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,515 : INFO : built Dictionary(366 unique tokens: ['artifici', 'champion', 'chang', 'game', 'intellig']...) from 68 documents (total 539 corpus positions)\n",
      "2019-04-24 17:00:49,539 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,542 : INFO : built Dictionary(181 unique tokens: ['afterward', 'bar', 'drink', 'power', 'protein']...) from 22 documents (total 288 corpus positions)\n",
      "2019-04-24 17:00:49,553 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,556 : INFO : built Dictionary(147 unique tokens: ['access', 'bring', 'disabl', 'hard', 'interact']...) from 15 documents (total 250 corpus positions)\n",
      "2019-04-24 17:00:49,584 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,589 : INFO : built Dictionary(807 unique tokens: ['apólic', 'carga', 'comprando', 'contratar', 'deve']...) from 141 documents (total 2168 corpus positions)\n",
      "2019-04-24 17:00:49,774 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,776 : INFO : built Dictionary(204 unique tokens: ['american', 'asean', 'asian', 'associ', 'depart']...) from 20 documents (total 327 corpus positions)\n",
      "2019-04-24 17:00:49,789 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,791 : INFO : built Dictionary(126 unique tokens: ['announc', 'creation', 'degre', 'digit', 'document']...) from 18 documents (total 203 corpus positions)\n",
      "2019-04-24 17:00:49,803 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,805 : INFO : built Dictionary(120 unique tokens: ['bank', 'central', 'deposit', 'europ', 'impos']...) from 17 documents (total 203 corpus positions)\n",
      "2019-04-24 17:00:49,829 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,832 : INFO : built Dictionary(296 unique tokens: ['asset', 'associ', 'blockchain', 'cdc', 'chamber']...) from 47 documents (total 530 corpus positions)\n",
      "2019-04-24 17:00:49,862 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,865 : INFO : built Dictionary(213 unique tokens: ['bank', 'bitcoin', 'blockchain', 'chair', 'cnbc']...) from 29 documents (total 350 corpus positions)\n",
      "2019-04-24 17:00:49,881 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,884 : INFO : built Dictionary(239 unique tokens: ['announc', 'author', 'christoph', 'compani', 'competit']...) from 20 documents (total 365 corpus positions)\n",
      "2019-04-24 17:00:49,901 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,908 : INFO : built Dictionary(315 unique tokens: ['bot', 'build', 'develop', 'facebook', 'insid']...) from 69 documents (total 656 corpus positions)\n",
      "2019-04-24 17:00:49,954 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,957 : INFO : built Dictionary(280 unique tokens: ['apostando', 'com', 'cresc', 'dia', 'estão']...) from 24 documents (total 430 corpus positions)\n",
      "2019-04-24 17:00:49,975 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:49,979 : INFO : built Dictionary(244 unique tokens: ['beta', 'bot', 'convers', 'earli', 'engin']...) from 65 documents (total 495 corpus positions)\n",
      "2019-04-24 17:00:50,006 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,008 : INFO : built Dictionary(182 unique tokens: ['aprendo', 'como', 'dia', 'doi', 'espiritu']...) from 16 documents (total 224 corpus positions)\n",
      "2019-04-24 17:00:50,020 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,023 : INFO : built Dictionary(241 unique tokens: ['benchmark', 'cassandra', 'databas', 'nosql', 'mongodb']...) from 29 documents (total 468 corpus positions)\n",
      "2019-04-24 17:00:50,039 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,041 : INFO : built Dictionary(95 unique tokens: ['calendar', 'help', 'time', 'user', 'activ']...) from 13 documents (total 190 corpus positions)\n",
      "2019-04-24 17:00:50,050 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,052 : INFO : built Dictionary(97 unique tokens: ['calendar', 'call', 'exercis', 'famili', 'featur']...) from 11 documents (total 144 corpus positions)\n",
      "2019-04-24 17:00:50,059 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,061 : INFO : built Dictionary(107 unique tokens: ['annual', 'aspect', 'cloud', 'code', 'comput']...) from 15 documents (total 211 corpus positions)\n",
      "2019-04-24 17:00:50,068 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:50,070 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,072 : INFO : built Dictionary(44 unique tokens: ['animação', 'atravé', 'como', 'câmera', 'diferent']...) from 2 documents (total 47 corpus positions)\n",
      "2019-04-24 17:00:50,074 : WARNING : Input corpus is expected to have at least 10 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:50,076 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:50,078 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:50,081 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:50,083 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,086 : INFO : built Dictionary(117 unique tokens: ['banca', 'bank', 'blockchain', 'capit', 'credit']...) from 9 documents (total 168 corpus positions)\n",
      "2019-04-24 17:00:50,087 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:50,099 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,102 : INFO : built Dictionary(275 unique tokens: ['american', 'birkbeck', 'colleg', 'guest', 'herian']...) from 41 documents (total 474 corpus positions)\n",
      "2019-04-24 17:00:50,139 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,143 : INFO : built Dictionary(700 unique tokens: ['framework', 'free', 'googl', 'open', 'power']...) from 136 documents (total 1440 corpus positions)\n",
      "2019-04-24 17:00:50,242 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,245 : INFO : built Dictionary(100 unique tokens: ['block', 'comput', 'disk', 'engin', 'googl']...) from 18 documents (total 172 corpus positions)\n",
      "2019-04-24 17:00:50,259 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,264 : INFO : built Dictionary(136 unique tokens: ['block', 'busi', 'comput', 'disk', 'engin']...) from 20 documents (total 247 corpus positions)\n",
      "2019-04-24 17:00:50,282 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,291 : INFO : built Dictionary(127 unique tokens: ['app', 'expand', 'facebook', 'framework', 'nativ']...) from 16 documents (total 216 corpus positions)\n",
      "2019-04-24 17:00:50,314 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,318 : INFO : built Dictionary(171 unique tokens: ['ano', 'cartoon', 'da', 'desenho', 'est']...) from 19 documents (total 253 corpus positions)\n",
      "2019-04-24 17:00:50,332 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:50,335 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,338 : INFO : built Dictionary(81 unique tokens: ['announc', 'comput', 'googl', 'hard', 'launch']...) from 7 documents (total 121 corpus positions)\n",
      "2019-04-24 17:00:50,341 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:50,357 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,360 : INFO : built Dictionary(235 unique tokens: ['better', 'calendar', 'commit', 'goal', 'googl']...) from 30 documents (total 365 corpus positions)\n",
      "2019-04-24 17:00:50,379 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,382 : INFO : built Dictionary(133 unique tokens: ['android', 'burk', 'dave', 'develop', 'engin']...) from 22 documents (total 245 corpus positions)\n",
      "2019-04-24 17:00:50,401 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,405 : INFO : built Dictionary(263 unique tokens: ['biggest', 'gloystein', 'hen', 'jam', 'keith']...) from 31 documents (total 427 corpus positions)\n",
      "2019-04-24 17:00:50,423 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,425 : INFO : built Dictionary(145 unique tokens: ['nomin', 'win', 'award', 'devin', 'di']...) from 15 documents (total 182 corpus positions)\n",
      "2019-04-24 17:00:50,441 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,444 : INFO : built Dictionary(218 unique tokens: ['app', 'blog', 'caught', 'chri', 'engin']...) from 40 documents (total 400 corpus positions)\n",
      "2019-04-24 17:00:50,466 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,470 : INFO : built Dictionary(122 unique tokens: ['develop', 'drupal', 'fenc', 'hope', 'post']...) from 27 documents (total 221 corpus positions)\n",
      "2019-04-24 17:00:50,489 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,493 : INFO : built Dictionary(260 unique tokens: ['commun', 'creat', 'dai', 'drupal', 'latest']...) from 30 documents (total 444 corpus positions)\n",
      "2019-04-24 17:00:50,523 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,527 : INFO : built Dictionary(392 unique tokens: ['build', 'autom', 'compil', 'consolid', 'depend']...) from 85 documents (total 924 corpus positions)\n",
      "2019-04-24 17:00:50,588 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,592 : INFO : built Dictionary(185 unique tokens: ['annual', 'billion', 'burda', 'distribut', 'drupal']...) from 29 documents (total 315 corpus positions)\n",
      "2019-04-24 17:00:50,617 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,620 : INFO : built Dictionary(385 unique tokens: ['fly', 'iphon', 'star', 'ag', 'alpha']...) from 49 documents (total 597 corpus positions)\n",
      "2019-04-24 17:00:50,675 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,681 : INFO : built Dictionary(350 unique tokens: ['april', 'comput', 'connect', 'engin', 'extern']...) from 120 documents (total 1716 corpus positions)\n",
      "2019-04-24 17:00:50,734 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:50,737 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,739 : INFO : built Dictionary(107 unique tokens: ['decad', 'easter', 'egg', 'figur', 'game']...) from 9 documents (total 137 corpus positions)\n",
      "2019-04-24 17:00:50,741 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:50,759 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,765 : INFO : built Dictionary(212 unique tokens: ['aren', 'avail', 'demo', 'devic', 'disclaim']...) from 79 documents (total 507 corpus positions)\n",
      "2019-04-24 17:00:50,817 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,825 : INFO : built Dictionary(289 unique tokens: ['end', 'spider', 'win', 'game', 'quantum']...) from 46 documents (total 480 corpus positions)\n",
      "2019-04-24 17:00:50,848 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:50,851 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,854 : INFO : built Dictionary(33 unique tokens: ['abram', 'awaken', 'breakout', 'clearli', 'droid']...) from 3 documents (total 34 corpus positions)\n",
      "2019-04-24 17:00:50,856 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:50,858 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:50,861 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:50,868 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,872 : INFO : built Dictionary(140 unique tokens: ['butterfield', 'ceo', 'come', 'comment', 'compon']...) from 18 documents (total 249 corpus positions)\n",
      "2019-04-24 17:00:50,893 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,897 : INFO : built Dictionary(301 unique tokens: ['built', 'containerd', 'docker', 'engin', 'excit']...) from 62 documents (total 580 corpus positions)\n",
      "2019-04-24 17:00:50,928 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,930 : INFO : built Dictionary(184 unique tokens: ['acquir', 'app', 'billion', 'busi', 'engin']...) from 24 documents (total 284 corpus positions)\n",
      "2019-04-24 17:00:50,949 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,952 : INFO : built Dictionary(175 unique tokens: ['abril', 'acabam', 'amendoim', 'caju', 'castanha']...) from 22 documents (total 290 corpus positions)\n",
      "2019-04-24 17:00:50,969 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:50,972 : INFO : built Dictionary(150 unique tokens: ['interact', 'interfac', 'user', 'cloud', 'complex']...) from 27 documents (total 290 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:51,006 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,011 : INFO : built Dictionary(489 unique tokens: ['algun', 'americano', 'atacar', 'custo', 'descobrindo']...) from 43 documents (total 810 corpus positions)\n",
      "2019-04-24 17:00:51,045 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,049 : INFO : built Dictionary(229 unique tokens: ['amando', 'com', 'escrev', 'estou', 'medium']...) from 26 documents (total 380 corpus positions)\n",
      "2019-04-24 17:00:51,071 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,076 : INFO : built Dictionary(268 unique tokens: ['difícil', 'escolha', 'mai', 'sempr', 'caminho']...) from 39 documents (total 460 corpus positions)\n",
      "2019-04-24 17:00:51,098 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,102 : INFO : built Dictionary(92 unique tokens: ['exactli', 'featur', 'isn', 'mobil', 'product']...) from 13 documents (total 154 corpus positions)\n",
      "2019-04-24 17:00:51,116 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,120 : INFO : built Dictionary(246 unique tokens: ['access', 'announc', 'data', 'excit', 'javascript']...) from 51 documents (total 444 corpus positions)\n",
      "2019-04-24 17:00:51,156 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,160 : INFO : built Dictionary(573 unique tokens: ['cabeça', 'machismo', 'pensa', 'quando', 'que']...) from 74 documents (total 1059 corpus positions)\n",
      "2019-04-24 17:00:51,220 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,223 : INFO : built Dictionary(176 unique tokens: ['accident', 'compani', 'custom', 'delet', 'host']...) from 25 documents (total 286 corpus positions)\n",
      "2019-04-24 17:00:51,245 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,250 : INFO : built Dictionary(374 unique tokens: ['bui', 'care', 'chore', 'hous', 'imagin']...) from 77 documents (total 674 corpus positions)\n",
      "2019-04-24 17:00:51,290 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,293 : INFO : built Dictionary(174 unique tokens: ['artifici', 'automat', 'clean', 'design', 'game']...) from 24 documents (total 307 corpus positions)\n",
      "2019-04-24 17:00:51,308 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,311 : INFO : built Dictionary(161 unique tokens: ['aren', 'connect', 'develop', 'editor', 'environ']...) from 20 documents (total 250 corpus positions)\n",
      "2019-04-24 17:00:51,333 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,337 : INFO : built Dictionary(395 unique tokens: ['alex', 'articl', 'bui', 'case', 'displai']...) from 71 documents (total 751 corpus positions)\n",
      "2019-04-24 17:00:51,383 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,387 : INFO : built Dictionary(435 unique tokens: ['glanc', 'happen', 'hard', 'know', 'pictur']...) from 55 documents (total 687 corpus positions)\n",
      "2019-04-24 17:00:51,419 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,423 : INFO : built Dictionary(118 unique tokens: ['allow', 'attract', 'game', 'gamer', 'onlin']...) from 16 documents (total 201 corpus positions)\n",
      "2019-04-24 17:00:51,440 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,444 : INFO : built Dictionary(162 unique tokens: ['cdk', 'evelop', 'hello', 'ompon', 'react']...) from 68 documents (total 375 corpus positions)\n",
      "2019-04-24 17:00:51,470 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:51,473 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,476 : INFO : built Dictionary(25 unique tokens: ['css', 'experi', 'html', 'interest', 'javascript']...) from 5 documents (total 31 corpus positions)\n",
      "2019-04-24 17:00:51,479 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:51,488 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,492 : INFO : built Dictionary(146 unique tokens: ['bad', 'door', 'drive', 'fan', 'get']...) from 21 documents (total 231 corpus positions)\n",
      "2019-04-24 17:00:51,504 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:51,507 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,509 : INFO : built Dictionary(120 unique tokens: ['algun', 'amada', 'ano', 'complet', 'cupertino']...) from 7 documents (total 155 corpus positions)\n",
      "2019-04-24 17:00:51,513 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:51,532 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,537 : INFO : built Dictionary(339 unique tokens: ['deadlin', 'deliv', 'easi', 'forget', 'import']...) from 77 documents (total 744 corpus positions)\n",
      "2019-04-24 17:00:51,586 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:51,590 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,592 : INFO : built Dictionary(94 unique tokens: ['advogada', 'ano', 'até', 'carvalho', 'com']...) from 6 documents (total 126 corpus positions)\n",
      "2019-04-24 17:00:51,595 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:51,604 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:51,606 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,608 : INFO : built Dictionary(125 unique tokens: ['applic', 'blockchain', 'chief', 'clearinghous', 'compani']...) from 5 documents (total 163 corpus positions)\n",
      "2019-04-24 17:00:51,611 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:51,623 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,627 : INFO : built Dictionary(324 unique tokens: ['agendar', 'agora', 'aplicativo', 'assistência', 'cafeteira']...) from 51 documents (total 725 corpus positions)\n",
      "2019-04-24 17:00:51,674 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,678 : INFO : built Dictionary(164 unique tokens: ['blockchain', 'brooklyn', 'directli', 'energi', 'ethereum']...) from 19 documents (total 278 corpus positions)\n",
      "2019-04-24 17:00:51,690 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:51,693 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,697 : INFO : built Dictionary(51 unique tokens: ['common', 'devic', 'tool', 'work', 'need']...) from 7 documents (total 71 corpus positions)\n",
      "2019-04-24 17:00:51,700 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:51,707 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:51,712 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,716 : INFO : built Dictionary(49 unique tokens: ['busi', 'cours', 'innov', 'todai', 'better']...) from 7 documents (total 65 corpus positions)\n",
      "2019-04-24 17:00:51,719 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:51,736 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,743 : INFO : built Dictionary(394 unique tokens: ['appl', 'bot', 'chatbot', 'começando', 'diminuir']...) from 59 documents (total 744 corpus positions)\n",
      "2019-04-24 17:00:51,789 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,793 : INFO : built Dictionary(379 unique tokens: ['anunci', 'chatbot', 'esta', 'facebook', 'ganhou']...) from 44 documents (total 636 corpus positions)\n",
      "2019-04-24 17:00:51,824 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,827 : INFO : built Dictionary(234 unique tokens: ['abr', 'bot', 'consigo', 'disruptiva', 'do']...) from 31 documents (total 384 corpus positions)\n",
      "2019-04-24 17:00:51,846 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,850 : INFO : built Dictionary(121 unique tokens: ['algorithm', 'code', 'codechalleng', 'codesprint', 'compani']...) from 17 documents (total 164 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:51,858 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:51,861 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,864 : INFO : built Dictionary(33 unique tokens: ['code', 'develop', 'git', 'help', 'internet']...) from 2 documents (total 34 corpus positions)\n",
      "2019-04-24 17:00:51,867 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:51,871 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:51,874 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:51,909 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:51,916 : INFO : built Dictionary(547 unique tokens: ['chanc', 'earlier', 'episod', 'googl', 'got']...) from 129 documents (total 1614 corpus positions)\n",
      "2019-04-24 17:00:52,067 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,070 : INFO : built Dictionary(299 unique tokens: ['best', 'detail', 'http', 'post', 'practic']...) from 46 documents (total 586 corpus positions)\n",
      "2019-04-24 17:00:52,109 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,113 : INFO : built Dictionary(301 unique tokens: ['agent', 'build', 'insur', 'new', 'silicon']...) from 49 documents (total 531 corpus positions)\n",
      "2019-04-24 17:00:52,153 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,158 : INFO : built Dictionary(331 unique tokens: ['entir', 'glanc', 'project', 'promis', 'singl']...) from 122 documents (total 785 corpus positions)\n",
      "2019-04-24 17:00:52,231 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,235 : INFO : built Dictionary(164 unique tokens: ['brother', 'california', 'chico', 'fratern', 'gardner']...) from 34 documents (total 273 corpus positions)\n",
      "2019-04-24 17:00:52,254 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:52,257 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,260 : INFO : built Dictionary(79 unique tokens: ['barrier', 'fantast', 'harder', 'languag', 'learn']...) from 9 documents (total 102 corpus positions)\n",
      "2019-04-24 17:00:52,263 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:52,275 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,279 : INFO : built Dictionary(239 unique tokens: ['ajuda', 'alguma', 'com', 'comunicação', 'crescido']...) from 24 documents (total 401 corpus positions)\n",
      "2019-04-24 17:00:52,298 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:52,301 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,304 : INFO : built Dictionary(152 unique tokens: ['adianta', 'afin', 'aplicação', 'atenção', 'bem']...) from 8 documents (total 215 corpus positions)\n",
      "2019-04-24 17:00:52,307 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:52,325 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,328 : INFO : built Dictionary(207 unique tokens: ['introduct', 'mention', 'technolog', 'convent', 'dao']...) from 50 documents (total 572 corpus positions)\n",
      "2019-04-24 17:00:52,387 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,393 : INFO : built Dictionary(841 unique tokens: ['black', 'death', 'disastr', 'diseas', 'europ']...) from 169 documents (total 2092 corpus positions)\n",
      "2019-04-24 17:00:52,600 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,604 : INFO : built Dictionary(171 unique tokens: ['bunch', 'code', 'execut', 'git', 'peopl']...) from 53 documents (total 259 corpus positions)\n",
      "2019-04-24 17:00:52,634 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,638 : INFO : built Dictionary(207 unique tokens: ['broad', 'comput', 'eager', 'gener', 'larri']...) from 65 documents (total 499 corpus positions)\n",
      "2019-04-24 17:00:52,682 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,685 : INFO : built Dictionary(288 unique tokens: ['aplicação', 'arquitetura', 'evolutiva', 'incrementai', 'mudança']...) from 30 documents (total 533 corpus positions)\n",
      "2019-04-24 17:00:52,706 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,710 : INFO : built Dictionary(150 unique tokens: ['attent', 'bui', 'compani', 'confer', 'coupl']...) from 20 documents (total 225 corpus positions)\n",
      "2019-04-24 17:00:52,718 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:52,721 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,723 : INFO : built Dictionary(27 unique tokens: ['allow', 'arrai', 'attempt', 'ball', 'browser']...) from 3 documents (total 30 corpus positions)\n",
      "2019-04-24 17:00:52,725 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:52,727 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:52,730 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:52,732 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,736 : INFO : built Dictionary(83 unique tokens: ['agora', 'cartório', 'com', 'doi', 'dua']...) from 10 documents (total 101 corpus positions)\n",
      "2019-04-24 17:00:52,750 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,755 : INFO : built Dictionary(267 unique tokens: ['adapt', 'classifi', 'craigslist', 'despit', 'domin']...) from 44 documents (total 484 corpus positions)\n",
      "2019-04-24 17:00:52,788 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,793 : INFO : built Dictionary(306 unique tokens: ['ago', 'announc', 'expand', 'friendli', 'googl']...) from 96 documents (total 614 corpus positions)\n",
      "2019-04-24 17:00:52,857 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,861 : INFO : built Dictionary(302 unique tokens: ['annual', 'app', 'big', 'bot', 'confer']...) from 61 documents (total 573 corpus positions)\n",
      "2019-04-24 17:00:52,937 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:52,951 : INFO : built Dictionary(1415 unique tokens: ['bob', 'dylan', 'explain', 'kill', 'like']...) from 210 documents (total 2619 corpus positions)\n",
      "2019-04-24 17:00:53,273 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:53,279 : INFO : built Dictionary(569 unique tokens: ['creat', 'custom', 'effort', 'experi', 'leader']...) from 142 documents (total 1600 corpus positions)\n",
      "2019-04-24 17:00:53,484 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:53,487 : INFO : built Dictionary(118 unique tokens: ['anticip', 'app', 'chat', 'enterpris', 'hotli']...) from 18 documents (total 187 corpus positions)\n",
      "2019-04-24 17:00:53,536 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:53,542 : INFO : built Dictionary(554 unique tokens: ['javascript', 'languag', 'wonder', 'coupl', 'dynam']...) from 208 documents (total 1902 corpus positions)\n",
      "2019-04-24 17:00:53,790 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:53,793 : INFO : built Dictionary(256 unique tokens: ['battl', 'campbel', 'cancer', 'coach', 'di']...) from 37 documents (total 363 corpus positions)\n",
      "2019-04-24 17:00:53,816 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:53,820 : INFO : built Dictionary(188 unique tokens: ['decad', 'iceland', 'rough', 'bank', 'corrupt']...) from 18 documents (total 254 corpus positions)\n",
      "2019-04-24 17:00:53,837 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:53,841 : INFO : built Dictionary(227 unique tokens: ['ago', 'alpha', 'cdn', 'googl', 'launch']...) from 25 documents (total 399 corpus positions)\n",
      "2019-04-24 17:00:53,871 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:53,876 : INFO : built Dictionary(429 unique tokens: ['fiction', 'frolow', 'illustr', 'longer', 'maciej']...) from 53 documents (total 702 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:53,917 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:53,920 : INFO : built Dictionary(312 unique tokens: ['bot', 'killer', 'rocki', 'search', 'silicon']...) from 73 documents (total 546 corpus positions)\n",
      "2019-04-24 17:00:53,986 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:53,990 : INFO : built Dictionary(330 unique tokens: ['class', 'code', 'dai', 'develop', 'entir']...) from 59 documents (total 505 corpus positions)\n",
      "2019-04-24 17:00:54,028 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,033 : INFO : built Dictionary(359 unique tokens: ['aliá', 'ambient', 'andré', 'criar', 'desenvolvimento']...) from 34 documents (total 799 corpus positions)\n",
      "2019-04-24 17:00:54,066 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,070 : INFO : built Dictionary(302 unique tokens: ['accommod', 'airbnb', 'appear', 'card', 'detail']...) from 31 documents (total 485 corpus positions)\n",
      "2019-04-24 17:00:54,094 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,099 : INFO : built Dictionary(155 unique tokens: ['beacon', 'import', 'mark', 'object', 'place']...) from 33 documents (total 379 corpus positions)\n",
      "2019-04-24 17:00:54,119 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,122 : INFO : built Dictionary(124 unique tokens: ['annual', 'come', 'compani', 'confer', 'develop']...) from 14 documents (total 188 corpus positions)\n",
      "2019-04-24 17:00:54,132 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,136 : INFO : built Dictionary(102 unique tokens: ['access', 'app', 'drive', 'easi', 'file']...) from 15 documents (total 177 corpus positions)\n",
      "2019-04-24 17:00:54,147 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,150 : INFO : built Dictionary(84 unique tokens: ['come', 'complet', 'connect', 'easi', 'employe']...) from 10 documents (total 147 corpus positions)\n",
      "2019-04-24 17:00:54,159 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,162 : INFO : built Dictionary(111 unique tokens: ['ask', 'build', 'cloud', 'compliant', 'custom']...) from 16 documents (total 176 corpus positions)\n",
      "2019-04-24 17:00:54,172 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,175 : INFO : built Dictionary(185 unique tokens: ['absorv', 'acessam', 'adianta', 'algum', 'aquela']...) from 12 documents (total 316 corpus positions)\n",
      "2019-04-24 17:00:54,195 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,199 : INFO : built Dictionary(378 unique tokens: ['aspect', 'chang', 'decad', 'digit', 'live']...) from 55 documents (total 716 corpus positions)\n",
      "2019-04-24 17:00:54,230 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:54,233 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,237 : INFO : built Dictionary(78 unique tokens: ['apena', 'apresentei', 'arquivo', 'brasil', 'com']...) from 8 documents (total 127 corpus positions)\n",
      "2019-04-24 17:00:54,241 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:54,256 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,260 : INFO : built Dictionary(190 unique tokens: ['avail', 'drupal', 'minor', 'releas', 'adopt']...) from 47 documents (total 523 corpus positions)\n",
      "2019-04-24 17:00:54,288 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,292 : INFO : built Dictionary(257 unique tokens: ['brazil', 'case', 'certainli', 'congress', 'dilma']...) from 34 documents (total 394 corpus positions)\n",
      "2019-04-24 17:00:54,337 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,344 : INFO : built Dictionary(452 unique tokens: ['git', 'learn', 'past', 'practic', 'share']...) from 179 documents (total 1699 corpus positions)\n",
      "2019-04-24 17:00:54,760 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:54,763 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,766 : INFO : built Dictionary(48 unique tokens: ['io', 'swift', 'updat', 'api', 'applic']...) from 7 documents (total 56 corpus positions)\n",
      "2019-04-24 17:00:54,769 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:54,806 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,812 : INFO : built Dictionary(635 unique tokens: ['administr', 'docker', 'geek', 'heard', 'linux']...) from 134 documents (total 1595 corpus positions)\n",
      "2019-04-24 17:00:54,936 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,940 : INFO : built Dictionary(463 unique tokens: ['aplicativo', 'atravé', 'brasil', 'brasileiro', 'chatbot']...) from 53 documents (total 828 corpus positions)\n",
      "2019-04-24 17:00:54,980 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:54,983 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:54,988 : INFO : built Dictionary(26 unique tokens: ['bryant', 'came', 'feet', 'field', 'final']...) from 3 documents (total 29 corpus positions)\n",
      "2019-04-24 17:00:54,997 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:55,001 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:55,005 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:55,039 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,048 : INFO : built Dictionary(690 unique tokens: ['announc', 'ben', 'biggest', 'design', 'engin']...) from 143 documents (total 1461 corpus positions)\n",
      "2019-04-24 17:00:55,178 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,181 : INFO : built Dictionary(235 unique tokens: ['abertura', 'apresentado', 'data', 'dia', 'io']...) from 29 documents (total 387 corpus positions)\n",
      "2019-04-24 17:00:55,196 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,199 : INFO : built Dictionary(112 unique tokens: ['aderiu', 'brasil', 'copel', 'da', 'dado']...) from 10 documents (total 164 corpus positions)\n",
      "2019-04-24 17:00:55,215 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,218 : INFO : built Dictionary(231 unique tokens: ['bad', 'bash', 'check', 'content', 'curl']...) from 33 documents (total 482 corpus positions)\n",
      "2019-04-24 17:00:55,247 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,251 : INFO : built Dictionary(221 unique tokens: ['administr', 'allow', 'creat', 'custom', 'layout']...) from 51 documents (total 479 corpus positions)\n",
      "2019-04-24 17:00:55,278 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:55,280 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,283 : INFO : built Dictionary(23 unique tokens: ['captur', 'drupal', 'enabl', 'featur', 'manag']...) from 3 documents (total 30 corpus positions)\n",
      "2019-04-24 17:00:55,285 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:55,289 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:55,293 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:55,296 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,298 : INFO : built Dictionary(23 unique tokens: ['conform', 'creat', 'modul', 'org', 'sitemap']...) from 3 documents (total 29 corpus positions)\n",
      "2019-04-24 17:00:55,302 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:55,306 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:55,309 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:55,311 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,314 : INFO : built Dictionary(21 unique tokens: ['api', 'drupal', 'featur', 'follow', 'integr']...) from 2 documents (total 37 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:55,317 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:55,319 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:55,322 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:55,334 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,338 : INFO : built Dictionary(173 unique tokens: ['api', 'applic', 'data', 'drupal', 'encrypt']...) from 50 documents (total 471 corpus positions)\n",
      "2019-04-24 17:00:55,362 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:55,365 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,368 : INFO : built Dictionary(25 unique tokens: ['creat', 'drupal', 'easili', 'engin', 'entiti']...) from 2 documents (total 29 corpus positions)\n",
      "2019-04-24 17:00:55,370 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:55,373 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:55,376 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:55,378 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:55,382 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,385 : INFO : built Dictionary(27 unique tokens: ['better', 'box', 'button', 'checkbox', 'default']...) from 3 documents (total 34 corpus positions)\n",
      "2019-04-24 17:00:55,388 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:55,392 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:55,396 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:55,400 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,402 : INFO : built Dictionary(27 unique tokens: ['api', 'build', 'client', 'commun', 'drupal']...) from 3 documents (total 33 corpus positions)\n",
      "2019-04-24 17:00:55,405 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:55,409 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:55,412 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:55,414 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,417 : INFO : built Dictionary(22 unique tokens: ['defin', 'enforc', 'modul', 'password', 'polici']...) from 3 documents (total 31 corpus positions)\n",
      "2019-04-24 17:00:55,420 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:55,425 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:55,428 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:55,431 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,433 : INFO : built Dictionary(26 unique tokens: ['anonym', 'authcach', 'authent', 'cach', 'log']...) from 3 documents (total 33 corpus positions)\n",
      "2019-04-24 17:00:55,436 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:55,441 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:55,450 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,456 : INFO : built Dictionary(160 unique tokens: ['chan', 'chri', 'deadli', 'duo', 'hour']...) from 36 documents (total 335 corpus positions)\n",
      "2019-04-24 17:00:55,478 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,482 : INFO : built Dictionary(264 unique tokens: ['acontec', 'assim', 'atrai', 'automotivo', 'cada']...) from 32 documents (total 416 corpus positions)\n",
      "2019-04-24 17:00:55,523 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,529 : INFO : built Dictionary(333 unique tokens: ['address', 'configur', 'data', 'deploi', 'drupal']...) from 143 documents (total 1225 corpus positions)\n",
      "2019-04-24 17:00:55,685 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,689 : INFO : built Dictionary(199 unique tokens: ['aggreg', 'analyt', 'data', 'experi', 'facet']...) from 55 documents (total 599 corpus positions)\n",
      "2019-04-24 17:00:55,734 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,737 : INFO : built Dictionary(207 unique tokens: ['api', 'differ', 'ecommerc', 'facet', 'implement']...) from 44 documents (total 446 corpus positions)\n",
      "2019-04-24 17:00:55,790 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,800 : INFO : built Dictionary(376 unique tokens: ['aggreg', 'base', 'bucket', 'built', 'dynam']...) from 117 documents (total 1661 corpus positions)\n",
      "2019-04-24 17:00:55,930 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:55,932 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,934 : INFO : built Dictionary(29 unique tokens: ['aaduino', 'aren', 'bui', 'readi', 'github']...) from 3 documents (total 30 corpus positions)\n",
      "2019-04-24 17:00:55,936 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:55,940 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:55,945 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:55,952 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,955 : INFO : built Dictionary(122 unique tokens: ['amazon', 'best', 'cloud', 'comput', 'fortun']...) from 18 documents (total 211 corpus positions)\n",
      "2019-04-24 17:00:55,976 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:55,980 : INFO : built Dictionary(297 unique tokens: ['case', 'currenc', 'digit', 'ethereum', 'firm']...) from 38 documents (total 570 corpus positions)\n",
      "2019-04-24 17:00:56,006 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,009 : INFO : built Dictionary(103 unique tokens: ['busi', 'life', 'inbox', 'bill', 'insid']...) from 18 documents (total 161 corpus positions)\n",
      "2019-04-24 17:00:56,018 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:56,021 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,023 : INFO : built Dictionary(23 unique tokens: ['aggreg', 'altern', 'attract', 'benefici', 'elasticsearch']...) from 3 documents (total 28 corpus positions)\n",
      "2019-04-24 17:00:56,025 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:56,029 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:56,035 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,038 : INFO : built Dictionary(136 unique tokens: ['add', 'base', 'client', 'compani', 'email']...) from 18 documents (total 234 corpus positions)\n",
      "2019-04-24 17:00:56,054 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,057 : INFO : built Dictionary(266 unique tokens: ['ano', 'aqui', 'big', 'blog', 'data']...) from 23 documents (total 422 corpus positions)\n",
      "2019-04-24 17:00:56,082 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,087 : INFO : built Dictionary(390 unique tokens: ['anterior', 'api', 'com', 'como', 'falamo']...) from 57 documents (total 1115 corpus positions)\n",
      "2019-04-24 17:00:56,135 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,139 : INFO : built Dictionary(379 unique tokens: ['api', 'aplicaçõ', 'atualment', 'bem', 'comum']...) from 58 documents (total 990 corpus positions)\n",
      "2019-04-24 17:00:56,182 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,185 : INFO : built Dictionary(163 unique tokens: ['agência', 'ano', 'como', 'crescendo', 'da']...) from 15 documents (total 213 corpus positions)\n",
      "2019-04-24 17:00:56,201 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,205 : INFO : built Dictionary(363 unique tokens: ['activ', 'clear', 'cliché', 'fail', 'head']...) from 53 documents (total 553 corpus positions)\n",
      "2019-04-24 17:00:56,231 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:56,234 : INFO : built Dictionary(116 unique tokens: ['announc', 'back', 'bitcasa', 'cloud', 'compani']...) from 15 documents (total 161 corpus positions)\n",
      "2019-04-24 17:00:56,246 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,251 : INFO : built Dictionary(204 unique tokens: ['batteri', 'biggest', 'come', 'design', 'gadget']...) from 30 documents (total 313 corpus positions)\n",
      "2019-04-24 17:00:56,275 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,279 : INFO : built Dictionary(369 unique tokens: ['ano', 'apena', 'aplicativo', 'bancário', 'cartõ']...) from 42 documents (total 632 corpus positions)\n",
      "2019-04-24 17:00:56,324 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:56,327 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,330 : INFO : built Dictionary(53 unique tokens: ['brainstorm', 'brand', 'built', 'come', 'identif']...) from 6 documents (total 66 corpus positions)\n",
      "2019-04-24 17:00:56,333 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:56,356 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,362 : INFO : built Dictionary(485 unique tokens: ['aquela', 'bem', 'client', 'dez', 'entr']...) from 87 documents (total 1039 corpus positions)\n",
      "2019-04-24 17:00:56,440 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,444 : INFO : built Dictionary(286 unique tokens: ['averag', 'doom', 'equal', 'imag', 'instal']...) from 48 documents (total 461 corpus positions)\n",
      "2019-04-24 17:00:56,475 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,479 : INFO : built Dictionary(252 unique tokens: ['assist', 'big', 'compani', 'rage', 'tech']...) from 47 documents (total 611 corpus positions)\n",
      "2019-04-24 17:00:56,521 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,526 : INFO : built Dictionary(559 unique tokens: ['circuit', 'counter', 'counterinsurg', 'favorit', 'form']...) from 98 documents (total 1064 corpus positions)\n",
      "2019-04-24 17:00:56,618 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,622 : INFO : built Dictionary(482 unique tokens: ['articl', 'blog', 'comment', 'edit', 'eleg']...) from 153 documents (total 810 corpus positions)\n",
      "2019-04-24 17:00:56,714 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,717 : INFO : built Dictionary(173 unique tokens: ['couldn', 'gcp', 'month', 'learn', 'lucki']...) from 22 documents (total 273 corpus positions)\n",
      "2019-04-24 17:00:56,731 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,734 : INFO : built Dictionary(96 unique tokens: ['announc', 'bot', 'cross', 'excit', 'facebook']...) from 19 documents (total 157 corpus positions)\n",
      "2019-04-24 17:00:56,745 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:56,748 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,750 : INFO : built Dictionary(31 unique tokens: ['ano', 'banco', 'bolt', 'campanha', 'corredor']...) from 2 documents (total 39 corpus positions)\n",
      "2019-04-24 17:00:56,753 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:56,756 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:56,759 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:56,767 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,771 : INFO : built Dictionary(128 unique tokens: ['artifici', 'begin', 'busi', 'cloud', 'comput']...) from 15 documents (total 182 corpus positions)\n",
      "2019-04-24 17:00:56,781 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,784 : INFO : built Dictionary(107 unique tokens: ['globe', 'golden', 'nomin', 'rate', 'win']...) from 11 documents (total 124 corpus positions)\n",
      "2019-04-24 17:00:56,792 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:56,795 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,798 : INFO : built Dictionary(67 unique tokens: ['altern', 'charg', 'combust', 'conduct', 'help']...) from 7 documents (total 81 corpus positions)\n",
      "2019-04-24 17:00:56,801 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:56,820 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,824 : INFO : built Dictionary(378 unique tokens: ['chines', 'cooler', 'experi', 'happen', 'peru']...) from 77 documents (total 829 corpus positions)\n",
      "2019-04-24 17:00:56,896 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,901 : INFO : built Dictionary(204 unique tokens: ['central', 'dai', 'doc', 'drive', 'earli']...) from 53 documents (total 517 corpus positions)\n",
      "2019-04-24 17:00:56,947 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,951 : INFO : built Dictionary(159 unique tokens: ['ben', 'ceo', 'excerpt', 'getti', 'interview']...) from 27 documents (total 264 corpus positions)\n",
      "2019-04-24 17:00:56,973 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:56,977 : INFO : built Dictionary(316 unique tokens: ['comput', 'connect', 'devic', 'encrypt', 'face']...) from 43 documents (total 623 corpus positions)\n",
      "2019-04-24 17:00:57,022 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,030 : INFO : built Dictionary(400 unique tokens: ['convers', 'discuss', 'especi', 'everydai', 'ibm']...) from 112 documents (total 693 corpus positions)\n",
      "2019-04-24 17:00:57,083 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,086 : INFO : built Dictionary(92 unique tokens: ['emmi', 'primetim', 'won', 'nomin', 'win']...) from 10 documents (total 108 corpus positions)\n",
      "2019-04-24 17:00:57,146 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,156 : INFO : built Dictionary(1174 unique tokens: ['big', 'convers', 'late', 'talk', 'thing']...) from 275 documents (total 2765 corpus positions)\n",
      "2019-04-24 17:00:57,584 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,587 : INFO : built Dictionary(342 unique tokens: ['case', 'currenc', 'date', 'flat', 'hold']...) from 52 documents (total 638 corpus positions)\n",
      "2019-04-24 17:00:57,620 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,623 : INFO : built Dictionary(128 unique tokens: ['emmi', 'nomin', 'primetim', 'award', 'devast']...) from 21 documents (total 156 corpus positions)\n",
      "2019-04-24 17:00:57,632 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,635 : INFO : built Dictionary(77 unique tokens: ['bring', 'chrome', 'chromebook', 'design', 'materi']...) from 10 documents (total 96 corpus positions)\n",
      "2019-04-24 17:00:57,651 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,655 : INFO : built Dictionary(316 unique tokens: ['base', 'bed', 'car', 'complet', 'currenc']...) from 44 documents (total 496 corpus positions)\n",
      "2019-04-24 17:00:57,681 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,684 : INFO : built Dictionary(236 unique tokens: ['adapt', 'architectur', 'hexagon', 'know', 'peopl']...) from 40 documents (total 434 corpus positions)\n",
      "2019-04-24 17:00:57,700 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:57,703 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,705 : INFO : built Dictionary(27 unique tokens: ['antholog', 'dark', 'life', 'seri', 'show']...) from 3 documents (total 27 corpus positions)\n",
      "2019-04-24 17:00:57,708 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:57,711 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:57,729 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,733 : INFO : built Dictionary(311 unique tokens: ['apollo', 'build', 'data', 'earlier', 'graphql']...) from 97 documents (total 969 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:57,799 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,802 : INFO : built Dictionary(141 unique tokens: ['awai', 'fritter', 'life', 'simplifi', 'applic']...) from 33 documents (total 240 corpus positions)\n",
      "2019-04-24 17:00:57,824 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,828 : INFO : built Dictionary(399 unique tokens: ['alcanc', 'alternativa', 'andamento', 'ao', 'aplicativo']...) from 55 documents (total 770 corpus positions)\n",
      "2019-04-24 17:00:57,874 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,879 : INFO : built Dictionary(261 unique tokens: ['announc', 'bot', 'busi', 'commun', 'credit']...) from 84 documents (total 611 corpus positions)\n",
      "2019-04-24 17:00:57,929 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,932 : INFO : built Dictionary(434 unique tokens: ['abril', 'agricultura', 'agrishow', 'agrícola', 'ação']...) from 35 documents (total 721 corpus positions)\n",
      "2019-04-24 17:00:57,961 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,964 : INFO : built Dictionary(171 unique tokens: ['cryptograph', 'dev', 'herbert', 'linux', 'long']...) from 24 documents (total 328 corpus positions)\n",
      "2019-04-24 17:00:57,984 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:57,987 : INFO : built Dictionary(219 unique tokens: ['content', 'creat', 'css', 'depth', 'friend']...) from 50 documents (total 626 corpus positions)\n",
      "2019-04-24 17:00:58,012 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:58,014 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,016 : INFO : built Dictionary(105 unique tokens: ['abrir', 'algum', 'ant', 'autoriz', 'banco']...) from 9 documents (total 134 corpus positions)\n",
      "2019-04-24 17:00:58,019 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:58,033 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,037 : INFO : built Dictionary(347 unique tokens: ['almaden', 'atop', 'california', 'downtown', 'green']...) from 55 documents (total 566 corpus positions)\n",
      "2019-04-24 17:00:58,063 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:58,066 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,068 : INFO : built Dictionary(34 unique tokens: ['abertura', 'aprov', 'cmn', 'conselho', 'conta']...) from 2 documents (total 35 corpus positions)\n",
      "2019-04-24 17:00:58,071 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:58,073 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:00:58,075 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:58,086 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,090 : INFO : built Dictionary(207 unique tokens: ['challeng', 'decim', 'easi', 'mathemat', 'number']...) from 43 documents (total 388 corpus positions)\n",
      "2019-04-24 17:00:58,158 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,166 : INFO : built Dictionary(1038 unique tokens: ['agil', 'brief', 'develop', 'function', 'idea']...) from 277 documents (total 3259 corpus positions)\n",
      "2019-04-24 17:00:58,680 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,683 : INFO : built Dictionary(208 unique tokens: ['bodi', 'bone', 'forc', 'jumper', 'time']...) from 39 documents (total 428 corpus positions)\n",
      "2019-04-24 17:00:58,723 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,728 : INFO : built Dictionary(567 unique tokens: ['aqui', 'começ', 'criar', 'diagrama', 'empreend']...) from 89 documents (total 1383 corpus positions)\n",
      "2019-04-24 17:00:58,805 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,807 : INFO : built Dictionary(157 unique tokens: ['abrir', 'agência', 'bancária', 'comparec', 'conta']...) from 10 documents (total 228 corpus positions)\n",
      "2019-04-24 17:00:58,814 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:58,816 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,818 : INFO : built Dictionary(86 unique tokens: ['america', 'bank', 'base', 'blockchain', 'consortium']...) from 7 documents (total 113 corpus positions)\n",
      "2019-04-24 17:00:58,820 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:58,832 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,835 : INFO : built Dictionary(239 unique tokens: ['burnout', 'pipelin', 'problem', 'harass', 'issu']...) from 44 documents (total 443 corpus positions)\n",
      "2019-04-24 17:00:58,861 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,865 : INFO : built Dictionary(329 unique tokens: ['capit', 'cersei', 'end', 'game', 'humili']...) from 42 documents (total 471 corpus positions)\n",
      "2019-04-24 17:00:58,884 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,888 : INFO : built Dictionary(221 unique tokens: ['acesso', 'da', 'ganh', 'ma', 'maior']...) from 22 documents (total 352 corpus positions)\n",
      "2019-04-24 17:00:58,902 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:58,904 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,907 : INFO : built Dictionary(60 unique tokens: ['big', 'camera', 'foundat', 'imag', 'infrar']...) from 5 documents (total 70 corpus positions)\n",
      "2019-04-24 17:00:58,910 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:58,918 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,921 : INFO : built Dictionary(130 unique tokens: ['applic', 'code', 'copenhagen', 'creat', 'depart']...) from 18 documents (total 218 corpus positions)\n",
      "2019-04-24 17:00:58,935 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,939 : INFO : built Dictionary(212 unique tokens: ['network', 'neural', 'resum', 'shakespear', 'write']...) from 39 documents (total 309 corpus positions)\n",
      "2019-04-24 17:00:58,955 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,958 : INFO : built Dictionary(108 unique tokens: ['achiev', 'high', 'product', 'word', 'finit']...) from 16 documents (total 153 corpus positions)\n",
      "2019-04-24 17:00:58,967 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,970 : INFO : built Dictionary(145 unique tokens: ['abr', 'autoridad', 'construido', 'costa', 'del']...) from 12 documents (total 207 corpus positions)\n",
      "2019-04-24 17:00:58,990 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:58,993 : INFO : built Dictionary(209 unique tokens: ['account', 'firebas', 'free', 'need', 'sign']...) from 35 documents (total 476 corpus positions)\n",
      "2019-04-24 17:00:59,024 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,028 : INFO : built Dictionary(290 unique tokens: ['huge', 'marketplac', 'onlin', 'amazon', 'attract']...) from 47 documents (total 577 corpus positions)\n",
      "2019-04-24 17:00:59,052 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:59,054 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,056 : INFO : built Dictionary(69 unique tokens: ['afin', 'atravé', 'área', 'circuito', 'comunidad']...) from 4 documents (total 85 corpus positions)\n",
      "2019-04-24 17:00:59,058 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:59,062 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:59,067 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,070 : INFO : built Dictionary(69 unique tokens: ['good', 'got', 'hope', 'idea', 'like']...) from 18 documents (total 113 corpus positions)\n",
      "2019-04-24 17:00:59,086 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,090 : INFO : built Dictionary(301 unique tokens: ['clariti', 'import', 'logout', 'repeat', 'verb']...) from 96 documents (total 633 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:00:59,138 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,140 : INFO : built Dictionary(257 unique tokens: ['aprendida', 'ciclo', 'compartilh', 'consultor', 'desenvolvimento']...) from 15 documents (total 454 corpus positions)\n",
      "2019-04-24 17:00:59,161 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,165 : INFO : built Dictionary(557 unique tokens: ['alguma', 'bem', 'crédito', 'escritório', 'não']...) from 74 documents (total 1120 corpus positions)\n",
      "2019-04-24 17:00:59,235 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,239 : INFO : built Dictionary(280 unique tokens: ['announc', 'bash', 'binari', 'elf', 'enabl']...) from 61 documents (total 758 corpus positions)\n",
      "2019-04-24 17:00:59,277 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:59,279 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,281 : INFO : built Dictionary(30 unique tokens: ['exactli', 'experi', 'clever', 'creativ', 'great']...) from 4 documents (total 31 corpus positions)\n",
      "2019-04-24 17:00:59,283 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:59,287 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:00:59,296 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,300 : INFO : built Dictionary(191 unique tokens: ['autom', 'develop', 'facto', 'grown', 'handl']...) from 33 documents (total 299 corpus positions)\n",
      "2019-04-24 17:00:59,319 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,322 : INFO : built Dictionary(214 unique tokens: ['adsens', 'busi', 'decemb', 'develop', 'googl']...) from 43 documents (total 344 corpus positions)\n",
      "2019-04-24 17:00:59,347 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,350 : INFO : built Dictionary(298 unique tokens: ['android', 'confer', 'develop', 'futur', 'googl']...) from 43 documents (total 503 corpus positions)\n",
      "2019-04-24 17:00:59,373 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,376 : INFO : built Dictionary(124 unique tokens: ['app', 'beat', 'china', 'global', 'ipad']...) from 19 documents (total 197 corpus positions)\n",
      "2019-04-24 17:00:59,387 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,390 : INFO : built Dictionary(170 unique tokens: ['car', 'citi', 'drive', 'effici', 'execut']...) from 15 documents (total 229 corpus positions)\n",
      "2019-04-24 17:00:59,404 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,407 : INFO : built Dictionary(204 unique tokens: ['astonish', 'buzz', 'crowd', 'danc', 'demo']...) from 24 documents (total 320 corpus positions)\n",
      "2019-04-24 17:00:59,421 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,425 : INFO : built Dictionary(128 unique tokens: ['autom', 'changer', 'field', 'game', 'iiot']...) from 12 documents (total 218 corpus positions)\n",
      "2019-04-24 17:00:59,441 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,445 : INFO : built Dictionary(209 unique tokens: ['facebook', 'follow', 'like', 'photo', 'slate']...) from 19 documents (total 320 corpus positions)\n",
      "2019-04-24 17:00:59,474 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,479 : INFO : built Dictionary(446 unique tokens: ['common', 'java', 'program', 'tend', 'thing']...) from 134 documents (total 1166 corpus positions)\n",
      "2019-04-24 17:00:59,585 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,588 : INFO : built Dictionary(320 unique tokens: ['like', 'train', 'love', 'rebellab', 'immens']...) from 93 documents (total 709 corpus positions)\n",
      "2019-04-24 17:00:59,634 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:00:59,636 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,639 : INFO : built Dictionary(83 unique tokens: ['api', 'app', 'built', 'cloud', 'consum']...) from 9 documents (total 116 corpus positions)\n",
      "2019-04-24 17:00:59,641 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:00:59,671 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,676 : INFO : built Dictionary(668 unique tokens: ['afternoon', 'alik', 'bad', 'capitalist', 'dump']...) from 135 documents (total 1468 corpus positions)\n",
      "2019-04-24 17:00:59,811 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,817 : INFO : built Dictionary(726 unique tokens: ['custom', 'join', 'lead', 'roli', 'saxena']...) from 223 documents (total 1648 corpus positions)\n",
      "2019-04-24 17:00:59,993 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:00:59,996 : INFO : built Dictionary(126 unique tokens: ['cidad', 'design', 'medalha', 'merec', 'modalidad']...) from 11 documents (total 160 corpus positions)\n",
      "2019-04-24 17:01:00,010 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,014 : INFO : built Dictionary(267 unique tokens: ['amazon', 'amzn', 'center', 'cloud', 'giant']...) from 36 documents (total 426 corpus positions)\n",
      "2019-04-24 17:01:00,031 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:00,034 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,036 : INFO : built Dictionary(124 unique tokens: ['acaba', 'americano', 'banco', 'brasileira', 'com']...) from 7 documents (total 166 corpus positions)\n",
      "2019-04-24 17:01:00,039 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:00,058 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,062 : INFO : built Dictionary(305 unique tokens: ['bigqueri', 'blog', 'differ', 'gave', 'hood']...) from 55 documents (total 604 corpus positions)\n",
      "2019-04-24 17:01:00,095 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,099 : INFO : built Dictionary(163 unique tokens: ['bummer', 'googl', 'phone', 'preinstal', 'real']...) from 45 documents (total 350 corpus positions)\n",
      "2019-04-24 17:01:00,119 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,121 : INFO : built Dictionary(88 unique tokens: ['android', 'announc', 'applic', 'calendar', 'easier']...) from 12 documents (total 140 corpus positions)\n",
      "2019-04-24 17:01:00,134 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,137 : INFO : built Dictionary(223 unique tokens: ['advanc', 'announc', 'april', 'back', 'better']...) from 24 documents (total 402 corpus positions)\n",
      "2019-04-24 17:01:00,155 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,158 : INFO : built Dictionary(195 unique tokens: ['ben', 'chamber', 'data', 'debug', 'difficult']...) from 35 documents (total 377 corpus positions)\n",
      "2019-04-24 17:01:00,177 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,180 : INFO : built Dictionary(197 unique tokens: ['comput', 'engin', 'googl', 'hardwar', 'hum']...) from 27 documents (total 348 corpus positions)\n",
      "2019-04-24 17:01:00,199 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,202 : INFO : built Dictionary(164 unique tokens: ['ask', 'audienc', 'late', 'lot', 'march']...) from 27 documents (total 265 corpus positions)\n",
      "2019-04-24 17:01:00,220 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,224 : INFO : built Dictionary(245 unique tokens: ['configur', 'cornerston', 'distribut', 'group', 'inform']...) from 23 documents (total 549 corpus positions)\n",
      "2019-04-24 17:01:00,237 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:00,240 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,243 : INFO : built Dictionary(69 unique tokens: ['adotado', 'android', 'buscador', 'com', 'descolada']...) from 5 documents (total 82 corpus positions)\n",
      "2019-04-24 17:01:00,245 : WARNING : Input corpus is expected to have at least 10 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:00,251 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:00,254 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,256 : INFO : built Dictionary(24 unique tokens: ['glove', 'invent', 'languag', 'sign', 'speech']...) from 6 documents (total 30 corpus positions)\n",
      "2019-04-24 17:01:00,259 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:00,271 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,274 : INFO : built Dictionary(255 unique tokens: ['algorithm', 'beta', 'compar', 'develop', 'gym']...) from 54 documents (total 447 corpus positions)\n",
      "2019-04-24 17:01:00,299 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,303 : INFO : built Dictionary(94 unique tokens: ['announc', 'bitcoin', 'bring', 'game', 'gamer']...) from 13 documents (total 145 corpus positions)\n",
      "2019-04-24 17:01:00,323 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,328 : INFO : built Dictionary(339 unique tokens: ['know', 'known', 'thing', 'unknown', 'defens']...) from 87 documents (total 820 corpus positions)\n",
      "2019-04-24 17:01:00,386 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,389 : INFO : built Dictionary(230 unique tokens: ['agreement', 'april', 'bergin', 'chri', 'dragon']...) from 27 documents (total 417 corpus positions)\n",
      "2019-04-24 17:01:00,405 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:00,407 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,411 : INFO : built Dictionary(56 unique tokens: ['android', 'apena', 'aplicativo', 'com', 'desenvolv']...) from 9 documents (total 88 corpus positions)\n",
      "2019-04-24 17:01:00,413 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:00,419 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:00,421 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,423 : INFO : built Dictionary(113 unique tokens: ['certament', 'dinheiro', 'mai', 'mundo', 'popular']...) from 8 documents (total 134 corpus positions)\n",
      "2019-04-24 17:01:00,425 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:00,435 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,438 : INFO : built Dictionary(194 unique tokens: ['continu', 'facebook', 'long', 'wait', 'work']...) from 18 documents (total 308 corpus positions)\n",
      "2019-04-24 17:01:00,458 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,464 : INFO : built Dictionary(312 unique tokens: ['cdi', 'certament', 'com', 'contexto', 'da']...) from 30 documents (total 907 corpus positions)\n",
      "2019-04-24 17:01:00,482 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:00,484 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,487 : INFO : built Dictionary(26 unique tokens: ['bank', 'biometr', 'corpor', 'custom', 'gone']...) from 2 documents (total 27 corpus positions)\n",
      "2019-04-24 17:01:00,489 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:00,492 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:00,495 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:00,504 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,508 : INFO : built Dictionary(248 unique tokens: ['devic', 'intellig', 'modern', 'remark', 'smartphon']...) from 28 documents (total 397 corpus positions)\n",
      "2019-04-24 17:01:00,520 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:00,523 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,525 : INFO : built Dictionary(120 unique tokens: ['avon', 'cosmético', 'divulg', 'drag', 'entrando']...) from 9 documents (total 148 corpus positions)\n",
      "2019-04-24 17:01:00,528 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:00,538 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,541 : INFO : built Dictionary(214 unique tokens: ['bem', 'cada', 'cuidar', 'publicado', 'saúd']...) from 19 documents (total 321 corpus positions)\n",
      "2019-04-24 17:01:00,563 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,567 : INFO : built Dictionary(301 unique tokens: ['analyt', 'capabl', 'compani', 'critic', 'effort']...) from 59 documents (total 802 corpus positions)\n",
      "2019-04-24 17:01:00,617 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,620 : INFO : built Dictionary(237 unique tokens: ['ago', 'announc', 'flir', 'follow', 'heel']...) from 34 documents (total 406 corpus positions)\n",
      "2019-04-24 17:01:00,640 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,644 : INFO : built Dictionary(325 unique tokens: ['apaixonada', 'arroz', 'bolinho', 'desd', 'entendo']...) from 23 documents (total 597 corpus positions)\n",
      "2019-04-24 17:01:00,662 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,666 : INFO : built Dictionary(233 unique tokens: ['alguma', 'apaixonada', 'carn', 'carpaccio', 'cevich']...) from 18 documents (total 372 corpus positions)\n",
      "2019-04-24 17:01:00,678 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,681 : INFO : built Dictionary(126 unique tokens: ['announc', 'certif', 'clearli', 'compani', 'coverag']...) from 15 documents (total 225 corpus positions)\n",
      "2019-04-24 17:01:00,707 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,712 : INFO : built Dictionary(427 unique tokens: ['clariti', 'content', 'fundament', 'goal', 'import']...) from 104 documents (total 1001 corpus positions)\n",
      "2019-04-24 17:01:00,794 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,798 : INFO : built Dictionary(427 unique tokens: ['clariti', 'content', 'fundament', 'goal', 'import']...) from 104 documents (total 1001 corpus positions)\n",
      "2019-04-24 17:01:00,873 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,875 : INFO : built Dictionary(290 unique tokens: ['algun', 'andré', 'anterior', 'artigo', 'básico']...) from 29 documents (total 617 corpus positions)\n",
      "2019-04-24 17:01:00,897 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,900 : INFO : built Dictionary(100 unique tokens: ['announc', 'chatbot', 'chatter', 'compani', 'facebook']...) from 13 documents (total 121 corpus positions)\n",
      "2019-04-24 17:01:00,910 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,913 : INFO : built Dictionary(157 unique tokens: ['angular', 'guid', 'multipl', 'version', 'appropri']...) from 29 documents (total 259 corpus positions)\n",
      "2019-04-24 17:01:00,926 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,928 : INFO : built Dictionary(115 unique tokens: ['nomin', 'win', 'award', 'storylin', 'year']...) from 18 documents (total 134 corpus positions)\n",
      "2019-04-24 17:01:00,941 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,944 : INFO : built Dictionary(198 unique tokens: ['coerc', 'debt', 'dude', 'know', 'lebowski']...) from 30 documents (total 239 corpus positions)\n",
      "2019-04-24 17:01:00,959 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,961 : INFO : built Dictionary(133 unique tokens: ['belief', 'dement', 'desmond', 'focus', 'goddess']...) from 12 documents (total 154 corpus positions)\n",
      "2019-04-24 17:01:00,970 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,974 : INFO : built Dictionary(140 unique tokens: ['movi', 'nomin', 'oscar', 'rate', 'win']...) from 17 documents (total 164 corpus positions)\n",
      "2019-04-24 17:01:00,984 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:00,988 : INFO : built Dictionary(115 unique tokens: ['nomin', 'win', 'antiqu', 'appreci', 'art']...) from 11 documents (total 136 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:01,000 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,006 : INFO : built Dictionary(123 unique tokens: ['absolut', 'art', 'best', 'cobb', 'danger']...) from 13 documents (total 145 corpus positions)\n",
      "2019-04-24 17:01:01,016 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:01,018 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,021 : INFO : built Dictionary(61 unique tokens: ['addit', 'certif', 'cloud', 'commit', 'custom']...) from 7 documents (total 98 corpus positions)\n",
      "2019-04-24 17:01:01,024 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:01,042 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,047 : INFO : built Dictionary(340 unique tokens: ['hear', 'rare', 'wow', 'enterpris', 'insert']...) from 113 documents (total 744 corpus positions)\n",
      "2019-04-24 17:01:01,117 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:01,119 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,121 : INFO : built Dictionary(72 unique tokens: ['comprou', 'consumo', 'da', 'dermocosmético', 'empresa']...) from 7 documents (total 93 corpus positions)\n",
      "2019-04-24 17:01:01,124 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:01,134 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,137 : INFO : built Dictionary(234 unique tokens: ['achismo', 'acho', 'aquela', 'estudo', 'falo']...) from 24 documents (total 397 corpus positions)\n",
      "2019-04-24 17:01:01,155 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,158 : INFO : built Dictionary(76 unique tokens: ['career', 'data', 'field', 'grow', 'pai']...) from 11 documents (total 122 corpus positions)\n",
      "2019-04-24 17:01:01,181 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,187 : INFO : built Dictionary(377 unique tokens: ['consum', 'enterpris', 'import', 'linux', 'space']...) from 111 documents (total 889 corpus positions)\n",
      "2019-04-24 17:01:01,261 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,264 : INFO : built Dictionary(85 unique tokens: ['android', 'biggest', 'calendar', 'corner', 'event']...) from 12 documents (total 104 corpus positions)\n",
      "2019-04-24 17:01:01,304 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,309 : INFO : built Dictionary(696 unique tokens: ['date', 'farther', 'good', 'internet', 'lucki']...) from 186 documents (total 1580 corpus positions)\n",
      "2019-04-24 17:01:01,486 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,490 : INFO : built Dictionary(426 unique tokens: ['estim', 'guilti', 'live', 'minut', 'past']...) from 118 documents (total 1036 corpus positions)\n",
      "2019-04-24 17:01:01,569 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,573 : INFO : built Dictionary(515 unique tokens: ['founder', 'futur', 'highlight', 'larri', 'letter']...) from 98 documents (total 1078 corpus positions)\n",
      "2019-04-24 17:01:01,641 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:01,644 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,646 : INFO : built Dictionary(90 unique tokens: ['chang', 'game', 'human', 'implic', 'liter']...) from 8 documents (total 108 corpus positions)\n",
      "2019-04-24 17:01:01,649 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:01,665 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,670 : INFO : built Dictionary(315 unique tokens: ['editor', 'email', 'like', 'automat', 'gener']...) from 81 documents (total 648 corpus positions)\n",
      "2019-04-24 17:01:01,721 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,724 : INFO : built Dictionary(177 unique tokens: ['app', 'applic', 'begin', 'detail', 'googl']...) from 20 documents (total 285 corpus positions)\n",
      "2019-04-24 17:01:01,738 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,740 : INFO : built Dictionary(116 unique tokens: ['algorithm', 'art', 'artifici', 'build', 'conduct']...) from 11 documents (total 168 corpus positions)\n",
      "2019-04-24 17:01:01,804 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:01,813 : INFO : built Dictionary(1584 unique tokens: ['approxim', 'deft', 'ecosystem', 'era', 'facet']...) from 424 documents (total 3789 corpus positions)\n",
      "2019-04-24 17:01:02,478 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:02,481 : INFO : built Dictionary(186 unique tokens: ['abl', 'activ', 'app', 'build', 'dai']...) from 36 documents (total 304 corpus positions)\n",
      "2019-04-24 17:01:02,497 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:02,500 : INFO : built Dictionary(66 unique tokens: ['account', 'alert', 'bot', 'discontinu', 'magic']...) from 10 documents (total 92 corpus positions)\n",
      "2019-04-24 17:01:02,543 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:02,549 : INFO : built Dictionary(1058 unique tokens: ['app', 'april', 'builder', 'develop', 'given']...) from 288 documents (total 2037 corpus positions)\n",
      "2019-04-24 17:01:02,786 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:02,788 : INFO : built Dictionary(156 unique tokens: ['américa', 'ao', 'campanha', 'client', 'com']...) from 12 documents (total 224 corpus positions)\n",
      "2019-04-24 17:01:02,809 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:02,814 : INFO : built Dictionary(433 unique tokens: ['good', 'softwar', 'take', 'year', 'associ']...) from 102 documents (total 861 corpus positions)\n",
      "2019-04-24 17:01:02,882 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:02,886 : INFO : built Dictionary(621 unique tokens: ['better', 'code', 'heard', 'joel', 'sema']...) from 158 documents (total 1363 corpus positions)\n",
      "2019-04-24 17:01:03,016 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,020 : INFO : built Dictionary(441 unique tokens: ['autom', 'develop', 'essenti', 'introduct', 'softwar']...) from 127 documents (total 1352 corpus positions)\n",
      "2019-04-24 17:01:03,130 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,134 : INFO : built Dictionary(450 unique tokens: ['blog', 'christoph', 'contributor', 'dole', 'guest']...) from 102 documents (total 1032 corpus positions)\n",
      "2019-04-24 17:01:03,189 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,192 : INFO : built Dictionary(93 unique tokens: ['app', 'basi', 'daili', 'differ', 'minut']...) from 12 documents (total 137 corpus positions)\n",
      "2019-04-24 17:01:03,203 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,205 : INFO : built Dictionary(142 unique tokens: ['featur', 'googl', 'got', 'ifttt', 'major']...) from 27 documents (total 265 corpus positions)\n",
      "2019-04-24 17:01:03,222 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,225 : INFO : built Dictionary(283 unique tokens: ['coffe', 'drink', 'italian', 'met', 'acquaint']...) from 39 documents (total 443 corpus positions)\n",
      "2019-04-24 17:01:03,249 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,251 : INFO : built Dictionary(179 unique tokens: ['bot', 'dai', 'deliv', 'discoveri', 'distribut']...) from 35 documents (total 361 corpus positions)\n",
      "2019-04-24 17:01:03,274 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,277 : INFO : built Dictionary(213 unique tokens: ['app', 'commun', 'contain', 'container', 'convers']...) from 43 documents (total 390 corpus positions)\n",
      "2019-04-24 17:01:03,299 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,302 : INFO : built Dictionary(170 unique tokens: ['big', 'chatbot', 'misunderstand', 'trend', 'china']...) from 22 documents (total 238 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:03,310 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:03,312 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,315 : INFO : built Dictionary(28 unique tokens: ['best', 'choos', 'citi', 'daniel', 'daunt']...) from 5 documents (total 39 corpus positions)\n",
      "2019-04-24 17:01:03,318 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:03,334 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,338 : INFO : built Dictionary(378 unique tokens: ['annual', 'artifici', 'better', 'blind', 'build']...) from 52 documents (total 763 corpus positions)\n",
      "2019-04-24 17:01:03,389 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,393 : INFO : built Dictionary(666 unique tokens: ['artifici', 'fall', 'intellig', 'predict', 'scenario']...) from 136 documents (total 1293 corpus positions)\n",
      "2019-04-24 17:01:03,496 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,499 : INFO : built Dictionary(386 unique tokens: ['acquir', 'billion', 'facebook', 'whatsapp', 'astronom']...) from 62 documents (total 799 corpus positions)\n",
      "2019-04-24 17:01:03,527 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,531 : INFO : built Dictionary(58 unique tokens: ['accord', 'beirn', 'citi', 'googl', 'increas']...) from 10 documents (total 95 corpus positions)\n",
      "2019-04-24 17:01:03,541 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,544 : INFO : built Dictionary(185 unique tokens: ['oscar', 'won', 'nomin', 'win', 'award']...) from 25 documents (total 231 corpus positions)\n",
      "2019-04-24 17:01:03,568 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,572 : INFO : built Dictionary(405 unique tokens: ['bank', 'bot', 'branch', 'convers', 'access']...) from 115 documents (total 864 corpus positions)\n",
      "2019-04-24 17:01:03,641 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,644 : INFO : built Dictionary(200 unique tokens: ['adult', 'code', 'learn', 'pizza', 'serv']...) from 41 documents (total 324 corpus positions)\n",
      "2019-04-24 17:01:03,668 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,672 : INFO : built Dictionary(275 unique tokens: ['wait', 'base', 'complet', 'gener', 'high']...) from 42 documents (total 542 corpus positions)\n",
      "2019-04-24 17:01:03,697 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,700 : INFO : built Dictionary(204 unique tokens: ['biggest', 'bike', 'differ', 'electr', 'kind']...) from 26 documents (total 308 corpus positions)\n",
      "2019-04-24 17:01:03,725 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,729 : INFO : built Dictionary(365 unique tokens: ['android', 'command', 'global', 'market', 'mobil']...) from 65 documents (total 720 corpus positions)\n",
      "2019-04-24 17:01:03,768 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,771 : INFO : built Dictionary(214 unique tokens: ['build', 'configur', 'drupal', 'edit', 'experi']...) from 50 documents (total 526 corpus positions)\n",
      "2019-04-24 17:01:03,797 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,800 : INFO : built Dictionary(167 unique tokens: ['comfort', 'fact', 'gcp', 'lover', 'music']...) from 20 documents (total 233 corpus positions)\n",
      "2019-04-24 17:01:03,817 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,821 : INFO : built Dictionary(285 unique tokens: ['better', 'box', 'code', 'constantli', 'evalu']...) from 71 documents (total 549 corpus positions)\n",
      "2019-04-24 17:01:03,867 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,871 : INFO : built Dictionary(338 unique tokens: ['agil', 'big', 'compani', 'corpor', 'devop']...) from 94 documents (total 684 corpus positions)\n",
      "2019-04-24 17:01:03,919 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,922 : INFO : built Dictionary(241 unique tokens: ['adrian', 'convers', 'design', 'interfac', 'meant']...) from 40 documents (total 441 corpus positions)\n",
      "2019-04-24 17:01:03,953 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:03,957 : INFO : built Dictionary(244 unique tokens: ['domin', 'ecosystem', 'grow', 'learn', 'machin']...) from 78 documents (total 639 corpus positions)\n",
      "2019-04-24 17:01:03,999 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,002 : INFO : built Dictionary(123 unique tokens: ['coach', 'com', 'crédito', 'da', 'disseram']...) from 10 documents (total 178 corpus positions)\n",
      "2019-04-24 17:01:04,009 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:04,012 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,014 : INFO : built Dictionary(71 unique tokens: ['architect', 'clan', 'cost', 'crime', 'gener']...) from 5 documents (total 77 corpus positions)\n",
      "2019-04-24 17:01:04,016 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:04,024 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,027 : INFO : built Dictionary(194 unique tokens: ['depend', 'enormement', 'funcionário', 'googl', 'inovador']...) from 22 documents (total 291 corpus positions)\n",
      "2019-04-24 17:01:04,040 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,042 : INFO : built Dictionary(145 unique tokens: ['email', 'freemium', 'hubspot', 'tool', 'activ']...) from 22 documents (total 206 corpus positions)\n",
      "2019-04-24 17:01:04,057 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,061 : INFO : built Dictionary(209 unique tokens: ['life', 'solar', 'best', 'bet', 'earth']...) from 36 documents (total 397 corpus positions)\n",
      "2019-04-24 17:01:04,085 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,089 : INFO : built Dictionary(234 unique tokens: ['advanc', 'base', 'blockchain', 'cabinet', 'digit']...) from 50 documents (total 410 corpus positions)\n",
      "2019-04-24 17:01:04,113 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,117 : INFO : built Dictionary(160 unique tokens: ['benefit', 'chipmak', 'continu', 'gadget', 'help']...) from 20 documents (total 262 corpus positions)\n",
      "2019-04-24 17:01:04,134 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,139 : INFO : built Dictionary(174 unique tokens: ['effect', 'extrem', 'generalist', 'highli', 'owner']...) from 41 documents (total 346 corpus positions)\n",
      "2019-04-24 17:01:04,159 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,163 : INFO : built Dictionary(106 unique tokens: ['announc', 'compani', 'deep', 'develop', 'kit']...) from 13 documents (total 170 corpus positions)\n",
      "2019-04-24 17:01:04,183 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,189 : INFO : built Dictionary(426 unique tokens: ['bicentenni', 'chatbot', 'critic', 'evolut', 'film']...) from 68 documents (total 783 corpus positions)\n",
      "2019-04-24 17:01:04,236 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,240 : INFO : built Dictionary(359 unique tokens: ['anatel', 'banda', 'barrarem', 'com', 'consumidor']...) from 33 documents (total 644 corpus positions)\n",
      "2019-04-24 17:01:04,264 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,269 : INFO : built Dictionary(285 unique tokens: ['agropecuária', 'ano', 'apresentar', 'avanç', 'brasileiro']...) from 35 documents (total 476 corpus positions)\n",
      "2019-04-24 17:01:04,292 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,296 : INFO : built Dictionary(186 unique tokens: ['oscar', 'won', 'nomin', 'win', 'adapt']...) from 30 documents (total 262 corpus positions)\n",
      "2019-04-24 17:01:04,308 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,311 : INFO : built Dictionary(114 unique tokens: ['american', 'edg', 'frontier', 'mcbain', 'move']...) from 14 documents (total 124 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:04,318 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,321 : INFO : built Dictionary(126 unique tokens: ['award', 'bafta', 'film', 'nomin', 'win']...) from 15 documents (total 153 corpus positions)\n",
      "2019-04-24 17:01:04,332 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,336 : INFO : built Dictionary(167 unique tokens: ['globe', 'golden', 'nomin', 'win', 'award']...) from 26 documents (total 220 corpus positions)\n",
      "2019-04-24 17:01:04,349 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,353 : INFO : built Dictionary(151 unique tokens: ['nomin', 'win', 'award', 'built', 'exist']...) from 19 documents (total 182 corpus positions)\n",
      "2019-04-24 17:01:04,364 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,367 : INFO : built Dictionary(196 unique tokens: ['movi', 'nomin', 'oscar', 'rate', 'win']...) from 32 documents (total 246 corpus positions)\n",
      "2019-04-24 17:01:04,381 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,384 : INFO : built Dictionary(147 unique tokens: ['globe', 'golden', 'nomin', 'win', 'award']...) from 16 documents (total 191 corpus positions)\n",
      "2019-04-24 17:01:04,394 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:04,397 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,400 : INFO : built Dictionary(99 unique tokens: ['nomin', 'win', 'award', 'barbar', 'booksel']...) from 9 documents (total 113 corpus positions)\n",
      "2019-04-24 17:01:04,403 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:04,412 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,415 : INFO : built Dictionary(170 unique tokens: ['award', 'bafta', 'film', 'nomin', 'win']...) from 22 documents (total 219 corpus positions)\n",
      "2019-04-24 17:01:04,424 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,427 : INFO : built Dictionary(102 unique tokens: ['nomin', 'win', 'award', 'boi', 'death']...) from 12 documents (total 120 corpus positions)\n",
      "2019-04-24 17:01:04,434 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,437 : INFO : built Dictionary(122 unique tokens: ['averag', 'cell', 'explan', 'imprison', 'kidnap']...) from 18 documents (total 142 corpus positions)\n",
      "2019-04-24 17:01:04,446 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,449 : INFO : built Dictionary(123 unique tokens: ['nomin', 'win', 'award', 'dai', 'happi']...) from 22 documents (total 150 corpus positions)\n",
      "2019-04-24 17:01:04,459 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,462 : INFO : built Dictionary(197 unique tokens: ['nomin', 'win', 'appoint', 'arriv', 'award']...) from 20 documents (total 249 corpus positions)\n",
      "2019-04-24 17:01:04,475 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,478 : INFO : built Dictionary(248 unique tokens: ['acontec', 'brasileiro', 'criatividad', 'dia', 'do']...) from 24 documents (total 417 corpus positions)\n",
      "2019-04-24 17:01:04,491 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:04,493 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,496 : INFO : built Dictionary(118 unique tokens: ['além', 'android', 'aplicativo', 'chrome', 'como']...) from 6 documents (total 153 corpus positions)\n",
      "2019-04-24 17:01:04,499 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:04,506 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,509 : INFO : built Dictionary(142 unique tokens: ['abril', 'apresenta', 'com', 'concedida', 'consumidor']...) from 15 documents (total 211 corpus positions)\n",
      "2019-04-24 17:01:04,518 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:04,520 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,523 : INFO : built Dictionary(50 unique tokens: ['align', 'collabor', 'creativ', 'cross', 'cultur']...) from 4 documents (total 57 corpus positions)\n",
      "2019-04-24 17:01:04,525 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:04,528 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:04,559 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,564 : INFO : built Dictionary(526 unique tokens: ['bui', 'compani', 'custom', 'experi', 'help']...) from 206 documents (total 1478 corpus positions)\n",
      "2019-04-24 17:01:04,754 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,756 : INFO : built Dictionary(108 unique tokens: ['andreessen', 'com', 'dot', 'geniu', 'horowitz']...) from 39 documents (total 197 corpus positions)\n",
      "2019-04-24 17:01:04,769 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,772 : INFO : built Dictionary(82 unique tokens: ['acquir', 'app', 'base', 'employe', 'googl']...) from 10 documents (total 134 corpus positions)\n",
      "2019-04-24 17:01:04,778 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:04,780 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,783 : INFO : built Dictionary(45 unique tokens: ['agil', 'alex', 'appli', 'consult', 'decad']...) from 3 documents (total 55 corpus positions)\n",
      "2019-04-24 17:01:04,785 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:04,788 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:04,797 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,801 : INFO : built Dictionary(240 unique tokens: ['apach', 'benchmark', 'carri', 'caveat', 'cloud']...) from 27 documents (total 462 corpus positions)\n",
      "2019-04-24 17:01:04,825 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,828 : INFO : built Dictionary(301 unique tokens: ['agre', 'agricultur', 'applic', 'brazil', 'brazilian']...) from 32 documents (total 572 corpus positions)\n",
      "2019-04-24 17:01:04,855 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,858 : INFO : built Dictionary(390 unique tokens: ['blog', 'comment', 'dy', 'edit', 'eleg']...) from 90 documents (total 572 corpus positions)\n",
      "2019-04-24 17:01:04,911 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:04,916 : INFO : built Dictionary(583 unique tokens: ['ad', 'client', 'clue', 'displai', 'googl']...) from 135 documents (total 1359 corpus positions)\n",
      "2019-04-24 17:01:05,026 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,029 : INFO : built Dictionary(141 unique tokens: ['nomin', 'oscar', 'win', 'actress', 'amnesia']...) from 15 documents (total 166 corpus positions)\n",
      "2019-04-24 17:01:05,037 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,039 : INFO : built Dictionary(102 unique tokens: ['anunci', 'brasil', 'durant', 'evento', 'expo']...) from 13 documents (total 129 corpus positions)\n",
      "2019-04-24 17:01:05,048 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,051 : INFO : built Dictionary(162 unique tokens: ['famili', 'hard', 'life', 'mine', 'morgan']...) from 21 documents (total 201 corpus positions)\n",
      "2019-04-24 17:01:05,063 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,065 : INFO : built Dictionary(155 unique tokens: ['ag', 'backstag', 'broadwai', 'chan', 'ev']...) from 19 documents (total 195 corpus positions)\n",
      "2019-04-24 17:01:05,077 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,080 : INFO : built Dictionary(208 unique tokens: ['parabén', 'ab', 'campeão', 'cristal', 'então']...) from 26 documents (total 331 corpus positions)\n",
      "2019-04-24 17:01:05,099 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,102 : INFO : built Dictionary(368 unique tokens: ['aponta', 'atend', 'atraent', 'ceo', 'client']...) from 30 documents (total 652 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:05,127 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,131 : INFO : built Dictionary(282 unique tokens: ['app', 'assist', 'crm', 'data', 'digit']...) from 61 documents (total 499 corpus positions)\n",
      "2019-04-24 17:01:05,184 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,190 : INFO : built Dictionary(471 unique tokens: ['build', 'competit', 'data', 'fantast', 'kaggl']...) from 232 documents (total 1951 corpus positions)\n",
      "2019-04-24 17:01:05,431 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,434 : INFO : built Dictionary(307 unique tokens: ['asia', 'connect', 'digit', 'global', 'half']...) from 40 documents (total 530 corpus positions)\n",
      "2019-04-24 17:01:05,457 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,462 : INFO : built Dictionary(356 unique tokens: ['abr', 'anális', 'boca', 'dado', 'empresa']...) from 42 documents (total 616 corpus positions)\n",
      "2019-04-24 17:01:05,488 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,490 : INFO : built Dictionary(235 unique tokens: ['abril', 'ambient', 'briga', 'com', 'comunicação']...) from 25 documents (total 373 corpus positions)\n",
      "2019-04-24 17:01:05,508 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,511 : INFO : built Dictionary(212 unique tokens: ['crescent', 'desenvolv', 'diferent', 'empresa', 'especialment']...) from 19 documents (total 312 corpus positions)\n",
      "2019-04-24 17:01:05,544 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,549 : INFO : built Dictionary(557 unique tokens: ['agil', 'develop', 'discret', 'organ', 'product']...) from 114 documents (total 1513 corpus positions)\n",
      "2019-04-24 17:01:05,667 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,669 : INFO : built Dictionary(132 unique tokens: ['bike', 'depress', 'economi', 'get', 'good']...) from 11 documents (total 150 corpus positions)\n",
      "2019-04-24 17:01:05,698 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,703 : INFO : built Dictionary(583 unique tokens: ['accord', 'attent', 'busi', 'compar', 'end']...) from 102 documents (total 1252 corpus positions)\n",
      "2019-04-24 17:01:05,769 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:05,772 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,775 : INFO : built Dictionary(94 unique tokens: ['artifici', 'chang', 'fundament', 'human', 'intellig']...) from 8 documents (total 122 corpus positions)\n",
      "2019-04-24 17:01:05,778 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:05,807 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,811 : INFO : built Dictionary(447 unique tokens: ['american', 'erect', 'institut', 'passeng', 'pneumat']...) from 122 documents (total 1199 corpus positions)\n",
      "2019-04-24 17:01:05,918 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,921 : INFO : built Dictionary(174 unique tokens: ['file', 'set', 'text', 'track', 'work']...) from 61 documents (total 401 corpus positions)\n",
      "2019-04-24 17:01:05,952 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:05,956 : INFO : built Dictionary(302 unique tokens: ['follow', 'node', 'origin', 'post', 'python']...) from 87 documents (total 498 corpus positions)\n",
      "2019-04-24 17:01:05,998 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,002 : INFO : built Dictionary(286 unique tokens: ['fiction', 'let', 'life', 'peopl', 'potenti']...) from 48 documents (total 452 corpus positions)\n",
      "2019-04-24 17:01:06,026 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,029 : INFO : built Dictionary(146 unique tokens: ['sleep', 'import', 'new', 'newborn', 'parent']...) from 25 documents (total 238 corpus positions)\n",
      "2019-04-24 17:01:06,044 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,047 : INFO : built Dictionary(113 unique tokens: ['effect', 'interact', 'know', 'present', 'skill']...) from 14 documents (total 199 corpus positions)\n",
      "2019-04-24 17:01:06,063 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,066 : INFO : built Dictionary(415 unique tokens: ['appl', 'park', 'run', 'space', 'capac']...) from 70 documents (total 679 corpus positions)\n",
      "2019-04-24 17:01:06,106 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,109 : INFO : built Dictionary(118 unique tokens: ['contain', 'dangl', 'docker', 'dust', 'imag']...) from 25 documents (total 241 corpus positions)\n",
      "2019-04-24 17:01:06,123 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,125 : INFO : built Dictionary(134 unique tokens: ['arbezzano', 'build', 'code', 'contain', 'continu']...) from 15 documents (total 274 corpus positions)\n",
      "2019-04-24 17:01:06,137 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,140 : INFO : built Dictionary(248 unique tokens: ['apreço', 'bola', 'brasileiro', 'burrofon', 'campeão']...) from 25 documents (total 376 corpus positions)\n",
      "2019-04-24 17:01:06,159 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,163 : INFO : built Dictionary(277 unique tokens: ['ben', 'dai', 'data', 'episod', 'finish']...) from 39 documents (total 526 corpus positions)\n",
      "2019-04-24 17:01:06,186 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,189 : INFO : built Dictionary(294 unique tokens: ['abril', 'alguma', 'da', 'encontraram', 'escritório']...) from 26 documents (total 488 corpus positions)\n",
      "2019-04-24 17:01:06,205 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:06,208 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,211 : INFO : built Dictionary(82 unique tokens: ['adicion', 'causar', 'classificar', 'durant', 'dúvida']...) from 6 documents (total 96 corpus positions)\n",
      "2019-04-24 17:01:06,213 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:06,221 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,223 : INFO : built Dictionary(198 unique tokens: ['bom', 'com', 'como', 'entend', 'escrev']...) from 30 documents (total 252 corpus positions)\n",
      "2019-04-24 17:01:06,240 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,243 : INFO : built Dictionary(376 unique tokens: ['afastamento', 'cunha', 'câmara', 'deputado', 'determin']...) from 23 documents (total 680 corpus positions)\n",
      "2019-04-24 17:01:06,262 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,265 : INFO : built Dictionary(249 unique tokens: ['amigável', 'banco', 'cada', 'cartão', 'com']...) from 26 documents (total 470 corpus positions)\n",
      "2019-04-24 17:01:06,288 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,292 : INFO : built Dictionary(330 unique tokens: ['bui', 'class', 'colleg', 'got', 'gui']...) from 63 documents (total 619 corpus positions)\n",
      "2019-04-24 17:01:06,368 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,373 : INFO : built Dictionary(611 unique tokens: ['angular', 'applic', 'convent', 'guid', 'look']...) from 248 documents (total 3491 corpus positions)\n",
      "2019-04-24 17:01:06,651 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:06,653 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,655 : INFO : built Dictionary(111 unique tokens: ['acordo', 'assin', 'automóvei', 'brasil', 'carteira']...) from 8 documents (total 156 corpus positions)\n",
      "2019-04-24 17:01:06,657 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:06,666 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,668 : INFO : built Dictionary(163 unique tokens: ['appl', 'assist', 'ground', 'help', 'hundr']...) from 22 documents (total 247 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:06,679 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,681 : INFO : built Dictionary(89 unique tokens: ['nomin', 'win', 'award', 'blind', 'boi']...) from 10 documents (total 106 corpus positions)\n",
      "2019-04-24 17:01:06,691 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,694 : INFO : built Dictionary(152 unique tokens: ['nomin', 'win', 'adam', 'area', 'award']...) from 20 documents (total 192 corpus positions)\n",
      "2019-04-24 17:01:06,752 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:06,759 : INFO : built Dictionary(833 unique tokens: ['busi', 'current', 'ecommerc', 'effort', 'fall']...) from 414 documents (total 3731 corpus positions)\n",
      "2019-04-24 17:01:07,717 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:07,722 : INFO : built Dictionary(140 unique tokens: ['center', 'cours', 'descript', 'design', 'end']...) from 17 documents (total 257 corpus positions)\n",
      "2019-04-24 17:01:07,742 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:07,748 : INFO : built Dictionary(195 unique tokens: ['acontec', 'adulto', 'ação', 'campina', 'circuito']...) from 15 documents (total 288 corpus positions)\n",
      "2019-04-24 17:01:07,773 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:07,777 : INFO : built Dictionary(266 unique tokens: ['app', 'com', 'come', 'comput', 'custom']...) from 49 documents (total 427 corpus positions)\n",
      "2019-04-24 17:01:07,815 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:07,819 : INFO : built Dictionary(113 unique tokens: ['approxim', 'creativ', 'design', 'durat', 'futur']...) from 12 documents (total 156 corpus positions)\n",
      "2019-04-24 17:01:07,846 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:07,853 : INFO : built Dictionary(512 unique tokens: ['academia', 'aula', 'dia', 'draft', 'fioretti']...) from 81 documents (total 948 corpus positions)\n",
      "2019-04-24 17:01:07,930 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:07,932 : INFO : built Dictionary(160 unique tokens: ['alimento', 'centr', 'cientista', 'desenvolv', 'dimensõ']...) from 16 documents (total 219 corpus positions)\n",
      "2019-04-24 17:01:07,955 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:07,959 : INFO : built Dictionary(378 unique tokens: ['artigo', 'brasileiro', 'cerebrai', 'conhecida', 'cérebro']...) from 30 documents (total 615 corpus positions)\n",
      "2019-04-24 17:01:07,987 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:07,991 : INFO : built Dictionary(326 unique tokens: ['aeroporto', 'afiliada', 'airlin', 'apresent', 'aviõ']...) from 31 documents (total 648 corpus positions)\n",
      "2019-04-24 17:01:08,027 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,033 : INFO : built Dictionary(145 unique tokens: ['bu', 'googl', 'novel', 'okai', 'pull']...) from 17 documents (total 226 corpus positions)\n",
      "2019-04-24 17:01:08,071 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,077 : INFO : built Dictionary(394 unique tokens: ['agil', 'continu', 'effici', 'essenc', 'improv']...) from 116 documents (total 797 corpus positions)\n",
      "2019-04-24 17:01:08,153 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,156 : INFO : built Dictionary(106 unique tokens: ['ano', 'anterior', 'desafio', 'edição', 'engajar']...) from 11 documents (total 169 corpus positions)\n",
      "2019-04-24 17:01:08,166 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:08,168 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,171 : INFO : built Dictionary(117 unique tokens: ['acordo', 'ao', 'assinatura', 'bloomberg', 'canai']...) from 9 documents (total 150 corpus positions)\n",
      "2019-04-24 17:01:08,174 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:08,189 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,192 : INFO : built Dictionary(229 unique tokens: ['announc', 'cloud', 'comput', 'entertain', 'googl']...) from 22 documents (total 367 corpus positions)\n",
      "2019-04-24 17:01:08,218 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,223 : INFO : built Dictionary(279 unique tokens: ['access', 'applic', 'ball', 'combin', 'crystal']...) from 66 documents (total 475 corpus positions)\n",
      "2019-04-24 17:01:08,260 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,264 : INFO : built Dictionary(158 unique tokens: ['alimento', 'alimentícia', 'apresentarão', 'artificiai', 'barata']...) from 12 documents (total 228 corpus positions)\n",
      "2019-04-24 17:01:08,275 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,279 : INFO : built Dictionary(193 unique tokens: ['bad', 'bit', 'chatbot', 'littl', 'appar']...) from 25 documents (total 272 corpus positions)\n",
      "2019-04-24 17:01:08,300 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,304 : INFO : built Dictionary(255 unique tokens: ['googl', 'launch', 'new', 'readi', 'vision']...) from 45 documents (total 432 corpus positions)\n",
      "2019-04-24 17:01:08,323 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:08,326 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,328 : INFO : built Dictionary(31 unique tokens: ['agricultura', 'agrícola', 'climático', 'gestão', 'instrumento']...) from 2 documents (total 35 corpus positions)\n",
      "2019-04-24 17:01:08,331 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:08,333 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:08,335 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:08,361 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,368 : INFO : built Dictionary(416 unique tokens: ['current', 'draft', 'earli', 'introduct', 'jsr']...) from 76 documents (total 1326 corpus positions)\n",
      "2019-04-24 17:01:08,442 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,447 : INFO : built Dictionary(455 unique tokens: ['answer', 'command', 'digit', 'econom', 'execut']...) from 78 documents (total 926 corpus positions)\n",
      "2019-04-24 17:01:08,505 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,508 : INFO : built Dictionary(101 unique tokens: ['announc', 'app', 'bit', 'bring', 'closer']...) from 11 documents (total 178 corpus positions)\n",
      "2019-04-24 17:01:08,523 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,528 : INFO : built Dictionary(197 unique tokens: ['accuraci', 'dai', 'data', 'highest', 'hour']...) from 33 documents (total 472 corpus positions)\n",
      "2019-04-24 17:01:08,548 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,550 : INFO : built Dictionary(148 unique tokens: ['app', 'artwork', 'base', 'commentari', 'like']...) from 15 documents (total 175 corpus positions)\n",
      "2019-04-24 17:01:08,560 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,563 : INFO : built Dictionary(173 unique tokens: ['ajuda', 'atravé', 'caminho', 'comunicação', 'desistir']...) from 22 documents (total 282 corpus positions)\n",
      "2019-04-24 17:01:08,582 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,586 : INFO : built Dictionary(290 unique tokens: ['deep', 'internet', 'network', 'neural', 'remak']...) from 60 documents (total 628 corpus positions)\n",
      "2019-04-24 17:01:08,628 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,632 : INFO : built Dictionary(410 unique tokens: ['buzz', 'design', 'notif', 'phone', 'smart']...) from 99 documents (total 716 corpus positions)\n",
      "2019-04-24 17:01:08,681 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,684 : INFO : built Dictionary(149 unique tokens: ['anim', 'destroy', 'german', 'horn', 'name']...) from 25 documents (total 231 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:08,700 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,702 : INFO : built Dictionary(97 unique tokens: ['android', 'app', 'call', 'chrome', 'develop']...) from 23 documents (total 199 corpus positions)\n",
      "2019-04-24 17:01:08,714 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,717 : INFO : built Dictionary(127 unique tokens: ['abelson', 'ask', 'base', 'classic', 'cours']...) from 21 documents (total 178 corpus positions)\n",
      "2019-04-24 17:01:08,751 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,757 : INFO : built Dictionary(729 unique tokens: ['compani', 'curtain', 'document', 'highli', 'insid']...) from 117 documents (total 1727 corpus positions)\n",
      "2019-04-24 17:01:08,883 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,886 : INFO : built Dictionary(124 unique tokens: ['compani', 'confer', 'develop', 'googl', 'highlight']...) from 10 documents (total 189 corpus positions)\n",
      "2019-04-24 17:01:08,903 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,907 : INFO : built Dictionary(318 unique tokens: ['artifici', 'intellig', 'invis', 'outsid', 'start']...) from 55 documents (total 615 corpus positions)\n",
      "2019-04-24 17:01:08,957 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:08,963 : INFO : built Dictionary(364 unique tokens: ['difficult', 'discern', 'distanc', 'easi', 'midst']...) from 49 documents (total 579 corpus positions)\n",
      "2019-04-24 17:01:08,999 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,005 : INFO : built Dictionary(190 unique tokens: ['abl', 'ceo', 'cfo', 'compens', 'consum']...) from 31 documents (total 314 corpus positions)\n",
      "2019-04-24 17:01:09,022 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:09,025 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,027 : INFO : built Dictionary(88 unique tokens: ['build', 'chelsea', 'cool', 'elev', 'floor']...) from 8 documents (total 97 corpus positions)\n",
      "2019-04-24 17:01:09,030 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:09,049 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,053 : INFO : built Dictionary(267 unique tokens: ['abil', 'comput', 'explicitli', 'field', 'give']...) from 45 documents (total 926 corpus positions)\n",
      "2019-04-24 17:01:09,093 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,097 : INFO : built Dictionary(295 unique tokens: ['activ', 'ad', 'android', 'api', 'brief']...) from 72 documents (total 942 corpus positions)\n",
      "2019-04-24 17:01:09,148 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,150 : INFO : built Dictionary(105 unique tokens: ['announc', 'battlefield', 'disrupt', 'particip', 'pleas']...) from 15 documents (total 139 corpus positions)\n",
      "2019-04-24 17:01:09,158 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,161 : INFO : built Dictionary(119 unique tokens: ['ashecliff', 'assign', 'boston', 'come', 'daniel']...) from 12 documents (total 141 corpus positions)\n",
      "2019-04-24 17:01:09,188 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,192 : INFO : built Dictionary(469 unique tokens: ['critic', 'fair', 'moment', 'node', 'prais']...) from 102 documents (total 1332 corpus positions)\n",
      "2019-04-24 17:01:09,263 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,265 : INFO : built Dictionary(82 unique tokens: ['cours', 'dai', 'everybodi', 'languag', 'us']...) from 13 documents (total 133 corpus positions)\n",
      "2019-04-24 17:01:09,274 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:09,276 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,278 : INFO : built Dictionary(54 unique tokens: ['anticip', 'artifici', 'assist', 'ceo', 'dag']...) from 7 documents (total 68 corpus positions)\n",
      "2019-04-24 17:01:09,280 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:09,304 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,308 : INFO : built Dictionary(572 unique tokens: ['abordar', 'adotar', 'aqui', 'artigo', 'caso']...) from 71 documents (total 1280 corpus positions)\n",
      "2019-04-24 17:01:09,373 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:09,375 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,377 : INFO : built Dictionary(89 unique tokens: ['comentar', 'como', 'convidaram', 'el', 'ela']...) from 5 documents (total 114 corpus positions)\n",
      "2019-04-24 17:01:09,379 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:09,396 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,400 : INFO : built Dictionary(403 unique tokens: ['decad', 'digit', 'industri', 'past', 'systemat']...) from 37 documents (total 843 corpus positions)\n",
      "2019-04-24 17:01:09,430 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,433 : INFO : built Dictionary(314 unique tokens: ['attack', 'cost', 'custom', 'low', 'lucr']...) from 35 documents (total 534 corpus positions)\n",
      "2019-04-24 17:01:09,453 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,456 : INFO : built Dictionary(107 unique tokens: ['ago', 'bank', 'industri', 'pretti', 'ugli']...) from 22 documents (total 128 corpus positions)\n",
      "2019-04-24 17:01:09,471 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,475 : INFO : built Dictionary(256 unique tokens: ['frontier', 'latest', 'live', 'media', 'social']...) from 71 documents (total 526 corpus positions)\n",
      "2019-04-24 17:01:09,515 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,518 : INFO : built Dictionary(297 unique tokens: ['artigo', 'brotar', 'centena', 'devem', 'dia']...) from 38 documents (total 481 corpus positions)\n",
      "2019-04-24 17:01:09,537 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,540 : INFO : built Dictionary(151 unique tokens: ['compani', 'employe', 'facebook', 'fblearner', 'flow']...) from 19 documents (total 226 corpus positions)\n",
      "2019-04-24 17:01:09,562 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,566 : INFO : built Dictionary(343 unique tokens: ['accommod', 'airbnb', 'guest', 'host', 'look']...) from 81 documents (total 884 corpus positions)\n",
      "2019-04-24 17:01:09,623 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,625 : INFO : built Dictionary(93 unique tokens: ['briefli', 'develop', 'googl', 'leaf', 'releas']...) from 14 documents (total 138 corpus positions)\n",
      "2019-04-24 17:01:09,634 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,637 : INFO : built Dictionary(156 unique tokens: ['breast', 'cancer', 'jeet', 'longer', 'mom']...) from 21 documents (total 208 corpus positions)\n",
      "2019-04-24 17:01:09,647 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:09,649 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,652 : INFO : built Dictionary(92 unique tokens: ['anunciada', 'aplicativo', 'criação', 'foi', 'forma']...) from 7 documents (total 115 corpus positions)\n",
      "2019-04-24 17:01:09,654 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:09,662 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,665 : INFO : built Dictionary(174 unique tokens: ['família', 'filho', 'formada', 'mãe', 'pai']...) from 20 documents (total 239 corpus positions)\n",
      "2019-04-24 17:01:09,682 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,685 : INFO : built Dictionary(282 unique tokens: ['bet', 'big', 'derbi', 'follow', 'francisco']...) from 63 documents (total 552 corpus positions)\n",
      "2019-04-24 17:01:09,718 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:09,721 : INFO : built Dictionary(179 unique tokens: ['algorithm', 'carri', 'credibl', 'experiment', 'gener']...) from 27 documents (total 305 corpus positions)\n",
      "2019-04-24 17:01:09,735 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,738 : INFO : built Dictionary(152 unique tokens: ['build', 'chatbot', 'chudnovski', 'despit', 'develop']...) from 18 documents (total 220 corpus positions)\n",
      "2019-04-24 17:01:09,748 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:09,750 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,751 : INFO : built Dictionary(64 unique tokens: ['abl', 'amazon', 'announc', 'apron', 'blue']...) from 7 documents (total 80 corpus positions)\n",
      "2019-04-24 17:01:09,753 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:09,758 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:09,760 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,762 : INFO : built Dictionary(23 unique tokens: ['cloud', 'comput', 'engin', 'entrant', 'gce']...) from 4 documents (total 29 corpus positions)\n",
      "2019-04-24 17:01:09,763 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:09,767 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:09,774 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,778 : INFO : built Dictionary(146 unique tokens: ['app', 'custom', 'ident', 'introduc', 'quickli']...) from 27 documents (total 309 corpus positions)\n",
      "2019-04-24 17:01:09,792 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:09,796 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,798 : INFO : built Dictionary(69 unique tokens: ['announc', 'featur', 'fulli', 'gentl', 'graduat']...) from 7 documents (total 99 corpus positions)\n",
      "2019-04-24 17:01:09,801 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:09,824 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,830 : INFO : built Dictionary(369 unique tokens: ['access', 'adopt', 'advertis', 'analyst', 'annual']...) from 91 documents (total 1033 corpus positions)\n",
      "2019-04-24 17:01:09,899 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,901 : INFO : built Dictionary(159 unique tokens: ['acredita', 'algoritmo', 'enova', 'paulo', 'poder']...) from 21 documents (total 221 corpus positions)\n",
      "2019-04-24 17:01:09,913 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,916 : INFO : built Dictionary(262 unique tokens: ['ainda', 'aposta', 'banco', 'capaz', 'concorrent']...) from 21 documents (total 443 corpus positions)\n",
      "2019-04-24 17:01:09,933 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,936 : INFO : built Dictionary(244 unique tokens: ['access', 'annual', 'confer', 'develop', 'earli']...) from 35 documents (total 431 corpus positions)\n",
      "2019-04-24 17:01:09,970 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:09,974 : INFO : built Dictionary(391 unique tokens: ['annual', 'biggest', 'compani', 'develop', 'ecosystem']...) from 76 documents (total 901 corpus positions)\n",
      "2019-04-24 17:01:10,031 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,034 : INFO : built Dictionary(357 unique tokens: ['brought', 'factori', 'industri', 'power', 'revolut']...) from 57 documents (total 627 corpus positions)\n",
      "2019-04-24 17:01:10,062 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,065 : INFO : built Dictionary(123 unique tokens: ['attend', 'attende', 'center', 'clara', 'convent']...) from 12 documents (total 174 corpus positions)\n",
      "2019-04-24 17:01:10,074 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,077 : INFO : built Dictionary(161 unique tokens: ['amazon', 'appl', 'bank', 'facebook', 'googl']...) from 19 documents (total 241 corpus positions)\n",
      "2019-04-24 17:01:10,088 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,090 : INFO : built Dictionary(58 unique tokens: ['click', 'collect', 'connect', 'elasticsearch', 'explor']...) from 10 documents (total 134 corpus positions)\n",
      "2019-04-24 17:01:10,098 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,101 : INFO : built Dictionary(109 unique tokens: ['announc', 'com', 'couldn', 'excit', 'github']...) from 17 documents (total 205 corpus positions)\n",
      "2019-04-24 17:01:10,113 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:10,115 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,118 : INFO : built Dictionary(175 unique tokens: ['acontec', 'allianc', 'america', 'americano', 'américa']...) from 8 documents (total 289 corpus positions)\n",
      "2019-04-24 17:01:10,121 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:10,128 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:10,131 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,133 : INFO : built Dictionary(61 unique tokens: ['avail', 'bootload', 'devic', 'factori', 'flash']...) from 9 documents (total 78 corpus positions)\n",
      "2019-04-24 17:01:10,136 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:10,142 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,145 : INFO : built Dictionary(65 unique tokens: ['avail', 'come', 'desktop', 'facebook', 'make']...) from 12 documents (total 98 corpus positions)\n",
      "2019-04-24 17:01:10,157 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,160 : INFO : built Dictionary(277 unique tokens: ['bot', 'drink', 'eat', 'help', 'look']...) from 40 documents (total 418 corpus positions)\n",
      "2019-04-24 17:01:10,187 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,191 : INFO : built Dictionary(336 unique tokens: ['agrishow', 'café', 'da', 'durant', 'estavam']...) from 39 documents (total 589 corpus positions)\n",
      "2019-04-24 17:01:10,217 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,220 : INFO : built Dictionary(112 unique tokens: ['blog', 'jenkin', 'post', 'product', 'readi']...) from 18 documents (total 322 corpus positions)\n",
      "2019-04-24 17:01:10,232 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,235 : INFO : built Dictionary(235 unique tokens: ['acompanh', 'ajudam', 'américa', 'annual', 'award']...) from 18 documents (total 358 corpus positions)\n",
      "2019-04-24 17:01:10,246 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:10,248 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,251 : INFO : built Dictionary(53 unique tokens: ['canal', 'costa', 'equip', 'feito', 'foi']...) from 6 documents (total 58 corpus positions)\n",
      "2019-04-24 17:01:10,253 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:10,264 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,268 : INFO : built Dictionary(242 unique tokens: ['print', 'want', 'area', 'dprintler', 'engin']...) from 35 documents (total 439 corpus positions)\n",
      "2019-04-24 17:01:10,292 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,295 : INFO : built Dictionary(326 unique tokens: ['give', 'handbag', 'iphon', 'launch', 'outlin']...) from 63 documents (total 566 corpus positions)\n",
      "2019-04-24 17:01:10,324 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,326 : INFO : built Dictionary(129 unique tokens: ['abac', 'administradora', 'agência', 'ano', 'aquisiçõ']...) from 14 documents (total 202 corpus positions)\n",
      "2019-04-24 17:01:10,357 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,362 : INFO : built Dictionary(517 unique tokens: ['abc', 'madrid', 'museo', 'flickr', 'paul']...) from 108 documents (total 1428 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:10,458 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,460 : INFO : built Dictionary(439 unique tokens: ['brilho', 'com', 'empreendedor', 'inovar', 'no']...) from 41 documents (total 670 corpus positions)\n",
      "2019-04-24 17:01:10,484 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,487 : INFO : built Dictionary(157 unique tokens: ['android', 'best', 'blog', 'cofound', 'engadget']...) from 24 documents (total 255 corpus positions)\n",
      "2019-04-24 17:01:10,503 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,506 : INFO : built Dictionary(151 unique tokens: ['athlet', 'ben', 'clown', 'dreari', 'fright']...) from 14 documents (total 210 corpus positions)\n",
      "2019-04-24 17:01:10,518 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,522 : INFO : built Dictionary(153 unique tokens: ['convers', 'encapsul', 'friend', 'happen', 'perfectli']...) from 20 documents (total 222 corpus positions)\n",
      "2019-04-24 17:01:10,539 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,542 : INFO : built Dictionary(298 unique tokens: ['amo', 'baião', 'brasileiríssima', 'doi', 'paixão']...) from 29 documents (total 527 corpus positions)\n",
      "2019-04-24 17:01:10,557 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:10,560 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,562 : INFO : built Dictionary(56 unique tokens: ['ama', 'aprend', 'boteco', 'comidinha', 'dar']...) from 4 documents (total 63 corpus positions)\n",
      "2019-04-24 17:01:10,565 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:10,569 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:10,578 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,581 : INFO : built Dictionary(199 unique tokens: ['hopper', 'job', 'millenni', 'peopl', 'accord']...) from 37 documents (total 365 corpus positions)\n",
      "2019-04-24 17:01:10,599 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:10,602 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,604 : INFO : built Dictionary(26 unique tokens: ['book', 'busi', 'guidelin', 'hope', 'rememb']...) from 5 documents (total 35 corpus positions)\n",
      "2019-04-24 17:01:10,606 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:10,623 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,627 : INFO : built Dictionary(402 unique tokens: ['articl', 'buzzfe', 'compani', 'data', 'long']...) from 79 documents (total 769 corpus positions)\n",
      "2019-04-24 17:01:10,672 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,674 : INFO : built Dictionary(116 unique tokens: ['apach', 'databrick', 'futur', 'java', 'matei']...) from 18 documents (total 214 corpus positions)\n",
      "2019-04-24 17:01:10,685 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,689 : INFO : built Dictionary(113 unique tokens: ['ball', 'enterpris', 'excel', 'execut', 'format']...) from 18 documents (total 150 corpus positions)\n",
      "2019-04-24 17:01:10,703 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,707 : INFO : built Dictionary(255 unique tokens: ['agil', 'dead', 'eulog', 'time', 'claim']...) from 40 documents (total 434 corpus positions)\n",
      "2019-04-24 17:01:10,728 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,731 : INFO : built Dictionary(204 unique tokens: ['afastamento', 'ant', 'aproveit', 'ato', 'com']...) from 16 documents (total 287 corpus positions)\n",
      "2019-04-24 17:01:10,740 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:10,742 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,745 : INFO : built Dictionary(83 unique tokens: ['anunci', 'extra', 'funçõ', 'gboard', 'googl']...) from 6 documents (total 97 corpus positions)\n",
      "2019-04-24 17:01:10,748 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:10,756 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,759 : INFO : built Dictionary(175 unique tokens: ['algorithm', 'cloud', 'internet', 'thing', 'data']...) from 25 documents (total 287 corpus positions)\n",
      "2019-04-24 17:01:10,774 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,778 : INFO : built Dictionary(216 unique tokens: ['ano', 'aplicativo', 'atrá', 'daqui', 'dez']...) from 22 documents (total 333 corpus positions)\n",
      "2019-04-24 17:01:10,791 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,793 : INFO : built Dictionary(124 unique tokens: ['acquisit', 'close', 'dai', 'feedburn', 'googl']...) from 17 documents (total 214 corpus positions)\n",
      "2019-04-24 17:01:10,804 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,807 : INFO : built Dictionary(97 unique tokens: ['acquisit', 'close', 'dai', 'feedburn', 'goal']...) from 12 documents (total 167 corpus positions)\n",
      "2019-04-24 17:01:10,825 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,830 : INFO : built Dictionary(376 unique tokens: ['achiev', 'adopt', 'amazon', 'book', 'call']...) from 95 documents (total 742 corpus positions)\n",
      "2019-04-24 17:01:10,888 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,891 : INFO : built Dictionary(406 unique tokens: ['applic', 'blockchain', 'busi', 'excerpt', 'follow']...) from 70 documents (total 716 corpus positions)\n",
      "2019-04-24 17:01:10,939 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,942 : INFO : built Dictionary(231 unique tokens: ['announc', 'chang', 'com', 'github', 'paid']...) from 49 documents (total 470 corpus positions)\n",
      "2019-04-24 17:01:10,973 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:10,976 : INFO : built Dictionary(285 unique tokens: ['googl', 'human', 'intellig', 'languag', 'lot']...) from 46 documents (total 553 corpus positions)\n",
      "2019-04-24 17:01:11,014 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,018 : INFO : built Dictionary(379 unique tokens: ['ano', 'assim', 'claro', 'com', 'como']...) from 37 documents (total 741 corpus positions)\n",
      "2019-04-24 17:01:11,062 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,066 : INFO : built Dictionary(523 unique tokens: ['articl', 'attempt', 'bitcoin', 'blockchain', 'call']...) from 125 documents (total 1245 corpus positions)\n",
      "2019-04-24 17:01:11,151 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,154 : INFO : built Dictionary(162 unique tokens: ['administrativo', 'aprov', 'bandeira', 'cade', 'cartão']...) from 13 documents (total 226 corpus positions)\n",
      "2019-04-24 17:01:11,165 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,168 : INFO : built Dictionary(233 unique tokens: ['aggreg', 'analyz', 'big', 'cloud', 'comput']...) from 30 documents (total 379 corpus positions)\n",
      "2019-04-24 17:01:11,186 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,189 : INFO : built Dictionary(104 unique tokens: ['amazon', 'aw', 'believ', 'button', 'cloud']...) from 17 documents (total 174 corpus positions)\n",
      "2019-04-24 17:01:11,199 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:11,201 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,204 : INFO : built Dictionary(53 unique tokens: ['announc', 'devic', 'directli', 'function', 'googl']...) from 7 documents (total 71 corpus positions)\n",
      "2019-04-24 17:01:11,207 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:11,222 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,225 : INFO : built Dictionary(336 unique tokens: ['artifici', 'intellig', 'assist', 'car', 'dai']...) from 71 documents (total 639 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:11,269 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,273 : INFO : built Dictionary(249 unique tokens: ['creat', 'javascript', 'littl', 'origin', 'page']...) from 48 documents (total 511 corpus positions)\n",
      "2019-04-24 17:01:11,297 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,300 : INFO : built Dictionary(124 unique tokens: ['cheap', 'despit', 'digit', 'easier', 'inform']...) from 13 documents (total 158 corpus positions)\n",
      "2019-04-24 17:01:11,306 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:11,308 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,311 : INFO : built Dictionary(38 unique tokens: ['adob', 'audiência', 'conteúdo', 'curadoria', 'digit']...) from 3 documents (total 39 corpus positions)\n",
      "2019-04-24 17:01:11,314 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:11,316 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:11,318 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:11,324 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,327 : INFO : built Dictionary(142 unique tokens: ['announc', 'bring', 'built', 'channel', 'document']...) from 27 documents (total 251 corpus positions)\n",
      "2019-04-24 17:01:11,342 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:11,344 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,347 : INFO : built Dictionary(87 unique tokens: ['amigo', 'aplicativo', 'envio', 'forma', 'googl']...) from 7 documents (total 107 corpus positions)\n",
      "2019-04-24 17:01:11,350 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:11,356 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:11,358 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,361 : INFO : built Dictionary(80 unique tokens: ['além', 'brasil', 'chegada', 'descobrir', 'dia']...) from 9 documents (total 115 corpus positions)\n",
      "2019-04-24 17:01:11,363 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:11,370 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:11,372 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,375 : INFO : built Dictionary(102 unique tokens: ['apena', 'botão', 'brasil', 'com', 'conteúdo']...) from 9 documents (total 136 corpus positions)\n",
      "2019-04-24 17:01:11,378 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:11,389 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,393 : INFO : built Dictionary(231 unique tokens: ['busi', 'craft', 'gener', 'handbook', 'improv']...) from 28 documents (total 373 corpus positions)\n",
      "2019-04-24 17:01:11,424 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,428 : INFO : built Dictionary(430 unique tokens: ['convolut', 'dabbl', 'deep', 'introduct', 'learn']...) from 100 documents (total 1026 corpus positions)\n",
      "2019-04-24 17:01:11,499 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,503 : INFO : built Dictionary(382 unique tokens: ['arduino', 'eletrônico', 'ferramenta', 'hobbista', 'maker']...) from 30 documents (total 735 corpus positions)\n",
      "2019-04-24 17:01:11,524 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,526 : INFO : built Dictionary(122 unique tokens: ['calendar', 'differ', 'googl', 'iphon', 'kati']...) from 19 documents (total 210 corpus positions)\n",
      "2019-04-24 17:01:11,538 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,541 : INFO : built Dictionary(149 unique tokens: ['amazon', 'deep', 'entranc', 'learn', 'open']...) from 21 documents (total 223 corpus positions)\n",
      "2019-04-24 17:01:11,552 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:11,555 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,557 : INFO : built Dictionary(83 unique tokens: ['ask', 'bank', 'countri', 'digit', 'face']...) from 6 documents (total 107 corpus positions)\n",
      "2019-04-24 17:01:11,559 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:11,580 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,585 : INFO : built Dictionary(460 unique tokens: ['sure', 'movi', 'predat', 'heat', 'vision']...) from 161 documents (total 873 corpus positions)\n",
      "2019-04-24 17:01:11,667 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,669 : INFO : built Dictionary(126 unique tokens: ['artifici', 'fawn', 'great', 'intellig', 'languag']...) from 17 documents (total 177 corpus positions)\n",
      "2019-04-24 17:01:11,676 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:11,678 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,681 : INFO : built Dictionary(83 unique tokens: ['acionista', 'ccr', 'com', 'dbtran', 'demai']...) from 8 documents (total 102 corpus positions)\n",
      "2019-04-24 17:01:11,684 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:11,691 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:11,694 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,696 : INFO : built Dictionary(73 unique tokens: ['accord', 'android', 'consol', 'develop', 'googl']...) from 9 documents (total 110 corpus positions)\n",
      "2019-04-24 17:01:11,699 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:11,718 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,722 : INFO : built Dictionary(451 unique tokens: ['biggest', 'confer', 'expect', 'googl', 'time']...) from 85 documents (total 861 corpus positions)\n",
      "2019-04-24 17:01:11,785 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,789 : INFO : built Dictionary(354 unique tokens: ['attribut', 'consum', 'criteria', 'decis', 'focu']...) from 68 documents (total 676 corpus positions)\n",
      "2019-04-24 17:01:11,821 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,824 : INFO : built Dictionary(138 unique tokens: ['aplicativo', 'caro', 'desenvolvedor', 'meu', 'olá']...) from 16 documents (total 184 corpus positions)\n",
      "2019-04-24 17:01:11,847 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,852 : INFO : built Dictionary(405 unique tokens: ['alex', 'articl', 'brasetvik', 'elasticsearch', 'host']...) from 144 documents (total 1062 corpus positions)\n",
      "2019-04-24 17:01:11,960 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:11,963 : INFO : built Dictionary(263 unique tokens: ['continu', 'democrat', 'learn', 'machin', 'agenda']...) from 46 documents (total 491 corpus positions)\n",
      "2019-04-24 17:01:11,997 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,001 : INFO : built Dictionary(388 unique tokens: ['access', 'base', 'depend', 'give', 'googl']...) from 80 documents (total 733 corpus positions)\n",
      "2019-04-24 17:01:12,045 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,047 : INFO : built Dictionary(189 unique tokens: ['develop', 'googl', 'head', 'market', 'mike']...) from 26 documents (total 287 corpus positions)\n",
      "2019-04-24 17:01:12,064 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,067 : INFO : built Dictionary(285 unique tokens: ['bank', 'breed', 'digit', 'like', 'live']...) from 78 documents (total 579 corpus positions)\n",
      "2019-04-24 17:01:12,101 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,105 : INFO : built Dictionary(148 unique tokens: ['browser', 'extend', 'java', 'javapoli', 'javascript']...) from 19 documents (total 265 corpus positions)\n",
      "2019-04-24 17:01:12,116 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:12,119 : INFO : built Dictionary(134 unique tokens: ['ago', 'amit', 'bort', 'busi', 'cloud']...) from 19 documents (total 215 corpus positions)\n",
      "2019-04-24 17:01:12,128 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:12,131 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,133 : INFO : built Dictionary(110 unique tokens: ['boa', 'brasileiro', 'cloud', 'comput', 'contratação']...) from 8 documents (total 144 corpus positions)\n",
      "2019-04-24 17:01:12,136 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:12,144 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,147 : INFO : built Dictionary(161 unique tokens: ['amazon', 'assign', 'button', 'customiz', 'dash']...) from 17 documents (total 225 corpus positions)\n",
      "2019-04-24 17:01:12,157 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:12,159 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,161 : INFO : built Dictionary(65 unique tokens: ['check', 'confer', 'develop', 'event', 'googl']...) from 8 documents (total 81 corpus positions)\n",
      "2019-04-24 17:01:12,164 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:12,180 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,184 : INFO : built Dictionary(328 unique tokens: ['applic', 'base', 'count', 'gui', 'kloc']...) from 73 documents (total 646 corpus positions)\n",
      "2019-04-24 17:01:12,226 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,229 : INFO : built Dictionary(274 unique tokens: ['autoajuda', 'contrário', 'livro', 'não', 'poder']...) from 43 documents (total 411 corpus positions)\n",
      "2019-04-24 17:01:12,250 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,252 : INFO : built Dictionary(168 unique tokens: ['approv', 'babel', 'build', 'ecma', 'intern']...) from 19 documents (total 364 corpus positions)\n",
      "2019-04-24 17:01:12,266 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,269 : INFO : built Dictionary(207 unique tokens: ['automat', 'employe', 'equat', 'lai', 'percent']...) from 27 documents (total 292 corpus positions)\n",
      "2019-04-24 17:01:12,281 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:12,283 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,286 : INFO : built Dictionary(81 unique tokens: ['anunci', 'cabeça', 'captura', 'colaboração', 'com']...) from 7 documents (total 101 corpus positions)\n",
      "2019-04-24 17:01:12,288 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:12,293 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:12,296 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,298 : INFO : built Dictionary(29 unique tokens: ['app', 'basi', 'daili', 'great', 'import']...) from 4 documents (total 39 corpus positions)\n",
      "2019-04-24 17:01:12,300 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:12,304 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:12,310 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,314 : INFO : built Dictionary(265 unique tokens: ['alert', 'banco', 'basicament', 'custo', 'desafiada']...) from 37 documents (total 396 corpus positions)\n",
      "2019-04-24 17:01:12,331 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,334 : INFO : built Dictionary(87 unique tokens: ['abl', 'agenc', 'app', 'appl', 'ceo']...) from 10 documents (total 137 corpus positions)\n",
      "2019-04-24 17:01:12,342 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:12,344 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,348 : INFO : built Dictionary(107 unique tokens: ['app', 'boundari', 'brush', 'definit', 'googl']...) from 9 documents (total 138 corpus positions)\n",
      "2019-04-24 17:01:12,350 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:12,380 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,384 : INFO : built Dictionary(458 unique tokens: ['accur', 'crockford', 'describ', 'dougla', 'illustr']...) from 151 documents (total 1448 corpus positions)\n",
      "2019-04-24 17:01:12,520 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,523 : INFO : built Dictionary(424 unique tokens: ['científica', 'como', 'contato', 'ficção', 'história']...) from 54 documents (total 806 corpus positions)\n",
      "2019-04-24 17:01:12,564 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,568 : INFO : built Dictionary(517 unique tokens: ['bitcoin', 'blockchain', 'contabilidad', 'dado', 'entrada']...) from 43 documents (total 951 corpus positions)\n",
      "2019-04-24 17:01:12,624 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,629 : INFO : built Dictionary(567 unique tokens: ['author', 'averag', 'brain', 'director', 'educ']...) from 235 documents (total 1645 corpus positions)\n",
      "2019-04-24 17:01:12,817 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,819 : INFO : built Dictionary(182 unique tokens: ['life', 'live', 'sign', 'accolad', 'impress']...) from 26 documents (total 258 corpus positions)\n",
      "2019-04-24 17:01:12,835 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,839 : INFO : built Dictionary(302 unique tokens: ['futur', 'googl', 'android', 'balloon', 'biggest']...) from 84 documents (total 598 corpus positions)\n",
      "2019-04-24 17:01:12,898 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,902 : INFO : built Dictionary(649 unique tokens: ['agência', 'até', 'dificilment', 'distant', 'foram']...) from 83 documents (total 1325 corpus positions)\n",
      "2019-04-24 17:01:12,963 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,965 : INFO : built Dictionary(166 unique tokens: ['bitcoin', 'blockchain', 'call', 'compani', 'interest']...) from 41 documents (total 323 corpus positions)\n",
      "2019-04-24 17:01:12,994 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:12,998 : INFO : built Dictionary(271 unique tokens: ['analysi', 'area', 'big', 'data', 'far']...) from 36 documents (total 453 corpus positions)\n",
      "2019-04-24 17:01:13,027 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,030 : INFO : built Dictionary(249 unique tokens: ['anonym', 'app', 'face', 'founder', 'new']...) from 33 documents (total 392 corpus positions)\n",
      "2019-04-24 17:01:13,064 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,068 : INFO : built Dictionary(507 unique tokens: ['cool', 'make', 'uri', 'chang', 'sort']...) from 174 documents (total 1199 corpus positions)\n",
      "2019-04-24 17:01:13,186 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,189 : INFO : built Dictionary(389 unique tokens: ['april', 'braddi', 'cmo', 'eat', 'entrepreneur']...) from 77 documents (total 618 corpus positions)\n",
      "2019-04-24 17:01:13,221 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,224 : INFO : built Dictionary(238 unique tokens: ['advanc', 'android', 'artifici', 'chrome', 'confer']...) from 30 documents (total 422 corpus positions)\n",
      "2019-04-24 17:01:13,238 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,241 : INFO : built Dictionary(111 unique tokens: ['amazon', 'bigger', 'dsstne', 'leap', 'learn']...) from 12 documents (total 169 corpus positions)\n",
      "2019-04-24 17:01:13,250 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,252 : INFO : built Dictionary(116 unique tokens: ['anytim', 'appear', 'artifici', 'attornei', 'courtroom']...) from 13 documents (total 155 corpus positions)\n",
      "2019-04-24 17:01:13,284 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,289 : INFO : built Dictionary(763 unique tokens: ['address', 'better', 'competitor', 'consum', 'evolv']...) from 157 documents (total 1727 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:13,428 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,430 : INFO : built Dictionary(161 unique tokens: ['abil', 'aim', 'allow', 'art', 'bring']...) from 23 documents (total 259 corpus positions)\n",
      "2019-04-24 17:01:13,440 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:13,442 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,444 : INFO : built Dictionary(96 unique tokens: ['abolir', 'além', 'classificação', 'comemorado', 'considerar']...) from 8 documents (total 131 corpus positions)\n",
      "2019-04-24 17:01:13,446 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:13,460 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,463 : INFO : built Dictionary(293 unique tokens: ['assist', 'cours', 'dai', 'dash', 'eric']...) from 49 documents (total 483 corpus positions)\n",
      "2019-04-24 17:01:13,493 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,496 : INFO : built Dictionary(193 unique tokens: ['agil', 'approach', 'book', 'cours', 'estim']...) from 54 documents (total 471 corpus positions)\n",
      "2019-04-24 17:01:13,532 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,536 : INFO : built Dictionary(392 unique tokens: ['believ', 'have', 'oper', 'respons', 'spotifi']...) from 78 documents (total 816 corpus positions)\n",
      "2019-04-24 17:01:13,582 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,585 : INFO : built Dictionary(107 unique tokens: ['barra', 'celebr', 'corner', 'giddi', 'googlei']...) from 14 documents (total 137 corpus positions)\n",
      "2019-04-24 17:01:13,605 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,609 : INFO : built Dictionary(439 unique tokens: ['abil', 'agil', 'big', 'challeng', 'chang']...) from 110 documents (total 843 corpus positions)\n",
      "2019-04-24 17:01:13,669 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,671 : INFO : built Dictionary(167 unique tokens: ['alpha', 'chamado', 'cloud', 'function', 'googl']...) from 12 documents (total 263 corpus positions)\n",
      "2019-04-24 17:01:13,691 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,696 : INFO : built Dictionary(360 unique tokens: ['america', 'battl', 'captain', 'civil', 'iron']...) from 79 documents (total 675 corpus positions)\n",
      "2019-04-24 17:01:13,735 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,738 : INFO : built Dictionary(144 unique tokens: ['bulk', 'hen', 'japanes', 'learn', 'make']...) from 31 documents (total 215 corpus positions)\n",
      "2019-04-24 17:01:13,750 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,752 : INFO : built Dictionary(112 unique tokens: ['automática', 'convergência', 'conversa', 'diferent', 'falam']...) from 11 documents (total 147 corpus positions)\n",
      "2019-04-24 17:01:13,762 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,764 : INFO : built Dictionary(105 unique tokens: ['allow', 'android', 'api', 'contentprovid', 'join']...) from 19 documents (total 212 corpus positions)\n",
      "2019-04-24 17:01:13,776 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,779 : INFO : built Dictionary(192 unique tokens: ['ambient', 'autor', 'complex', 'complexidad', 'conceito']...) from 22 documents (total 341 corpus positions)\n",
      "2019-04-24 17:01:13,794 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,797 : INFO : built Dictionary(218 unique tokens: ['afraid', 'ag', 'brain', 'differ', 'publish']...) from 45 documents (total 267 corpus positions)\n",
      "2019-04-24 17:01:13,809 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,812 : INFO : built Dictionary(62 unique tokens: ['announc', 'awai', 'expect', 'googl', 'hour']...) from 10 documents (total 80 corpus positions)\n",
      "2019-04-24 17:01:13,817 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:13,819 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,822 : INFO : built Dictionary(26 unique tokens: ['advanc', 'beauti', 'bring', 'compani', 'digit']...) from 2 documents (total 30 corpus positions)\n",
      "2019-04-24 17:01:13,824 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:13,827 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:13,829 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:13,839 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,842 : INFO : built Dictionary(257 unique tokens: ['amphitheatr', 'celebr', 'develop', 'earlier', 'event']...) from 37 documents (total 545 corpus positions)\n",
      "2019-04-24 17:01:13,867 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,870 : INFO : built Dictionary(277 unique tokens: ['andamento', 'apó', 'bem', 'coach', 'concluída']...) from 39 documents (total 457 corpus positions)\n",
      "2019-04-24 17:01:13,896 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,900 : INFO : built Dictionary(282 unique tokens: ['android', 'app', 'billion', 'built', 'burk']...) from 41 documents (total 599 corpus positions)\n",
      "2019-04-24 17:01:13,924 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,927 : INFO : built Dictionary(149 unique tokens: ['approach', 'core', 'demand', 'interact', 'open']...) from 25 documents (total 229 corpus positions)\n",
      "2019-04-24 17:01:13,940 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,943 : INFO : built Dictionary(113 unique tokens: ['app', 'datacent', 'devic', 'googl', 'host']...) from 27 documents (total 305 corpus positions)\n",
      "2019-04-24 17:01:13,958 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,961 : INFO : built Dictionary(146 unique tokens: ['acab', 'anunciar', 'aplicativo', 'com', 'como']...) from 17 documents (total 227 corpus positions)\n",
      "2019-04-24 17:01:13,988 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:13,993 : INFO : built Dictionary(435 unique tokens: ['metric', 'mayb', 'biggest', 'check', 'encourag']...) from 187 documents (total 1058 corpus positions)\n",
      "2019-04-24 17:01:14,107 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,109 : INFO : built Dictionary(200 unique tokens: ['acontec', 'android', 'anunci', 'desta', 'gent']...) from 16 documents (total 294 corpus positions)\n",
      "2019-04-24 17:01:14,117 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,119 : INFO : built Dictionary(105 unique tokens: ['android', 'aplicativo', 'chamada', 'conexõ', 'desenvolvido']...) from 10 documents (total 137 corpus positions)\n",
      "2019-04-24 17:01:14,128 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,131 : INFO : built Dictionary(149 unique tokens: ['app', 'blog', 'cross', 'develop', 'googl']...) from 25 documents (total 308 corpus positions)\n",
      "2019-04-24 17:01:14,144 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:14,146 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,149 : INFO : built Dictionary(86 unique tokens: ['connect', 'internet', 'know', 'phone', 'spotti']...) from 8 documents (total 130 corpus positions)\n",
      "2019-04-24 17:01:14,151 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:14,158 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,162 : INFO : built Dictionary(101 unique tokens: ['chart', 'compel', 'data', 'displai', 'help']...) from 12 documents (total 166 corpus positions)\n",
      "2019-04-24 17:01:14,174 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,178 : INFO : built Dictionary(147 unique tokens: ['applic', 'googl', 'learn', 'love', 'machin']...) from 16 documents (total 215 corpus positions)\n",
      "2019-04-24 17:01:14,202 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:14,206 : INFO : built Dictionary(403 unique tokens: ['appropri', 'feedback', 'go', 'heurist', 'inform']...) from 89 documents (total 751 corpus positions)\n",
      "2019-04-24 17:01:14,253 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,257 : INFO : built Dictionary(185 unique tokens: ['babi', 'best', 'celebr', 'discov', 'famili']...) from 33 documents (total 328 corpus positions)\n",
      "2019-04-24 17:01:14,276 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,280 : INFO : built Dictionary(344 unique tokens: ['apoio', 'brasil', 'cada', 'corporaçõ', 'dirigido']...) from 33 documents (total 630 corpus positions)\n",
      "2019-04-24 17:01:14,302 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,305 : INFO : built Dictionary(118 unique tokens: ['confer', 'cool', 'demo', 'drink', 'food']...) from 13 documents (total 147 corpus positions)\n",
      "2019-04-24 17:01:14,318 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,322 : INFO : built Dictionary(231 unique tokens: ['core', 'data', 'framework', 'power', 'simpl']...) from 51 documents (total 499 corpus positions)\n",
      "2019-04-24 17:01:14,351 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,355 : INFO : built Dictionary(278 unique tokens: ['build', 'continu', 'delight', 'googl', 'learn']...) from 52 documents (total 598 corpus positions)\n",
      "2019-04-24 17:01:14,383 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,385 : INFO : built Dictionary(150 unique tokens: ['afp', 'agrícola', 'alemão', 'americana', 'apresenta']...) from 16 documents (total 198 corpus positions)\n",
      "2019-04-24 17:01:14,396 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,399 : INFO : built Dictionary(179 unique tokens: ['assembl', 'directli', 'harder', 'languag', 'real']...) from 35 documents (total 271 corpus positions)\n",
      "2019-04-24 17:01:14,427 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,432 : INFO : built Dictionary(476 unique tokens: ['airberlin', 'airlin', 'app', 'delight', 'develop']...) from 86 documents (total 1056 corpus positions)\n",
      "2019-04-24 17:01:14,485 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:14,488 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,491 : INFO : built Dictionary(43 unique tokens: ['allo', 'app', 'compar', 'hand', 'line']...) from 6 documents (total 51 corpus positions)\n",
      "2019-04-24 17:01:14,495 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:14,502 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,506 : INFO : built Dictionary(62 unique tokens: ['mobil', 'screen', 'todai', 'content', 'design']...) from 16 documents (total 76 corpus positions)\n",
      "2019-04-24 17:01:14,514 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,516 : INFO : built Dictionary(98 unique tokens: ['accord', 'analyt', 'april', 'boost', 'browser']...) from 13 documents (total 169 corpus positions)\n",
      "2019-04-24 17:01:14,524 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:14,526 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,529 : INFO : built Dictionary(108 unique tokens: ['ambient', 'anunci', 'aplicaçõ', 'com', 'conferência']...) from 8 documents (total 140 corpus positions)\n",
      "2019-04-24 17:01:14,531 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:14,540 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,542 : INFO : built Dictionary(200 unique tokens: ['ainda', 'apó', 'compartilh', 'explorar', 'exterior']...) from 17 documents (total 284 corpus positions)\n",
      "2019-04-24 17:01:14,557 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,560 : INFO : built Dictionary(318 unique tokens: ['alissa', 'autônomo', 'bastant', 'capacidad', 'carro']...) from 31 documents (total 553 corpus positions)\n",
      "2019-04-24 17:01:14,584 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,590 : INFO : built Dictionary(229 unique tokens: ['begin', 'chrome', 'end', 'final', 'flash']...) from 40 documents (total 470 corpus positions)\n",
      "2019-04-24 17:01:14,613 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,616 : INFO : built Dictionary(146 unique tokens: ['analysi', 'clean', 'consecut', 'dai', 'data']...) from 14 documents (total 245 corpus positions)\n",
      "2019-04-24 17:01:14,639 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,643 : INFO : built Dictionary(617 unique tokens: ['anual', 'cacetada', 'desenvolvedor', 'esperado', 'evento']...) from 72 documents (total 1182 corpus positions)\n",
      "2019-04-24 17:01:14,710 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,713 : INFO : built Dictionary(337 unique tokens: ['acontecendo', 'américa', 'até', 'bett', 'brasil']...) from 34 documents (total 624 corpus positions)\n",
      "2019-04-24 17:01:14,730 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:14,733 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,735 : INFO : built Dictionary(36 unique tokens: ['ano', 'apesar', 'clareza', 'cobrança', 'consumidor']...) from 2 documents (total 37 corpus positions)\n",
      "2019-04-24 17:01:14,737 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:14,739 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:14,742 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:14,745 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:14,747 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,750 : INFO : built Dictionary(36 unique tokens: ['ano', 'apesar', 'clareza', 'cobrança', 'consumidor']...) from 2 documents (total 37 corpus positions)\n",
      "2019-04-24 17:01:14,752 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:14,754 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:14,756 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:14,770 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,775 : INFO : built Dictionary(400 unique tokens: ['daquel', 'ideia', 'muita', 'negócio', 'que']...) from 77 documents (total 859 corpus positions)\n",
      "2019-04-24 17:01:14,833 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,836 : INFO : built Dictionary(145 unique tokens: ['assert', 'confid', 'know', 'want', 'aggress']...) from 48 documents (total 293 corpus positions)\n",
      "2019-04-24 17:01:14,857 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:14,859 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,863 : INFO : built Dictionary(92 unique tokens: ['abuso', 'academia', 'alerta', 'anglicismo', 'camapaña']...) from 8 documents (total 127 corpus positions)\n",
      "2019-04-24 17:01:14,866 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:14,872 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:14,875 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,879 : INFO : built Dictionary(68 unique tokens: ['app', 'athlet', 'better', 'brand', 'commun']...) from 6 documents (total 86 corpus positions)\n",
      "2019-04-24 17:01:14,881 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:14,901 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,905 : INFO : built Dictionary(533 unique tokens: ['aumentar', 'conheça', 'dia', 'digitai', 'empresa']...) from 58 documents (total 939 corpus positions)\n",
      "2019-04-24 17:01:14,956 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:14,959 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:14,962 : INFO : built Dictionary(66 unique tokens: ['william', 'acaba', 'coletar', 'como', 'criou']...) from 7 documents (total 78 corpus positions)\n",
      "2019-04-24 17:01:14,964 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:14,972 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:14,978 : INFO : built Dictionary(114 unique tokens: ['advanc', 'announc', 'atap', 'confer', 'googl']...) from 13 documents (total 171 corpus positions)\n",
      "2019-04-24 17:01:14,998 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,003 : INFO : built Dictionary(139 unique tokens: ['appear', 'daili', 'data', 'essai', 'fortun']...) from 22 documents (total 198 corpus positions)\n",
      "2019-04-24 17:01:15,017 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:15,020 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,023 : INFO : built Dictionary(105 unique tokens: ['anunci', 'apó', 'ara', 'breve', 'conferência']...) from 8 documents (total 126 corpus positions)\n",
      "2019-04-24 17:01:15,025 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:15,033 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,036 : INFO : built Dictionary(88 unique tokens: ['googl', 'incred', 'matt', 'pictur', 'pretti']...) from 13 documents (total 124 corpus positions)\n",
      "2019-04-24 17:01:15,043 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:15,046 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,049 : INFO : built Dictionary(98 unique tokens: ['android', 'anunci', 'aplicativo', 'disponibilidad', 'googl']...) from 9 documents (total 125 corpus positions)\n",
      "2019-04-24 17:01:15,052 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:15,059 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:15,063 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,065 : INFO : built Dictionary(82 unique tokens: ['boca', 'canal', 'caseiro', 'com', 'deliciosa']...) from 7 documents (total 106 corpus positions)\n",
      "2019-04-24 17:01:15,068 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:15,079 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,084 : INFO : built Dictionary(234 unique tokens: ['autonom', 'biggest', 'call', 'crowdfund', 'dao']...) from 40 documents (total 391 corpus positions)\n",
      "2019-04-24 17:01:15,105 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,107 : INFO : built Dictionary(122 unique tokens: ['avança', 'carro', 'condutor', 'frota', 'implantação']...) from 10 documents (total 169 corpus positions)\n",
      "2019-04-24 17:01:15,120 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,124 : INFO : built Dictionary(336 unique tokens: ['complexo', 'desenvolv', 'softwar', 'ainda', 'alta']...) from 32 documents (total 532 corpus positions)\n",
      "2019-04-24 17:01:15,144 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,147 : INFO : built Dictionary(186 unique tokens: ['discuss', 'efficaci', 'late', 'lot', 'surround']...) from 42 documents (total 338 corpus positions)\n",
      "2019-04-24 17:01:15,165 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,168 : INFO : built Dictionary(124 unique tokens: ['aeronáutica', 'coursera', 'curso', 'ensino', 'está']...) from 20 documents (total 164 corpus positions)\n",
      "2019-04-24 17:01:15,179 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,181 : INFO : built Dictionary(90 unique tokens: ['app', 'backend', 'build', 'commun', 'develop']...) from 12 documents (total 140 corpus positions)\n",
      "2019-04-24 17:01:15,197 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,201 : INFO : built Dictionary(313 unique tokens: ['api', 'applic', 'area', 'connect', 'critic']...) from 44 documents (total 567 corpus positions)\n",
      "2019-04-24 17:01:15,229 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,232 : INFO : built Dictionary(267 unique tokens: ['dica', 'executivo', 'foto', 'revista', 'selecion']...) from 24 documents (total 391 corpus positions)\n",
      "2019-04-24 17:01:15,247 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:15,249 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,252 : INFO : built Dictionary(145 unique tokens: ['app', 'base', 'commun', 'develop', 'free']...) from 8 documents (total 331 corpus positions)\n",
      "2019-04-24 17:01:15,255 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:15,266 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,270 : INFO : built Dictionary(200 unique tokens: ['busi', 'commun', 'compani', 'custom', 'email']...) from 42 documents (total 323 corpus positions)\n",
      "2019-04-24 17:01:15,455 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:15,458 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,462 : INFO : built Dictionary(60 unique tokens: ['channel', 'chore', 'conveni', 'creat', 'dai']...) from 9 documents (total 95 corpus positions)\n",
      "2019-04-24 17:01:15,464 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:15,479 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,483 : INFO : built Dictionary(414 unique tokens: ['algo', 'atingir', 'busca', 'empreendedor', 'empresa']...) from 43 documents (total 733 corpus positions)\n",
      "2019-04-24 17:01:15,511 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,514 : INFO : built Dictionary(124 unique tokens: ['app', 'mobil', 'popular', 'whatsapp', 'world']...) from 23 documents (total 195 corpus positions)\n",
      "2019-04-24 17:01:15,526 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,528 : INFO : built Dictionary(171 unique tokens: ['começa', 'céu', 'deix', 'esa', 'mart']...) from 18 documents (total 249 corpus positions)\n",
      "2019-04-24 17:01:15,575 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,581 : INFO : built Dictionary(986 unique tokens: ['android', 'appear', 'attain', 'attent', 'consum']...) from 163 documents (total 2505 corpus positions)\n",
      "2019-04-24 17:01:15,759 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,762 : INFO : built Dictionary(140 unique tokens: ['ad', 'advertis', 'anthoni', 'block', 'commerc']...) from 22 documents (total 216 corpus positions)\n",
      "2019-04-24 17:01:15,856 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:15,868 : INFO : built Dictionary(1906 unique tokens: ['consult', 'design', 'digit', 'emerg', 'explor']...) from 703 documents (total 6462 corpus positions)\n",
      "2019-04-24 17:01:17,998 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,001 : INFO : built Dictionary(315 unique tokens: ['bruno', 'champanh', 'guiçardi', 'pote', 'ritual']...) from 37 documents (total 468 corpus positions)\n",
      "2019-04-24 17:01:18,031 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,035 : INFO : built Dictionary(538 unique tokens: ['amigo', 'brasileiro', 'doi', 'fizeram', 'mercado']...) from 64 documents (total 909 corpus positions)\n",
      "2019-04-24 17:01:18,074 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,077 : INFO : built Dictionary(100 unique tokens: ['art', 'artifici', 'dream', 'googl', 'intellig']...) from 13 documents (total 156 corpus positions)\n",
      "2019-04-24 17:01:18,086 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,089 : INFO : built Dictionary(172 unique tokens: ['anuidad', 'aplicativo', 'atravé', 'brasileira', 'cartão']...) from 19 documents (total 233 corpus positions)\n",
      "2019-04-24 17:01:18,112 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:18,116 : INFO : built Dictionary(395 unique tokens: ['francisco', 'held', 'june', 'san', 'spark']...) from 82 documents (total 1111 corpus positions)\n",
      "2019-04-24 17:01:18,185 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,189 : INFO : built Dictionary(290 unique tokens: ['fla', 'orlando', 'build', 'creat', 'digit']...) from 50 documents (total 607 corpus positions)\n",
      "2019-04-24 17:01:18,216 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,218 : INFO : built Dictionary(111 unique tokens: ['add', 'allow', 'automat', 'browser', 'certain']...) from 18 documents (total 201 corpus positions)\n",
      "2019-04-24 17:01:18,229 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:18,231 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,235 : INFO : built Dictionary(101 unique tokens: ['absinth', 'annual', 'atlassian', 'bar', 'confer']...) from 9 documents (total 153 corpus positions)\n",
      "2019-04-24 17:01:18,237 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:18,249 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,252 : INFO : built Dictionary(237 unique tokens: ['accomplish', 'barrier', 'connect', 'facebook', 'languag']...) from 35 documents (total 401 corpus positions)\n",
      "2019-04-24 17:01:18,274 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,279 : INFO : built Dictionary(196 unique tokens: ['chang', 'faster', 'industri', 'innov', 'pick']...) from 36 documents (total 320 corpus positions)\n",
      "2019-04-24 17:01:18,301 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,305 : INFO : built Dictionary(165 unique tokens: ['aim', 'creat', 'databas', 'develop', 'easili']...) from 30 documents (total 367 corpus positions)\n",
      "2019-04-24 17:01:18,323 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,326 : INFO : built Dictionary(201 unique tokens: ['app', 'crowd', 'disappear', 'ephemer', 'messag']...) from 30 documents (total 334 corpus positions)\n",
      "2019-04-24 17:01:18,348 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,351 : INFO : built Dictionary(238 unique tokens: ['aim', 'differ', 'intro', 'layer', 'observ']...) from 62 documents (total 539 corpus positions)\n",
      "2019-04-24 17:01:18,382 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,385 : INFO : built Dictionary(133 unique tokens: ['acfr', 'ano', 'australian', 'centr', 'fazenda']...) from 12 documents (total 179 corpus positions)\n",
      "2019-04-24 17:01:18,392 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:18,394 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,397 : INFO : built Dictionary(68 unique tokens: ['alemanha', 'beethoven', 'centena', 'cidad', 'céu']...) from 5 documents (total 82 corpus positions)\n",
      "2019-04-24 17:01:18,400 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:18,408 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,411 : INFO : built Dictionary(198 unique tokens: ['air', 'appl', 'arment', 'artifici', 'blackberri']...) from 26 documents (total 281 corpus positions)\n",
      "2019-04-24 17:01:18,424 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:18,426 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,428 : INFO : built Dictionary(79 unique tokens: ['comfort', 'desk', 'fun', 'kubernet', 'leav']...) from 8 documents (total 98 corpus positions)\n",
      "2019-04-24 17:01:18,431 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:18,448 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,452 : INFO : built Dictionary(375 unique tokens: ['action', 'author', 'compani', 'distinguish', 'fast']...) from 64 documents (total 767 corpus positions)\n",
      "2019-04-24 17:01:18,493 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,496 : INFO : built Dictionary(181 unique tokens: ['acquisit', 'align', 'approach', 'base', 'build']...) from 22 documents (total 301 corpus positions)\n",
      "2019-04-24 17:01:18,509 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,511 : INFO : built Dictionary(113 unique tokens: ['audio', 'avail', 'collect', 'contemporari', 'dataset']...) from 18 documents (total 174 corpus positions)\n",
      "2019-04-24 17:01:18,520 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:18,522 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,524 : INFO : built Dictionary(76 unique tokens: ['apena', 'budget', 'com', 'dia', 'diária']...) from 5 documents (total 96 corpus positions)\n",
      "2019-04-24 17:01:18,526 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:18,537 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,541 : INFO : built Dictionary(281 unique tokens: ['balmi', 'bui', 'drink', 'entrepreneur', 'janeiro']...) from 32 documents (total 393 corpus positions)\n",
      "2019-04-24 17:01:18,555 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:18,557 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,559 : INFO : built Dictionary(99 unique tokens: ['abacu', 'agora', 'ano', 'até', 'como']...) from 8 documents (total 114 corpus positions)\n",
      "2019-04-24 17:01:18,562 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:18,579 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,584 : INFO : built Dictionary(336 unique tokens: ['api', 'boot', 'core', 'product', 'rest']...) from 64 documents (total 832 corpus positions)\n",
      "2019-04-24 17:01:18,650 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,656 : INFO : built Dictionary(899 unique tokens: ['act', 'crucial', 'cycl', 'disrupt', 'incumb']...) from 159 documents (total 1822 corpus positions)\n",
      "2019-04-24 17:01:18,792 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,795 : INFO : built Dictionary(376 unique tokens: ['beset', 'book', 'busi', 'column', 'economi']...) from 37 documents (total 547 corpus positions)\n",
      "2019-04-24 17:01:18,813 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,816 : INFO : built Dictionary(265 unique tokens: ['aproximando', 'brasil', 'dia', 'edição', 'está']...) from 26 documents (total 446 corpus positions)\n",
      "2019-04-24 17:01:18,831 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,833 : INFO : built Dictionary(93 unique tokens: ['atmospher', 'bulb', 'cent', 'effici', 'energi']...) from 10 documents (total 133 corpus positions)\n",
      "2019-04-24 17:01:18,847 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,850 : INFO : built Dictionary(318 unique tokens: ['announc', 'comput', 'distribut', 'heron', 'introduct']...) from 46 documents (total 550 corpus positions)\n",
      "2019-04-24 17:01:18,879 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,882 : INFO : built Dictionary(187 unique tokens: ['architectur', 'big', 'bring', 'context', 'forc']...) from 32 documents (total 347 corpus positions)\n",
      "2019-04-24 17:01:18,897 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,900 : INFO : built Dictionary(140 unique tokens: ['artifici', 'ceo', 'compani', 'cool', 'event']...) from 18 documents (total 226 corpus positions)\n",
      "2019-04-24 17:01:18,912 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,915 : INFO : built Dictionary(258 unique tokens: ['digit', 'dua', 'impresso', 'integrar', 'market']...) from 29 documents (total 491 corpus positions)\n",
      "2019-04-24 17:01:18,944 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:18,949 : INFO : built Dictionary(629 unique tokens: ['ana', 'casal', 'clau', 'como', 'edição']...) from 112 documents (total 1182 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:19,045 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,048 : INFO : built Dictionary(272 unique tokens: ['artifici', 'awash', 'intellig', 'talk', 'tech']...) from 49 documents (total 467 corpus positions)\n",
      "2019-04-24 17:01:19,079 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,083 : INFO : built Dictionary(406 unique tokens: ['agora', 'aposta', 'apresent', 'capit', 'comerci']...) from 50 documents (total 729 corpus positions)\n",
      "2019-04-24 17:01:19,120 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,124 : INFO : built Dictionary(258 unique tokens: ['airport', 'cap', 'fall', 'govern', 'hourli']...) from 53 documents (total 488 corpus positions)\n",
      "2019-04-24 17:01:19,153 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,157 : INFO : built Dictionary(208 unique tokens: ['attent', 'bigger', 'ecommerc', 'gener', 'get']...) from 34 documents (total 392 corpus positions)\n",
      "2019-04-24 17:01:19,172 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:19,175 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,177 : INFO : built Dictionary(64 unique tokens: ['android', 'api', 'breath', 'develop', 'fair']...) from 7 documents (total 79 corpus positions)\n",
      "2019-04-24 17:01:19,180 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:19,195 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,199 : INFO : built Dictionary(335 unique tokens: ['consum', 'custom', 'especi', 'experi', 'industri']...) from 47 documents (total 591 corpus positions)\n",
      "2019-04-24 17:01:19,224 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,227 : INFO : built Dictionary(167 unique tokens: ['ago', 'come', 'engin', 'googl', 'moment']...) from 22 documents (total 226 corpus positions)\n",
      "2019-04-24 17:01:19,239 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,241 : INFO : built Dictionary(105 unique tokens: ['googl', 'oracl', 'won', 'android', 'billion']...) from 11 documents (total 148 corpus positions)\n",
      "2019-04-24 17:01:19,250 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,253 : INFO : built Dictionary(88 unique tokens: ['check', 'compar', 'data', 'game', 'improv']...) from 11 documents (total 141 corpus positions)\n",
      "2019-04-24 17:01:19,262 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,265 : INFO : built Dictionary(94 unique tokens: ['android', 'app', 'compani', 'flagship', 'io']...) from 10 documents (total 147 corpus positions)\n",
      "2019-04-24 17:01:19,279 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,283 : INFO : built Dictionary(274 unique tokens: ['late', 'slack', 'talk', 'aim', 'app']...) from 52 documents (total 499 corpus positions)\n",
      "2019-04-24 17:01:19,313 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,316 : INFO : built Dictionary(242 unique tokens: ['airbnb', 'autom', 'billion', 'build', 'compani']...) from 43 documents (total 446 corpus positions)\n",
      "2019-04-24 17:01:19,335 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:19,337 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,340 : INFO : built Dictionary(110 unique tokens: ['burger', 'eua', 'facebook', 'king', 'messeng']...) from 9 documents (total 127 corpus positions)\n",
      "2019-04-24 17:01:19,342 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:19,353 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,356 : INFO : built Dictionary(276 unique tokens: ['comunidad', 'dependendo', 'está', 'indústria', 'mai']...) from 25 documents (total 434 corpus positions)\n",
      "2019-04-24 17:01:19,375 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,379 : INFO : built Dictionary(256 unique tokens: ['ashlei', 'facebook', 'foto', 'grand', 'mauric']...) from 39 documents (total 400 corpus positions)\n",
      "2019-04-24 17:01:19,411 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,415 : INFO : built Dictionary(487 unique tokens: ['articl', 'design', 'languag', 'new', 'seri']...) from 112 documents (total 1000 corpus positions)\n",
      "2019-04-24 17:01:19,491 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,493 : INFO : built Dictionary(136 unique tokens: ['acquir', 'better', 'car', 'develop', 'drive']...) from 13 documents (total 202 corpus positions)\n",
      "2019-04-24 17:01:19,507 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,510 : INFO : built Dictionary(328 unique tokens: ['air', 'angel', 'broke', 'cover', 'dai']...) from 33 documents (total 441 corpus positions)\n",
      "2019-04-24 17:01:19,533 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,538 : INFO : built Dictionary(287 unique tokens: ['android', 'big', 'common', 'design', 'develop']...) from 62 documents (total 648 corpus positions)\n",
      "2019-04-24 17:01:19,583 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,585 : INFO : built Dictionary(185 unique tokens: ['appcach', 'ask', 'folk', 'good', 'invent']...) from 28 documents (total 297 corpus positions)\n",
      "2019-04-24 17:01:19,608 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,612 : INFO : built Dictionary(543 unique tokens: ['abstinência', 'acompanha', 'americano', 'canal', 'está']...) from 82 documents (total 1141 corpus positions)\n",
      "2019-04-24 17:01:19,672 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:19,674 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,676 : INFO : built Dictionary(43 unique tokens: ['chatbot', 'daniel', 'detail', 'kurzweil', 'lot']...) from 5 documents (total 46 corpus positions)\n",
      "2019-04-24 17:01:19,678 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:19,689 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,692 : INFO : built Dictionary(244 unique tokens: ['appl', 'big', 'siri', 'upgrad', 'youtub']...) from 51 documents (total 459 corpus positions)\n",
      "2019-04-24 17:01:19,719 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,722 : INFO : built Dictionary(173 unique tokens: ['accept', 'err', 'human', 'machin', 'advic']...) from 25 documents (total 250 corpus positions)\n",
      "2019-04-24 17:01:19,733 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,737 : INFO : built Dictionary(139 unique tokens: ['choos', 'countless', 'number', 'realiti', 'augment']...) from 14 documents (total 193 corpus positions)\n",
      "2019-04-24 17:01:19,751 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,754 : INFO : built Dictionary(249 unique tokens: ['abl', 'apolog', 'sexist', 'shit', 'shut']...) from 53 documents (total 385 corpus positions)\n",
      "2019-04-24 17:01:19,778 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,781 : INFO : built Dictionary(273 unique tokens: ['adventur', 'cautiou', 'kind', 'linux', 'user']...) from 47 documents (total 444 corpus positions)\n",
      "2019-04-24 17:01:19,800 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:19,802 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,804 : INFO : built Dictionary(60 unique tokens: ['ago', 'cultur', 'debut', 'decad', 'email']...) from 8 documents (total 76 corpus positions)\n",
      "2019-04-24 17:01:19,807 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:19,822 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,826 : INFO : built Dictionary(384 unique tokens: ['agil', 'concretização', 'devop', 'metodologia', 'ambient']...) from 48 documents (total 754 corpus positions)\n",
      "2019-04-24 17:01:19,855 : WARNING : Input text is expected to have at least 10 sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:19,857 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,860 : INFO : built Dictionary(24 unique tokens: ['assort', 'car', 'driverless', 'final', 'gather']...) from 3 documents (total 24 corpus positions)\n",
      "2019-04-24 17:01:19,862 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:19,865 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:19,878 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,883 : INFO : built Dictionary(335 unique tokens: ['bebop', 'bought', 'fall', 'googl', 'got']...) from 65 documents (total 656 corpus positions)\n",
      "2019-04-24 17:01:19,920 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:19,922 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,925 : INFO : built Dictionary(57 unique tokens: ['aproxima', 'behanc', 'criativo', 'evento', 'fora']...) from 4 documents (total 63 corpus positions)\n",
      "2019-04-24 17:01:19,927 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:19,931 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:19,935 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,938 : INFO : built Dictionary(107 unique tokens: ['anunciar', 'busi', 'cognit', 'comerciai', 'como']...) from 10 documents (total 144 corpus positions)\n",
      "2019-04-24 17:01:19,951 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:19,955 : INFO : built Dictionary(209 unique tokens: ['combin', 'contact', 'demand', 'diabet', 'dispens']...) from 29 documents (total 350 corpus positions)\n",
      "2019-04-24 17:01:20,006 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:20,012 : INFO : built Dictionary(841 unique tokens: ['april', 'gave', 'human', 'minut', 'note']...) from 280 documents (total 2286 corpus positions)\n",
      "2019-04-24 17:01:20,310 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:20,313 : INFO : built Dictionary(380 unique tokens: ['amplitud', 'central', 'data', 'datamonst', 'expert']...) from 70 documents (total 828 corpus positions)\n",
      "2019-04-24 17:01:20,361 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:20,365 : INFO : built Dictionary(254 unique tokens: ['investor', 'rais', 'silicon', 'vallei', 'custom']...) from 71 documents (total 580 corpus positions)\n",
      "2019-04-24 17:01:20,401 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:20,404 : INFO : built Dictionary(204 unique tokens: ['dai', 'earnestli', 'goal', 'meet', 'set']...) from 51 documents (total 313 corpus positions)\n",
      "2019-04-24 17:01:20,446 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:20,451 : INFO : built Dictionary(717 unique tokens: ['compani', 'end', 'evalu', 'happen', 'jettison']...) from 145 documents (total 1658 corpus positions)\n",
      "2019-04-24 17:01:20,607 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:20,610 : INFO : built Dictionary(615 unique tokens: ['academi', 'corpor', 'digit', 'gener', 'mean']...) from 86 documents (total 1193 corpus positions)\n",
      "2019-04-24 17:01:20,668 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:20,670 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:20,673 : INFO : built Dictionary(55 unique tokens: ['acontec', 'além', 'ant', 'brasil', 'dia']...) from 6 documents (total 64 corpus positions)\n",
      "2019-04-24 17:01:20,675 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:20,686 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:20,689 : INFO : built Dictionary(352 unique tokens: ['estratégia', 'falar', 'faz', 'kpi', 'muito']...) from 50 documents (total 661 corpus positions)\n",
      "2019-04-24 17:01:20,717 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:20,719 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:20,722 : INFO : built Dictionary(72 unique tokens: ['adicionando', 'deseja', 'encontrar', 'escolha', 'está']...) from 5 documents (total 92 corpus positions)\n",
      "2019-04-24 17:01:20,724 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:20,732 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:20,735 : INFO : built Dictionary(182 unique tokens: ['acesso', 'adulto', 'analfabetismo', 'board', 'coisa']...) from 18 documents (total 272 corpus positions)\n",
      "2019-04-24 17:01:20,758 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:20,763 : INFO : built Dictionary(621 unique tokens: ['club', 'falar', 'ouviu', 'da', 'intervalo']...) from 100 documents (total 1416 corpus positions)\n",
      "2019-04-24 17:01:20,853 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:20,857 : INFO : built Dictionary(572 unique tokens: ['andrew', 'assoulin', 'exist', 'foto', 'getti']...) from 70 documents (total 1026 corpus positions)\n",
      "2019-04-24 17:01:20,899 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:20,902 : INFO : built Dictionary(158 unique tokens: ['caminhõ', 'do', 'ford', 'lança', 'marca']...) from 15 documents (total 245 corpus positions)\n",
      "2019-04-24 17:01:20,925 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:20,930 : INFO : built Dictionary(449 unique tokens: ['book', 'corpor', 'design', 'googl', 'insid']...) from 152 documents (total 1061 corpus positions)\n",
      "2019-04-24 17:01:21,045 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,048 : INFO : built Dictionary(337 unique tokens: ['build', 'busi', 'cook', 'engin', 'giant']...) from 62 documents (total 597 corpus positions)\n",
      "2019-04-24 17:01:21,077 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,080 : INFO : built Dictionary(51 unique tokens: ['bonanza', 'data', 'live', 'ceo', 'custom']...) from 11 documents (total 62 corpus positions)\n",
      "2019-04-24 17:01:21,092 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,095 : INFO : built Dictionary(196 unique tokens: ['myspac', 'thought', 'visit', 'year', 'ye']...) from 30 documents (total 343 corpus positions)\n",
      "2019-04-24 17:01:21,113 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:21,115 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,117 : INFO : built Dictionary(92 unique tokens: ['devop', 'kubernet', 'microservic', 'nanodegre', 'program']...) from 8 documents (total 122 corpus positions)\n",
      "2019-04-24 17:01:21,119 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:21,132 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,135 : INFO : built Dictionary(284 unique tokens: ['emphas', 'import', 'industri', 'leader', 'manag']...) from 29 documents (total 422 corpus positions)\n",
      "2019-04-24 17:01:21,157 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,161 : INFO : built Dictionary(359 unique tokens: ['employe', 'ensur', 'fit', 'futur', 'habit']...) from 78 documents (total 597 corpus positions)\n",
      "2019-04-24 17:01:21,203 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,206 : INFO : built Dictionary(406 unique tokens: ['uber', 'want', 'atom', 'coupl', 'heard']...) from 58 documents (total 809 corpus positions)\n",
      "2019-04-24 17:01:21,241 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,244 : INFO : built Dictionary(183 unique tokens: ['agora', 'bank', 'brasileiro', 'chegou', 'conquistar']...) from 20 documents (total 289 corpus positions)\n",
      "2019-04-24 17:01:21,258 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,260 : INFO : built Dictionary(155 unique tokens: ['banco', 'bilhõ', 'brasileiro', 'destinaram', 'esforço']...) from 17 documents (total 235 corpus positions)\n",
      "2019-04-24 17:01:21,290 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:21,295 : INFO : built Dictionary(857 unique tokens: ['dead', 'forest', 'know', 'season', 'southland']...) from 127 documents (total 1449 corpus positions)\n",
      "2019-04-24 17:01:21,385 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,387 : INFO : built Dictionary(131 unique tokens: ['base', 'big', 'busi', 'close', 'cloud']...) from 13 documents (total 240 corpus positions)\n",
      "2019-04-24 17:01:21,395 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:21,397 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,399 : INFO : built Dictionary(26 unique tokens: ['activ', 'algorithm', 'aspect', 'classic', 'deep']...) from 2 documents (total 32 corpus positions)\n",
      "2019-04-24 17:01:21,402 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:21,404 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:21,407 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:21,418 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,422 : INFO : built Dictionary(213 unique tokens: ['activ', 'app', 'ask', 'averag', 'dai']...) from 54 documents (total 525 corpus positions)\n",
      "2019-04-24 17:01:21,455 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:21,458 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,461 : INFO : built Dictionary(108 unique tokens: ['aberto', 'brasil', 'cachich', 'com', 'conversamo']...) from 6 documents (total 123 corpus positions)\n",
      "2019-04-24 17:01:21,464 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:21,476 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,480 : INFO : built Dictionary(286 unique tokens: ['anim', 'final', 'krita', 'releas', 'excit']...) from 57 documents (total 477 corpus positions)\n",
      "2019-04-24 17:01:21,503 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,507 : INFO : built Dictionary(173 unique tokens: ['américa', 'banco', 'baseado', 'blockchain', 'compartilhado']...) from 13 documents (total 230 corpus positions)\n",
      "2019-04-24 17:01:21,528 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,532 : INFO : built Dictionary(404 unique tokens: ['adob', 'analyt', 'autom', 'cloud', 'effort']...) from 91 documents (total 900 corpus positions)\n",
      "2019-04-24 17:01:21,588 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,591 : INFO : built Dictionary(225 unique tokens: ['pessoal', 'contain', 'net', 'rodar', 'sim']...) from 16 documents (total 408 corpus positions)\n",
      "2019-04-24 17:01:21,602 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,605 : INFO : built Dictionary(119 unique tokens: ['adopt', 'analysi', 'artifici', 'compani', 'data']...) from 28 documents (total 236 corpus positions)\n",
      "2019-04-24 17:01:21,620 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,623 : INFO : built Dictionary(141 unique tokens: ['onlin', 'sell', 'googl', 'help', 'paid']...) from 19 documents (total 242 corpus positions)\n",
      "2019-04-24 17:01:21,633 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:21,635 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,638 : INFO : built Dictionary(34 unique tokens: ['fastest', 'go', 'learn', 'read', 'report']...) from 5 documents (total 43 corpus positions)\n",
      "2019-04-24 17:01:21,640 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:21,646 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:21,648 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,651 : INFO : built Dictionary(56 unique tokens: ['brand', 'expect', 'help', 'innov', 'reshap']...) from 9 documents (total 76 corpus positions)\n",
      "2019-04-24 17:01:21,654 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:21,668 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,672 : INFO : built Dictionary(231 unique tokens: ['francisco', 'held', 'june', 'san', 'spark']...) from 52 documents (total 600 corpus positions)\n",
      "2019-04-24 17:01:21,700 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,703 : INFO : built Dictionary(182 unique tokens: ['ano', 'apostaram', 'assinatura', 'barna', 'beauchamp']...) from 14 documents (total 268 corpus positions)\n",
      "2019-04-24 17:01:21,734 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,739 : INFO : built Dictionary(951 unique tokens: ['americana', 'analogia', 'anunci', 'baixo', 'brasil']...) from 150 documents (total 2068 corpus positions)\n",
      "2019-04-24 17:01:21,892 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,894 : INFO : built Dictionary(274 unique tokens: ['accur', 'algorithm', 'app', 'artifici', 'creat']...) from 27 documents (total 444 corpus positions)\n",
      "2019-04-24 17:01:21,909 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,912 : INFO : built Dictionary(157 unique tokens: ['calif', 'palo', 'rancho', 'verd', 'accord']...) from 19 documents (total 209 corpus positions)\n",
      "2019-04-24 17:01:21,922 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,924 : INFO : built Dictionary(91 unique tokens: ['accuraci', 'call', 'claim', 'deeptext', 'develop']...) from 12 documents (total 145 corpus positions)\n",
      "2019-04-24 17:01:21,937 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,940 : INFO : built Dictionary(285 unique tokens: ['alto', 'center', 'common', 'consid', 'founder']...) from 25 documents (total 402 corpus positions)\n",
      "2019-04-24 17:01:21,954 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,957 : INFO : built Dictionary(102 unique tokens: ['acquir', 'agre', 'base', 'bet', 'beverag']...) from 12 documents (total 158 corpus positions)\n",
      "2019-04-24 17:01:21,966 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,969 : INFO : built Dictionary(101 unique tokens: ['googl', 'listen', 'record', 'said', 'year']...) from 19 documents (total 165 corpus positions)\n",
      "2019-04-24 17:01:21,990 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:21,993 : INFO : built Dictionary(368 unique tokens: ['cluster', 'comput', 'contain', 'current', 'infrastructur']...) from 55 documents (total 791 corpus positions)\n",
      "2019-04-24 17:01:22,031 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,034 : INFO : built Dictionary(101 unique tokens: ['alvo', 'anhanguera', 'ano', 'compra', 'concluir']...) from 10 documents (total 139 corpus positions)\n",
      "2019-04-24 17:01:22,040 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:22,042 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,045 : INFO : built Dictionary(50 unique tokens: ['appl', 'build', 'languag', 'major', 'open']...) from 6 documents (total 76 corpus positions)\n",
      "2019-04-24 17:01:22,047 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:22,059 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,063 : INFO : built Dictionary(374 unique tokens: ['advogado', 'dessa', 'deve', 'embaixador', 'expressõ']...) from 49 documents (total 616 corpus positions)\n",
      "2019-04-24 17:01:22,088 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:22,090 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,092 : INFO : built Dictionary(90 unique tokens: ['artifici', 'artística', 'capaz', 'certa', 'com']...) from 7 documents (total 113 corpus positions)\n",
      "2019-04-24 17:01:22,095 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:22,103 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:22,106 : INFO : built Dictionary(131 unique tokens: ['applianc', 'brew', 'fad', 'go', 'home']...) from 18 documents (total 182 corpus positions)\n",
      "2019-04-24 17:01:22,119 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,123 : INFO : built Dictionary(334 unique tokens: ['agência', 'aldemir', 'anéi', 'bendin', 'bilhõ']...) from 28 documents (total 489 corpus positions)\n",
      "2019-04-24 17:01:22,162 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,167 : INFO : built Dictionary(661 unique tokens: ['design', 'estim', 'ethicist', 'googl', 'hijack']...) from 159 documents (total 1666 corpus positions)\n",
      "2019-04-24 17:01:22,297 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,301 : INFO : built Dictionary(441 unique tokens: ['aluminum', 'appl', 'blogger', 'comment', 'daniel']...) from 80 documents (total 992 corpus positions)\n",
      "2019-04-24 17:01:22,353 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,357 : INFO : built Dictionary(338 unique tokens: ['commun', 'facebook', 'form', 'preval', 'text']...) from 57 documents (total 728 corpus positions)\n",
      "2019-04-24 17:01:22,387 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,389 : INFO : built Dictionary(127 unique tokens: ['analítica', 'com', 'compromisso', 'corporativa', 'está']...) from 12 documents (total 169 corpus positions)\n",
      "2019-04-24 17:01:22,396 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:22,398 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,400 : INFO : built Dictionary(73 unique tokens: ['povo', 'westerosi', 'cobertura', 'continuamo', 'emoçõ']...) from 8 documents (total 90 corpus positions)\n",
      "2019-04-24 17:01:22,403 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:22,411 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,414 : INFO : built Dictionary(161 unique tokens: ['best', 'claim', 'compani', 'heard', 'hire']...) from 30 documents (total 228 corpus positions)\n",
      "2019-04-24 17:01:22,428 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,431 : INFO : built Dictionary(183 unique tokens: ['agência', 'ano', 'arquivo', 'banco', 'brasil']...) from 15 documents (total 302 corpus positions)\n",
      "2019-04-24 17:01:22,450 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,455 : INFO : built Dictionary(363 unique tokens: ['api', 'applic', 'content', 'data', 'deliveri']...) from 51 documents (total 773 corpus positions)\n",
      "2019-04-24 17:01:22,488 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,491 : INFO : built Dictionary(203 unique tokens: ['administração', 'bom', 'coach', 'como', 'compelido']...) from 30 documents (total 334 corpus positions)\n",
      "2019-04-24 17:01:22,509 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,512 : INFO : built Dictionary(187 unique tokens: ['architectur', 'big', 'bring', 'context', 'forc']...) from 32 documents (total 347 corpus positions)\n",
      "2019-04-24 17:01:22,533 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,536 : INFO : built Dictionary(174 unique tokens: ['editor', 'guidanc', 'multipl', 'node', 'note']...) from 37 documents (total 466 corpus positions)\n",
      "2019-04-24 17:01:22,558 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,562 : INFO : built Dictionary(227 unique tokens: ['allo', 'cloud', 'daydream', 'demo', 'duo']...) from 23 documents (total 346 corpus positions)\n",
      "2019-04-24 17:01:22,575 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,578 : INFO : built Dictionary(129 unique tokens: ['clear', 'disjoint', 'emerg', 'left', 'list']...) from 11 documents (total 188 corpus positions)\n",
      "2019-04-24 17:01:22,588 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,592 : INFO : built Dictionary(147 unique tokens: ['applic', 'contain', 'develop', 'docker', 'experi']...) from 22 documents (total 259 corpus positions)\n",
      "2019-04-24 17:01:22,605 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,608 : INFO : built Dictionary(122 unique tokens: ['googl', 'obsess', 'product', 'speed', 'web']...) from 20 documents (total 210 corpus positions)\n",
      "2019-04-24 17:01:22,619 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,622 : INFO : built Dictionary(86 unique tokens: ['cloud', 'googl', 'languag', 'let', 'platform']...) from 18 documents (total 157 corpus positions)\n",
      "2019-04-24 17:01:22,634 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,638 : INFO : built Dictionary(204 unique tokens: ['billion', 'farm', 'feed', 'peopl', 'popul']...) from 29 documents (total 357 corpus positions)\n",
      "2019-04-24 17:01:22,654 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,656 : INFO : built Dictionary(140 unique tokens: ['annual', 'applic', 'best', 'build', 'cloud']...) from 14 documents (total 193 corpus positions)\n",
      "2019-04-24 17:01:22,665 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,668 : INFO : built Dictionary(96 unique tokens: ['learn', 'limit', 'machin', 'like', 'art']...) from 13 documents (total 132 corpus positions)\n",
      "2019-04-24 17:01:22,677 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,680 : INFO : built Dictionary(215 unique tokens: ['adotar', 'coolhow', 'costum', 'ferramenta', 'funcionário']...) from 25 documents (total 318 corpus positions)\n",
      "2019-04-24 17:01:22,693 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:22,696 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,698 : INFO : built Dictionary(114 unique tokens: ['assistir', 'casai', 'consigam', 'costum', 'criaram']...) from 9 documents (total 149 corpus positions)\n",
      "2019-04-24 17:01:22,701 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:22,710 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,714 : INFO : built Dictionary(217 unique tokens: ['abrir', 'acionista', 'algun', 'américa', 'atlant']...) from 19 documents (total 340 corpus positions)\n",
      "2019-04-24 17:01:22,727 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,731 : INFO : built Dictionary(212 unique tokens: ['abertura', 'ano', 'anunci', 'atuai', 'brasileira']...) from 14 documents (total 311 corpus positions)\n",
      "2019-04-24 17:01:22,741 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,743 : INFO : built Dictionary(105 unique tokens: ['break', 'clear', 'crystal', 'import', 'join']...) from 24 documents (total 131 corpus positions)\n",
      "2019-04-24 17:01:22,758 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,761 : INFO : built Dictionary(263 unique tokens: ['analyt', 'bigqueri', 'cloud', 'data', 'googl']...) from 38 documents (total 479 corpus positions)\n",
      "2019-04-24 17:01:22,787 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,790 : INFO : built Dictionary(285 unique tokens: ['curiou', 'engin', 'releas', 'art', 'goe']...) from 48 documents (total 580 corpus positions)\n",
      "2019-04-24 17:01:22,825 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,829 : INFO : built Dictionary(342 unique tokens: ['app', 'compel', 'end', 'excit', 'initi']...) from 97 documents (total 754 corpus positions)\n",
      "2019-04-24 17:01:22,884 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,887 : INFO : built Dictionary(348 unique tokens: ['arguabl', 'chang', 'decad', 'learn', 'machin']...) from 51 documents (total 807 corpus positions)\n",
      "2019-04-24 17:01:22,927 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,932 : INFO : built Dictionary(219 unique tokens: ['welcom', 'haircut', 'new', 'chang', 'password']...) from 69 documents (total 461 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:22,978 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:22,984 : INFO : built Dictionary(494 unique tokens: ['broke', 'dai', 'github', 'streak', 'learn']...) from 142 documents (total 950 corpus positions)\n",
      "2019-04-24 17:01:23,072 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,074 : INFO : built Dictionary(107 unique tokens: ['announc', 'com', 'compani', 'dab', 'fast']...) from 13 documents (total 151 corpus positions)\n",
      "2019-04-24 17:01:23,083 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,086 : INFO : built Dictionary(205 unique tokens: ['april', 'armi', 'brand', 'chatbot', 'develop']...) from 32 documents (total 299 corpus positions)\n",
      "2019-04-24 17:01:23,117 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,122 : INFO : built Dictionary(410 unique tokens: ['applic', 'bewild', 'choic', 'connect', 'develop']...) from 62 documents (total 1132 corpus positions)\n",
      "2019-04-24 17:01:23,171 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,174 : INFO : built Dictionary(183 unique tokens: ['cloud', 'googl', 'hard', 'isn', 'lot']...) from 34 documents (total 288 corpus positions)\n",
      "2019-04-24 17:01:23,211 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,217 : INFO : built Dictionary(508 unique tokens: ['book', 'cover', 'develop', 'java', 'june']...) from 187 documents (total 1604 corpus positions)\n",
      "2019-04-24 17:01:23,374 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,377 : INFO : built Dictionary(230 unique tokens: ['bit', 'commentari', 'design', 'googl', 'io']...) from 51 documents (total 386 corpus positions)\n",
      "2019-04-24 17:01:23,427 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,432 : INFO : built Dictionary(601 unique tokens: ['agil', 'busi', 'continu', 'deliveri', 'gain']...) from 146 documents (total 2007 corpus positions)\n",
      "2019-04-24 17:01:23,582 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,584 : INFO : built Dictionary(237 unique tokens: ['acceler', 'actual', 'batch', 'big', 'check']...) from 23 documents (total 341 corpus positions)\n",
      "2019-04-24 17:01:23,600 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,602 : INFO : built Dictionary(147 unique tokens: ['busi', 'casual', 'chat', 'confer', 'free']...) from 44 documents (total 414 corpus positions)\n",
      "2019-04-24 17:01:23,630 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,634 : INFO : built Dictionary(244 unique tokens: ['allianc', 'author', 'berkelei', 'board', 'california']...) from 42 documents (total 519 corpus positions)\n",
      "2019-04-24 17:01:23,676 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,681 : INFO : built Dictionary(578 unique tokens: ['fashion', 'get', 'go', 'good', 'know']...) from 210 documents (total 1347 corpus positions)\n",
      "2019-04-24 17:01:23,838 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:23,840 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,842 : INFO : built Dictionary(113 unique tokens: ['adorno', 'algun', 'atleta', 'brasil', 'chegarem']...) from 8 documents (total 143 corpus positions)\n",
      "2019-04-24 17:01:23,844 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:23,855 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,858 : INFO : built Dictionary(222 unique tokens: ['cycl', 'cyclist', 'equip', 'game', 'glass']...) from 29 documents (total 347 corpus positions)\n",
      "2019-04-24 17:01:23,876 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,881 : INFO : built Dictionary(255 unique tokens: ['anymor', 'applic', 'blockchain', 'impress', 'new']...) from 35 documents (total 459 corpus positions)\n",
      "2019-04-24 17:01:23,927 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:23,931 : INFO : built Dictionary(567 unique tokens: ['advent', 'applic', 'base', 'client', 'deliv']...) from 122 documents (total 1582 corpus positions)\n",
      "2019-04-24 17:01:24,034 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,036 : INFO : built Dictionary(344 unique tokens: ['build', 'develop', 'europ', 'facebook', 'focu']...) from 71 documents (total 654 corpus positions)\n",
      "2019-04-24 17:01:24,084 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,088 : INFO : built Dictionary(773 unique tokens: ['brasil', 'descrição', 'do', 'evento', 'maior']...) from 79 documents (total 1238 corpus positions)\n",
      "2019-04-24 17:01:24,144 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,148 : INFO : built Dictionary(453 unique tokens: ['amid', 'brazil', 'compani', 'consum', 'countri']...) from 84 documents (total 891 corpus positions)\n",
      "2019-04-24 17:01:24,198 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,200 : INFO : built Dictionary(178 unique tokens: ['annabel', 'ano', 'com', 'da', 'denominada']...) from 19 documents (total 263 corpus positions)\n",
      "2019-04-24 17:01:24,208 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:24,211 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,213 : INFO : built Dictionary(117 unique tokens: ['ano', 'carro', 'cinco', 'civic', 'depoi']...) from 6 documents (total 149 corpus positions)\n",
      "2019-04-24 17:01:24,215 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:24,221 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,224 : INFO : built Dictionary(112 unique tokens: ['app', 'base', 'book', 'cent', 'close']...) from 11 documents (total 156 corpus positions)\n",
      "2019-04-24 17:01:24,251 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,260 : INFO : built Dictionary(486 unique tokens: ['algorithm', 'artifici', 'calif', 'googl', 'greatest']...) from 124 documents (total 1196 corpus positions)\n",
      "2019-04-24 17:01:24,350 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,353 : INFO : built Dictionary(281 unique tokens: ['borough', 'coast', 'east', 'ground', 'innov']...) from 36 documents (total 503 corpus positions)\n",
      "2019-04-24 17:01:24,368 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:24,371 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,373 : INFO : built Dictionary(24 unique tokens: ['boss', 'career', 'compani', 'cours', 'critic']...) from 2 documents (total 29 corpus positions)\n",
      "2019-04-24 17:01:24,375 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:24,377 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:24,378 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:24,385 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,388 : INFO : built Dictionary(183 unique tokens: ['catch', 'cloud', 'competit', 'enterpris', 'googl']...) from 18 documents (total 302 corpus positions)\n",
      "2019-04-24 17:01:24,427 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,434 : INFO : built Dictionary(612 unique tokens: ['disclaim', 'like', 'start', 'develop', 'django']...) from 208 documents (total 1832 corpus positions)\n",
      "2019-04-24 17:01:24,629 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,632 : INFO : built Dictionary(312 unique tokens: ['bigger', 'compani', 'core', 'design', 'devic']...) from 49 documents (total 532 corpus positions)\n",
      "2019-04-24 17:01:24,656 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,659 : INFO : built Dictionary(170 unique tokens: ['like', 'look', 'pin', 'real', 'virtual']...) from 12 documents (total 242 corpus positions)\n",
      "2019-04-24 17:01:24,665 : WARNING : Input text is expected to have at least 10 sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:24,667 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,669 : INFO : built Dictionary(29 unique tokens: ['accuraci', 'algorithm', 'applic', 'bring', 'compani']...) from 2 documents (total 32 corpus positions)\n",
      "2019-04-24 17:01:24,672 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:24,674 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:24,676 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:24,680 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:24,682 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,685 : INFO : built Dictionary(65 unique tokens: ['client', 'cours', 'design', 'manag', 'pai']...) from 6 documents (total 86 corpus positions)\n",
      "2019-04-24 17:01:24,687 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:24,694 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,697 : INFO : built Dictionary(117 unique tokens: ['applic', 'bank', 'build', 'chang', 'develop']...) from 11 documents (total 190 corpus positions)\n",
      "2019-04-24 17:01:24,705 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:24,707 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,709 : INFO : built Dictionary(48 unique tokens: ['african', 'commun', 'cultur', 'hallmark', 'long']...) from 6 documents (total 59 corpus positions)\n",
      "2019-04-24 17:01:24,712 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:24,717 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:24,719 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,722 : INFO : built Dictionary(54 unique tokens: ['behavior', 'consum', 'driver', 'epic', 'primari']...) from 6 documents (total 65 corpus positions)\n",
      "2019-04-24 17:01:24,724 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:24,736 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,739 : INFO : built Dictionary(275 unique tokens: ['ad', 'empow', 'gener', 'impress', 'leav']...) from 46 documents (total 453 corpus positions)\n",
      "2019-04-24 17:01:24,769 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,773 : INFO : built Dictionary(387 unique tokens: ['best', 'carousel', 'design', 'fat', 'featur']...) from 66 documents (total 803 corpus positions)\n",
      "2019-04-24 17:01:24,822 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,825 : INFO : built Dictionary(367 unique tokens: ['avail', 'blog', 'compar', 'drupal', 'earlier']...) from 51 documents (total 831 corpus positions)\n",
      "2019-04-24 17:01:24,865 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,868 : INFO : built Dictionary(291 unique tokens: ['blog', 'editori', 'ndepend', 'note', 'origin']...) from 61 documents (total 508 corpus positions)\n",
      "2019-04-24 17:01:24,898 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,900 : INFO : built Dictionary(78 unique tokens: ['editor', 'heavi', 'struggl', 'weight', 'especi']...) from 13 documents (total 93 corpus positions)\n",
      "2019-04-24 17:01:24,907 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:24,909 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,911 : INFO : built Dictionary(86 unique tokens: ['api', 'aplicação', 'apresentado', 'arquitetura', 'case']...) from 5 documents (total 103 corpus positions)\n",
      "2019-04-24 17:01:24,913 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:24,920 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:24,923 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,926 : INFO : built Dictionary(105 unique tokens: ['api', 'como', 'código', 'design', 'fazendo']...) from 6 documents (total 128 corpus positions)\n",
      "2019-04-24 17:01:24,928 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:24,937 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,940 : INFO : built Dictionary(153 unique tokens: ['digit', 'look', 'physic', 'project', 'right']...) from 17 documents (total 258 corpus positions)\n",
      "2019-04-24 17:01:24,955 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:24,959 : INFO : built Dictionary(371 unique tokens: ['advisori', 'ambient', 'auditoria', 'austero', 'big']...) from 34 documents (total 616 corpus positions)\n",
      "2019-04-24 17:01:25,032 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:25,043 : INFO : built Dictionary(527 unique tokens: ['appl', 'googl', 'map', 'android', 'app']...) from 278 documents (total 2321 corpus positions)\n",
      "2019-04-24 17:01:25,590 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:25,594 : INFO : built Dictionary(297 unique tokens: ['andreessen', 'autonom', 'capit', 'decentr', 'firm']...) from 67 documents (total 582 corpus positions)\n",
      "2019-04-24 17:01:25,644 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:25,648 : INFO : built Dictionary(218 unique tokens: ['email', 'fix', 'hiri', 'latest', 'startup']...) from 32 documents (total 331 corpus positions)\n",
      "2019-04-24 17:01:25,670 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:25,673 : INFO : built Dictionary(187 unique tokens: ['canva', 'clean', 'close', 'crowdflow', 'crowdsourc']...) from 22 documents (total 288 corpus positions)\n",
      "2019-04-24 17:01:25,694 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:25,698 : INFO : built Dictionary(257 unique tokens: ['busi', 'demand', 'forecast', 'cook', 'diner']...) from 60 documents (total 598 corpus positions)\n",
      "2019-04-24 17:01:25,726 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:25,730 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:25,733 : INFO : built Dictionary(26 unique tokens: ['home', 'life', 'mac', 'pc', 'window']...) from 4 documents (total 28 corpus positions)\n",
      "2019-04-24 17:01:25,736 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:25,740 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:25,751 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:25,756 : INFO : built Dictionary(344 unique tokens: ['baseada', 'benchmark', 'conhec', 'dado', 'decisõ']...) from 41 documents (total 612 corpus positions)\n",
      "2019-04-24 17:01:25,779 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:25,782 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:25,785 : INFO : built Dictionary(82 unique tokens: ['anunci', 'azur', 'buscam', 'campanha', 'com']...) from 7 documents (total 109 corpus positions)\n",
      "2019-04-24 17:01:25,787 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:25,804 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:25,808 : INFO : built Dictionary(261 unique tokens: ['channel', 'consid', 'email', 'gener', 'high']...) from 57 documents (total 551 corpus positions)\n",
      "2019-04-24 17:01:25,845 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:25,849 : INFO : built Dictionary(258 unique tokens: ['begin', 'defin', 'design', 'let', 'pattern']...) from 58 documents (total 519 corpus positions)\n",
      "2019-04-24 17:01:25,902 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:25,907 : INFO : built Dictionary(380 unique tokens: ['big', 'brave', 'busi', 'chang', 'come']...) from 114 documents (total 1467 corpus positions)\n",
      "2019-04-24 17:01:26,024 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,026 : INFO : built Dictionary(144 unique tokens: ['answer', 'come', 'email', 'googl', 'help']...) from 16 documents (total 209 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:26,049 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,055 : INFO : built Dictionary(471 unique tokens: ['até', 'da', 'experiência', 'fantástica', 'hoje']...) from 63 documents (total 923 corpus positions)\n",
      "2019-04-24 17:01:26,103 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,107 : INFO : built Dictionary(193 unique tokens: ['byttow', 'compani', 'david', 'goe', 'insid']...) from 24 documents (total 258 corpus positions)\n",
      "2019-04-24 17:01:26,121 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,124 : INFO : built Dictionary(173 unique tokens: ['aspect', 'bot', 'caus', 'clear', 'commerc']...) from 36 documents (total 326 corpus positions)\n",
      "2019-04-24 17:01:26,175 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,183 : INFO : built Dictionary(1164 unique tokens: ['geniu', 'mark', 'zuckerberg', 'abil', 'asperg']...) from 194 documents (total 2165 corpus positions)\n",
      "2019-04-24 17:01:26,390 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,392 : INFO : built Dictionary(289 unique tokens: ['absolut', 'best', 'declar', 'definit', 'drink']...) from 30 documents (total 443 corpus positions)\n",
      "2019-04-24 17:01:26,419 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,423 : INFO : built Dictionary(344 unique tokens: ['digit', 'forrest', 'forum', 'held', 'major']...) from 69 documents (total 836 corpus positions)\n",
      "2019-04-24 17:01:26,480 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,484 : INFO : built Dictionary(426 unique tokens: ['easi', 'knuedg', 'startup', 'administr', 'aeronaut']...) from 90 documents (total 810 corpus positions)\n",
      "2019-04-24 17:01:26,534 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:26,536 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,539 : INFO : built Dictionary(81 unique tokens: ['gent', 'adoro', 'gravei', 'hoje', 'intraempreendedorismo']...) from 9 documents (total 104 corpus positions)\n",
      "2019-04-24 17:01:26,542 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:26,566 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,571 : INFO : built Dictionary(535 unique tokens: ['develop', 'easi', 'enterpris', 'interest', 'java']...) from 106 documents (total 1227 corpus positions)\n",
      "2019-04-24 17:01:26,662 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,666 : INFO : built Dictionary(331 unique tokens: ['acentuam', 'aquém', 'atribuir', 'cada', 'caso']...) from 50 documents (total 503 corpus positions)\n",
      "2019-04-24 17:01:26,695 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,698 : INFO : built Dictionary(202 unique tokens: ['answer', 'gener', 'interest', 'question', 'try']...) from 33 documents (total 401 corpus positions)\n",
      "2019-04-24 17:01:26,733 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,739 : INFO : built Dictionary(631 unique tokens: ['coisa', 'deveria', 'escrev', 'mail', 'não']...) from 206 documents (total 1434 corpus positions)\n",
      "2019-04-24 17:01:26,898 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,901 : INFO : built Dictionary(353 unique tokens: ['amazon', 'appl', 'battl', 'big', 'come']...) from 71 documents (total 665 corpus positions)\n",
      "2019-04-24 17:01:26,933 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,936 : INFO : built Dictionary(120 unique tokens: ['amplitud', 'announc', 'fund', 'million', 'morn']...) from 15 documents (total 175 corpus positions)\n",
      "2019-04-24 17:01:26,953 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,957 : INFO : built Dictionary(203 unique tokens: ['devtool', 'doc', 'move', 'articl', 'chrome']...) from 48 documents (total 547 corpus positions)\n",
      "2019-04-24 17:01:26,989 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:26,992 : INFO : built Dictionary(298 unique tokens: ['concern', 'jake', 'knapp', 'pass', 'speed']...) from 77 documents (total 529 corpus positions)\n",
      "2019-04-24 17:01:27,031 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,034 : INFO : built Dictionary(129 unique tokens: ['anim', 'aplicativo', 'conhecimento', 'contabilidad', 'descontinuado']...) from 17 documents (total 354 corpus positions)\n",
      "2019-04-24 17:01:27,046 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,051 : INFO : built Dictionary(173 unique tokens: ['apertar', 'botão', 'carregar', 'conteúdo', 'continu']...) from 20 documents (total 320 corpus positions)\n",
      "2019-04-24 17:01:27,063 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,066 : INFO : built Dictionary(211 unique tokens: ['alto', 'apagão', 'cio', 'desd', 'digit']...) from 19 documents (total 302 corpus positions)\n",
      "2019-04-24 17:01:27,077 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,080 : INFO : built Dictionary(166 unique tokens: ['alic', 'caminho', 'cheshir', 'conhec', 'da']...) from 19 documents (total 259 corpus positions)\n",
      "2019-04-24 17:01:27,089 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,092 : INFO : built Dictionary(89 unique tokens: ['code', 'contain', 'docker', 'gamblin', 'jerri']...) from 13 documents (total 162 corpus positions)\n",
      "2019-04-24 17:01:27,099 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,101 : INFO : built Dictionary(103 unique tokens: ['compani', 'design', 'especi', 'googl', 'kingdom']...) from 14 documents (total 164 corpus positions)\n",
      "2019-04-24 17:01:27,111 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,114 : INFO : built Dictionary(171 unique tokens: ['bit', 'develop', 'differ', 'grant', 'norm']...) from 34 documents (total 284 corpus positions)\n",
      "2019-04-24 17:01:27,126 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,129 : INFO : built Dictionary(229 unique tokens: ['afirmam', 'aguardado', 'analista', 'anunci', 'aplicativo']...) from 16 documents (total 356 corpus positions)\n",
      "2019-04-24 17:01:27,141 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,144 : INFO : built Dictionary(207 unique tokens: ['alan', 'app', 'ceo', 'late', 'littl']...) from 37 documents (total 344 corpus positions)\n",
      "2019-04-24 17:01:27,160 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,163 : INFO : built Dictionary(219 unique tokens: ['auto', 'creat', 'financ', 'forefront', 'innov']...) from 14 documents (total 411 corpus positions)\n",
      "2019-04-24 17:01:27,175 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,178 : INFO : built Dictionary(205 unique tokens: ['francisco', 'san', 'visa', 'account', 'back']...) from 24 documents (total 392 corpus positions)\n",
      "2019-04-24 17:01:27,197 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,200 : INFO : built Dictionary(479 unique tokens: ['amazon', 'ano', 'da', 'multiplicação', 'promovendo']...) from 69 documents (total 845 corpus positions)\n",
      "2019-04-24 17:01:27,233 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:27,235 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,237 : INFO : built Dictionary(64 unique tokens: ['anunci', 'desktop', 'disponibilidad', 'do', 'formatação']...) from 6 documents (total 69 corpus positions)\n",
      "2019-04-24 17:01:27,238 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:27,244 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,246 : INFO : built Dictionary(121 unique tokens: ['countri', 'friend', 'help', 'identifi', 'memori']...) from 17 documents (total 178 corpus positions)\n",
      "2019-04-24 17:01:27,256 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,258 : INFO : built Dictionary(138 unique tokens: ['brand', 'cloth', 'conduct', 'creat', 'fabric']...) from 14 documents (total 191 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:27,273 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,276 : INFO : built Dictionary(362 unique tokens: ['compani', 'make', 'uniqu', 'align', 'constantli']...) from 54 documents (total 689 corpus positions)\n",
      "2019-04-24 17:01:27,306 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,308 : INFO : built Dictionary(144 unique tokens: ['coffe', 'interview', 'welcom', 'break', 'need']...) from 61 documents (total 311 corpus positions)\n",
      "2019-04-24 17:01:27,331 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,336 : INFO : built Dictionary(190 unique tokens: ['benefit', 'emot', 'improv', 'intellig', 'answer']...) from 33 documents (total 325 corpus positions)\n",
      "2019-04-24 17:01:27,349 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,351 : INFO : built Dictionary(123 unique tokens: ['artifici', 'creat', 'curiou', 'intellig', 'need']...) from 13 documents (total 177 corpus positions)\n",
      "2019-04-24 17:01:27,358 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,361 : INFO : built Dictionary(44 unique tokens: ['beauti', 'deepart', 'art', 'photo', 'piec']...) from 12 documents (total 68 corpus positions)\n",
      "2019-04-24 17:01:27,373 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,376 : INFO : built Dictionary(296 unique tokens: ['base', 'basic', 'built', 'common', 'multiten']...) from 51 documents (total 586 corpus positions)\n",
      "2019-04-24 17:01:27,402 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,405 : INFO : built Dictionary(254 unique tokens: ['absurd', 'ago', 'anti', 'campaign', 'concept']...) from 70 documents (total 480 corpus positions)\n",
      "2019-04-24 17:01:27,447 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,450 : INFO : built Dictionary(435 unique tokens: ['autofil', 'credit', 'dev', 'know', 'mobil']...) from 142 documents (total 1259 corpus positions)\n",
      "2019-04-24 17:01:27,569 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,573 : INFO : built Dictionary(297 unique tokens: ['adapt', 'billion', 'headphon', 'jack', 'liter']...) from 57 documents (total 604 corpus positions)\n",
      "2019-04-24 17:01:27,605 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,608 : INFO : built Dictionary(151 unique tokens: ['belmont', 'citi', 'connect', 'design', 'driver']...) from 31 documents (total 282 corpus positions)\n",
      "2019-04-24 17:01:27,620 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,623 : INFO : built Dictionary(83 unique tokens: ['emmi', 'nomin', 'primetim', 'win', 'award']...) from 12 documents (total 102 corpus positions)\n",
      "2019-04-24 17:01:27,645 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,649 : INFO : built Dictionary(406 unique tokens: ['differ', 'littl', 'year', 'announc', 'app']...) from 120 documents (total 962 corpus positions)\n",
      "2019-04-24 17:01:27,728 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,729 : INFO : built Dictionary(109 unique tokens: ['ask', 'bank', 'build', 'caught', 'convers']...) from 22 documents (total 204 corpus positions)\n",
      "2019-04-24 17:01:27,748 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,752 : INFO : built Dictionary(288 unique tokens: ['internet', 'stori', 'success', 'balanc', 'coloss']...) from 90 documents (total 565 corpus positions)\n",
      "2019-04-24 17:01:27,798 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,802 : INFO : built Dictionary(330 unique tokens: ['attempt', 'bear', 'defin', 'face', 'home']...) from 48 documents (total 551 corpus positions)\n",
      "2019-04-24 17:01:27,833 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,836 : INFO : built Dictionary(270 unique tokens: ['attend', 'demonstr', 'mutat', 'open', 'space']...) from 96 documents (total 619 corpus positions)\n",
      "2019-04-24 17:01:27,880 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:27,883 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,885 : INFO : built Dictionary(72 unique tokens: ['android', 'anunci', 'aparelho', 'aplicativo', 'atualização']...) from 6 documents (total 91 corpus positions)\n",
      "2019-04-24 17:01:27,888 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:27,895 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,897 : INFO : built Dictionary(119 unique tokens: ['android', 'appli', 'chang', 'channel', 'chrome']...) from 15 documents (total 182 corpus positions)\n",
      "2019-04-24 17:01:27,909 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,912 : INFO : built Dictionary(314 unique tokens: ['ant', 'anunci', 'app', 'appl', 'assinatura']...) from 42 documents (total 624 corpus positions)\n",
      "2019-04-24 17:01:27,938 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,945 : INFO : built Dictionary(274 unique tokens: ['atendimento', 'canai', 'client', 'colocar', 'com']...) from 32 documents (total 501 corpus positions)\n",
      "2019-04-24 17:01:27,963 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,966 : INFO : built Dictionary(215 unique tokens: ['com', 'como', 'compartilh', 'curiosa', 'filetoffish']...) from 26 documents (total 282 corpus positions)\n",
      "2019-04-24 17:01:27,978 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,980 : INFO : built Dictionary(132 unique tokens: ['api', 'function', 'issu', 'jame', 'known']...) from 14 documents (total 253 corpus positions)\n",
      "2019-04-24 17:01:27,992 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:27,994 : INFO : built Dictionary(247 unique tokens: ['brasil', 'cabifi', 'cidad', 'começando', 'estreia']...) from 30 documents (total 414 corpus positions)\n",
      "2019-04-24 17:01:28,012 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,014 : INFO : built Dictionary(171 unique tokens: ['action', 'centuri', 'corpor', 'defin', 'effort']...) from 27 documents (total 287 corpus positions)\n",
      "2019-04-24 17:01:28,025 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:28,027 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,029 : INFO : built Dictionary(29 unique tokens: ['access', 'author', 'bodi', 'help', 'intent']...) from 2 documents (total 30 corpus positions)\n",
      "2019-04-24 17:01:28,031 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:28,033 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:28,036 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:28,044 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,047 : INFO : built Dictionary(247 unique tokens: ['applic', 'attempt', 'break', 'challeng', 'cornel']...) from 35 documents (total 420 corpus positions)\n",
      "2019-04-24 17:01:28,063 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,066 : INFO : built Dictionary(260 unique tokens: ['agitado', 'boa', 'coisa', 'dia', 'estressant']...) from 16 documents (total 393 corpus positions)\n",
      "2019-04-24 17:01:28,079 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,082 : INFO : built Dictionary(204 unique tokens: ['ago', 'call', 'differ', 'engin', 'flavor']...) from 43 documents (total 416 corpus positions)\n",
      "2019-04-24 17:01:28,110 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,114 : INFO : built Dictionary(400 unique tokens: ['appl', 'confer', 'debut', 'develop', 'event']...) from 72 documents (total 1010 corpus positions)\n",
      "2019-04-24 17:01:28,163 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,165 : INFO : built Dictionary(194 unique tokens: ['appl', 'event', 'june', 'kick', 'mondai']...) from 27 documents (total 402 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:28,185 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,189 : INFO : built Dictionary(297 unique tokens: ['hyperdev', 'introduc', 'thing', 'awhil', 'creek']...) from 102 documents (total 629 corpus positions)\n",
      "2019-04-24 17:01:28,240 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,243 : INFO : built Dictionary(463 unique tokens: ['glow', 'like', 'net', 'packet', 'review']...) from 132 documents (total 1118 corpus positions)\n",
      "2019-04-24 17:01:28,320 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,322 : INFO : built Dictionary(339 unique tokens: ['cio', 'como', 'competência', 'considera', 'empresa']...) from 33 documents (total 593 corpus positions)\n",
      "2019-04-24 17:01:28,339 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:28,343 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,345 : INFO : built Dictionary(48 unique tokens: ['click', 'inspir', 'link', 'probabl', 'seen']...) from 6 documents (total 59 corpus positions)\n",
      "2019-04-24 17:01:28,348 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:28,355 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,358 : INFO : built Dictionary(161 unique tokens: ['anunci', 'ao', 'aplicativo', 'app', 'atualização']...) from 11 documents (total 264 corpus positions)\n",
      "2019-04-24 17:01:28,376 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,380 : INFO : built Dictionary(388 unique tokens: ['app', 'bot', 'call', 'damn', 'fireman']...) from 68 documents (total 740 corpus positions)\n",
      "2019-04-24 17:01:28,419 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,422 : INFO : built Dictionary(223 unique tokens: ['advertis', 'chatter', 'converg', 'distinct', 'industri']...) from 39 documents (total 367 corpus positions)\n",
      "2019-04-24 17:01:28,436 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,439 : INFO : built Dictionary(145 unique tokens: ['anunci', 'bilhõ', 'comprará', 'dólare', 'hoje']...) from 14 documents (total 200 corpus positions)\n",
      "2019-04-24 17:01:28,446 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:28,448 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,450 : INFO : built Dictionary(50 unique tokens: ['acquir', 'agreement', 'announc', 'billion', 'cash']...) from 7 documents (total 63 corpus positions)\n",
      "2019-04-24 17:01:28,451 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:28,457 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,459 : INFO : built Dictionary(149 unique tokens: ['começ', 'intenso', 'mercado', 'ritmo', 'semana']...) from 15 documents (total 192 corpus positions)\n",
      "2019-04-24 17:01:28,469 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,473 : INFO : built Dictionary(153 unique tokens: ['applianc', 'call', 'citi', 'hero', 'high']...) from 22 documents (total 210 corpus positions)\n",
      "2019-04-24 17:01:28,484 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:28,486 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,488 : INFO : built Dictionary(119 unique tokens: ['acelerar', 'acordo', 'advinda', 'ano', 'aplicação']...) from 5 documents (total 155 corpus positions)\n",
      "2019-04-24 17:01:28,490 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:28,500 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,504 : INFO : built Dictionary(317 unique tokens: ['aplicativo', 'doc', 'documento', 'drive', 'editor']...) from 41 documents (total 655 corpus positions)\n",
      "2019-04-24 17:01:28,525 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,527 : INFO : built Dictionary(108 unique tokens: ['app', 'brag', 'direct', 'draw', 'game']...) from 22 documents (total 161 corpus positions)\n",
      "2019-04-24 17:01:28,541 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,545 : INFO : built Dictionary(328 unique tokens: ['act', 'anticip', 'benefit', 'busi', 'certain']...) from 25 documents (total 660 corpus positions)\n",
      "2019-04-24 17:01:28,561 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,564 : INFO : built Dictionary(249 unique tokens: ['alexei', 'bozoma', 'john', 'oreskov', 'saint']...) from 34 documents (total 379 corpus positions)\n",
      "2019-04-24 17:01:28,576 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,580 : INFO : built Dictionary(143 unique tokens: ['airbu', 'anunci', 'capit', 'com', 'demanda']...) from 10 documents (total 214 corpus positions)\n",
      "2019-04-24 17:01:28,588 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,591 : INFO : built Dictionary(212 unique tokens: ['ao', 'campo', 'damo', 'erro', 'experiência']...) from 21 documents (total 322 corpus positions)\n",
      "2019-04-24 17:01:28,600 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,603 : INFO : built Dictionary(150 unique tokens: ['agosto', 'center', 'confer', 'dia', 'edição']...) from 11 documents (total 220 corpus positions)\n",
      "2019-04-24 17:01:28,615 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,618 : INFO : built Dictionary(294 unique tokens: ['abl', 'assumpt', 'event', 'happen', 'navig']...) from 33 documents (total 497 corpus positions)\n",
      "2019-04-24 17:01:28,635 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,638 : INFO : built Dictionary(153 unique tokens: ['apf', 'current', 'disk', 'startup', 'volum']...) from 30 documents (total 294 corpus positions)\n",
      "2019-04-24 17:01:28,655 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,658 : INFO : built Dictionary(136 unique tokens: ['anchor', 'auto', 'easier', 'guid', 'io']...) from 28 documents (total 320 corpus positions)\n",
      "2019-04-24 17:01:28,685 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,690 : INFO : built Dictionary(479 unique tokens: ['big', 'hit', 'japanes', 'learn', 'wall']...) from 176 documents (total 1079 corpus positions)\n",
      "2019-04-24 17:01:28,786 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,790 : INFO : built Dictionary(247 unique tokens: ['afloat', 'bank', 'commun', 'consolid', 'credit']...) from 30 documents (total 448 corpus positions)\n",
      "2019-04-24 17:01:28,809 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,812 : INFO : built Dictionary(260 unique tokens: ['activ', 'compani', 'fight', 'go', 'men']...) from 40 documents (total 365 corpus positions)\n",
      "2019-04-24 17:01:28,897 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:28,907 : INFO : built Dictionary(2220 unique tokens: ['acrescentar', 'apresentamo', 'aqui', 'comentário', 'complementar']...) from 369 documents (total 6485 corpus positions)\n",
      "2019-04-24 17:01:30,014 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,017 : INFO : built Dictionary(208 unique tokens: ['al', 'alesat', 'aquisição', 'assin', 'combustívei']...) from 15 documents (total 295 corpus positions)\n",
      "2019-04-24 17:01:30,032 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,035 : INFO : built Dictionary(209 unique tokens: ['browser', 'contain', 'css', 'develop', 'layout']...) from 45 documents (total 541 corpus positions)\n",
      "2019-04-24 17:01:30,062 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:30,064 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,066 : INFO : built Dictionary(101 unique tokens: ['announc', 'assist', 'busi', 'compani', 'custom']...) from 8 documents (total 151 corpus positions)\n",
      "2019-04-24 17:01:30,068 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:30,077 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:30,082 : INFO : built Dictionary(151 unique tokens: ['address', 'asic', 'atmospher', 'audienc', 'custom']...) from 19 documents (total 273 corpus positions)\n",
      "2019-04-24 17:01:30,094 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,097 : INFO : built Dictionary(124 unique tokens: ['decemb', 'final', 'global', 'long', 'netflix']...) from 14 documents (total 178 corpus positions)\n",
      "2019-04-24 17:01:30,108 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,111 : INFO : built Dictionary(220 unique tokens: ['battl', 'cdh', 'cloudera', 'come', 'distribut']...) from 36 documents (total 378 corpus positions)\n",
      "2019-04-24 17:01:30,130 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,133 : INFO : built Dictionary(188 unique tokens: ['consum', 'dig', 'file', 'probabl', 'read']...) from 37 documents (total 307 corpus positions)\n",
      "2019-04-24 17:01:30,156 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,160 : INFO : built Dictionary(356 unique tokens: ['date', 'help', 'hurrican', 'iphon', 'pal']...) from 58 documents (total 604 corpus positions)\n",
      "2019-04-24 17:01:30,204 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,208 : INFO : built Dictionary(420 unique tokens: ['appl', 'artifici', 'attitud', 'bid', 'data']...) from 65 documents (total 849 corpus positions)\n",
      "2019-04-24 17:01:30,256 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,259 : INFO : built Dictionary(324 unique tokens: ['advertis', 'appl', 'bespok', 'creep', 'decor']...) from 41 documents (total 525 corpus positions)\n",
      "2019-04-24 17:01:30,284 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,288 : INFO : built Dictionary(261 unique tokens: ['airhorn', 'app', 'built', 'demonstr', 'guitar']...) from 50 documents (total 529 corpus positions)\n",
      "2019-04-24 17:01:30,321 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,324 : INFO : built Dictionary(199 unique tokens: ['cloud', 'command', 'gatewai', 'gcloud', 'googl']...) from 45 documents (total 656 corpus positions)\n",
      "2019-04-24 17:01:30,353 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,356 : INFO : built Dictionary(107 unique tokens: ['announc', 'appl', 'artifici', 'big', 'develop']...) from 14 documents (total 151 corpus positions)\n",
      "2019-04-24 17:01:30,372 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,376 : INFO : built Dictionary(269 unique tokens: ['appli', 'document', 'experi', 'issu', 'list']...) from 53 documents (total 650 corpus positions)\n",
      "2019-04-24 17:01:30,411 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,415 : INFO : built Dictionary(278 unique tokens: ['aem', 'document', 'file', 'manag', 'metadata']...) from 61 documents (total 667 corpus positions)\n",
      "2019-04-24 17:01:30,452 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,455 : INFO : built Dictionary(88 unique tokens: ['attribut', 'child', 'consist', 'element', 'exclud']...) from 21 documents (total 206 corpus positions)\n",
      "2019-04-24 17:01:30,474 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,478 : INFO : built Dictionary(241 unique tokens: ['app', 'data', 'progress', 'seri', 'sync']...) from 88 documents (total 670 corpus positions)\n",
      "2019-04-24 17:01:30,532 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,535 : INFO : built Dictionary(132 unique tokens: ['ainda', 'bell', 'chegará', 'comida', 'especializada']...) from 11 documents (total 183 corpus positions)\n",
      "2019-04-24 17:01:30,553 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,557 : INFO : built Dictionary(330 unique tokens: ['architectur', 'code', 'microservic', 'opportun', 'share']...) from 65 documents (total 757 corpus positions)\n",
      "2019-04-24 17:01:30,599 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,603 : INFO : built Dictionary(231 unique tokens: ['busi', 'custom', 'employ', 'establish', 'meet']...) from 93 documents (total 431 corpus positions)\n",
      "2019-04-24 17:01:30,640 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,643 : INFO : built Dictionary(272 unique tokens: ['author', 'eric', 'agenda', 'dai', 'develop']...) from 45 documents (total 382 corpus positions)\n",
      "2019-04-24 17:01:30,667 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,671 : INFO : built Dictionary(263 unique tokens: ['blog', 'chang', 'combin', 'go', 'latest']...) from 60 documents (total 540 corpus positions)\n",
      "2019-04-24 17:01:30,709 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,713 : INFO : built Dictionary(374 unique tokens: ['career', 'commun', 'data', 'divis', 'evolv']...) from 63 documents (total 626 corpus positions)\n",
      "2019-04-24 17:01:30,741 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:30,744 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,746 : INFO : built Dictionary(107 unique tokens: ['ano', 'apena', 'berner', 'cientista', 'como']...) from 5 documents (total 137 corpus positions)\n",
      "2019-04-24 17:01:30,748 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:30,760 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,764 : INFO : built Dictionary(370 unique tokens: ['amazônica', 'belém', 'combú', 'especificament', 'floresta']...) from 66 documents (total 669 corpus positions)\n",
      "2019-04-24 17:01:30,796 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,799 : INFO : built Dictionary(88 unique tokens: ['black', 'coalesc', 'gravit', 'hole', 'mass']...) from 13 documents (total 118 corpus positions)\n",
      "2019-04-24 17:01:30,808 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,811 : INFO : built Dictionary(222 unique tokens: ['close', 'cultur', 'engin', 'fund', 'growth']...) from 24 documents (total 325 corpus positions)\n",
      "2019-04-24 17:01:30,824 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,827 : INFO : built Dictionary(124 unique tokens: ['acquir', 'android', 'answer', 'custom', 'fleksi']...) from 13 documents (total 176 corpus positions)\n",
      "2019-04-24 17:01:30,834 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:30,836 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,839 : INFO : built Dictionary(38 unique tokens: ['bird', 'blue', 'charact', 'circl', 'compris']...) from 2 documents (total 39 corpus positions)\n",
      "2019-04-24 17:01:30,841 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:30,843 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:30,848 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:30,853 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,857 : INFO : built Dictionary(120 unique tokens: ['brasil', 'campina', 'centro', 'comparativa', 'convençõ']...) from 13 documents (total 177 corpus positions)\n",
      "2019-04-24 17:01:30,872 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,876 : INFO : built Dictionary(331 unique tokens: ['ago', 'berkelei', 'biologist', 'ca', 'california']...) from 74 documents (total 567 corpus positions)\n",
      "2019-04-24 17:01:30,909 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,913 : INFO : built Dictionary(169 unique tokens: ['call', 'game', 'internet', 'iot', 'perpetu']...) from 16 documents (total 274 corpus positions)\n",
      "2019-04-24 17:01:30,932 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,935 : INFO : built Dictionary(381 unique tokens: ['bore', 'gonna', 'hous', 'interest', 'meet']...) from 61 documents (total 669 corpus positions)\n",
      "2019-04-24 17:01:30,962 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:30,965 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,969 : INFO : built Dictionary(29 unique tokens: ['mac', 'ask', 'capabl', 'debut', 'design']...) from 7 documents (total 34 corpus positions)\n",
      "2019-04-24 17:01:30,971 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:30,979 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:30,982 : INFO : built Dictionary(84 unique tokens: ['announc', 'bet', 'center', 'engin', 'enhanc']...) from 10 documents (total 125 corpus positions)\n",
      "2019-04-24 17:01:30,993 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:30,996 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,002 : INFO : built Dictionary(19 unique tokens: ['abstract', 'design', 'featur', 'hand', 'learn']...) from 3 documents (total 30 corpus positions)\n",
      "2019-04-24 17:01:31,006 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:31,010 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:31,017 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,021 : INFO : built Dictionary(170 unique tokens: ['bancário', 'cartão', 'débito', 'futuro', 'mai']...) from 17 documents (total 265 corpus positions)\n",
      "2019-04-24 17:01:31,043 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,048 : INFO : built Dictionary(349 unique tokens: ['agenc', 'code', 'foreign', 'freelanc', 'practic']...) from 89 documents (total 707 corpus positions)\n",
      "2019-04-24 17:01:31,115 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,118 : INFO : built Dictionary(557 unique tokens: ['algorithm', 'aspir', 'comput', 'core', 'develop']...) from 104 documents (total 1384 corpus positions)\n",
      "2019-04-24 17:01:31,204 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,207 : INFO : built Dictionary(263 unique tokens: ['dai', 'far', 'highest', 'mortem', 'post']...) from 81 documents (total 560 corpus positions)\n",
      "2019-04-24 17:01:31,258 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,262 : INFO : built Dictionary(373 unique tokens: ['deliv', 'engin', 'melbourn', 'present', 'squiz']...) from 189 documents (total 965 corpus positions)\n",
      "2019-04-24 17:01:31,393 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,397 : INFO : built Dictionary(538 unique tokens: ['develop', 'gentlemen', 'histori', 'ladi', 'moment']...) from 181 documents (total 1634 corpus positions)\n",
      "2019-04-24 17:01:31,584 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,589 : INFO : built Dictionary(435 unique tokens: ['autom', 'design', 'graphic', 'interfac', 'open']...) from 143 documents (total 1191 corpus positions)\n",
      "2019-04-24 17:01:31,717 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,721 : INFO : built Dictionary(360 unique tokens: ['except', 'featur', 'java', 'languag', 'misus']...) from 75 documents (total 678 corpus positions)\n",
      "2019-04-24 17:01:31,770 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,774 : INFO : built Dictionary(302 unique tokens: ['blog', 'editori', 'note', 'origin', 'post']...) from 64 documents (total 534 corpus positions)\n",
      "2019-04-24 17:01:31,812 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,816 : INFO : built Dictionary(211 unique tokens: ['announc', 'busi', 'centric', 'commun', 'excit']...) from 58 documents (total 408 corpus positions)\n",
      "2019-04-24 17:01:31,847 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,851 : INFO : built Dictionary(289 unique tokens: ['particularli', 'person', 'smart', 'spot', 'desk']...) from 45 documents (total 394 corpus positions)\n",
      "2019-04-24 17:01:31,872 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,875 : INFO : built Dictionary(186 unique tokens: ['alta', 'app', 'chegou', 'class', 'compartilhada']...) from 25 documents (total 280 corpus positions)\n",
      "2019-04-24 17:01:31,897 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,902 : INFO : built Dictionary(310 unique tokens: ['chanc', 'compani', 'door', 'isn', 'slack']...) from 82 documents (total 537 corpus positions)\n",
      "2019-04-24 17:01:31,945 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:31,949 : INFO : built Dictionary(367 unique tokens: ['app', 'let', 'progress', 'talk', 'web']...) from 69 documents (total 802 corpus positions)\n",
      "2019-04-24 17:01:31,997 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:31,999 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,002 : INFO : built Dictionary(91 unique tokens: ['alphabet', 'append', 'busi', 'cfo', 'comment']...) from 5 documents (total 128 corpus positions)\n",
      "2019-04-24 17:01:32,004 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:32,013 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,017 : INFO : built Dictionary(218 unique tokens: ['answer', 'current', 'elev', 'engin', 'everest']...) from 17 documents (total 323 corpus positions)\n",
      "2019-04-24 17:01:32,028 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,031 : INFO : built Dictionary(112 unique tokens: ['arch', 'bunch', 'debian', 'distro', 'fedora']...) from 13 documents (total 160 corpus positions)\n",
      "2019-04-24 17:01:32,037 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:32,039 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,042 : INFO : built Dictionary(35 unique tokens: ['curiou', 'disabl', 'fail', 'found', 'got']...) from 6 documents (total 37 corpus positions)\n",
      "2019-04-24 17:01:32,045 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:32,048 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:32,050 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:32,063 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,067 : INFO : built Dictionary(380 unique tokens: ['dalek', 'flickr', 'sourc', 'steve', 'adapt']...) from 45 documents (total 646 corpus positions)\n",
      "2019-04-24 17:01:32,096 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,100 : INFO : built Dictionary(341 unique tokens: ['assunto', 'coitado', 'injustiçado', 'rand', 'além']...) from 62 documents (total 646 corpus positions)\n",
      "2019-04-24 17:01:32,150 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,154 : INFO : built Dictionary(486 unique tokens: ['contin', 'dai', 'feel', 'leav', 'like']...) from 108 documents (total 1137 corpus positions)\n",
      "2019-04-24 17:01:32,236 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,239 : INFO : built Dictionary(195 unique tokens: ['assess', 'compani', 'consult', 'creat', 'digit']...) from 17 documents (total 365 corpus positions)\n",
      "2019-04-24 17:01:32,256 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,260 : INFO : built Dictionary(178 unique tokens: ['android', 'app', 'compil', 'get', 'mean']...) from 21 documents (total 281 corpus positions)\n",
      "2019-04-24 17:01:32,278 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,281 : INFO : built Dictionary(177 unique tokens: ['balanc', 'choic', 'commun', 'complianc', 'develop']...) from 21 documents (total 244 corpus positions)\n",
      "2019-04-24 17:01:32,294 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:32,297 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:32,300 : INFO : built Dictionary(22 unique tokens: ['advanc', 'author', 'build', 'develop', 'drupal']...) from 3 documents (total 28 corpus positions)\n",
      "2019-04-24 17:01:32,304 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:32,307 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:32,310 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:32,331 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,338 : INFO : built Dictionary(393 unique tokens: ['acqui', 'busi', 'cloud', 'dian', 'engin']...) from 82 documents (total 771 corpus positions)\n",
      "2019-04-24 17:01:32,410 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,415 : INFO : built Dictionary(286 unique tokens: ['cenário', 'difícil', 'está', 'mundo', 'pra']...) from 46 documents (total 543 corpus positions)\n",
      "2019-04-24 17:01:32,448 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:32,451 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,454 : INFO : built Dictionary(50 unique tokens: ['da', 'próxima', 'quer', 'saber', 'turma']...) from 6 documents (total 99 corpus positions)\n",
      "2019-04-24 17:01:32,458 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:32,482 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,487 : INFO : built Dictionary(535 unique tokens: ['cadeira', 'mesa', 'que', 'acredita', 'aprend']...) from 92 documents (total 980 corpus positions)\n",
      "2019-04-24 17:01:32,551 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:32,553 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,556 : INFO : built Dictionary(44 unique tokens: ['better', 'biggest', 'conduct', 'design', 'ebook']...) from 6 documents (total 66 corpus positions)\n",
      "2019-04-24 17:01:32,559 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:32,579 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,583 : INFO : built Dictionary(411 unique tokens: ['build', 'develop', 'dynam', 'facebook', 'hacker']...) from 66 documents (total 916 corpus positions)\n",
      "2019-04-24 17:01:32,648 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,654 : INFO : built Dictionary(483 unique tokens: ['economi', 'greas', 'pave', 'place', 'share']...) from 78 documents (total 1030 corpus positions)\n",
      "2019-04-24 17:01:32,726 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,731 : INFO : built Dictionary(418 unique tokens: ['braid', 'river', 'alaska', 'flickr', 'nation']...) from 152 documents (total 1155 corpus positions)\n",
      "2019-04-24 17:01:32,846 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,848 : INFO : built Dictionary(122 unique tokens: ['alto', 'aprenda', 'com', 'como', 'crescimento']...) from 12 documents (total 176 corpus positions)\n",
      "2019-04-24 17:01:32,866 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,870 : INFO : built Dictionary(261 unique tokens: ['leo', 'london', 'man', 'name', 'septemb']...) from 67 documents (total 535 corpus positions)\n",
      "2019-04-24 17:01:32,919 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:32,924 : INFO : built Dictionary(428 unique tokens: ['adopt', 'billion', 'dai', 'download', 'enterpris']...) from 71 documents (total 913 corpus positions)\n",
      "2019-04-24 17:01:33,004 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,012 : INFO : built Dictionary(432 unique tokens: ['learn', 'machin', 'algorithm', 'code', 'custom']...) from 143 documents (total 1235 corpus positions)\n",
      "2019-04-24 17:01:33,136 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,139 : INFO : built Dictionary(499 unique tokens: ['algorithm', 'attribut', 'base', 'creat', 'estim']...) from 150 documents (total 1267 corpus positions)\n",
      "2019-04-24 17:01:33,243 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,247 : INFO : built Dictionary(413 unique tokens: ['comic', 'deep', 'famou', 'learn', 'object']...) from 144 documents (total 1187 corpus positions)\n",
      "2019-04-24 17:01:33,340 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,343 : INFO : built Dictionary(194 unique tokens: ['appeal', 'curat', 'directori', 'flipboard', 'follow']...) from 23 documents (total 283 corpus positions)\n",
      "2019-04-24 17:01:33,353 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,356 : INFO : built Dictionary(107 unique tokens: ['acaba', 'aproximação', 'aument', 'brasileiro', 'capodart']...) from 10 documents (total 127 corpus positions)\n",
      "2019-04-24 17:01:33,377 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,382 : INFO : built Dictionary(677 unique tokens: ['brasil', 'consumidor', 'do', 'financeiro', 'grand']...) from 123 documents (total 1313 corpus positions)\n",
      "2019-04-24 17:01:33,459 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,461 : INFO : built Dictionary(122 unique tokens: ['analyz', 'api', 'big', 'captur', 'combin']...) from 12 documents (total 184 corpus positions)\n",
      "2019-04-24 17:01:33,469 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,471 : INFO : built Dictionary(87 unique tokens: ['ad', 'app', 'appl', 'boost', 'card']...) from 15 documents (total 197 corpus positions)\n",
      "2019-04-24 17:01:33,489 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,493 : INFO : built Dictionary(336 unique tokens: ['access', 'ago', 'call', 'container', 'docker']...) from 66 documents (total 752 corpus positions)\n",
      "2019-04-24 17:01:33,530 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,534 : INFO : built Dictionary(181 unique tokens: ['compar', 'easi', 'iot', 'platform', 'tabl']...) from 41 documents (total 494 corpus positions)\n",
      "2019-04-24 17:01:33,561 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,565 : INFO : built Dictionary(306 unique tokens: ['look', 'shine', 'streetlight', 'big', 'darwinbel']...) from 47 documents (total 528 corpus positions)\n",
      "2019-04-24 17:01:33,587 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:33,589 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,591 : INFO : built Dictionary(88 unique tokens: ['advanc', 'apresent', 'atap', 'conferência', 'divisão']...) from 6 documents (total 99 corpus positions)\n",
      "2019-04-24 17:01:33,593 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:33,605 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,608 : INFO : built Dictionary(269 unique tokens: ['base', 'berlin', 'horizon', 'led', 'million']...) from 56 documents (total 485 corpus positions)\n",
      "2019-04-24 17:01:33,636 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,639 : INFO : built Dictionary(226 unique tokens: ['acessível', 'alternativa', 'compra', 'fev', 'gouvêa']...) from 20 documents (total 370 corpus positions)\n",
      "2019-04-24 17:01:33,657 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,660 : INFO : built Dictionary(358 unique tokens: ['acontec', 'boot', 'brasil', 'camp', 'certificação']...) from 49 documents (total 651 corpus positions)\n",
      "2019-04-24 17:01:33,687 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:33,690 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,693 : INFO : built Dictionary(50 unique tokens: ['américa', 'bem', 'começar', 'detail', 'event']...) from 4 documents (total 61 corpus positions)\n",
      "2019-04-24 17:01:33,696 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:33,699 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:33,704 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:33,707 : INFO : built Dictionary(89 unique tokens: ['confer', 'contain', 'develop', 'docker', 'ecosystem']...) from 11 documents (total 153 corpus positions)\n",
      "2019-04-24 17:01:33,719 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,723 : INFO : built Dictionary(254 unique tokens: ['app', 'call', 'chat', 'code', 'collabor']...) from 32 documents (total 437 corpus positions)\n",
      "2019-04-24 17:01:33,753 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,758 : INFO : built Dictionary(443 unique tokens: ['aw', 'bill', 'cloud', 'countri', 'expand']...) from 100 documents (total 1115 corpus positions)\n",
      "2019-04-24 17:01:33,831 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:33,833 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,835 : INFO : built Dictionary(86 unique tokens: ['account', 'admin', 'app', 'concern', 'employe']...) from 9 documents (total 133 corpus positions)\n",
      "2019-04-24 17:01:33,838 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:33,847 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,850 : INFO : built Dictionary(176 unique tokens: ['benefit', 'build', 'distribut', 'ensur', 'evenli']...) from 25 documents (total 262 corpus positions)\n",
      "2019-04-24 17:01:33,864 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,867 : INFO : built Dictionary(186 unique tokens: ['ano', 'até', 'bitcoin', 'blockchain', 'bradesco']...) from 23 documents (total 305 corpus positions)\n",
      "2019-04-24 17:01:33,889 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,893 : INFO : built Dictionary(307 unique tokens: ['confus', 'creat', 'experi', 'flawless', 'greater']...) from 53 documents (total 568 corpus positions)\n",
      "2019-04-24 17:01:33,923 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,926 : INFO : built Dictionary(167 unique tokens: ['junho', 'lgbt', 'mundial', 'mê', 'não']...) from 11 documents (total 229 corpus positions)\n",
      "2019-04-24 17:01:33,935 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,938 : INFO : built Dictionary(77 unique tokens: ['custom', 'enabl', 'encourag', 'intercom', 'mode']...) from 23 documents (total 179 corpus positions)\n",
      "2019-04-24 17:01:33,954 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,958 : INFO : built Dictionary(389 unique tokens: ['alta', 'ambição', 'carreira', 'claro', 'confiança']...) from 45 documents (total 653 corpus positions)\n",
      "2019-04-24 17:01:33,991 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:33,994 : INFO : built Dictionary(237 unique tokens: ['address', 'appl', 'confer', 'develop', 'keynot']...) from 49 documents (total 460 corpus positions)\n",
      "2019-04-24 17:01:34,028 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,033 : INFO : built Dictionary(567 unique tokens: ['cansei', 'lero', 'carvalho', 'lee', 'licença']...) from 113 documents (total 1043 corpus positions)\n",
      "2019-04-24 17:01:34,104 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,107 : INFO : built Dictionary(324 unique tokens: ['championship', 'lucki', 'prepar', 'scan', 'supercomput']...) from 35 documents (total 537 corpus positions)\n",
      "2019-04-24 17:01:34,128 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,131 : INFO : built Dictionary(150 unique tokens: ['aim', 'best', 'ceil', 'chanc', 'dai']...) from 19 documents (total 222 corpus positions)\n",
      "2019-04-24 17:01:34,141 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,144 : INFO : built Dictionary(68 unique tokens: ['chip', 'commun', 'contribut', 'esp', 'hacker']...) from 15 documents (total 88 corpus positions)\n",
      "2019-04-24 17:01:34,156 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,159 : INFO : built Dictionary(283 unique tokens: ['beta', 'brasil', 'celular', 'chegando', 'está']...) from 29 documents (total 502 corpus positions)\n",
      "2019-04-24 17:01:34,180 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,183 : INFO : built Dictionary(226 unique tokens: ['banco', 'bastant', 'certo', 'deve', 'digitai']...) from 36 documents (total 383 corpus positions)\n",
      "2019-04-24 17:01:34,205 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,208 : INFO : built Dictionary(224 unique tokens: ['backlog', 'busi', 'career', 'expens', 'featur']...) from 45 documents (total 367 corpus positions)\n",
      "2019-04-24 17:01:34,225 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,228 : INFO : built Dictionary(120 unique tokens: ['code', 'easi', 'learn', 'sai', 'stop']...) from 44 documents (total 173 corpus positions)\n",
      "2019-04-24 17:01:34,240 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,242 : INFO : built Dictionary(97 unique tokens: ['banco', 'dará', 'distribuidor', 'do', 'grand']...) from 13 documents (total 137 corpus positions)\n",
      "2019-04-24 17:01:34,252 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,255 : INFO : built Dictionary(193 unique tokens: ['açúcar', 'cana', 'canavieira', 'centro', 'ctc']...) from 22 documents (total 308 corpus positions)\n",
      "2019-04-24 17:01:34,271 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,274 : INFO : built Dictionary(185 unique tokens: ['announc', 'cloud', 'educ', 'excit', 'faculti']...) from 25 documents (total 310 corpus positions)\n",
      "2019-04-24 17:01:34,294 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,298 : INFO : built Dictionary(321 unique tokens: ['artifici', 'call', 'code', 'confer', 'founder']...) from 39 documents (total 584 corpus positions)\n",
      "2019-04-24 17:01:34,314 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:34,317 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,318 : INFO : built Dictionary(21 unique tokens: ['acquir', 'agreement', 'enter', 'excit', 'fiber']...) from 2 documents (total 27 corpus positions)\n",
      "2019-04-24 17:01:34,321 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:34,324 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:34,326 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:34,331 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:34,337 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,340 : INFO : built Dictionary(127 unique tokens: ['analyst', 'busi', 'cloud', 'credit', 'crest']...) from 8 documents (total 171 corpus positions)\n",
      "2019-04-24 17:01:34,343 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:34,352 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,355 : INFO : built Dictionary(184 unique tokens: ['aliada', 'client', 'com', 'comercialização', 'como']...) from 23 documents (total 301 corpus positions)\n",
      "2019-04-24 17:01:34,370 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,374 : INFO : built Dictionary(198 unique tokens: ['apontado', 'como', 'est', 'line', 'lucrativo']...) from 19 documents (total 347 corpus positions)\n",
      "2019-04-24 17:01:34,394 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,398 : INFO : built Dictionary(248 unique tokens: ['handshak', 'happen', 'hug', 'kiss', 'mayb']...) from 29 documents (total 454 corpus positions)\n",
      "2019-04-24 17:01:34,416 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:34,418 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,421 : INFO : built Dictionary(65 unique tokens: ['global', 'googl', 'learn', 'machin', 'photo']...) from 5 documents (total 87 corpus positions)\n",
      "2019-04-24 17:01:34,423 : WARNING : Input corpus is expected to have at least 10 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:34,435 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,440 : INFO : built Dictionary(184 unique tokens: ['api', 'awesom', 'biggest', 'button', 'capabl']...) from 29 documents (total 319 corpus positions)\n",
      "2019-04-24 17:01:34,462 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,465 : INFO : built Dictionary(241 unique tokens: ['aceleradora', 'américa', 'da', 'divulgamo', 'fundac']...) from 24 documents (total 493 corpus positions)\n",
      "2019-04-24 17:01:34,480 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,483 : INFO : built Dictionary(157 unique tokens: ['brasil', 'da', 'deverá', 'empresa', 'está']...) from 18 documents (total 235 corpus positions)\n",
      "2019-04-24 17:01:34,498 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,502 : INFO : built Dictionary(210 unique tokens: ['achiev', 'brand', 'client', 'consult', 'design']...) from 43 documents (total 374 corpus positions)\n",
      "2019-04-24 17:01:34,574 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:34,580 : INFO : built Dictionary(825 unique tokens: ['algorithm', 'factor', 'googl', 'know', 'probabl']...) from 319 documents (total 3280 corpus positions)\n",
      "2019-04-24 17:01:35,134 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:35,137 : INFO : built Dictionary(244 unique tokens: ['announc', 'eclips', 'eponym', 'fortran', 'foundat']...) from 37 documents (total 452 corpus positions)\n",
      "2019-04-24 17:01:35,156 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:35,159 : INFO : built Dictionary(191 unique tokens: ['algorithm', 'best', 'bit', 'camera', 'come']...) from 19 documents (total 248 corpus positions)\n",
      "2019-04-24 17:01:35,168 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:35,171 : INFO : built Dictionary(104 unique tokens: ['databas', 'datagrip', 'develop', 'id', 'meet']...) from 13 documents (total 148 corpus positions)\n",
      "2019-04-24 17:01:35,183 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:35,187 : INFO : built Dictionary(230 unique tokens: ['agiliza', 'contratação', 'diverso', 'facilita', 'gestor']...) from 17 documents (total 333 corpus positions)\n",
      "2019-04-24 17:01:35,201 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:35,204 : INFO : built Dictionary(157 unique tokens: ['abril', 'antiga', 'dgb', 'distribuição', 'express']...) from 13 documents (total 233 corpus positions)\n",
      "2019-04-24 17:01:35,227 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:35,232 : INFO : built Dictionary(469 unique tokens: ['abl', 'agent', 'air', 'antediluvian', 'bid']...) from 93 documents (total 1058 corpus positions)\n",
      "2019-04-24 17:01:35,293 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:35,296 : INFO : built Dictionary(374 unique tokens: ['expand', 'follow', 'knowledg', 'mind', 'opportun']...) from 55 documents (total 638 corpus positions)\n",
      "2019-04-24 17:01:35,329 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:35,333 : INFO : built Dictionary(353 unique tokens: ['agent', 'altern', 'differ', 'figur', 'flight']...) from 52 documents (total 612 corpus positions)\n",
      "2019-04-24 17:01:35,394 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:35,401 : INFO : built Dictionary(1245 unique tokens: ['acident', 'atividad', 'como', 'condiçõ', 'consequência']...) from 121 documents (total 3700 corpus positions)\n",
      "2019-04-24 17:01:35,655 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:35,662 : INFO : built Dictionary(960 unique tokens: ['aberta', 'algun', 'como', 'comparativament', 'complementar']...) from 69 documents (total 2500 corpus positions)\n",
      "2019-04-24 17:01:35,757 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:35,760 : INFO : built Dictionary(160 unique tokens: ['ano', 'capitalização', 'frança', 'mai', 'surgiram']...) from 15 documents (total 238 corpus positions)\n",
      "2019-04-24 17:01:35,769 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:35,771 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:35,774 : INFO : built Dictionary(47 unique tokens: ['como', 'englobar', 'microsseguro', 'nunca', 'para']...) from 2 documents (total 51 corpus positions)\n",
      "2019-04-24 17:01:35,777 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:35,779 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:35,782 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:35,834 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:35,844 : INFO : built Dictionary(1237 unique tokens: ['ao', 'dia', 'famoso', 'mercado', 'prodigioso']...) from 239 documents (total 3881 corpus positions)\n",
      "2019-04-24 17:01:36,463 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,468 : INFO : built Dictionary(309 unique tokens: ['began', 'exec', 'facebook', 'found', 'photo']...) from 55 documents (total 496 corpus positions)\n",
      "2019-04-24 17:01:36,526 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,531 : INFO : built Dictionary(485 unique tokens: ['compani', 'focu', 'great', 'realign', 'success']...) from 111 documents (total 1085 corpus positions)\n",
      "2019-04-24 17:01:36,621 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,625 : INFO : built Dictionary(267 unique tokens: ['digit', 'enterpris', 'establish', 'facebook', 'post']...) from 37 documents (total 410 corpus positions)\n",
      "2019-04-24 17:01:36,658 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,662 : INFO : built Dictionary(356 unique tokens: ['big', 'bui', 'deploi', 'enterpris', 'happen']...) from 63 documents (total 664 corpus positions)\n",
      "2019-04-24 17:01:36,704 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,708 : INFO : built Dictionary(121 unique tokens: ['assum', 'catch', 'robot', 'sitcom', 'slack']...) from 17 documents (total 165 corpus positions)\n",
      "2019-04-24 17:01:36,724 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,727 : INFO : built Dictionary(370 unique tokens: ['benefit', 'familiar', 'fear', 'job', 'machin']...) from 40 documents (total 503 corpus positions)\n",
      "2019-04-24 17:01:36,747 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,750 : INFO : built Dictionary(113 unique tokens: ['app', 'applic', 'browser', 'busi', 'expens']...) from 16 documents (total 187 corpus positions)\n",
      "2019-04-24 17:01:36,764 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,768 : INFO : built Dictionary(315 unique tokens: ['accord', 'artifici', 'attract', 'bostrom', 'confer']...) from 38 documents (total 462 corpus positions)\n",
      "2019-04-24 17:01:36,785 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:36,788 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,790 : INFO : built Dictionary(66 unique tokens: ['cours', 'field', 'introduct', 'languag', 'natur']...) from 8 documents (total 113 corpus positions)\n",
      "2019-04-24 17:01:36,793 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:36,800 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,803 : INFO : built Dictionary(155 unique tokens: ['anunciant', 'apresent', 'cann', 'compartilhamento', 'conteúdo']...) from 14 documents (total 235 corpus positions)\n",
      "2019-04-24 17:01:36,820 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,824 : INFO : built Dictionary(291 unique tokens: ['app', 'book', 'intrepid', 'introduc', 'journei']...) from 82 documents (total 557 corpus positions)\n",
      "2019-04-24 17:01:36,864 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,867 : INFO : built Dictionary(235 unique tokens: ['agricultura', 'contribuiçõ', 'divulgação', 'estratégico', 'estudo']...) from 17 documents (total 354 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:36,878 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,881 : INFO : built Dictionary(181 unique tokens: ['ano', 'casual', 'cia', 'da', 'empresa']...) from 12 documents (total 253 corpus positions)\n",
      "2019-04-24 17:01:36,892 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,895 : INFO : built Dictionary(260 unique tokens: ['apesar', 'apoiass', 'apoio', 'arrast', 'bissexuai']...) from 30 documents (total 438 corpus positions)\n",
      "2019-04-24 17:01:36,937 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:36,945 : INFO : built Dictionary(573 unique tokens: ['announc', 'asp', 'avail', 'core', 'entiti']...) from 199 documents (total 1869 corpus positions)\n",
      "2019-04-24 17:01:37,190 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,193 : INFO : built Dictionary(89 unique tokens: ['coupl', 'finish', 'method', 'part', 'pla']...) from 14 documents (total 146 corpus positions)\n",
      "2019-04-24 17:01:37,219 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,224 : INFO : built Dictionary(415 unique tokens: ['amin', 'anim', 'bernard', 'dana', 'design']...) from 116 documents (total 899 corpus positions)\n",
      "2019-04-24 17:01:37,320 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,324 : INFO : built Dictionary(343 unique tokens: ['amaz', 'app', 'applic', 'build', 'help']...) from 113 documents (total 997 corpus positions)\n",
      "2019-04-24 17:01:37,424 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,430 : INFO : built Dictionary(462 unique tokens: ['convolut', 'deep', 'interest', 'learn', 'network']...) from 128 documents (total 1179 corpus positions)\n",
      "2019-04-24 17:01:37,551 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,555 : INFO : built Dictionary(234 unique tokens: ['anymor', 'code', 'isn', 'microsoft', 'offici']...) from 41 documents (total 520 corpus positions)\n",
      "2019-04-24 17:01:37,580 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,582 : INFO : built Dictionary(69 unique tokens: ['build', 'devic', 'engin', 'mobil', 'pete']...) from 12 documents (total 102 corpus positions)\n",
      "2019-04-24 17:01:37,596 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,600 : INFO : built Dictionary(254 unique tokens: ['articl', 'blog', 'crunch', 'futur', 'java']...) from 61 documents (total 553 corpus positions)\n",
      "2019-04-24 17:01:37,634 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:37,637 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,639 : INFO : built Dictionary(90 unique tokens: ['android', 'devic', 'find', 'framework', 'googl']...) from 8 documents (total 129 corpus positions)\n",
      "2019-04-24 17:01:37,642 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:37,650 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,653 : INFO : built Dictionary(132 unique tokens: ['announc', 'api', 'app', 'awar', 'bhavik']...) from 15 documents (total 232 corpus positions)\n",
      "2019-04-24 17:01:37,663 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,666 : INFO : built Dictionary(138 unique tokens: ['captur', 'durant', 'escuro', 'hubbl', 'imagen']...) from 12 documents (total 203 corpus positions)\n",
      "2019-04-24 17:01:37,675 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,678 : INFO : built Dictionary(122 unique tokens: ['boil', 'emot', 'human', 'augment', 'button']...) from 23 documents (total 211 corpus positions)\n",
      "2019-04-24 17:01:37,693 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,697 : INFO : built Dictionary(206 unique tokens: ['ant', 'descobriram', 'desconhecido', 'expressão', 'matemático']...) from 27 documents (total 375 corpus positions)\n",
      "2019-04-24 17:01:37,714 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,717 : INFO : built Dictionary(111 unique tokens: ['account', 'angel', 'autom', 'busi', 'cherri']...) from 11 documents (total 149 corpus positions)\n",
      "2019-04-24 17:01:37,736 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,741 : INFO : built Dictionary(411 unique tokens: ['chang', 'effort', 'fail', 'research', 'tell']...) from 58 documents (total 747 corpus positions)\n",
      "2019-04-24 17:01:37,784 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:37,789 : INFO : built Dictionary(453 unique tokens: ['alguma', 'biblioteca', 'carregamento', 'imagem', 'no']...) from 71 documents (total 959 corpus positions)\n",
      "2019-04-24 17:01:38,026 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,030 : INFO : built Dictionary(330 unique tokens: ['gui', 'kei', 'know', 'look', 'stori']...) from 46 documents (total 533 corpus positions)\n",
      "2019-04-24 17:01:38,048 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:38,051 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,053 : INFO : built Dictionary(43 unique tokens: ['accept', 'appl', 'balanc', 'card', 'channel']...) from 4 documents (total 73 corpus positions)\n",
      "2019-04-24 17:01:38,056 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:38,059 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:38,078 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,082 : INFO : built Dictionary(509 unique tokens: ['chernobyl', 'complet', 'discov', 'dishwash', 'engross']...) from 85 documents (total 990 corpus positions)\n",
      "2019-04-24 17:01:38,137 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:38,139 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,141 : INFO : built Dictionary(69 unique tokens: ['bank', 'brazilian', 'consortium', 'distribut', 'institut']...) from 5 documents (total 90 corpus positions)\n",
      "2019-04-24 17:01:38,143 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:38,152 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,155 : INFO : built Dictionary(215 unique tokens: ['até', 'conhecem', 'famoso', 'forma', 'huehuehu']...) from 44 documents (total 345 corpus positions)\n",
      "2019-04-24 17:01:38,179 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,183 : INFO : built Dictionary(334 unique tokens: ['ask', 'bot', 'coffe', 'month', 'past']...) from 72 documents (total 576 corpus positions)\n",
      "2019-04-24 17:01:38,217 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,221 : INFO : built Dictionary(128 unique tokens: ['banco', 'brasileiro', 'commerc', 'dado', 'digit']...) from 12 documents (total 248 corpus positions)\n",
      "2019-04-24 17:01:38,232 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,236 : INFO : built Dictionary(97 unique tokens: ['artigo', 'brasileiro', 'esportivo', 'foi', 'grand']...) from 10 documents (total 126 corpus positions)\n",
      "2019-04-24 17:01:38,259 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,264 : INFO : built Dictionary(509 unique tokens: ['bori', 'confer', 'phone', 'robot', 'room']...) from 103 documents (total 985 corpus positions)\n",
      "2019-04-24 17:01:38,349 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,353 : INFO : built Dictionary(210 unique tokens: ['accomplish', 'confer', 'googl', 'la', 'pattern']...) from 30 documents (total 312 corpus positions)\n",
      "2019-04-24 17:01:38,371 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:38,373 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,376 : INFO : built Dictionary(106 unique tokens: ['ag', 'ask', 'experi', 'googl', 'grand']...) from 9 documents (total 131 corpus positions)\n",
      "2019-04-24 17:01:38,379 : WARNING : Input corpus is expected to have at least 10 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:38,395 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,400 : INFO : built Dictionary(381 unique tokens: ['certo', 'duvido', 'estou', 'ma', 'não']...) from 81 documents (total 823 corpus positions)\n",
      "2019-04-24 17:01:38,462 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,466 : INFO : built Dictionary(458 unique tokens: ['sens', 'center', 'come', 'compani', 'custom']...) from 103 documents (total 1059 corpus positions)\n",
      "2019-04-24 17:01:38,541 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,544 : INFO : built Dictionary(295 unique tokens: ['pensou', 'pep', 'ter', 'você', 'estratégico']...) from 21 documents (total 491 corpus positions)\n",
      "2019-04-24 17:01:38,586 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,591 : INFO : built Dictionary(781 unique tokens: ['begin', 'good', 'hash', 'password', 'algorithm']...) from 203 documents (total 2088 corpus positions)\n",
      "2019-04-24 17:01:38,827 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,831 : INFO : built Dictionary(197 unique tokens: ['applic', 'build', 'complex', 'group', 'place']...) from 72 documents (total 665 corpus positions)\n",
      "2019-04-24 17:01:38,888 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,892 : INFO : built Dictionary(414 unique tokens: ['advantag', 'autonom', 'best', 'car', 'choos']...) from 57 documents (total 802 corpus positions)\n",
      "2019-04-24 17:01:38,933 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,936 : INFO : built Dictionary(369 unique tokens: ['auto', 'car', 'figur', 'gener', 'head']...) from 46 documents (total 635 corpus positions)\n",
      "2019-04-24 17:01:38,964 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:38,966 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,968 : INFO : built Dictionary(99 unique tokens: ['acontec', 'codahal', 'com', 'código', 'descubra']...) from 8 documents (total 123 corpus positions)\n",
      "2019-04-24 17:01:38,971 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:38,978 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:38,981 : INFO : built Dictionary(127 unique tokens: ['acaba', 'commerc', 'como', 'digit', 'melhor']...) from 10 documents (total 172 corpus positions)\n",
      "2019-04-24 17:01:39,002 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,005 : INFO : built Dictionary(332 unique tokens: ['anim', 'appli', 'artist', 'brain', 'break']...) from 48 documents (total 588 corpus positions)\n",
      "2019-04-24 17:01:39,040 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,043 : INFO : built Dictionary(239 unique tokens: ['aren', 'bot', 'bright', 'learn', 'thing']...) from 26 documents (total 404 corpus positions)\n",
      "2019-04-24 17:01:39,071 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,075 : INFO : built Dictionary(409 unique tokens: ['acquisit', 'billion', 'deal', 'describ', 'gerard']...) from 100 documents (total 884 corpus positions)\n",
      "2019-04-24 17:01:39,133 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,137 : INFO : built Dictionary(140 unique tokens: ['bilhõ', 'cerca', 'com', 'comércio', 'crescent']...) from 10 documents (total 204 corpus positions)\n",
      "2019-04-24 17:01:39,145 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,148 : INFO : built Dictionary(131 unique tokens: ['chatbot', 'donotpai', 'free', 'lawyer', 'london']...) from 10 documents (total 167 corpus positions)\n",
      "2019-04-24 17:01:39,160 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,163 : INFO : built Dictionary(239 unique tokens: ['aplicação', 'arquitetura', 'básico', 'decisõ', 'desenvolvimento']...) from 17 documents (total 402 corpus positions)\n",
      "2019-04-24 17:01:39,174 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:39,176 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,179 : INFO : built Dictionary(86 unique tokens: ['aplicativo', 'celular', 'important', 'instalado', 'mai']...) from 9 documents (total 114 corpus positions)\n",
      "2019-04-24 17:01:39,182 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:39,188 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:39,190 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,193 : INFO : built Dictionary(62 unique tokens: ['build', 'child', 'compani', 'educ', 'fun']...) from 6 documents (total 73 corpus positions)\n",
      "2019-04-24 17:01:39,195 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:39,201 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:39,204 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,207 : INFO : built Dictionary(75 unique tokens: ['agora', 'ant', 'baunilha', 'brasil', 'cereja']...) from 8 documents (total 97 corpus positions)\n",
      "2019-04-24 17:01:39,209 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:39,216 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:39,218 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,221 : INFO : built Dictionary(68 unique tokens: ['america', 'bank', 'countri', 'expect', 'latin']...) from 8 documents (total 92 corpus positions)\n",
      "2019-04-24 17:01:39,223 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:39,231 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,233 : INFO : built Dictionary(102 unique tokens: ['activ', 'build', 'commun', 'creat', 'data']...) from 10 documents (total 156 corpus positions)\n",
      "2019-04-24 17:01:39,241 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,245 : INFO : built Dictionary(128 unique tokens: ['adob', 'automat', 'chines', 'futur', 'hong']...) from 12 documents (total 176 corpus positions)\n",
      "2019-04-24 17:01:39,257 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,260 : INFO : built Dictionary(211 unique tokens: ['drupal', 'evok', 'feel', 'complex', 'flexibl']...) from 39 documents (total 352 corpus positions)\n",
      "2019-04-24 17:01:39,307 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,312 : INFO : built Dictionary(587 unique tokens: ['citi', 'engin', 'leader', 'live', 'mike']...) from 154 documents (total 1692 corpus positions)\n",
      "2019-04-24 17:01:39,453 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:39,455 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,457 : INFO : built Dictionary(111 unique tokens: ['acordo', 'apena', 'busca', 'com', 'está']...) from 7 documents (total 150 corpus positions)\n",
      "2019-04-24 17:01:39,460 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:39,468 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,471 : INFO : built Dictionary(153 unique tokens: ['bigqueri', 'collabor', 'dataset', 'github', 'googl']...) from 33 documents (total 252 corpus positions)\n",
      "2019-04-24 17:01:39,495 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,499 : INFO : built Dictionary(265 unique tokens: ['announc', 'api', 'backend', 'com', 'commun']...) from 80 documents (total 795 corpus positions)\n",
      "2019-04-24 17:01:39,542 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:39,544 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,547 : INFO : built Dictionary(96 unique tokens: ['agência', 'artesp', 'da', 'dia', 'estado']...) from 9 documents (total 128 corpus positions)\n",
      "2019-04-24 17:01:39,548 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:39,555 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:39,557 : INFO : built Dictionary(89 unique tokens: ['explain', 'japanes', 'link', 'littl', 'need']...) from 22 documents (total 143 corpus positions)\n",
      "2019-04-24 17:01:39,584 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,589 : INFO : built Dictionary(732 unique tokens: ['great', 'write', 'content', 'acceler', 'ad']...) from 120 documents (total 1259 corpus positions)\n",
      "2019-04-24 17:01:39,671 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,674 : INFO : built Dictionary(317 unique tokens: ['develop', 'hybrid', 'mobil', 'present', 'year']...) from 95 documents (total 691 corpus positions)\n",
      "2019-04-24 17:01:39,719 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:39,721 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,723 : INFO : built Dictionary(42 unique tokens: ['adob', 'aem', 'ask', 'commun', 'develop']...) from 7 documents (total 72 corpus positions)\n",
      "2019-04-24 17:01:39,725 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:39,758 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:39,764 : INFO : built Dictionary(701 unique tokens: ['difficult', 'easi', 'infinit', 'javascript', 'languag']...) from 270 documents (total 1897 corpus positions)\n",
      "2019-04-24 17:01:40,014 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,016 : INFO : built Dictionary(156 unique tokens: ['criou', 'dele', 'direção', 'echo', 'encaixar']...) from 11 documents (total 227 corpus positions)\n",
      "2019-04-24 17:01:40,026 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,029 : INFO : built Dictionary(217 unique tokens: ['artifici', 'caça', 'combat', 'criado', 'derrot']...) from 17 documents (total 349 corpus positions)\n",
      "2019-04-24 17:01:40,039 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:40,041 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,043 : INFO : built Dictionary(42 unique tokens: ['brasil', 'costumamo', 'cultur', 'exaltar', 'pluralidad']...) from 2 documents (total 46 corpus positions)\n",
      "2019-04-24 17:01:40,046 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:40,048 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:40,050 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:40,077 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,084 : INFO : built Dictionary(623 unique tokens: ['dai', 'internet', 'januari', 'time', 'wast']...) from 134 documents (total 1466 corpus positions)\n",
      "2019-04-24 17:01:40,181 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:40,183 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,185 : INFO : built Dictionary(55 unique tokens: ['belief', 'come', 'disabl', 'especi', 'examin']...) from 8 documents (total 61 corpus positions)\n",
      "2019-04-24 17:01:40,187 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:40,192 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:40,194 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,196 : INFO : built Dictionary(61 unique tokens: ['art', 'creativ', 'disabl', 'edg', 'frontier']...) from 8 documents (total 67 corpus positions)\n",
      "2019-04-24 17:01:40,198 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:40,213 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,216 : INFO : built Dictionary(321 unique tokens: ['brazil', 'compani', 'divers', 'encourag', 'great']...) from 64 documents (total 519 corpus positions)\n",
      "2019-04-24 17:01:40,246 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,249 : INFO : built Dictionary(169 unique tokens: ['bank', 'big', 'card', 'compani', 'credit']...) from 19 documents (total 235 corpus positions)\n",
      "2019-04-24 17:01:40,268 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,272 : INFO : built Dictionary(362 unique tokens: ['aconteceu', 'bairro', 'build', 'campu', 'commun']...) from 42 documents (total 780 corpus positions)\n",
      "2019-04-24 17:01:40,308 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,312 : INFO : built Dictionary(478 unique tokens: ['agricultur', 'farm', 'indiana', 'industri', 'infanc']...) from 56 documents (total 875 corpus positions)\n",
      "2019-04-24 17:01:40,350 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,354 : INFO : built Dictionary(373 unique tokens: ['agricultor', 'ajudar', 'aliado', 'brasil', 'brasileiro']...) from 42 documents (total 631 corpus positions)\n",
      "2019-04-24 17:01:40,376 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,379 : INFO : built Dictionary(87 unique tokens: ['achiev', 'ag', 'ago', 'churyumov', 'comet']...) from 11 documents (total 118 corpus positions)\n",
      "2019-04-24 17:01:40,386 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:40,388 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,391 : INFO : built Dictionary(98 unique tokens: ['anunci', 'aplicativo', 'brasil', 'com', 'conteúdo']...) from 9 documents (total 118 corpus positions)\n",
      "2019-04-24 17:01:40,393 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:40,401 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,404 : INFO : built Dictionary(137 unique tokens: ['caso', 'como', 'da', 'dia', 'dinheiro']...) from 12 documents (total 213 corpus positions)\n",
      "2019-04-24 17:01:40,414 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,417 : INFO : built Dictionary(58 unique tokens: ['cloud', 'code', 'debugg', 'file', 'googl']...) from 11 documents (total 101 corpus positions)\n",
      "2019-04-24 17:01:40,432 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,435 : INFO : built Dictionary(199 unique tokens: ['mediacurr', 'secur', 'serious', 'websit', 'api']...) from 44 documents (total 472 corpus positions)\n",
      "2019-04-24 17:01:40,474 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,478 : INFO : built Dictionary(461 unique tokens: ['advent', 'applic', 'content', 'core', 'data']...) from 79 documents (total 1116 corpus positions)\n",
      "2019-04-24 17:01:40,545 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,548 : INFO : built Dictionary(263 unique tokens: ['aiaz', 'ecosystem', 'futur', 'googl', 'got']...) from 52 documents (total 457 corpus positions)\n",
      "2019-04-24 17:01:40,575 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,578 : INFO : built Dictionary(182 unique tokens: ['aren', 'begin', 'drupal', 'instal', 'load']...) from 61 documents (total 440 corpus positions)\n",
      "2019-04-24 17:01:40,604 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,607 : INFO : built Dictionary(108 unique tokens: ['amazon', 'announc', 'applic', 'avail', 'beta']...) from 14 documents (total 178 corpus positions)\n",
      "2019-04-24 17:01:40,617 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,620 : INFO : built Dictionary(122 unique tokens: ['allow', 'apart', 'bigqueri', 'cloud', 'data']...) from 14 documents (total 177 corpus positions)\n",
      "2019-04-24 17:01:40,639 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,642 : INFO : built Dictionary(313 unique tokens: ['api', 'build', 'microservic', 'want', 'compon']...) from 94 documents (total 731 corpus positions)\n",
      "2019-04-24 17:01:40,700 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,704 : INFO : built Dictionary(335 unique tokens: ['harder', 'instead', 'smarter', 'uncommon', 'wai']...) from 123 documents (total 599 corpus positions)\n",
      "2019-04-24 17:01:40,757 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:40,760 : INFO : built Dictionary(299 unique tokens: ['ago', 'amazon', 'arm', 'aw', 'busi']...) from 44 documents (total 600 corpus positions)\n",
      "2019-04-24 17:01:40,790 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,794 : INFO : built Dictionary(400 unique tokens: ['chegado', 'combinar', 'conversa', 'da', 'depoi']...) from 45 documents (total 702 corpus positions)\n",
      "2019-04-24 17:01:40,822 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,824 : INFO : built Dictionary(50 unique tokens: ['brain', 'come', 'new', 'program', 'sharpen']...) from 12 documents (total 61 corpus positions)\n",
      "2019-04-24 17:01:40,831 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,833 : INFO : built Dictionary(128 unique tokens: ['até', 'boa', 'carteira', 'com', 'da']...) from 11 documents (total 163 corpus positions)\n",
      "2019-04-24 17:01:40,842 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:40,845 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,848 : INFO : built Dictionary(111 unique tokens: ['banker', 'car', 'crash', 'davi', 'gyllenha']...) from 8 documents (total 127 corpus positions)\n",
      "2019-04-24 17:01:40,850 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:40,860 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,864 : INFO : built Dictionary(208 unique tokens: ['accentur', 'citi', 'content', 'creat', 'deliv']...) from 20 documents (total 410 corpus positions)\n",
      "2019-04-24 17:01:40,874 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:40,876 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,879 : INFO : built Dictionary(56 unique tokens: ['com', 'combinar', 'compra', 'consultar', 'devolvemo']...) from 7 documents (total 93 corpus positions)\n",
      "2019-04-24 17:01:40,881 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:40,888 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,891 : INFO : built Dictionary(88 unique tokens: ['com', 'compra', 'devolvemo', 'dinheiro', 'esperando']...) from 15 documents (total 142 corpus positions)\n",
      "2019-04-24 17:01:40,899 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:40,902 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,905 : INFO : built Dictionary(76 unique tokens: ['aren', 'artifici', 'attempt', 'come', 'law']...) from 7 documents (total 104 corpus positions)\n",
      "2019-04-24 17:01:40,908 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:40,915 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,918 : INFO : built Dictionary(92 unique tokens: ['bandwidth', 'big', 'cloud', 'cover', 'data']...) from 11 documents (total 127 corpus positions)\n",
      "2019-04-24 17:01:40,932 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,935 : INFO : built Dictionary(240 unique tokens: ['além', 'ampliação', 'açúcar', 'cachoeirinha', 'cd']...) from 23 documents (total 432 corpus positions)\n",
      "2019-04-24 17:01:40,950 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:40,954 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,957 : INFO : built Dictionary(37 unique tokens: ['abordando', 'adotado', 'américa', 'api', 'com']...) from 2 documents (total 40 corpus positions)\n",
      "2019-04-24 17:01:40,959 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:40,962 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:40,964 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:40,982 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:40,986 : INFO : built Dictionary(391 unique tokens: ['activ', 'core', 'creat', 'data', 'gener']...) from 86 documents (total 897 corpus positions)\n",
      "2019-04-24 17:01:41,060 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:41,064 : INFO : built Dictionary(183 unique tokens: ['combin', 'fit', 'know', 'look', 'market']...) from 34 documents (total 306 corpus positions)\n",
      "2019-04-24 17:01:41,078 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:41,081 : INFO : built Dictionary(69 unique tokens: ['acoust', 'begin', 'cours', 'electr', 'essenti']...) from 10 documents (total 111 corpus positions)\n",
      "2019-04-24 17:01:41,099 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:41,103 : INFO : built Dictionary(386 unique tokens: ['aki', 'datta', 'dekiru', 'hazu', 'kare']...) from 133 documents (total 786 corpus positions)\n",
      "2019-04-24 17:01:41,203 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:41,207 : INFO : built Dictionary(351 unique tokens: ['brennan', 'chaotic', 'compani', 'environ', 'framework']...) from 85 documents (total 695 corpus positions)\n",
      "2019-04-24 17:01:41,255 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:41,258 : INFO : built Dictionary(354 unique tokens: ['agent', 'call', 'chatbot', 'convers', 'dialog']...) from 85 documents (total 813 corpus positions)\n",
      "2019-04-24 17:01:41,321 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:41,325 : INFO : built Dictionary(452 unique tokens: ['base', 'bot', 'implement', 'post', 'retriev']...) from 169 documents (total 1449 corpus positions)\n",
      "2019-04-24 17:01:41,443 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:41,446 : INFO : built Dictionary(50 unique tokens: ['busi', 'campaign', 'experi', 'innov', 'market']...) from 10 documents (total 65 corpus positions)\n",
      "2019-04-24 17:01:41,451 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:41,452 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:41,454 : INFO : built Dictionary(25 unique tokens: ['best', 'corpor', 'culturev', 'deliv', 'experi']...) from 2 documents (total 34 corpus positions)\n",
      "2019-04-24 17:01:41,456 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:41,458 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:41,460 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:41,476 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:41,480 : INFO : built Dictionary(465 unique tokens: ['abil', 'follow', 'increas', 'industri', 'overal']...) from 95 documents (total 896 corpus positions)\n",
      "2019-04-24 17:01:41,531 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:41,534 : INFO : built Dictionary(107 unique tokens: ['ago', 'autom', 'start', 'talk', 'test']...) from 25 documents (total 169 corpus positions)\n",
      "2019-04-24 17:01:41,578 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:41,585 : INFO : built Dictionary(707 unique tokens: ['creat', 'foundat', 'hiragana', 'japanes', 'learn']...) from 437 documents (total 2300 corpus positions)\n",
      "2019-04-24 17:01:42,111 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:42,114 : INFO : built Dictionary(177 unique tokens: ['api', 'code', 'date', 'introduc', 'java']...) from 30 documents (total 380 corpus positions)\n",
      "2019-04-24 17:01:42,131 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:42,133 : INFO : built Dictionary(168 unique tokens: ['accur', 'doc', 'document', 'gener', 'readabl']...) from 36 documents (total 453 corpus positions)\n",
      "2019-04-24 17:01:42,153 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:42,156 : INFO : built Dictionary(163 unique tokens: ['album', 'allow', 'base', 'fail', 'famili']...) from 15 documents (total 225 corpus positions)\n",
      "2019-04-24 17:01:42,167 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:42,169 : INFO : built Dictionary(137 unique tokens: ['aggress', 'aim', 'amazon', 'applic', 'cloud']...) from 17 documents (total 215 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:42,183 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:42,187 : INFO : built Dictionary(247 unique tokens: ['faz', 'funcionar', 'okr', 'que', 'característica']...) from 39 documents (total 442 corpus positions)\n",
      "2019-04-24 17:01:42,212 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:42,215 : INFO : built Dictionary(199 unique tokens: ['anniversari', 'base', 'bash', 'big', 'develop']...) from 54 documents (total 585 corpus positions)\n",
      "2019-04-24 17:01:42,244 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:42,247 : INFO : built Dictionary(150 unique tokens: ['amazon', 'busca', 'compra', 'consultoria', 'consumidor']...) from 13 documents (total 239 corpus positions)\n",
      "2019-04-24 17:01:42,255 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:42,258 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:42,260 : INFO : built Dictionary(69 unique tokens: ['artifici', 'cognit', 'comput', 'hottest', 'intellig']...) from 8 documents (total 98 corpus positions)\n",
      "2019-04-24 17:01:42,262 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:42,286 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:42,291 : INFO : built Dictionary(482 unique tokens: ['board', 'busi', 'chang', 'cio', 'director']...) from 95 documents (total 1233 corpus positions)\n",
      "2019-04-24 17:01:42,369 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:42,371 : INFO : built Dictionary(248 unique tokens: ['acaba', 'com', 'companhia', 'dar', 'definitivo']...) from 21 documents (total 409 corpus positions)\n",
      "2019-04-24 17:01:42,508 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:42,524 : INFO : built Dictionary(1885 unique tokens: ['flickr', 'le', 'machin', 'sourc', 'traaf']...) from 733 documents (total 9684 corpus positions)\n",
      "2019-04-24 17:01:46,535 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,538 : INFO : built Dictionary(359 unique tokens: ['brazil', 'com', 'dai', 'entertain', 'experienc']...) from 55 documents (total 784 corpus positions)\n",
      "2019-04-24 17:01:46,573 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,576 : INFO : built Dictionary(201 unique tokens: ['aproximação', 'bellami', 'brasil', 'comunicação', 'contato']...) from 19 documents (total 297 corpus positions)\n",
      "2019-04-24 17:01:46,590 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,593 : INFO : built Dictionary(243 unique tokens: ['convers', 'cours', 'explor', 'hand', 'modern']...) from 24 documents (total 395 corpus positions)\n",
      "2019-04-24 17:01:46,606 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,608 : INFO : built Dictionary(76 unique tokens: ['bad', 'bercovici', 'bureau', 'busi', 'chief']...) from 10 documents (total 94 corpus positions)\n",
      "2019-04-24 17:01:46,618 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,621 : INFO : built Dictionary(244 unique tokens: ['anunci', 'ação', 'banco', 'bnde', 'coisa']...) from 28 documents (total 364 corpus positions)\n",
      "2019-04-24 17:01:46,645 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,649 : INFO : built Dictionary(613 unique tokens: ['abr', 'alguém', 'aqui', 'desta', 'dia']...) from 69 documents (total 1056 corpus positions)\n",
      "2019-04-24 17:01:46,694 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:46,696 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,698 : INFO : built Dictionary(76 unique tokens: ['career', 'charg', 'consum', 'cours', 'difficult']...) from 9 documents (total 99 corpus positions)\n",
      "2019-04-24 17:01:46,700 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:46,709 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,712 : INFO : built Dictionary(232 unique tokens: ['ainda', 'amamo', 'aqui', 'casa', 'cevich']...) from 22 documents (total 363 corpus positions)\n",
      "2019-04-24 17:01:46,728 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,731 : INFO : built Dictionary(237 unique tokens: ['calif', 'mountain', 'view', 'adam', 'bock']...) from 43 documents (total 389 corpus positions)\n",
      "2019-04-24 17:01:46,770 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,775 : INFO : built Dictionary(504 unique tokens: ['adopt', 'architectur', 'compani', 'custom', 'deliv']...) from 110 documents (total 1435 corpus positions)\n",
      "2019-04-24 17:01:46,877 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,880 : INFO : built Dictionary(115 unique tokens: ['acquir', 'announc', 'base', 'bolster', 'develop']...) from 13 documents (total 175 corpus positions)\n",
      "2019-04-24 17:01:46,889 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,892 : INFO : built Dictionary(201 unique tokens: ['airbnb', 'avaliado', 'bilhõ', 'com', 'da']...) from 25 documents (total 325 corpus positions)\n",
      "2019-04-24 17:01:46,908 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,912 : INFO : built Dictionary(195 unique tokens: ['aula', 'fez', 'inglê', 'você', 'alemão']...) from 26 documents (total 267 corpus positions)\n",
      "2019-04-24 17:01:46,929 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,934 : INFO : built Dictionary(266 unique tokens: ['alta', 'ano', 'antonio', 'aument', 'açúcar']...) from 31 documents (total 546 corpus positions)\n",
      "2019-04-24 17:01:46,975 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:46,982 : INFO : built Dictionary(366 unique tokens: ['applic', 'appropri', 'compil', 'jit', 'kei']...) from 97 documents (total 1128 corpus positions)\n",
      "2019-04-24 17:01:47,079 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:47,084 : INFO : built Dictionary(296 unique tokens: ['artifici', 'bot', 'develop', 'execut', 'hardli']...) from 43 documents (total 543 corpus positions)\n",
      "2019-04-24 17:01:47,153 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:47,159 : INFO : built Dictionary(735 unique tokens: ['peopl', 'process', 'stream', 'cqr', 'event']...) from 256 documents (total 2487 corpus positions)\n",
      "2019-04-24 17:01:47,511 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:47,514 : INFO : built Dictionary(273 unique tokens: ['concept', 'databas', 'misunderstand', 'nosql', 'relat']...) from 73 documents (total 601 corpus positions)\n",
      "2019-04-24 17:01:47,549 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:47,551 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:47,553 : INFO : built Dictionary(35 unique tokens: ['applic', 'busi', 'challeng', 'cours', 'design']...) from 3 documents (total 42 corpus positions)\n",
      "2019-04-24 17:01:47,555 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:47,558 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:47,586 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:47,592 : INFO : built Dictionary(1122 unique tokens: ['comunismo', 'falar', 'imagin', 'nunca', 'ouvido']...) from 151 documents (total 2317 corpus positions)\n",
      "2019-04-24 17:01:47,748 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:47,750 : INFO : built Dictionary(95 unique tokens: ['biggest', 'fuck', 'goal', 'hardest', 'right']...) from 23 documents (total 130 corpus positions)\n",
      "2019-04-24 17:01:47,766 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:47,770 : INFO : built Dictionary(309 unique tokens: ['big', 'compani', 'design', 'haircut', 'lead']...) from 81 documents (total 550 corpus positions)\n",
      "2019-04-24 17:01:47,818 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:47,823 : INFO : built Dictionary(524 unique tokens: ['cuidado', 'game', 'grand', 'throne', 'você']...) from 80 documents (total 1002 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:47,879 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:47,883 : INFO : built Dictionary(171 unique tokens: ['actual', 'come', 'foundat', 'innov', 'internet']...) from 27 documents (total 220 corpus positions)\n",
      "2019-04-24 17:01:47,905 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:47,909 : INFO : built Dictionary(261 unique tokens: ['adob', 'akamai', 'author', 'cach', 'correctli']...) from 77 documents (total 629 corpus positions)\n",
      "2019-04-24 17:01:47,966 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:47,968 : INFO : built Dictionary(158 unique tokens: ['announc', 'avail', 'come', 'contain', 'custom']...) from 15 documents (total 250 corpus positions)\n",
      "2019-04-24 17:01:47,978 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:47,981 : INFO : built Dictionary(128 unique tokens: ['america', 'basquet', 'brasileira', 'desta', 'doi']...) from 12 documents (total 163 corpus positions)\n",
      "2019-04-24 17:01:47,994 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:47,997 : INFO : built Dictionary(238 unique tokens: ['bot', 'channel', 'explod', 'field', 'import']...) from 35 documents (total 389 corpus positions)\n",
      "2019-04-24 17:01:48,020 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,024 : INFO : built Dictionary(263 unique tokens: ['announc', 'artifici', 'base', 'chatbot', 'deliv']...) from 44 documents (total 414 corpus positions)\n",
      "2019-04-24 17:01:48,066 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,074 : INFO : built Dictionary(740 unique tokens: ['battl', 'lose', 'microsoft', 'mobil', 'win']...) from 152 documents (total 1515 corpus positions)\n",
      "2019-04-24 17:01:48,209 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,212 : INFO : built Dictionary(315 unique tokens: ['convinc', 'doig', 'fletcher', 'interview', 'man']...) from 49 documents (total 530 corpus positions)\n",
      "2019-04-24 17:01:48,247 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,251 : INFO : built Dictionary(302 unique tokens: ['control', 'exist', 'explor', 'grow', 'post']...) from 66 documents (total 635 corpus positions)\n",
      "2019-04-24 17:01:48,307 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,311 : INFO : built Dictionary(339 unique tokens: ['began', 'centuri', 'compar', 'develop', 'disciplin']...) from 42 documents (total 695 corpus positions)\n",
      "2019-04-24 17:01:48,352 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,361 : INFO : built Dictionary(143 unique tokens: ['brincadeira', 'enganado', 'está', 'eterna', 'lego']...) from 10 documents (total 185 corpus positions)\n",
      "2019-04-24 17:01:48,380 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,385 : INFO : built Dictionary(255 unique tokens: ['ago', 'bank', 'confer', 'discuss', 'exponenti']...) from 26 documents (total 377 corpus positions)\n",
      "2019-04-24 17:01:48,407 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,411 : INFO : built Dictionary(158 unique tokens: ['ago', 'announc', 'aw', 'began', 'branch']...) from 18 documents (total 269 corpus positions)\n",
      "2019-04-24 17:01:48,427 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,430 : INFO : built Dictionary(191 unique tokens: ['answer', 'languag', 'mycroft', 'natur', 'open']...) from 33 documents (total 359 corpus positions)\n",
      "2019-04-24 17:01:48,454 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,458 : INFO : built Dictionary(252 unique tokens: ['app', 'attend', 'confer', 'continu', 'engin']...) from 44 documents (total 475 corpus positions)\n",
      "2019-04-24 17:01:48,501 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,507 : INFO : built Dictionary(463 unique tokens: ['approach', 'artifici', 'build', 'chang', 'continu']...) from 95 documents (total 1140 corpus positions)\n",
      "2019-04-24 17:01:48,593 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,596 : INFO : built Dictionary(228 unique tokens: ['cover', 'document', 'edit', 'lifecycl', 'page']...) from 61 documents (total 608 corpus positions)\n",
      "2019-04-24 17:01:48,629 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:48,631 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,634 : INFO : built Dictionary(35 unique tokens: ['ask', 'collect', 'data', 'field', 'omit']...) from 6 documents (total 41 corpus positions)\n",
      "2019-04-24 17:01:48,637 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:48,645 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,649 : INFO : built Dictionary(40 unique tokens: ['get', 'mean', 'work', 'constantli', 'dead']...) from 11 documents (total 55 corpus positions)\n",
      "2019-04-24 17:01:48,657 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:48,659 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,662 : INFO : built Dictionary(42 unique tokens: ['combin', 'configur', 'mode', 'multipl', 'run']...) from 8 documents (total 127 corpus positions)\n",
      "2019-04-24 17:01:48,665 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:48,673 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,675 : INFO : built Dictionary(88 unique tokens: ['appreci', 'baer', 'celebr', 'experi', 'grid']...) from 19 documents (total 143 corpus positions)\n",
      "2019-04-24 17:01:48,688 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,691 : INFO : built Dictionary(222 unique tokens: ['applic', 'check', 'code', 'guid', 'implement']...) from 48 documents (total 328 corpus positions)\n",
      "2019-04-24 17:01:48,726 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,731 : INFO : built Dictionary(723 unique tokens: ['afetiva', 'algum', 'brasil', 'com', 'experimentar']...) from 94 documents (total 1482 corpus positions)\n",
      "2019-04-24 17:01:48,839 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,844 : INFO : built Dictionary(361 unique tokens: ['acabar', 'avenida', 'carro', 'codigo', 'com']...) from 36 documents (total 810 corpus positions)\n",
      "2019-04-24 17:01:48,878 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,881 : INFO : built Dictionary(101 unique tokens: ['act', 'anim', 'articul', 'beautifulli', 'brené']...) from 18 documents (total 140 corpus positions)\n",
      "2019-04-24 17:01:48,899 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,903 : INFO : built Dictionary(291 unique tokens: ['data', 'dna', 'earli', 'import', 'megabyt']...) from 36 documents (total 468 corpus positions)\n",
      "2019-04-24 17:01:48,929 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,932 : INFO : built Dictionary(235 unique tokens: ['apollo', 'develop', 'exist', 'flight', 'instrument']...) from 27 documents (total 355 corpus positions)\n",
      "2019-04-24 17:01:48,957 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,962 : INFO : built Dictionary(275 unique tokens: ['brasileiro', 'center', 'estão', 'gastando', 'mai']...) from 45 documents (total 518 corpus positions)\n",
      "2019-04-24 17:01:48,994 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:48,999 : INFO : built Dictionary(204 unique tokens: ['algun', 'amigo', 'estudo', 'mail', 'olá']...) from 31 documents (total 325 corpus positions)\n",
      "2019-04-24 17:01:49,025 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,029 : INFO : built Dictionary(271 unique tokens: ['airbnb', 'analyt', 'belong', 'data', 'like']...) from 34 documents (total 464 corpus positions)\n",
      "2019-04-24 17:01:49,060 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,064 : INFO : built Dictionary(279 unique tokens: ['consol', 'director', 'entertain', 'europ', 'game']...) from 40 documents (total 454 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:49,090 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,094 : INFO : built Dictionary(358 unique tokens: ['alguma', 'apoio', 'aquela', 'chanc', 'com']...) from 30 documents (total 633 corpus positions)\n",
      "2019-04-24 17:01:49,117 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,120 : INFO : built Dictionary(170 unique tokens: ['acaba', 'ami', 'amigo', 'bel', 'bellami']...) from 16 documents (total 257 corpus positions)\n",
      "2019-04-24 17:01:49,161 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,169 : INFO : built Dictionary(996 unique tokens: ['constant', 'corpo', 'desd', 'dezembro', 'dia']...) from 229 documents (total 2447 corpus positions)\n",
      "2019-04-24 17:01:49,515 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,519 : INFO : built Dictionary(247 unique tokens: ['best', 'gain', 'hard', 'php', 'phpstorm']...) from 56 documents (total 600 corpus positions)\n",
      "2019-04-24 17:01:49,567 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,571 : INFO : built Dictionary(50 unique tokens: ['action', 'consum', 'custom', 'driven', 'foresight']...) from 10 documents (total 67 corpus positions)\n",
      "2019-04-24 17:01:49,580 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,584 : INFO : built Dictionary(134 unique tokens: ['capaz', 'lançar', 'pagamento', 'para', 'paulo']...) from 17 documents (total 215 corpus positions)\n",
      "2019-04-24 17:01:49,597 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,601 : INFO : built Dictionary(169 unique tokens: ['amazon', 'apena', 'dando', 'entrega', 'está']...) from 17 documents (total 238 corpus positions)\n",
      "2019-04-24 17:01:49,622 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,628 : INFO : built Dictionary(424 unique tokens: ['bonito', 'brasileiro', 'colocaram', 'ecoturismo', 'flutuaçõ']...) from 66 documents (total 919 corpus positions)\n",
      "2019-04-24 17:01:49,696 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,701 : INFO : built Dictionary(177 unique tokens: ['jump', 'link', 'read', 'us', 'command']...) from 101 documents (total 461 corpus positions)\n",
      "2019-04-24 17:01:49,751 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:49,754 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,758 : INFO : built Dictionary(95 unique tokens: ['acompanhar', 'agosto', 'alcançamo', 'brasil', 'edição']...) from 8 documents (total 114 corpus positions)\n",
      "2019-04-24 17:01:49,761 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:49,772 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,776 : INFO : built Dictionary(257 unique tokens: ['charrier', 'design', 'entrou', 'estavam', 'estudant']...) from 27 documents (total 390 corpus positions)\n",
      "2019-04-24 17:01:49,792 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:49,795 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,798 : INFO : built Dictionary(62 unique tokens: ['bitcoin', 'enviou', 'ess', 'hoje', 'iinterativa']...) from 7 documents (total 77 corpus positions)\n",
      "2019-04-24 17:01:49,801 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:49,812 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,816 : INFO : built Dictionary(205 unique tokens: ['brasil', 'mai', 'mata', 'mundo', 'paí']...) from 21 documents (total 329 corpus positions)\n",
      "2019-04-24 17:01:49,848 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,852 : INFO : built Dictionary(520 unique tokens: ['court', 'crime', 'feder', 'haven', 'netflix']...) from 110 documents (total 1132 corpus positions)\n",
      "2019-04-24 17:01:49,956 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:49,959 : INFO : built Dictionary(331 unique tokens: ['art', 'client', 'criação', 'cultura', 'desd']...) from 36 documents (total 666 corpus positions)\n",
      "2019-04-24 17:01:49,995 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,000 : INFO : built Dictionary(394 unique tokens: ['achei', 'automatizar', 'automação', 'bacana', 'bom']...) from 56 documents (total 791 corpus positions)\n",
      "2019-04-24 17:01:50,041 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,043 : INFO : built Dictionary(109 unique tokens: ['arrai', 'assum', 'basic', 'draw', 'file']...) from 22 documents (total 157 corpus positions)\n",
      "2019-04-24 17:01:50,053 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:50,056 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,058 : INFO : built Dictionary(109 unique tokens: ['aproveitar', 'como', 'conseguirem', 'divertido', 'estabelecimento']...) from 9 documents (total 159 corpus positions)\n",
      "2019-04-24 17:01:50,060 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:50,067 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:50,070 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,071 : INFO : built Dictionary(24 unique tokens: ['java', 'microservic', 'new', 'quickli', 'stand']...) from 4 documents (total 29 corpus positions)\n",
      "2019-04-24 17:01:50,074 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:50,079 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:50,093 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,098 : INFO : built Dictionary(274 unique tokens: ['commenc', 'holi', 'imag', 'spite', 'suggest']...) from 53 documents (total 526 corpus positions)\n",
      "2019-04-24 17:01:50,126 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,129 : INFO : built Dictionary(182 unique tokens: ['bebida', 'caso', 'criador', 'david', 'ess']...) from 20 documents (total 285 corpus positions)\n",
      "2019-04-24 17:01:50,141 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,145 : INFO : built Dictionary(105 unique tokens: ['acquisit', 'app', 'build', 'continu', 'effort']...) from 11 documents (total 158 corpus positions)\n",
      "2019-04-24 17:01:50,160 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,164 : INFO : built Dictionary(366 unique tokens: ['conquist', 'financeira', 'liberdad', 'pode', 'sua']...) from 45 documents (total 670 corpus positions)\n",
      "2019-04-24 17:01:50,196 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,201 : INFO : built Dictionary(201 unique tokens: ['ago', 'anki', 'announc', 'car', 'control']...) from 35 documents (total 336 corpus positions)\n",
      "2019-04-24 17:01:50,220 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,223 : INFO : built Dictionary(108 unique tokens: ['bid', 'cloud', 'compani', 'comput', 'contact']...) from 13 documents (total 139 corpus positions)\n",
      "2019-04-24 17:01:50,238 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,242 : INFO : built Dictionary(263 unique tokens: ['acompanhamento', 'analítica', 'aplicativo', 'conhecido', 'conversão']...) from 31 documents (total 597 corpus positions)\n",
      "2019-04-24 17:01:50,270 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,274 : INFO : built Dictionary(325 unique tokens: ['atirador', 'boat', 'deixou', 'dentro', 'estado']...) from 40 documents (total 497 corpus positions)\n",
      "2019-04-24 17:01:50,296 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:50,299 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,302 : INFO : built Dictionary(89 unique tokens: ['ainda', 'allo', 'anunciado', 'aplicativo', 'busca']...) from 7 documents (total 108 corpus positions)\n",
      "2019-04-24 17:01:50,305 : WARNING : Input corpus is expected to have at least 10 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:50,325 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,330 : INFO : built Dictionary(567 unique tokens: ['como', 'definir', 'ess', 'parec', 'sensacionalista']...) from 95 documents (total 1133 corpus positions)\n",
      "2019-04-24 17:01:50,419 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,422 : INFO : built Dictionary(227 unique tokens: ['coffe', 'com', 'common', 'daili', 'dialogu']...) from 43 documents (total 494 corpus positions)\n",
      "2019-04-24 17:01:50,440 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:50,443 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,448 : INFO : built Dictionary(52 unique tokens: ['devic', 'divers', 'game', 'mobil', 'new']...) from 4 documents (total 64 corpus positions)\n",
      "2019-04-24 17:01:50,451 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:50,455 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:50,466 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,470 : INFO : built Dictionary(379 unique tokens: ['administração', 'ainda', 'alto', 'analista', 'andam']...) from 28 documents (total 611 corpus positions)\n",
      "2019-04-24 17:01:50,488 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:50,491 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,493 : INFO : built Dictionary(46 unique tokens: ['global', 'imposs', 'live', 'technolog', 'ubiquit']...) from 5 documents (total 56 corpus positions)\n",
      "2019-04-24 17:01:50,495 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:50,505 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,509 : INFO : built Dictionary(137 unique tokens: ['autonom', 'connect', 'land', 'regular', 'road']...) from 16 documents (total 230 corpus positions)\n",
      "2019-04-24 17:01:50,541 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,547 : INFO : built Dictionary(537 unique tokens: ['consid', 'develop', 'includ', 'orient', 'task']...) from 143 documents (total 1342 corpus positions)\n",
      "2019-04-24 17:01:50,678 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,682 : INFO : built Dictionary(526 unique tokens: ['analyz', 'differ', 'object', 'point', 'psycholog']...) from 131 documents (total 1379 corpus positions)\n",
      "2019-04-24 17:01:50,796 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,800 : INFO : built Dictionary(531 unique tokens: ['certain', 'help', 'limit', 'manag', 'optim']...) from 149 documents (total 1351 corpus positions)\n",
      "2019-04-24 17:01:50,930 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:50,934 : INFO : built Dictionary(405 unique tokens: ['browser', 'connect', 'govern', 'http', 'hypertext']...) from 126 documents (total 1157 corpus positions)\n",
      "2019-04-24 17:01:51,056 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,059 : INFO : built Dictionary(189 unique tokens: ['algoritmo', 'aprendizado', 'com', 'important', 'mai']...) from 15 documents (total 306 corpus positions)\n",
      "2019-04-24 17:01:51,072 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,075 : INFO : built Dictionary(121 unique tokens: ['crescimento', 'feito', 'grupo', 'netsho', 'número']...) from 14 documents (total 184 corpus positions)\n",
      "2019-04-24 17:01:51,087 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,091 : INFO : built Dictionary(94 unique tokens: ['call', 'certif', 'compani', 'confer', 'dai']...) from 16 documents (total 172 corpus positions)\n",
      "2019-04-24 17:01:51,107 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,111 : INFO : built Dictionary(201 unique tokens: ['aquel', 'cheiro', 'da', 'específico', 'exalando']...) from 20 documents (total 307 corpus positions)\n",
      "2019-04-24 17:01:51,151 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,156 : INFO : built Dictionary(650 unique tokens: ['develop', 'releas', 'second', 'seri', 'version']...) from 114 documents (total 1375 corpus positions)\n",
      "2019-04-24 17:01:51,249 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,252 : INFO : built Dictionary(385 unique tokens: ['bank', 'challeng', 'conven', 'digit', 'discuss']...) from 59 documents (total 793 corpus positions)\n",
      "2019-04-24 17:01:51,296 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,299 : INFO : built Dictionary(191 unique tokens: ['balloon', 'bot', 'chat', 'comput', 'exampl']...) from 21 documents (total 323 corpus positions)\n",
      "2019-04-24 17:01:51,313 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,317 : INFO : built Dictionary(130 unique tokens: ['clone', 'get', 'hardwar', 'new', 'nintendo']...) from 14 documents (total 189 corpus positions)\n",
      "2019-04-24 17:01:51,365 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,374 : INFO : built Dictionary(779 unique tokens: ['java', 'landscap', 'report', 'technolog', 'tool']...) from 293 documents (total 2247 corpus positions)\n",
      "2019-04-24 17:01:51,692 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,694 : INFO : built Dictionary(337 unique tokens: ['bem', 'claro', 'comissão', 'conseguirá', 'está']...) from 22 documents (total 537 corpus positions)\n",
      "2019-04-24 17:01:51,711 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,714 : INFO : built Dictionary(240 unique tokens: ['apesar', 'ardorosa', 'audiência', 'comunidad', 'continua']...) from 18 documents (total 390 corpus positions)\n",
      "2019-04-24 17:01:51,730 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,733 : INFO : built Dictionary(252 unique tokens: ['back', 'billion', 'busi', 'compani', 'enterpris']...) from 39 documents (total 443 corpus positions)\n",
      "2019-04-24 17:01:51,749 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,752 : INFO : built Dictionary(46 unique tokens: ['android', 'creat', 'function', 'librari', 'provid']...) from 11 documents (total 84 corpus positions)\n",
      "2019-04-24 17:01:51,765 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,768 : INFO : built Dictionary(273 unique tokens: ['android', 'continu', 'ecosystem', 'expand', 'googl']...) from 46 documents (total 585 corpus positions)\n",
      "2019-04-24 17:01:51,797 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,800 : INFO : built Dictionary(366 unique tokens: ['ago', 'android', 'animoca', 'coupl', 'develop']...) from 66 documents (total 662 corpus positions)\n",
      "2019-04-24 17:01:51,831 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,833 : INFO : built Dictionary(74 unique tokens: ['amaz', 'consol', 'edit', 'game', 'load']...) from 11 documents (total 103 corpus positions)\n",
      "2019-04-24 17:01:51,840 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,842 : INFO : built Dictionary(126 unique tokens: ['dispositivo', 'do', 'era', 'inferno', 'no']...) from 14 documents (total 178 corpus positions)\n",
      "2019-04-24 17:01:51,852 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,855 : INFO : built Dictionary(234 unique tokens: ['acend', 'baixa', 'criaram', 'dia', 'durant']...) from 22 documents (total 356 corpus positions)\n",
      "2019-04-24 17:01:51,868 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,871 : INFO : built Dictionary(165 unique tokens: ['acessório', 'andrew', 'bateria', 'colo', 'com']...) from 15 documents (total 231 corpus positions)\n",
      "2019-04-24 17:01:51,880 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,883 : INFO : built Dictionary(181 unique tokens: ['base', 'bilhão', 'com', 'compartilh', 'daniel']...) from 13 documents (total 274 corpus positions)\n",
      "2019-04-24 17:01:51,892 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:51,895 : INFO : built Dictionary(178 unique tokens: ['william', 'alvoroço', 'americano', 'ano', 'anunci']...) from 14 documents (total 237 corpus positions)\n",
      "2019-04-24 17:01:51,905 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,907 : INFO : built Dictionary(132 unique tokens: ['android', 'bank', 'billion', 'blockchain', 'build']...) from 12 documents (total 176 corpus positions)\n",
      "2019-04-24 17:01:51,915 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:51,917 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,920 : INFO : built Dictionary(110 unique tokens: ['administrativa', 'apoio', 'até', 'belo', 'campanha']...) from 9 documents (total 186 corpus positions)\n",
      "2019-04-24 17:01:51,922 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:51,930 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,933 : INFO : built Dictionary(119 unique tokens: ['algorithm', 'announc', 'apach', 'call', 'cloud']...) from 18 documents (total 186 corpus positions)\n",
      "2019-04-24 17:01:51,949 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,954 : INFO : built Dictionary(455 unique tokens: ['aceita', 'apó', 'boa', 'cabe', 'cabeçada']...) from 61 documents (total 725 corpus positions)\n",
      "2019-04-24 17:01:51,982 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,985 : INFO : built Dictionary(206 unique tokens: ['acabar', 'acordo', 'alcanç', 'android', 'aplicativo']...) from 12 documents (total 303 corpus positions)\n",
      "2019-04-24 17:01:51,993 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:51,996 : INFO : built Dictionary(61 unique tokens: ['big', 'brand', 'caus', 'clean', 'damag']...) from 10 documents (total 79 corpus positions)\n",
      "2019-04-24 17:01:52,009 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,013 : INFO : built Dictionary(272 unique tokens: ['allow', 'anz', 'chang', 'compel', 'core']...) from 75 documents (total 497 corpus positions)\n",
      "2019-04-24 17:01:52,047 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,050 : INFO : built Dictionary(181 unique tokens: ['cultur', 'design', 'load', 'rare', 'term']...) from 28 documents (total 307 corpus positions)\n",
      "2019-04-24 17:01:52,063 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,066 : INFO : built Dictionary(157 unique tokens: ['brasileira', 'empresa', 'entra', 'leão', 'marca']...) from 16 documents (total 256 corpus positions)\n",
      "2019-04-24 17:01:52,078 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,081 : INFO : built Dictionary(233 unique tokens: ['anunci', 'expansão', 'hoje', 'mastercard', 'masterpass']...) from 30 documents (total 359 corpus positions)\n",
      "2019-04-24 17:01:52,099 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,101 : INFO : built Dictionary(269 unique tokens: ['aeroporto', 'américa', 'app', 'auxiliar', 'beacon']...) from 29 documents (total 425 corpus positions)\n",
      "2019-04-24 17:01:52,117 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:52,120 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,123 : INFO : built Dictionary(22 unique tokens: ['appl', 'confer', 'develop', 'follow', 'interest']...) from 3 documents (total 24 corpus positions)\n",
      "2019-04-24 17:01:52,125 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:52,128 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:52,129 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:52,136 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,140 : INFO : built Dictionary(189 unique tokens: ['alec', 'ava', 'bioengin', 'creat', 'ferment']...) from 24 documents (total 274 corpus positions)\n",
      "2019-04-24 17:01:52,167 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,172 : INFO : built Dictionary(742 unique tokens: ['aberto', 'janeiro', 'jogo', 'olímpico', 'rio']...) from 96 documents (total 1595 corpus positions)\n",
      "2019-04-24 17:01:52,257 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,260 : INFO : built Dictionary(325 unique tokens: ['ambul', 'appl', 'assist', 'error', 'fix']...) from 44 documents (total 540 corpus positions)\n",
      "2019-04-24 17:01:52,295 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,299 : INFO : built Dictionary(611 unique tokens: ['ago', 'app', 'believ', 'commerc', 'comput']...) from 89 documents (total 1161 corpus positions)\n",
      "2019-04-24 17:01:52,354 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:52,356 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,357 : INFO : built Dictionary(44 unique tokens: ['bebê', 'dia', 'hoje', 'rock', 'anakin']...) from 6 documents (total 45 corpus positions)\n",
      "2019-04-24 17:01:52,359 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:52,361 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:52,363 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:52,367 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,372 : INFO : built Dictionary(148 unique tokens: ['ad', 'attent', 'billion', 'cap', 'captur']...) from 18 documents (total 216 corpus positions)\n",
      "2019-04-24 17:01:52,384 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,388 : INFO : built Dictionary(269 unique tokens: ['aceito', 'anunci', 'apoio', 'banco', 'brasil']...) from 22 documents (total 530 corpus positions)\n",
      "2019-04-24 17:01:52,420 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,424 : INFO : built Dictionary(221 unique tokens: ['common', 'contain', 'creat', 'docker', 'misconcept']...) from 95 documents (total 856 corpus positions)\n",
      "2019-04-24 17:01:52,491 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,494 : INFO : built Dictionary(197 unique tokens: ['accord', 'big', 'bigger', 'buchachon', 'cloud']...) from 28 documents (total 315 corpus positions)\n",
      "2019-04-24 17:01:52,504 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:52,506 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,508 : INFO : built Dictionary(52 unique tokens: ['capaz', 'conduzir', 'eletricidad', 'empresa', 'invent']...) from 5 documents (total 60 corpus positions)\n",
      "2019-04-24 17:01:52,511 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:52,536 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,541 : INFO : built Dictionary(828 unique tokens: ['aplicativo', 'certament', 'desd', 'dia', 'falar']...) from 142 documents (total 1911 corpus positions)\n",
      "2019-04-24 17:01:52,677 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,680 : INFO : built Dictionary(236 unique tokens: ['anunci', 'avanço', 'banco', 'cibc', 'grand']...) from 17 documents (total 322 corpus positions)\n",
      "2019-04-24 17:01:52,695 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,699 : INFO : built Dictionary(308 unique tokens: ['action', 'cours', 'creat', 'desir', 'digit']...) from 55 documents (total 594 corpus positions)\n",
      "2019-04-24 17:01:52,734 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,738 : INFO : built Dictionary(199 unique tokens: ['belt', 'docker', 'nifti', 'tool', 'develop']...) from 56 documents (total 500 corpus positions)\n",
      "2019-04-24 17:01:52,763 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,765 : INFO : built Dictionary(83 unique tokens: ['basic', 'constant', 'defin', 'deft', 'develop']...) from 13 documents (total 144 corpus positions)\n",
      "2019-04-24 17:01:52,772 : WARNING : Input text is expected to have at least 10 sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:52,774 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,777 : INFO : built Dictionary(98 unique tokens: ['aumento', 'da', 'diária', 'embora', 'insignificant']...) from 9 documents (total 147 corpus positions)\n",
      "2019-04-24 17:01:52,779 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:52,784 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:52,786 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,788 : INFO : built Dictionary(49 unique tokens: ['atividad', 'conjunto', 'eficaz', 'ferramenta', 'fornecemo']...) from 5 documents (total 59 corpus positions)\n",
      "2019-04-24 17:01:52,790 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:52,796 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,798 : INFO : built Dictionary(130 unique tokens: ['acessam', 'alvo', 'atravé', 'blog', 'como']...) from 12 documents (total 220 corpus positions)\n",
      "2019-04-24 17:01:52,809 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,812 : INFO : built Dictionary(279 unique tokens: ['assustado', 'atualização', 'bem', 'confuso', 'deixou']...) from 32 documents (total 434 corpus positions)\n",
      "2019-04-24 17:01:52,828 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,831 : INFO : built Dictionary(116 unique tokens: ['americano', 'apó', 'cartõ', 'cobra', 'começ']...) from 10 documents (total 210 corpus positions)\n",
      "2019-04-24 17:01:52,841 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,843 : INFO : built Dictionary(136 unique tokens: ['android', 'burk', 'close', 'dave', 'develop']...) from 16 documents (total 253 corpus positions)\n",
      "2019-04-24 17:01:52,856 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,859 : INFO : built Dictionary(236 unique tokens: ['algoritmo', 'android', 'aplicativo', 'chave', 'começar']...) from 24 documents (total 436 corpus positions)\n",
      "2019-04-24 17:01:52,872 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:52,875 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,876 : INFO : built Dictionary(130 unique tokens: ['anunci', 'buyukkokten', 'criador', 'engenheiro', 'extinto']...) from 9 documents (total 165 corpus positions)\n",
      "2019-04-24 17:01:52,879 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:52,886 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,889 : INFO : built Dictionary(98 unique tokens: ['alura', 'com', 'começo', 'jovemnerd', 'montou']...) from 15 documents (total 116 corpus positions)\n",
      "2019-04-24 17:01:52,902 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,905 : INFO : built Dictionary(205 unique tokens: ['android', 'engin', 'layer', 'multipl', 'overview']...) from 35 documents (total 510 corpus positions)\n",
      "2019-04-24 17:01:52,924 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:52,927 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,928 : INFO : built Dictionary(77 unique tokens: ['acquir', 'agre', 'announc', 'busi', 'club']...) from 8 documents (total 98 corpus positions)\n",
      "2019-04-24 17:01:52,930 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:52,942 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,944 : INFO : built Dictionary(221 unique tokens: ['bird', 'dove', 'griev', 'heard', 'love']...) from 30 documents (total 379 corpus positions)\n",
      "2019-04-24 17:01:52,959 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,961 : INFO : built Dictionary(57 unique tokens: ['convers', 'download', 'japanes', 'line', 'ninja']...) from 12 documents (total 81 corpus positions)\n",
      "2019-04-24 17:01:52,968 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,970 : INFO : built Dictionary(105 unique tokens: ['compani', 'financ', 'game', 'have', 'healthi']...) from 11 documents (total 138 corpus positions)\n",
      "2019-04-24 17:01:52,985 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:52,993 : INFO : built Dictionary(197 unique tokens: ['mean', 'summer', 'time', 'vacat', 'android']...) from 34 documents (total 322 corpus positions)\n",
      "2019-04-24 17:01:53,029 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,034 : INFO : built Dictionary(611 unique tokens: ['abrir', 'analisar', 'ativa', 'concorrência', 'deve']...) from 82 documents (total 1519 corpus positions)\n",
      "2019-04-24 17:01:53,122 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,125 : INFO : built Dictionary(199 unique tokens: ['accident', 'accustom', 'altern', 'behavior', 'build']...) from 42 documents (total 426 corpus positions)\n",
      "2019-04-24 17:01:53,145 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,149 : INFO : built Dictionary(295 unique tokens: ['learn', 'time', 'area', 'collect', 'develop']...) from 45 documents (total 467 corpus positions)\n",
      "2019-04-24 17:01:53,174 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,177 : INFO : built Dictionary(273 unique tokens: ['announc', 'cloud', 'excit', 'expans', 'follow']...) from 29 documents (total 524 corpus positions)\n",
      "2019-04-24 17:01:53,199 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,203 : INFO : built Dictionary(388 unique tokens: ['africa', 'agência', 'algun', 'ano', 'auxiliar']...) from 50 documents (total 746 corpus positions)\n",
      "2019-04-24 17:01:53,239 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,243 : INFO : built Dictionary(422 unique tokens: ['até', 'bem', 'com', 'conceito', 'diferent']...) from 61 documents (total 873 corpus positions)\n",
      "2019-04-24 17:01:53,301 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,305 : INFO : built Dictionary(450 unique tokens: ['app', 'build', 'built', 'care', 'consensu']...) from 171 documents (total 1141 corpus positions)\n",
      "2019-04-24 17:01:53,406 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:53,407 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,409 : INFO : built Dictionary(121 unique tokens: ['artifici', 'com', 'comércio', 'conversar', 'da']...) from 8 documents (total 163 corpus positions)\n",
      "2019-04-24 17:01:53,412 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:53,429 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,434 : INFO : built Dictionary(452 unique tokens: ['alto', 'artigo', 'automatizado', 'baixo', 'com']...) from 69 documents (total 1252 corpus positions)\n",
      "2019-04-24 17:01:53,489 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,491 : INFO : built Dictionary(84 unique tokens: ['complex', 'concern', 'dai', 'datacent', 'deepmind']...) from 10 documents (total 100 corpus positions)\n",
      "2019-04-24 17:01:53,499 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,501 : INFO : built Dictionary(176 unique tokens: ['appl', 'clamshel', 'forward', 'ibook', 'major']...) from 21 documents (total 248 corpus positions)\n",
      "2019-04-24 17:01:53,512 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:53,514 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,515 : INFO : built Dictionary(77 unique tokens: ['breez', 'clearanc', 'consul', 'countri', 'deni']...) from 8 documents (total 111 corpus positions)\n",
      "2019-04-24 17:01:53,517 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:53,523 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,525 : INFO : built Dictionary(71 unique tokens: ['cours', 'inact', 'killer', 'physic', 'sedentari']...) from 16 documents (total 116 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:53,546 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,550 : INFO : built Dictionary(510 unique tokens: ['countri', 'fast', 'financ', 'furiou', 'growth']...) from 80 documents (total 1042 corpus positions)\n",
      "2019-04-24 17:01:53,609 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,611 : INFO : built Dictionary(285 unique tokens: ['américa', 'aposta', 'com', 'computação', 'impulsionado']...) from 34 documents (total 428 corpus positions)\n",
      "2019-04-24 17:01:53,632 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,635 : INFO : built Dictionary(234 unique tokens: ['come', 'game', 'perform', 'web', 'asset']...) from 45 documents (total 462 corpus positions)\n",
      "2019-04-24 17:01:53,656 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,659 : INFO : built Dictionary(135 unique tokens: ['actual', 'allow', 'aren', 'believ', 'design']...) from 11 documents (total 197 corpus positions)\n",
      "2019-04-24 17:01:53,695 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,700 : INFO : built Dictionary(636 unique tokens: ['background', 'carv', 'continu', 'creat', 'develop']...) from 202 documents (total 1868 corpus positions)\n",
      "2019-04-24 17:01:53,863 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,865 : INFO : built Dictionary(234 unique tokens: ['come', 'contrapt', 'cowboi', 'hear', 'mind']...) from 23 documents (total 349 corpus positions)\n",
      "2019-04-24 17:01:53,875 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,878 : INFO : built Dictionary(110 unique tokens: ['choic', 'comic', 'devic', 'increasingli', 'justic']...) from 14 documents (total 182 corpus positions)\n",
      "2019-04-24 17:01:53,886 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:53,888 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,891 : INFO : built Dictionary(59 unique tokens: ['billion', 'compani', 'cost', 'employe', 'flickr']...) from 9 documents (total 77 corpus positions)\n",
      "2019-04-24 17:01:53,893 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:53,902 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:53,904 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,907 : INFO : built Dictionary(130 unique tokens: ['arugorizumu', 'koushin', 'abunai', 'aichi', 'air']...) from 9 documents (total 342 corpus positions)\n",
      "2019-04-24 17:01:53,909 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:53,919 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,922 : INFO : built Dictionary(135 unique tokens: ['anthoni', 'app', 'instruct', 'manual', 'new']...) from 48 documents (total 315 corpus positions)\n",
      "2019-04-24 17:01:53,961 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:53,965 : INFO : built Dictionary(349 unique tokens: ['averag', 'daili', 'data', 'deal', 'load']...) from 112 documents (total 955 corpus positions)\n",
      "2019-04-24 17:01:54,042 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,045 : INFO : built Dictionary(371 unique tokens: ['abhishek', 'averag', 'cross', 'daili', 'data']...) from 113 documents (total 1016 corpus positions)\n",
      "2019-04-24 17:01:54,126 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,131 : INFO : built Dictionary(515 unique tokens: ['convolut', 'network', 'neural', 'biologi', 'combin']...) from 172 documents (total 1601 corpus positions)\n",
      "2019-04-24 17:01:54,279 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,282 : INFO : built Dictionary(294 unique tokens: ['case', 'haven', 'major', 'notic', 'shift']...) from 45 documents (total 412 corpus positions)\n",
      "2019-04-24 17:01:54,300 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,303 : INFO : built Dictionary(221 unique tokens: ['let', 'straight', 'borg', 'build', 'extern']...) from 39 documents (total 330 corpus positions)\n",
      "2019-04-24 17:01:54,316 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:54,318 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,321 : INFO : built Dictionary(122 unique tokens: ['adaptador', 'algun', 'alta', 'até', 'bastant']...) from 6 documents (total 173 corpus positions)\n",
      "2019-04-24 17:01:54,323 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:54,331 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,333 : INFO : built Dictionary(113 unique tokens: ['come', 'hit', 'prisma', 'android', 'app']...) from 13 documents (total 148 corpus positions)\n",
      "2019-04-24 17:01:54,350 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,354 : INFO : built Dictionary(439 unique tokens: ['alguma', 'apena', 'bom', 'coisa', 'conselho']...) from 55 documents (total 1028 corpus positions)\n",
      "2019-04-24 17:01:54,392 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,395 : INFO : built Dictionary(211 unique tokens: ['abrasc', 'center', 'conhecendo', 'divulga', 'do']...) from 20 documents (total 325 corpus positions)\n",
      "2019-04-24 17:01:54,412 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,415 : INFO : built Dictionary(346 unique tokens: ['abil', 'decad', 'educ', 'kei', 'realiti']...) from 38 documents (total 512 corpus positions)\n",
      "2019-04-24 17:01:54,444 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,448 : INFO : built Dictionary(524 unique tokens: ['aceitação', 'android', 'como', 'constantement', 'devo']...) from 65 documents (total 1229 corpus positions)\n",
      "2019-04-24 17:01:54,503 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,506 : INFO : built Dictionary(161 unique tokens: ['acordo', 'banco', 'brasil', 'cartão', 'com']...) from 16 documents (total 245 corpus positions)\n",
      "2019-04-24 17:01:54,519 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,522 : INFO : built Dictionary(333 unique tokens: ['agora', 'apena', 'até', 'fenômeno', 'lançado']...) from 40 documents (total 531 corpus positions)\n",
      "2019-04-24 17:01:54,540 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:54,543 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,545 : INFO : built Dictionary(24 unique tokens: ['adob', 'build', 'enabl', 'expans', 'guid']...) from 3 documents (total 28 corpus positions)\n",
      "2019-04-24 17:01:54,547 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:54,551 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:54,557 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,559 : INFO : built Dictionary(90 unique tokens: ['android', 'api', 'app', 'build', 'center']...) from 14 documents (total 152 corpus positions)\n",
      "2019-04-24 17:01:54,569 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,572 : INFO : built Dictionary(248 unique tokens: ['característica', 'classificação', 'evolutiva', 'humano', 'máquina']...) from 19 documents (total 398 corpus positions)\n",
      "2019-04-24 17:01:54,583 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:54,586 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,589 : INFO : built Dictionary(137 unique tokens: ['acordo', 'ainda', 'anunci', 'apresentar', 'aproveitar']...) from 8 documents (total 215 corpus positions)\n",
      "2019-04-24 17:01:54,591 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:54,598 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:54,601 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,604 : INFO : built Dictionary(126 unique tokens: ['acordo', 'anunci', 'ao', 'brasileira', 'casa']...) from 9 documents (total 171 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:54,606 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:54,617 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,620 : INFO : built Dictionary(249 unique tokens: ['bank', 'corpor', 'financi', 'invest', 'servic']...) from 32 documents (total 409 corpus positions)\n",
      "2019-04-24 17:01:54,636 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:54,638 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,641 : INFO : built Dictionary(103 unique tokens: ['desrespeitosa', 'importa', 'intrusiva', 'machista', 'não']...) from 4 documents (total 114 corpus positions)\n",
      "2019-04-24 17:01:54,643 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:54,647 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:54,651 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,654 : INFO : built Dictionary(138 unique tokens: ['acab', 'ampla', 'campanha', 'carin', 'começ']...) from 10 documents (total 217 corpus positions)\n",
      "2019-04-24 17:01:54,664 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,667 : INFO : built Dictionary(202 unique tokens: ['avaliam', 'avaliando', 'el', 'estão', 'exatament']...) from 19 documents (total 329 corpus positions)\n",
      "2019-04-24 17:01:54,687 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,691 : INFO : built Dictionary(386 unique tokens: ['como', 'contexto', 'conteúdo', 'falou', 'funciona']...) from 49 documents (total 894 corpus positions)\n",
      "2019-04-24 17:01:54,732 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,735 : INFO : built Dictionary(337 unique tokens: ['como', 'dia', 'el', 'facebook', 'falando']...) from 44 documents (total 578 corpus positions)\n",
      "2019-04-24 17:01:54,761 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,763 : INFO : built Dictionary(178 unique tokens: ['audio', 'element', 'experi', 'immers', 'kei']...) from 23 documents (total 298 corpus positions)\n",
      "2019-04-24 17:01:54,779 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,781 : INFO : built Dictionary(147 unique tokens: ['adopt', 'distribut', 'git', 'industri', 'juli']...) from 17 documents (total 245 corpus positions)\n",
      "2019-04-24 17:01:54,794 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,796 : INFO : built Dictionary(81 unique tokens: ['capabl', 'cluster', 'docker', 'engin', 'group']...) from 13 documents (total 151 corpus positions)\n",
      "2019-04-24 17:01:54,802 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:54,805 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,807 : INFO : built Dictionary(69 unique tokens: ['anger', 'daili', 'delight', 'differ', 'doh']...) from 8 documents (total 87 corpus positions)\n",
      "2019-04-24 17:01:54,809 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:54,814 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:54,816 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,819 : INFO : built Dictionary(24 unique tokens: ['access', 'content', 'follow', 'guidelin', 'wcag']...) from 3 documents (total 28 corpus positions)\n",
      "2019-04-24 17:01:54,820 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:54,824 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:54,829 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,831 : INFO : built Dictionary(101 unique tokens: ['emoji', 'onlin', 'percent', 'popul', 'us']...) from 15 documents (total 162 corpus positions)\n",
      "2019-04-24 17:01:54,840 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:54,842 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,844 : INFO : built Dictionary(74 unique tokens: ['busi', 'data', 'deliv', 'hand', 'know']...) from 9 documents (total 86 corpus positions)\n",
      "2019-04-24 17:01:54,848 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:54,854 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,857 : INFO : built Dictionary(122 unique tokens: ['carrefour', 'commerc', 'feira', 'grupo', 'lançou']...) from 10 documents (total 158 corpus positions)\n",
      "2019-04-24 17:01:54,873 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,877 : INFO : built Dictionary(407 unique tokens: ['artigo', 'capybara', 'cucumb', 'desenvolvimento', 'dessa']...) from 52 documents (total 944 corpus positions)\n",
      "2019-04-24 17:01:54,910 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,913 : INFO : built Dictionary(85 unique tokens: ['appl', 'authent', 'avail', 'code', 'factor']...) from 10 documents (total 139 corpus positions)\n",
      "2019-04-24 17:01:54,923 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,926 : INFO : built Dictionary(192 unique tokens: ['acabei', 'atuo', 'classificação', 'como', 'construindo']...) from 22 documents (total 432 corpus positions)\n",
      "2019-04-24 17:01:54,945 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,948 : INFO : built Dictionary(271 unique tokens: ['blockchain', 'bring', 'financi', 'greater', 'market']...) from 29 documents (total 427 corpus positions)\n",
      "2019-04-24 17:01:54,964 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,967 : INFO : built Dictionary(136 unique tokens: ['activ', 'board', 'especi', 'great', 'kayak']...) from 16 documents (total 186 corpus positions)\n",
      "2019-04-24 17:01:54,983 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:54,990 : INFO : built Dictionary(319 unique tokens: ['constantement', 'da', 'melhorar', 'novo', 'para']...) from 44 documents (total 589 corpus positions)\n",
      "2019-04-24 17:01:55,022 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,025 : INFO : built Dictionary(103 unique tokens: ['botanist', 'smartphon', 'start', 'unfortun', 'asia']...) from 13 documents (total 135 corpus positions)\n",
      "2019-04-24 17:01:55,033 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:55,035 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,038 : INFO : built Dictionary(93 unique tokens: ['algun', 'aprenderá', 'commit', 'control', 'descobrir']...) from 6 documents (total 172 corpus positions)\n",
      "2019-04-24 17:01:55,040 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:55,048 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,051 : INFO : built Dictionary(150 unique tokens: ['alta', 'automóvel', 'colisão', 'com', 'corpo']...) from 14 documents (total 214 corpus positions)\n",
      "2019-04-24 17:01:55,062 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,064 : INFO : built Dictionary(170 unique tokens: ['atuação', 'cfp', 'com', 'conselho', 'direcionar']...) from 14 documents (total 255 corpus positions)\n",
      "2019-04-24 17:01:55,077 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,080 : INFO : built Dictionary(276 unique tokens: ['decisão', 'direcionar', 'informaçõ', 'intensificar', 'para']...) from 22 documents (total 429 corpus positions)\n",
      "2019-04-24 17:01:55,095 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,097 : INFO : built Dictionary(208 unique tokens: ['ano', 'apó', 'aventura', 'dia', 'do']...) from 15 documents (total 290 corpus positions)\n",
      "2019-04-24 17:01:55,119 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,124 : INFO : built Dictionary(630 unique tokens: ['alasca', 'autorretrato', 'christoph', 'como', 'encontrado']...) from 74 documents (total 1314 corpus positions)\n",
      "2019-04-24 17:01:55,186 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,189 : INFO : built Dictionary(355 unique tokens: ['alocação', 'mai', 'pensa', 'que', 'recurso']...) from 50 documents (total 643 corpus positions)\n",
      "2019-04-24 17:01:55,230 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,236 : INFO : built Dictionary(679 unique tokens: ['até', 'com', 'continuar', 'cotidiana', 'desanimado']...) from 145 documents (total 1521 corpus positions)\n",
      "2019-04-24 17:01:55,350 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,352 : INFO : built Dictionary(143 unique tokens: ['afternoon', 'annual', 'author', 'compani', 'confer']...) from 31 documents (total 197 corpus positions)\n",
      "2019-04-24 17:01:55,373 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,377 : INFO : built Dictionary(583 unique tokens: ['alan', 'assunto', 'bastant', 'cezar', 'com']...) from 112 documents (total 1163 corpus positions)\n",
      "2019-04-24 17:01:55,453 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,456 : INFO : built Dictionary(253 unique tokens: ['amaz', 'commun', 'contribut', 'core', 'couldn']...) from 55 documents (total 492 corpus positions)\n",
      "2019-04-24 17:01:55,479 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,483 : INFO : built Dictionary(207 unique tokens: ['alami', 'annual', 'grzegorz', 'ieee', 'illustr']...) from 32 documents (total 345 corpus positions)\n",
      "2019-04-24 17:01:55,503 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,506 : INFO : built Dictionary(252 unique tokens: ['corpu', 'googl', 'hand', 'loos', 'million']...) from 52 documents (total 466 corpus positions)\n",
      "2019-04-24 17:01:55,534 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,538 : INFO : built Dictionary(339 unique tokens: ['comprado', 'devolvido', 'meno', 'onlin', 'pelo']...) from 40 documents (total 672 corpus positions)\n",
      "2019-04-24 17:01:55,562 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,565 : INFO : built Dictionary(130 unique tokens: ['aggress', 'busi', 'compet', 'fast', 'femal']...) from 28 documents (total 170 corpus positions)\n",
      "2019-04-24 17:01:55,576 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,579 : INFO : built Dictionary(184 unique tokens: ['avaliação', 'avaliaçõ', 'brasil', 'coleta', 'commerc']...) from 14 documents (total 290 corpus positions)\n",
      "2019-04-24 17:01:55,590 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,592 : INFO : built Dictionary(165 unique tokens: ['adequar', 'ajust', 'ano', 'anunci', 'açúcar']...) from 16 documents (total 234 corpus positions)\n",
      "2019-04-24 17:01:55,603 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,606 : INFO : built Dictionary(229 unique tokens: ['apó', 'atma', 'biggi', 'brasileiro', 'chega']...) from 14 documents (total 353 corpus positions)\n",
      "2019-04-24 17:01:55,623 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,627 : INFO : built Dictionary(286 unique tokens: ['constraintlayout', 'current', 'editor', 'layout', 'preview']...) from 63 documents (total 645 corpus positions)\n",
      "2019-04-24 17:01:55,669 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,672 : INFO : built Dictionary(235 unique tokens: ['constraintlayout', 'current', 'editor', 'layout', 'preview']...) from 57 documents (total 545 corpus positions)\n",
      "2019-04-24 17:01:55,702 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,704 : INFO : built Dictionary(134 unique tokens: ['adapt', 'busi', 'chang', 'difficult', 'digitalis']...) from 22 documents (total 167 corpus positions)\n",
      "2019-04-24 17:01:55,724 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,729 : INFO : built Dictionary(533 unique tokens: ['clássico', 'do', 'história', 'holm', 'literatura']...) from 94 documents (total 1135 corpus positions)\n",
      "2019-04-24 17:01:55,818 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,821 : INFO : built Dictionary(436 unique tokens: ['abil', 'aw', 'cloud', 'demonstr', 'design']...) from 90 documents (total 1824 corpus positions)\n",
      "2019-04-24 17:01:55,906 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,910 : INFO : built Dictionary(504 unique tokens: ['access', 'allow', 'aw', 'base', 'cloud']...) from 61 documents (total 1479 corpus positions)\n",
      "2019-04-24 17:01:55,957 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,960 : INFO : built Dictionary(280 unique tokens: ['abil', 'architectur', 'capac', 'comput', 'control']...) from 20 documents (total 581 corpus positions)\n",
      "2019-04-24 17:01:55,985 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:55,988 : INFO : built Dictionary(452 unique tokens: ['aw', 'commun', 'free', 'lot', 'mention']...) from 73 documents (total 1167 corpus positions)\n",
      "2019-04-24 17:01:56,034 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,038 : INFO : built Dictionary(322 unique tokens: ['architect', 'attempt', 'aw', 'certif', 'certifi']...) from 49 documents (total 492 corpus positions)\n",
      "2019-04-24 17:01:56,067 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,071 : INFO : built Dictionary(401 unique tokens: ['autoridad', 'da', 'maior', 'mundo', 'previsão']...) from 50 documents (total 848 corpus positions)\n",
      "2019-04-24 17:01:56,127 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,132 : INFO : built Dictionary(718 unique tokens: ['clippi', 'decemb', 'integr', 'launch', 'messag']...) from 130 documents (total 1522 corpus positions)\n",
      "2019-04-24 17:01:56,230 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,233 : INFO : built Dictionary(260 unique tokens: ['android', 'compil', 'exist', 'googl', 'intend']...) from 45 documents (total 540 corpus positions)\n",
      "2019-04-24 17:01:56,262 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,265 : INFO : built Dictionary(396 unique tokens: ['approach', 'brazil', 'countri', 'crude', 'despit']...) from 66 documents (total 756 corpus positions)\n",
      "2019-04-24 17:01:56,310 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,313 : INFO : built Dictionary(346 unique tokens: ['automatização', 'chão', 'engana', 'fábrica', 'pensa']...) from 36 documents (total 602 corpus positions)\n",
      "2019-04-24 17:01:56,338 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,342 : INFO : built Dictionary(425 unique tokens: ['aqui', 'artigo', 'autor', 'caracterizando', 'colunista']...) from 39 documents (total 695 corpus positions)\n",
      "2019-04-24 17:01:56,365 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,368 : INFO : built Dictionary(184 unique tokens: ['agora', 'alguma', 'atendimento', 'celular', 'claudia']...) from 17 documents (total 269 corpus positions)\n",
      "2019-04-24 17:01:56,387 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,391 : INFO : built Dictionary(333 unique tokens: ['architectur', 'develop', 'microservic', 'nginx', 'refer']...) from 62 documents (total 729 corpus positions)\n",
      "2019-04-24 17:01:56,422 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,425 : INFO : built Dictionary(79 unique tokens: ['analysi', 'data', 'elasticsearch', 'kibana', 'love']...) from 13 documents (total 107 corpus positions)\n",
      "2019-04-24 17:01:56,438 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,441 : INFO : built Dictionary(221 unique tokens: ['googl', 'investor', 'pleas', 'alphabet', 'analyst']...) from 45 documents (total 474 corpus positions)\n",
      "2019-04-24 17:01:56,468 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,471 : INFO : built Dictionary(276 unique tokens: ['applic', 'bump', 'challeng', 'enterpris', 'fair']...) from 43 documents (total 454 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:56,491 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,494 : INFO : built Dictionary(222 unique tokens: ['brasileira', 'considerada', 'da', 'estudo', 'exchang']...) from 27 documents (total 322 corpus positions)\n",
      "2019-04-24 17:01:56,515 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,519 : INFO : built Dictionary(323 unique tokens: ['app', 'better', 'big', 'channel', 'complet']...) from 76 documents (total 727 corpus positions)\n",
      "2019-04-24 17:01:56,561 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:56,563 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,564 : INFO : built Dictionary(71 unique tokens: ['app', 'correctli', 'dive', 'import', 'instrument']...) from 8 documents (total 134 corpus positions)\n",
      "2019-04-24 17:01:56,567 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:56,591 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,596 : INFO : built Dictionary(648 unique tokens: ['build', 'commun', 'complex', 'defin', 'economi']...) from 108 documents (total 1307 corpus positions)\n",
      "2019-04-24 17:01:56,688 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:56,690 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,692 : INFO : built Dictionary(64 unique tokens: ['america', 'base', 'central', 'citi', 'danger']...) from 7 documents (total 72 corpus positions)\n",
      "2019-04-24 17:01:56,694 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:56,716 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,722 : INFO : built Dictionary(548 unique tokens: ['busi', 'distanc', 'engin', 'entropi', 'fuck']...) from 174 documents (total 1151 corpus positions)\n",
      "2019-04-24 17:01:56,825 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,828 : INFO : built Dictionary(636 unique tokens: ['atividad', 'com', 'cumprir', 'daquel', 'deve']...) from 88 documents (total 1644 corpus positions)\n",
      "2019-04-24 17:01:56,963 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:56,965 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,967 : INFO : built Dictionary(104 unique tokens: ['api', 'até', 'conquistar', 'criação', 'desd']...) from 7 documents (total 127 corpus positions)\n",
      "2019-04-24 17:01:56,969 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:56,976 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:56,982 : INFO : built Dictionary(112 unique tokens: ['club', 'fight', 'rule', 'talk', 'second']...) from 31 documents (total 191 corpus positions)\n",
      "2019-04-24 17:01:57,011 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,015 : INFO : built Dictionary(318 unique tokens: ['apach', 'batch', 'meso', 'mix', 'netflix']...) from 60 documents (total 747 corpus positions)\n",
      "2019-04-24 17:01:57,051 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,054 : INFO : built Dictionary(68 unique tokens: ['add', 'collect', 'digit', 'easiest', 'itun']...) from 16 documents (total 107 corpus positions)\n",
      "2019-04-24 17:01:57,070 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,074 : INFO : built Dictionary(311 unique tokens: ['abound', 'app', 'articl', 'build', 'busi']...) from 70 documents (total 702 corpus positions)\n",
      "2019-04-24 17:01:57,123 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:57,126 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,128 : INFO : built Dictionary(111 unique tokens: ['american', 'ano', 'asl', 'biográfico', 'categoria']...) from 5 documents (total 139 corpus positions)\n",
      "2019-04-24 17:01:57,131 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:57,154 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,159 : INFO : built Dictionary(509 unique tokens: ['accentur', 'citi', 'consult', 'content', 'firm']...) from 78 documents (total 1121 corpus positions)\n",
      "2019-04-24 17:01:57,223 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,226 : INFO : built Dictionary(148 unique tokens: ['accord', 'analysi', 'busi', 'conclud', 'design']...) from 18 documents (total 204 corpus positions)\n",
      "2019-04-24 17:01:57,241 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,245 : INFO : built Dictionary(393 unique tokens: ['adventur', 'amateur', 'avid', 'base', 'cook']...) from 56 documents (total 595 corpus positions)\n",
      "2019-04-24 17:01:57,273 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,276 : INFO : built Dictionary(219 unique tokens: ['aceit', 'administração', 'anuncia', 'aquisiçõ', 'belga']...) from 15 documents (total 330 corpus positions)\n",
      "2019-04-24 17:01:57,288 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,291 : INFO : built Dictionary(124 unique tokens: ['blind', 'difficult', 'imagin', 'impair', 'person']...) from 17 documents (total 220 corpus positions)\n",
      "2019-04-24 17:01:57,309 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,312 : INFO : built Dictionary(298 unique tokens: ['bit', 'busi', 'digit', 'misnom', 'model']...) from 84 documents (total 632 corpus positions)\n",
      "2019-04-24 17:01:57,355 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:57,358 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,360 : INFO : built Dictionary(69 unique tokens: ['appear', 'billion', 'china', 'chux', 'combin']...) from 8 documents (total 87 corpus positions)\n",
      "2019-04-24 17:01:57,362 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:57,366 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:57,368 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,370 : INFO : built Dictionary(24 unique tokens: ['android', 'bodi', 'connect', 'inform', 'lightweight']...) from 2 documents (total 30 corpus positions)\n",
      "2019-04-24 17:01:57,372 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:57,375 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:01:57,377 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:57,381 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,384 : INFO : built Dictionary(102 unique tokens: ['feel', 'googl', 'know', 'like', 'properli']...) from 21 documents (total 190 corpus positions)\n",
      "2019-04-24 17:01:57,395 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,398 : INFO : built Dictionary(83 unique tokens: ['creat', 'drive', 'file', 'folder', 'googl']...) from 15 documents (total 154 corpus positions)\n",
      "2019-04-24 17:01:57,427 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,432 : INFO : built Dictionary(691 unique tokens: ['barani', 'call', 'francisco', 'igor', 'medic']...) from 110 documents (total 1431 corpus positions)\n",
      "2019-04-24 17:01:57,525 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,528 : INFO : built Dictionary(342 unique tokens: ['ano', 'coisa', 'comunica', 'conceito', 'da']...) from 30 documents (total 570 corpus positions)\n",
      "2019-04-24 17:01:57,552 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,554 : INFO : built Dictionary(179 unique tokens: ['add', 'autoscal', 'cluster', 'creat', 'kube']...) from 31 documents (total 503 corpus positions)\n",
      "2019-04-24 17:01:57,571 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,575 : INFO : built Dictionary(246 unique tokens: ['automação', 'está', 'market', 'para', 'todo']...) from 35 documents (total 404 corpus positions)\n",
      "2019-04-24 17:01:57,599 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:57,603 : INFO : built Dictionary(323 unique tokens: ['com', 'conhecido', 'dia', 'ess', 'inbound']...) from 41 documents (total 650 corpus positions)\n",
      "2019-04-24 17:01:57,629 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,632 : INFO : built Dictionary(270 unique tokens: ['acesso', 'como', 'desafio', 'digeri', 'empresa']...) from 22 documents (total 393 corpus positions)\n",
      "2019-04-24 17:01:57,648 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,651 : INFO : built Dictionary(147 unique tokens: ['becker', 'broker', 'builder', 'bullish', 'chairperson']...) from 15 documents (total 213 corpus positions)\n",
      "2019-04-24 17:01:57,663 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,666 : INFO : built Dictionary(183 unique tokens: ['announc', 'avail', 'behalf', 'bintrai', 'boot']...) from 27 documents (total 288 corpus positions)\n",
      "2019-04-24 17:01:57,678 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:57,681 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,683 : INFO : built Dictionary(58 unique tokens: ['aluno', 'android', 'ao', 'apena', 'aplicativo']...) from 3 documents (total 70 corpus positions)\n",
      "2019-04-24 17:01:57,685 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:57,690 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:57,694 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:57,697 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,699 : INFO : built Dictionary(78 unique tokens: ['capacitação', 'design', 'inova', 'jovem', 'primeira']...) from 7 documents (total 92 corpus positions)\n",
      "2019-04-24 17:01:57,702 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:57,763 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:57,771 : INFO : built Dictionary(1323 unique tokens: ['greatest', 'invent', 'nightmar', 'pathwai', 'revolut']...) from 243 documents (total 3439 corpus positions)\n",
      "2019-04-24 17:01:58,091 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:58,094 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,096 : INFO : built Dictionary(117 unique tokens: ['agência', 'alphabet', 'anunci', 'aviação', 'branca']...) from 6 documents (total 152 corpus positions)\n",
      "2019-04-24 17:01:58,098 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:58,106 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,109 : INFO : built Dictionary(161 unique tokens: ['ambient', 'ao', 'como', 'existissem', 'headset']...) from 14 documents (total 229 corpus positions)\n",
      "2019-04-24 17:01:58,118 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,121 : INFO : built Dictionary(84 unique tokens: ['abund', 'carbon', 'countri', 'emiss', 'energi']...) from 10 documents (total 111 corpus positions)\n",
      "2019-04-24 17:01:58,141 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,146 : INFO : built Dictionary(309 unique tokens: ['ago', 'journei', 'minim', 'start', 'year']...) from 85 documents (total 558 corpus positions)\n",
      "2019-04-24 17:01:58,184 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,187 : INFO : built Dictionary(212 unique tokens: ['deep', 'get', 'heart', 'know', 'major']...) from 22 documents (total 322 corpus positions)\n",
      "2019-04-24 17:01:58,203 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,206 : INFO : built Dictionary(430 unique tokens: ['ano', 'arrancada', 'bater', 'bola', 'boneca']...) from 38 documents (total 703 corpus positions)\n",
      "2019-04-24 17:01:58,227 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:58,229 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,231 : INFO : built Dictionary(45 unique tokens: ['ano', 'centro', 'com', 'comparação', 'compra']...) from 4 documents (total 55 corpus positions)\n",
      "2019-04-24 17:01:58,233 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:58,237 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:58,256 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,260 : INFO : built Dictionary(349 unique tokens: ['aleem', 'app', 'built', 'cloud', 'com']...) from 107 documents (total 1048 corpus positions)\n",
      "2019-04-24 17:01:58,350 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,352 : INFO : built Dictionary(295 unique tokens: ['dictionari', 'economi', 'english', 'idea', 'introduc']...) from 31 documents (total 510 corpus positions)\n",
      "2019-04-24 17:01:58,367 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,369 : INFO : built Dictionary(112 unique tokens: ['atual', 'brasileiro', 'comportamento', 'consumidor', 'crise']...) from 10 documents (total 146 corpus positions)\n",
      "2019-04-24 17:01:58,383 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,386 : INFO : built Dictionary(343 unique tokens: ['agricultur', 'america', 'beat', 'crop', 'depart']...) from 50 documents (total 646 corpus positions)\n",
      "2019-04-24 17:01:58,416 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,418 : INFO : built Dictionary(164 unique tokens: ['feel', 'ilooklikeanengin', 'later', 'todai', 'year']...) from 16 documents (total 221 corpus positions)\n",
      "2019-04-24 17:01:58,430 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,432 : INFO : built Dictionary(224 unique tokens: ['concorrent', 'digio', 'elopar', 'lança', 'nubank']...) from 25 documents (total 348 corpus positions)\n",
      "2019-04-24 17:01:58,449 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,452 : INFO : built Dictionary(202 unique tokens: ['acquir', 'announc', 'com', 'come', 'discuss']...) from 31 documents (total 409 corpus positions)\n",
      "2019-04-24 17:01:58,483 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,487 : INFO : built Dictionary(571 unique tokens: ['advanc', 'artifici', 'beat', 'checker', 'chess']...) from 104 documents (total 1028 corpus positions)\n",
      "2019-04-24 17:01:58,723 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,727 : INFO : built Dictionary(391 unique tokens: ['aspect', 'lot', 'presid', 'tough', 'perk']...) from 74 documents (total 659 corpus positions)\n",
      "2019-04-24 17:01:58,766 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,768 : INFO : built Dictionary(155 unique tokens: ['atualidad', 'bastant', 'computador', 'contra', 'correm']...) from 19 documents (total 201 corpus positions)\n",
      "2019-04-24 17:01:58,778 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:58,781 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,783 : INFO : built Dictionary(52 unique tokens: ['avanço', 'axa', 'bilhõ', 'com', 'divulgado']...) from 5 documents (total 71 corpus positions)\n",
      "2019-04-24 17:01:58,786 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:58,799 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,802 : INFO : built Dictionary(302 unique tokens: ['call', 'fight', 'late', 'lesson', 'life']...) from 55 documents (total 513 corpus positions)\n",
      "2019-04-24 17:01:58,829 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,832 : INFO : built Dictionary(177 unique tokens: ['accentur', 'além', 'aprimorar', 'banco', 'brasil']...) from 12 documents (total 269 corpus positions)\n",
      "2019-04-24 17:01:58,843 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,846 : INFO : built Dictionary(253 unique tokens: ['adoção', 'api', 'aplicativo', 'applic', 'apresentar']...) from 22 documents (total 403 corpus positions)\n",
      "2019-04-24 17:01:58,860 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:58,862 : INFO : built Dictionary(90 unique tokens: ['amazon', 'ambit', 'bear', 'behold', 'boldest']...) from 10 documents (total 122 corpus positions)\n",
      "2019-04-24 17:01:58,872 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,875 : INFO : built Dictionary(216 unique tokens: ['arquitetura', 'atravé', 'cadeia', 'corporativo', 'orientada']...) from 22 documents (total 421 corpus positions)\n",
      "2019-04-24 17:01:58,892 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,895 : INFO : built Dictionary(181 unique tokens: ['dai', 'devic', 'happen', 'major', 'mobil']...) from 41 documents (total 342 corpus positions)\n",
      "2019-04-24 17:01:58,911 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,913 : INFO : built Dictionary(85 unique tokens: ['allow', 'cloud', 'command', 'connect', 'googl']...) from 12 documents (total 133 corpus positions)\n",
      "2019-04-24 17:01:58,933 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,937 : INFO : built Dictionary(419 unique tokens: ['collabor', 'cross', 'design', 'develop', 'function']...) from 62 documents (total 872 corpus positions)\n",
      "2019-04-24 17:01:58,995 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:58,998 : INFO : built Dictionary(423 unique tokens: ['agosto', 'brasil', 'com', 'durant', 'estará']...) from 43 documents (total 793 corpus positions)\n",
      "2019-04-24 17:01:59,037 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:59,039 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,041 : INFO : built Dictionary(75 unique tokens: ['insight', 'know', 'market', 'mobifi', 'mobil']...) from 6 documents (total 130 corpus positions)\n",
      "2019-04-24 17:01:59,044 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:59,052 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,055 : INFO : built Dictionary(123 unique tokens: ['approach', 'behavior', 'believ', 'chang', 'happier']...) from 18 documents (total 218 corpus positions)\n",
      "2019-04-24 17:01:59,069 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,073 : INFO : built Dictionary(321 unique tokens: ['broken', 'entri', 'previou', 'theori', 'touch']...) from 47 documents (total 446 corpus positions)\n",
      "2019-04-24 17:01:59,093 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,097 : INFO : built Dictionary(136 unique tokens: ['app', 'applic', 'cloud', 'command', 'consol']...) from 18 documents (total 278 corpus positions)\n",
      "2019-04-24 17:01:59,110 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,113 : INFO : built Dictionary(180 unique tokens: ['best', 'dai', 'fridai', 'industri', 'music']...) from 32 documents (total 292 corpus positions)\n",
      "2019-04-24 17:01:59,128 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:59,130 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,132 : INFO : built Dictionary(66 unique tokens: ['acquir', 'acquisit', 'appl', 'bui', 'comment']...) from 4 documents (total 86 corpus positions)\n",
      "2019-04-24 17:01:59,135 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:59,139 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:59,145 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,148 : INFO : built Dictionary(153 unique tokens: ['admit', 'exec', 'remain', 'shut', 'skulli']...) from 17 documents (total 209 corpus positions)\n",
      "2019-04-24 17:01:59,159 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,162 : INFO : built Dictionary(187 unique tokens: ['compani', 'gartner', 'industri', 'leader', 'look']...) from 22 documents (total 276 corpus positions)\n",
      "2019-04-24 17:01:59,172 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:59,174 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,177 : INFO : built Dictionary(116 unique tokens: ['anunci', 'aplicativo', 'consultora', 'consumidor', 'encontrar']...) from 8 documents (total 151 corpus positions)\n",
      "2019-04-24 17:01:59,179 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:59,195 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,199 : INFO : built Dictionary(300 unique tokens: ['abil', 'cross', 'deliveri', 'engin', 'modern']...) from 82 documents (total 711 corpus positions)\n",
      "2019-04-24 17:01:59,251 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,255 : INFO : built Dictionary(174 unique tokens: ['acquir', 'amazon', 'announc', 'bid', 'biggest']...) from 17 documents (total 241 corpus positions)\n",
      "2019-04-24 17:01:59,266 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,269 : INFO : built Dictionary(242 unique tokens: ['da', 'dai', 'estev', 'jornada', 'palco']...) from 28 documents (total 352 corpus positions)\n",
      "2019-04-24 17:01:59,294 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,298 : INFO : built Dictionary(380 unique tokens: ['drupalcamp', 'excit', 'invit', 'juli', 'keynot']...) from 90 documents (total 698 corpus positions)\n",
      "2019-04-24 17:01:59,342 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,345 : INFO : built Dictionary(214 unique tokens: ['anunci', 'aquisição', 'açõ', 'bilhõ', 'com']...) from 22 documents (total 316 corpus positions)\n",
      "2019-04-24 17:01:59,357 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,360 : INFO : built Dictionary(147 unique tokens: ['android', 'appli', 'chang', 'channel', 'chrome']...) from 23 documents (total 215 corpus positions)\n",
      "2019-04-24 17:01:59,370 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:59,372 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,374 : INFO : built Dictionary(74 unique tokens: ['bem', 'científica', 'como', 'compreend', 'comun']...) from 6 documents (total 90 corpus positions)\n",
      "2019-04-24 17:01:59,376 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:59,389 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,392 : INFO : built Dictionary(363 unique tokens: ['ag', 'awesom', 'choic', 'danni', 'develop']...) from 57 documents (total 582 corpus positions)\n",
      "2019-04-24 17:01:59,421 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,424 : INFO : built Dictionary(251 unique tokens: ['aproveit', 'atenção', 'brasil', 'chamar', 'da']...) from 22 documents (total 381 corpus positions)\n",
      "2019-04-24 17:01:59,437 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,439 : INFO : built Dictionary(50 unique tokens: ['appl', 'connect', 'develop', 'easier', 'itun']...) from 11 documents (total 107 corpus positions)\n",
      "2019-04-24 17:01:59,457 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,460 : INFO : built Dictionary(526 unique tokens: ['carro', 'esquec', 'filho', 'função', 'ganhou']...) from 63 documents (total 1014 corpus positions)\n",
      "2019-04-24 17:01:59,505 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,507 : INFO : built Dictionary(122 unique tokens: ['amazon', 'cloud', 'comput', 'constantli', 'googl']...) from 11 documents (total 184 corpus positions)\n",
      "2019-04-24 17:01:59,515 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,517 : INFO : built Dictionary(152 unique tokens: ['emoçõ', 'estão', 'fort', 'janeiro', 'jogo']...) from 17 documents (total 234 corpus positions)\n",
      "2019-04-24 17:01:59,525 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,528 : INFO : built Dictionary(68 unique tokens: ['devot', 'fame', 'fanbas', 'formula', 'innov']...) from 10 documents (total 100 corpus positions)\n",
      "2019-04-24 17:01:59,540 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:01:59,543 : INFO : built Dictionary(224 unique tokens: ['announc', 'beta', 'confer', 'focus', 'futurestack']...) from 31 documents (total 435 corpus positions)\n",
      "2019-04-24 17:01:59,561 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,564 : INFO : built Dictionary(186 unique tokens: ['adept', 'alert', 'android', 'applic', 'assist']...) from 18 documents (total 288 corpus positions)\n",
      "2019-04-24 17:01:59,573 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:59,575 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,578 : INFO : built Dictionary(90 unique tokens: ['ajudar', 'anunci', 'caixa', 'com', 'encontrarem']...) from 7 documents (total 119 corpus positions)\n",
      "2019-04-24 17:01:59,580 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:59,590 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,593 : INFO : built Dictionary(190 unique tokens: ['anxieti', 'code', 'deploi', 'deploy', 'diagnos']...) from 37 documents (total 345 corpus positions)\n",
      "2019-04-24 17:01:59,623 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,627 : INFO : built Dictionary(460 unique tokens: ['account', 'better', 'busi', 'complet', 'custom']...) from 75 documents (total 958 corpus positions)\n",
      "2019-04-24 17:01:59,696 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,700 : INFO : built Dictionary(554 unique tokens: ['boister', 'digit', 'hui', 'live', 'market']...) from 95 documents (total 1008 corpus positions)\n",
      "2019-04-24 17:01:59,764 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,767 : INFO : built Dictionary(267 unique tokens: ['brasil', 'captur', 'client', 'elogio', 'empresa']...) from 41 documents (total 420 corpus positions)\n",
      "2019-04-24 17:01:59,788 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,791 : INFO : built Dictionary(219 unique tokens: ['app', 'build', 'configur', 'creat', 'react']...) from 65 documents (total 446 corpus positions)\n",
      "2019-04-24 17:01:59,818 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:59,821 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,823 : INFO : built Dictionary(102 unique tokens: ['apresentadora', 'assistir', 'atriz', 'estamo', 'executiva']...) from 9 documents (total 120 corpus positions)\n",
      "2019-04-24 17:01:59,825 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:59,831 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:59,833 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,835 : INFO : built Dictionary(47 unique tokens: ['acaso', 'ano', 'apareceu', 'bar', 'conhecida']...) from 3 documents (total 50 corpus positions)\n",
      "2019-04-24 17:01:59,838 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:59,841 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:59,852 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,856 : INFO : built Dictionary(382 unique tokens: ['alli', 'aug', 'bank', 'chase', 'financi']...) from 54 documents (total 662 corpus positions)\n",
      "2019-04-24 17:01:59,884 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:01:59,886 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,888 : INFO : built Dictionary(19 unique tokens: ['center', 'chang', 'data', 'fundament', 'build']...) from 4 documents (total 23 corpus positions)\n",
      "2019-04-24 17:01:59,890 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:01:59,893 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:01:59,927 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:01:59,933 : INFO : built Dictionary(570 unique tokens: ['compani', 'fast', 'let', 'map', 'start']...) from 300 documents (total 1699 corpus positions)\n",
      "2019-04-24 17:02:00,199 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,201 : INFO : built Dictionary(169 unique tokens: ['accord', 'appl', 'familiar', 'lineup', 'macbook']...) from 19 documents (total 270 corpus positions)\n",
      "2019-04-24 17:02:00,215 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,218 : INFO : built Dictionary(210 unique tokens: ['coach', 'manag', 'bad', 'categori', 'develop']...) from 52 documents (total 418 corpus positions)\n",
      "2019-04-24 17:02:00,251 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,254 : INFO : built Dictionary(267 unique tokens: ['architectur', 'brazilian', 'cassandra', 'com', 'complet']...) from 33 documents (total 467 corpus positions)\n",
      "2019-04-24 17:02:00,277 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,280 : INFO : built Dictionary(222 unique tokens: ['applic', 'command', 'desktop', 'graphic', 'host']...) from 39 documents (total 423 corpus positions)\n",
      "2019-04-24 17:02:00,296 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,299 : INFO : built Dictionary(100 unique tokens: ['email', 'gmail', 'help', 'introduc', 'new']...) from 10 documents (total 141 corpus positions)\n",
      "2019-04-24 17:02:00,306 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,309 : INFO : built Dictionary(128 unique tokens: ['appli', 'best', 'genderbread', 'learn', 'lesson']...) from 22 documents (total 190 corpus positions)\n",
      "2019-04-24 17:02:00,322 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,325 : INFO : built Dictionary(219 unique tokens: ['acl', 'announc', 'api', 'basi', 'cloud']...) from 36 documents (total 376 corpus positions)\n",
      "2019-04-24 17:02:00,342 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,344 : INFO : built Dictionary(91 unique tokens: ['acquir', 'appl', 'artifici', 'intellig', 'learn']...) from 11 documents (total 130 corpus positions)\n",
      "2019-04-24 17:02:00,355 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,358 : INFO : built Dictionary(248 unique tokens: ['todai', 'turn', 'woz', 'appl', 'august']...) from 27 documents (total 346 corpus positions)\n",
      "2019-04-24 17:02:00,372 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,375 : INFO : built Dictionary(124 unique tokens: ['appl', 'continu', 'doll', 'evan', 'expand']...) from 17 documents (total 195 corpus positions)\n",
      "2019-04-24 17:02:00,385 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,389 : INFO : built Dictionary(105 unique tokens: ['anim', 'animar', 'animatedvectordraw', 'animatorset', 'arquivo']...) from 11 documents (total 162 corpus positions)\n",
      "2019-04-24 17:02:00,397 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,403 : INFO : built Dictionary(93 unique tokens: ['access', 'drive', 'file', 'googl', 'learn']...) from 21 documents (total 209 corpus positions)\n",
      "2019-04-24 17:02:00,414 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,416 : INFO : built Dictionary(128 unique tokens: ['apó', 'chinê', 'decid', 'duelo', 'jogar']...) from 13 documents (total 172 corpus positions)\n",
      "2019-04-24 17:02:00,424 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,426 : INFO : built Dictionary(113 unique tokens: ['banco', 'bradesco', 'digit', 'lançar', 'novo']...) from 15 documents (total 153 corpus positions)\n",
      "2019-04-24 17:02:00,437 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,442 : INFO : built Dictionary(186 unique tokens: ['abril', 'agosto', 'feira', 'grupo', 'gustavo']...) from 14 documents (total 245 corpus positions)\n",
      "2019-04-24 17:02:00,454 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,456 : INFO : built Dictionary(160 unique tokens: ['ainda', 'algo', 'analayt', 'analis', 'analyt']...) from 15 documents (total 289 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:00,465 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:00,467 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,469 : INFO : built Dictionary(73 unique tokens: ['disabl', 'feliz', 'javascript', 'longo', 'mantêm']...) from 8 documents (total 85 corpus positions)\n",
      "2019-04-24 17:02:00,472 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:00,494 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,499 : INFO : built Dictionary(481 unique tokens: ['angular', 'appear', 'beta', 'blood', 'framework']...) from 140 documents (total 1138 corpus positions)\n",
      "2019-04-24 17:02:00,604 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,606 : INFO : built Dictionary(121 unique tokens: ['burg', 'drupal', 'earlier', 'intriguingli', 'post']...) from 22 documents (total 200 corpus positions)\n",
      "2019-04-24 17:02:00,616 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,620 : INFO : built Dictionary(199 unique tokens: ['bank', 'compon', 'cost', 'digit', 'disrupt']...) from 23 documents (total 264 corpus positions)\n",
      "2019-04-24 17:02:00,633 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,636 : INFO : built Dictionary(98 unique tokens: ['drive', 'file', 'folder', 'googl', 'learn']...) from 26 documents (total 256 corpus positions)\n",
      "2019-04-24 17:02:00,650 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,652 : INFO : built Dictionary(122 unique tokens: ['dan', 'hello', 'savag', 'comment', 'fan']...) from 33 documents (total 171 corpus positions)\n",
      "2019-04-24 17:02:00,664 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,666 : INFO : built Dictionary(120 unique tokens: ['bit', 'build', 'complet', 'fridai', 'googl']...) from 15 documents (total 160 corpus positions)\n",
      "2019-04-24 17:02:00,687 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,691 : INFO : built Dictionary(351 unique tokens: ['architect', 'aw', 'coupl', 'devop', 'exam']...) from 81 documents (total 785 corpus positions)\n",
      "2019-04-24 17:02:00,745 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,748 : INFO : built Dictionary(365 unique tokens: ['creat', 'data', 'handl', 'infrastructur', 'instanc']...) from 107 documents (total 974 corpus positions)\n",
      "2019-04-24 17:02:00,814 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:00,816 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,818 : INFO : built Dictionary(96 unique tokens: ['amass', 'announc', 'app', 'blab', 'ceo']...) from 8 documents (total 119 corpus positions)\n",
      "2019-04-24 17:02:00,820 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:00,828 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,831 : INFO : built Dictionary(140 unique tokens: ['baggag', 'bank', 'build', 'februari', 'nbsp']...) from 25 documents (total 203 corpus positions)\n",
      "2019-04-24 17:02:00,841 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:00,844 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,847 : INFO : built Dictionary(94 unique tokens: ['adoção', 'android', 'anunci', 'aplicativo', 'aqui']...) from 7 documents (total 163 corpus positions)\n",
      "2019-04-24 17:02:00,850 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:00,855 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:00,857 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,860 : INFO : built Dictionary(32 unique tokens: ['build', 'deloitt', 'disrupt', 'distribut', 'econom']...) from 2 documents (total 40 corpus positions)\n",
      "2019-04-24 17:02:00,862 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:00,864 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:00,867 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:00,870 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:00,873 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,875 : INFO : built Dictionary(27 unique tokens: ['absolut', 'break', 'chang', 'github', 'hedgerwang']...) from 2 documents (total 32 corpus positions)\n",
      "2019-04-24 17:02:00,877 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:00,880 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:00,882 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:00,890 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,894 : INFO : built Dictionary(194 unique tokens: ['advic', 'agenc', 'carnegi', 'chief', 'commiss']...) from 29 documents (total 335 corpus positions)\n",
      "2019-04-24 17:02:00,912 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,915 : INFO : built Dictionary(225 unique tokens: ['appl', 'save', 'audienc', 'august', 'brightli']...) from 27 documents (total 317 corpus positions)\n",
      "2019-04-24 17:02:00,934 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,937 : INFO : built Dictionary(308 unique tokens: ['cook', 'lot', 'tim', 'appl', 'compani']...) from 71 documents (total 517 corpus positions)\n",
      "2019-04-24 17:02:00,967 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:00,969 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,972 : INFO : built Dictionary(112 unique tokens: ['come', 'control', 'data', 'group', 'lab']...) from 9 documents (total 155 corpus positions)\n",
      "2019-04-24 17:02:00,975 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:00,987 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:00,990 : INFO : built Dictionary(316 unique tokens: ['beauti', 'languag', 'specif', 'annual', 'billion']...) from 43 documents (total 466 corpus positions)\n",
      "2019-04-24 17:02:01,009 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,012 : INFO : built Dictionary(115 unique tokens: ['author', 'content', 'descript', 'document', 'huge']...) from 25 documents (total 219 corpus positions)\n",
      "2019-04-24 17:02:01,038 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,042 : INFO : built Dictionary(278 unique tokens: ['biggest', 'bot', 'chat', 'know', 'read']...) from 76 documents (total 769 corpus positions)\n",
      "2019-04-24 17:02:01,099 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,103 : INFO : built Dictionary(185 unique tokens: ['channel', 'discov', 'media', 'product', 'thought']...) from 28 documents (total 396 corpus positions)\n",
      "2019-04-24 17:02:01,118 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,121 : INFO : built Dictionary(85 unique tokens: ['air', 'announc', 'avail', 'googl', 'hangout']...) from 22 documents (total 173 corpus positions)\n",
      "2019-04-24 17:02:01,136 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,139 : INFO : built Dictionary(254 unique tokens: ['advanc', 'analyt', 'data', 'expens', 'gain']...) from 37 documents (total 453 corpus positions)\n",
      "2019-04-24 17:02:01,176 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,180 : INFO : built Dictionary(497 unique tokens: ['adapt', 'conf', 'dehghani', 'keynot', 'nginx']...) from 138 documents (total 1143 corpus positions)\n",
      "2019-04-24 17:02:01,269 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:01,271 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,273 : INFO : built Dictionary(111 unique tokens: ['anunci', 'anunciant', 'anúncio', 'ação', 'bloqueio']...) from 8 documents (total 141 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:01,275 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:01,316 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,323 : INFO : built Dictionary(1210 unique tokens: ['best', 'choic', 'collaps', 'complex', 'convers']...) from 242 documents (total 2671 corpus positions)\n",
      "2019-04-24 17:02:01,534 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:01,536 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,538 : INFO : built Dictionary(79 unique tokens: ['cerimônia', 'da', 'empresa', 'entr', 'foto']...) from 7 documents (total 140 corpus positions)\n",
      "2019-04-24 17:02:01,541 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:01,551 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,554 : INFO : built Dictionary(226 unique tokens: ['android', 'app', 'bare', 'bone', 'call']...) from 37 documents (total 380 corpus positions)\n",
      "2019-04-24 17:02:01,580 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,583 : INFO : built Dictionary(368 unique tokens: ['govern', 'littl', 'open', 'agenc', 'avail']...) from 62 documents (total 691 corpus positions)\n",
      "2019-04-24 17:02:01,616 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:01,619 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,621 : INFO : built Dictionary(90 unique tokens: ['air', 'dia', 'googl', 'hangout', 'para']...) from 9 documents (total 132 corpus positions)\n",
      "2019-04-24 17:02:01,623 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:01,632 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,635 : INFO : built Dictionary(207 unique tokens: ['definit', 'hype', 'littl', 'wari', 'attract']...) from 27 documents (total 333 corpus positions)\n",
      "2019-04-24 17:02:01,651 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,654 : INFO : built Dictionary(204 unique tokens: ['address', 'advanc', 'area', 'artifici', 'chang']...) from 24 documents (total 351 corpus positions)\n",
      "2019-04-24 17:02:01,675 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,679 : INFO : built Dictionary(417 unique tokens: ['la', 'platform', 'springon', 'vega', 'week']...) from 83 documents (total 728 corpus positions)\n",
      "2019-04-24 17:02:01,736 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,741 : INFO : built Dictionary(552 unique tokens: ['architectur', 'dissect', 'fascin', 'favorit', 'folk']...) from 124 documents (total 1409 corpus positions)\n",
      "2019-04-24 17:02:01,832 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,834 : INFO : built Dictionary(210 unique tokens: ['best', 'cloud', 'commit', 'databas', 'googl']...) from 26 documents (total 431 corpus positions)\n",
      "2019-04-24 17:02:01,847 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,850 : INFO : built Dictionary(126 unique tokens: ['broker', 'bunch', 'exploit', 'group', 'heard']...) from 18 documents (total 205 corpus positions)\n",
      "2019-04-24 17:02:01,858 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,861 : INFO : built Dictionary(92 unique tokens: ['bank', 'herald', 'imag', 'interact', 'jerri']...) from 10 documents (total 115 corpus positions)\n",
      "2019-04-24 17:02:01,878 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,882 : INFO : built Dictionary(245 unique tokens: ['app', 'boss', 'hear', 'hei', 'know']...) from 178 documents (total 595 corpus positions)\n",
      "2019-04-24 17:02:01,960 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,963 : INFO : built Dictionary(365 unique tokens: ['believ', 'caus', 'commun', 'core', 'dark']...) from 71 documents (total 574 corpus positions)\n",
      "2019-04-24 17:02:01,991 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:01,994 : INFO : built Dictionary(238 unique tokens: ['beacon', 'breve', 'carioca', 'com', 'desenvolvida']...) from 26 documents (total 394 corpus positions)\n",
      "2019-04-24 17:02:02,007 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:02,010 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,012 : INFO : built Dictionary(69 unique tokens: ['campanha', 'conduzir', 'empresa', 'googl', 'nuvem']...) from 6 documents (total 79 corpus positions)\n",
      "2019-04-24 17:02:02,014 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:02,016 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:02,019 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:02,025 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,028 : INFO : built Dictionary(199 unique tokens: ['agosto', 'autogestão', 'comentário', 'disposição', 'enviado']...) from 14 documents (total 371 corpus positions)\n",
      "2019-04-24 17:02:02,035 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:02,037 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,040 : INFO : built Dictionary(21 unique tokens: ['app', 'engin', 'isol', 'resourc', 'servic']...) from 3 documents (total 29 corpus positions)\n",
      "2019-04-24 17:02:02,042 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:02,045 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:02,057 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,060 : INFO : built Dictionary(373 unique tokens: ['confer', 'fit', 'francisco', 'landscap', 'market']...) from 53 documents (total 634 corpus positions)\n",
      "2019-04-24 17:02:02,090 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,093 : INFO : built Dictionary(326 unique tokens: ['com', 'dói', 'escutado', 'essa', 'frequência']...) from 44 documents (total 580 corpus positions)\n",
      "2019-04-24 17:02:02,112 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,115 : INFO : built Dictionary(160 unique tokens: ['broke', 'car', 'drive', 'earli', 'new']...) from 24 documents (total 255 corpus positions)\n",
      "2019-04-24 17:02:02,145 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,150 : INFO : built Dictionary(580 unique tokens: ['autom', 'avoid', 'car', 'crash', 'equip']...) from 107 documents (total 1324 corpus positions)\n",
      "2019-04-24 17:02:02,244 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,248 : INFO : built Dictionary(122 unique tokens: ['air', 'anunci', 'descontinuado', 'dia', 'googl']...) from 11 documents (total 193 corpus positions)\n",
      "2019-04-24 17:02:02,258 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:02,260 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,263 : INFO : built Dictionary(90 unique tokens: ['ao', 'brasil', 'desd', 'disponível', 'estado']...) from 8 documents (total 123 corpus positions)\n",
      "2019-04-24 17:02:02,266 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:02,273 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:02,276 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,279 : INFO : built Dictionary(75 unique tokens: ['analyz', 'creat', 'distribut', 'easi', 'form']...) from 6 documents (total 104 corpus positions)\n",
      "2019-04-24 17:02:02,281 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:02,303 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,307 : INFO : built Dictionary(587 unique tokens: ['alberto', 'ano', 'brasil', 'costuma', 'design']...) from 83 documents (total 1056 corpus positions)\n",
      "2019-04-24 17:02:02,374 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,377 : INFO : built Dictionary(208 unique tokens: ['owner', 'person', 'product', 'theori', 'complex']...) from 38 documents (total 519 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:02,395 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,398 : INFO : built Dictionary(207 unique tokens: ['adaptarem', 'analista', 'anúncio', 'cenário', 'cisco']...) from 18 documents (total 298 corpus positions)\n",
      "2019-04-24 17:02:02,439 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,445 : INFO : built Dictionary(511 unique tokens: ['abil', 'custom', 'enabl', 'extend', 'govern']...) from 188 documents (total 1772 corpus positions)\n",
      "2019-04-24 17:02:02,607 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:02,609 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,610 : INFO : built Dictionary(17 unique tokens: ['certainli', 'compon', 'consid', 'import', 'manag']...) from 3 documents (total 18 corpus positions)\n",
      "2019-04-24 17:02:02,612 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:02,616 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:02,622 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,625 : INFO : built Dictionary(189 unique tokens: ['chamada', 'complicada', 'experiência', 'frustrant', 'ma']...) from 23 documents (total 361 corpus positions)\n",
      "2019-04-24 17:02:02,642 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,645 : INFO : built Dictionary(151 unique tokens: ['back', 'corpor', 'crop', 'harvest', 'improv']...) from 11 documents (total 260 corpus positions)\n",
      "2019-04-24 17:02:02,662 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,666 : INFO : built Dictionary(295 unique tokens: ['earn', 'honor', 'learn', 'machin', 'march']...) from 43 documents (total 542 corpus positions)\n",
      "2019-04-24 17:02:02,699 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,703 : INFO : built Dictionary(338 unique tokens: ['cloud', 'custom', 'live', 'multi', 'platform']...) from 66 documents (total 685 corpus positions)\n",
      "2019-04-24 17:02:02,735 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:02,737 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,739 : INFO : built Dictionary(21 unique tokens: ['incred', 'learn', 'machin', 'move', 'quickli']...) from 3 documents (total 22 corpus positions)\n",
      "2019-04-24 17:02:02,741 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:02,743 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:02,746 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:02,748 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:02,750 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,753 : INFO : built Dictionary(42 unique tokens: ['atingir', 'bate', 'comportamentai', 'conhecimento', 'contínua']...) from 2 documents (total 43 corpus positions)\n",
      "2019-04-24 17:02:02,755 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:02,758 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:02,759 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:02,765 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,768 : INFO : built Dictionary(162 unique tokens: ['billion', 'content', 'dai', 'facebook', 'piec']...) from 20 documents (total 234 corpus positions)\n",
      "2019-04-24 17:02:02,781 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,784 : INFO : built Dictionary(186 unique tokens: ['andi', 'austin', 'call', 'data', 'earlier']...) from 31 documents (total 322 corpus positions)\n",
      "2019-04-24 17:02:02,817 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,822 : INFO : built Dictionary(480 unique tokens: ['analysi', 'app', 'blog', 'central', 'collect']...) from 107 documents (total 1273 corpus positions)\n",
      "2019-04-24 17:02:02,899 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,901 : INFO : built Dictionary(144 unique tokens: ['googl', 'home', 'wai', 'confer', 'fantast']...) from 30 documents (total 194 corpus positions)\n",
      "2019-04-24 17:02:02,910 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:02,912 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,915 : INFO : built Dictionary(100 unique tokens: ['appeal', 'appear', 'biggest', 'effici', 'fasttext']...) from 9 documents (total 129 corpus positions)\n",
      "2019-04-24 17:02:02,917 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:02,927 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,930 : INFO : built Dictionary(215 unique tokens: ['believ', 'featur', 'ionic', 'requir', 'speed']...) from 44 documents (total 395 corpus positions)\n",
      "2019-04-24 17:02:02,954 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,957 : INFO : built Dictionary(220 unique tokens: ['agre', 'edison', 'geniu', 'inspir', 'knew']...) from 37 documents (total 337 corpus positions)\n",
      "2019-04-24 17:02:02,972 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:02,974 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:02,977 : INFO : built Dictionary(110 unique tokens: ['abertura', 'abreconta', 'aplicativo', 'banco', 'conta']...) from 8 documents (total 152 corpus positions)\n",
      "2019-04-24 17:02:02,980 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:02,999 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,006 : INFO : built Dictionary(369 unique tokens: ['app', 'build', 'built', 'chang', 'deploi']...) from 65 documents (total 665 corpus positions)\n",
      "2019-04-24 17:02:03,063 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,067 : INFO : built Dictionary(543 unique tokens: ['algorithm', 'answer', 'data', 'depend', 'learn']...) from 145 documents (total 1423 corpus positions)\n",
      "2019-04-24 17:02:03,188 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,190 : INFO : built Dictionary(372 unique tokens: ['corpo', 'desenhada', 'humano', 'movimento', 'máquina']...) from 37 documents (total 485 corpus positions)\n",
      "2019-04-24 17:02:03,217 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,220 : INFO : built Dictionary(410 unique tokens: ['client', 'date', 'dev', 'impress', 'project']...) from 101 documents (total 727 corpus positions)\n",
      "2019-04-24 17:02:03,278 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,281 : INFO : built Dictionary(500 unique tokens: ['apocalypt', 'aris', 'concern', 'express', 'like']...) from 76 documents (total 932 corpus positions)\n",
      "2019-04-24 17:02:03,325 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,328 : INFO : built Dictionary(230 unique tokens: ['citi', 'look', 'afford', 'hous', 'job']...) from 54 documents (total 443 corpus positions)\n",
      "2019-04-24 17:02:03,355 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,359 : INFO : built Dictionary(264 unique tokens: ['conveni', 'faster', 'mobil', 'safer', 'space']...) from 47 documents (total 448 corpus positions)\n",
      "2019-04-24 17:02:03,387 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,391 : INFO : built Dictionary(351 unique tokens: ['data', 'discuss', 'gave', 'iheartradio', 'june']...) from 60 documents (total 816 corpus positions)\n",
      "2019-04-24 17:02:03,424 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,427 : INFO : built Dictionary(102 unique tokens: ['acordo', 'android', 'com', 'completament', 'construindo']...) from 10 documents (total 137 corpus positions)\n",
      "2019-04-24 17:02:03,436 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,439 : INFO : built Dictionary(218 unique tokens: ['answer', 'big', 'fear', 'onlin', 'purchas']...) from 28 documents (total 281 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:03,459 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,463 : INFO : built Dictionary(296 unique tokens: ['announc', 'challeng', 'consist', 'darpa', 'drc']...) from 60 documents (total 631 corpus positions)\n",
      "2019-04-24 17:02:03,488 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:03,490 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,492 : INFO : built Dictionary(109 unique tokens: ['acontec', 'acordo', 'android', 'aplicativo', 'assist']...) from 8 documents (total 144 corpus positions)\n",
      "2019-04-24 17:02:03,495 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:03,509 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,513 : INFO : built Dictionary(337 unique tokens: ['billion', 'connect', 'devic', 'discuss', 'follow']...) from 51 documents (total 604 corpus positions)\n",
      "2019-04-24 17:02:03,540 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,543 : INFO : built Dictionary(58 unique tokens: ['allow', 'connect', 'easier', 'far', 'faster']...) from 13 documents (total 76 corpus positions)\n",
      "2019-04-24 17:02:03,549 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,551 : INFO : built Dictionary(52 unique tokens: ['america', 'central', 'disharmoni', 'doom', 'engend']...) from 10 documents (total 59 corpus positions)\n",
      "2019-04-24 17:02:03,559 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,562 : INFO : built Dictionary(139 unique tokens: ['facebook', 'got', 'list', 'littl', 'longer']...) from 20 documents (total 196 corpus positions)\n",
      "2019-04-24 17:02:03,584 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,588 : INFO : built Dictionary(398 unique tokens: ['app', 'build', 'compil', 'complex', 'danni']...) from 100 documents (total 893 corpus positions)\n",
      "2019-04-24 17:02:03,654 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,657 : INFO : built Dictionary(367 unique tokens: ['chang', 'cours', 'doubt', 'ipad', 'kid']...) from 39 documents (total 570 corpus positions)\n",
      "2019-04-24 17:02:03,678 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,681 : INFO : built Dictionary(271 unique tokens: ['add', 'countri', 'dollar', 'easi', 'economi']...) from 36 documents (total 483 corpus positions)\n",
      "2019-04-24 17:02:03,703 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,706 : INFO : built Dictionary(224 unique tokens: ['app', 'chat', 'duo', 'googl', 'launch']...) from 42 documents (total 418 corpus positions)\n",
      "2019-04-24 17:02:03,732 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,735 : INFO : built Dictionary(281 unique tokens: ['abrissem', 'aumento', 'banco', 'calot', 'cavallari']...) from 31 documents (total 519 corpus positions)\n",
      "2019-04-24 17:02:03,754 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,757 : INFO : built Dictionary(212 unique tokens: ['annoy', 'robocal', 'threat', 'ident', 'scammer']...) from 32 documents (total 316 corpus positions)\n",
      "2019-04-24 17:02:03,768 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:03,771 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,773 : INFO : built Dictionary(25 unique tokens: ['acquia', 'boundari', 'digit', 'partner', 'possibl']...) from 3 documents (total 27 corpus positions)\n",
      "2019-04-24 17:02:03,775 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:03,778 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:03,780 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:03,783 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,785 : INFO : built Dictionary(19 unique tokens: ['institut', 'manag', 'project', 'reserv', 'right']...) from 2 documents (total 29 corpus positions)\n",
      "2019-04-24 17:02:03,787 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:03,790 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:03,792 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:03,802 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,806 : INFO : built Dictionary(270 unique tokens: ['ceo', 'chanc', 'develop', 'fintech', 'founder']...) from 54 documents (total 488 corpus positions)\n",
      "2019-04-24 17:02:03,834 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,837 : INFO : built Dictionary(218 unique tokens: ['platform', 'team', 'tool', 'wiki', 'commun']...) from 62 documents (total 527 corpus positions)\n",
      "2019-04-24 17:02:03,874 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,877 : INFO : built Dictionary(298 unique tokens: ['feedback', 'final', 'given', 'guid', 'past']...) from 20 documents (total 590 corpus positions)\n",
      "2019-04-24 17:02:03,907 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,912 : INFO : built Dictionary(475 unique tokens: ['abil', 'amazon', 'cdn', 'cloudfront', 'content']...) from 89 documents (total 1386 corpus positions)\n",
      "2019-04-24 17:02:03,970 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,972 : INFO : built Dictionary(265 unique tokens: ['aparentement', 'conhecemo', 'council', 'da', 'design']...) from 14 documents (total 383 corpus positions)\n",
      "2019-04-24 17:02:03,982 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:03,985 : INFO : built Dictionary(139 unique tokens: ['board', 'charg', 'code', 'exist', 'free']...) from 17 documents (total 207 corpus positions)\n",
      "2019-04-24 17:02:03,999 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,003 : INFO : built Dictionary(196 unique tokens: ['california', 'comput', 'confer', 'editor', 'final']...) from 40 documents (total 386 corpus positions)\n",
      "2019-04-24 17:02:04,028 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,032 : INFO : built Dictionary(498 unique tokens: ['aqui', 'era', 'falamo', 'fim', 'lembra']...) from 47 documents (total 777 corpus positions)\n",
      "2019-04-24 17:02:04,065 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,068 : INFO : built Dictionary(421 unique tokens: ['empresa', 'essenci', 'inovação', 'part', 'qualquer']...) from 37 documents (total 662 corpus positions)\n",
      "2019-04-24 17:02:04,090 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:04,092 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,094 : INFO : built Dictionary(107 unique tokens: ['com', 'edição', 'está', 'mai', 'programar']...) from 4 documents (total 136 corpus positions)\n",
      "2019-04-24 17:02:04,096 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:04,100 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:04,110 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,113 : INFO : built Dictionary(237 unique tokens: ['border', 'break', 'ebai', 'learn', 'machin']...) from 31 documents (total 423 corpus positions)\n",
      "2019-04-24 17:02:04,129 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:04,132 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,134 : INFO : built Dictionary(77 unique tokens: ['act', 'announc', 'appl', 'date', 'exhilar']...) from 8 documents (total 102 corpus positions)\n",
      "2019-04-24 17:02:04,137 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:04,143 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:04,145 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,147 : INFO : built Dictionary(74 unique tokens: ['appl', 'bid', 'built', 'job', 'onlin']...) from 8 documents (total 103 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:04,149 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:04,160 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,163 : INFO : built Dictionary(237 unique tokens: ['api', 'batteri', 'charger', 'danni', 'desper']...) from 31 documents (total 383 corpus positions)\n",
      "2019-04-24 17:02:04,183 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,188 : INFO : built Dictionary(273 unique tokens: ['ago', 'attend', 'coupl', 'design', 'event']...) from 57 documents (total 522 corpus positions)\n",
      "2019-04-24 17:02:04,221 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,224 : INFO : built Dictionary(286 unique tokens: ['experi', 'great', 'netflix', 'stream', 'test']...) from 57 documents (total 556 corpus positions)\n",
      "2019-04-24 17:02:04,248 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:04,250 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,252 : INFO : built Dictionary(25 unique tokens: ['add', 'branch', 'code', 'comput', 'coverag']...) from 3 documents (total 32 corpus positions)\n",
      "2019-04-24 17:02:04,255 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:04,257 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:04,259 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:04,266 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,269 : INFO : built Dictionary(177 unique tokens: ['august', 'craziest', 'engin', 'happen', 'life']...) from 30 documents (total 267 corpus positions)\n",
      "2019-04-24 17:02:04,282 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,287 : INFO : built Dictionary(110 unique tokens: ['announc', 'august', 'belfast', 'blockchain', 'blog']...) from 11 documents (total 181 corpus positions)\n",
      "2019-04-24 17:02:04,301 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,305 : INFO : built Dictionary(184 unique tokens: ['extrem', 'hack', 'javascript', 'post', 'share']...) from 33 documents (total 444 corpus positions)\n",
      "2019-04-24 17:02:04,324 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,327 : INFO : built Dictionary(183 unique tokens: ['artifici', 'email', 'intellig', 'look', 'messag']...) from 30 documents (total 294 corpus positions)\n",
      "2019-04-24 17:02:04,342 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,344 : INFO : built Dictionary(193 unique tokens: ['animada', 'autor', 'com', 'design', 'dia']...) from 18 documents (total 323 corpus positions)\n",
      "2019-04-24 17:02:04,363 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,368 : INFO : built Dictionary(461 unique tokens: ['aplicaçõ', 'com', 'diversa', 'extremament', 'função']...) from 49 documents (total 882 corpus positions)\n",
      "2019-04-24 17:02:04,411 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,414 : INFO : built Dictionary(350 unique tokens: ['core', 'cultur', 'engin', 'entrust', 'freedom']...) from 79 documents (total 805 corpus positions)\n",
      "2019-04-24 17:02:04,471 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,475 : INFO : built Dictionary(458 unique tokens: ['agora', 'alcançamo', 'ant', 'baita', 'com']...) from 122 documents (total 813 corpus positions)\n",
      "2019-04-24 17:02:04,533 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:04,535 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,538 : INFO : built Dictionary(79 unique tokens: ['acquir', 'allow', 'app', 'articl', 'design']...) from 8 documents (total 109 corpus positions)\n",
      "2019-04-24 17:02:04,540 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:04,549 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,552 : INFO : built Dictionary(174 unique tokens: ['allow', 'ceo', 'continu', 'health', 'job']...) from 22 documents (total 278 corpus positions)\n",
      "2019-04-24 17:02:04,568 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,571 : INFO : built Dictionary(136 unique tokens: ['anniversari', 'appl', 'appoint', 'august', 'board']...) from 18 documents (total 244 corpus positions)\n",
      "2019-04-24 17:02:04,587 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,590 : INFO : built Dictionary(184 unique tokens: ['app', 'cloud', 'datacent', 'describ', 'giant']...) from 30 documents (total 357 corpus positions)\n",
      "2019-04-24 17:02:04,613 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,616 : INFO : built Dictionary(336 unique tokens: ['decid', 'even', 'frazzl', 'hand', 'help']...) from 57 documents (total 495 corpus positions)\n",
      "2019-04-24 17:02:04,643 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,647 : INFO : built Dictionary(277 unique tokens: ['ceo', 'chen', 'editor', 'founder', 'guoguo']...) from 33 documents (total 568 corpus positions)\n",
      "2019-04-24 17:02:04,670 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,673 : INFO : built Dictionary(148 unique tokens: ['actual', 'artifici', 'chatbot', 'contest', 'free']...) from 16 documents (total 212 corpus positions)\n",
      "2019-04-24 17:02:04,682 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,685 : INFO : built Dictionary(103 unique tokens: ['announc', 'app', 'bot', 'categori', 'close']...) from 16 documents (total 138 corpus positions)\n",
      "2019-04-24 17:02:04,696 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,700 : INFO : built Dictionary(250 unique tokens: ['acab', 'com', 'compartilhar', 'conarh', 'congresso']...) from 30 documents (total 380 corpus positions)\n",
      "2019-04-24 17:02:04,718 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,721 : INFO : built Dictionary(167 unique tokens: ['dai', 'inform', 'media', 'new', 'peopl']...) from 29 documents (total 299 corpus positions)\n",
      "2019-04-24 17:02:04,740 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,744 : INFO : built Dictionary(250 unique tokens: ['appl', 'articl', 'artifici', 'compani', 'craig']...) from 37 documents (total 444 corpus positions)\n",
      "2019-04-24 17:02:04,772 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,776 : INFO : built Dictionary(455 unique tokens: ['ainda', 'futuro', 'mesmo', 'necessidad', 'planejar']...) from 64 documents (total 1066 corpus positions)\n",
      "2019-04-24 17:02:04,826 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,829 : INFO : built Dictionary(147 unique tokens: ['custom', 'excit', 'field', 'maxim', 'new']...) from 30 documents (total 294 corpus positions)\n",
      "2019-04-24 17:02:04,843 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:04,846 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,849 : INFO : built Dictionary(106 unique tokens: ['aplicação', 'asp', 'atual', 'baseada', 'com']...) from 6 documents (total 130 corpus positions)\n",
      "2019-04-24 17:02:04,852 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:04,862 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,865 : INFO : built Dictionary(236 unique tokens: ['acaba', 'accentiv', 'anunciar', 'atravé', 'cartõ']...) from 18 documents (total 413 corpus positions)\n",
      "2019-04-24 17:02:04,881 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,884 : INFO : built Dictionary(239 unique tokens: ['attack', 'buster', 'clinton', 'compani', 'donald']...) from 34 documents (total 369 corpus positions)\n",
      "2019-04-24 17:02:04,898 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,902 : INFO : built Dictionary(86 unique tokens: ['appl', 'archiv', 'bought', 'collect', 'collector']...) from 12 documents (total 117 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:04,912 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,915 : INFO : built Dictionary(167 unique tokens: ['drupal', 'modul', 'month', 'struck', 'chosen']...) from 38 documents (total 307 corpus positions)\n",
      "2019-04-24 17:02:04,935 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,938 : INFO : built Dictionary(213 unique tokens: ['attempt', 'brand', 'ceo', 'chatbot', 'discuss']...) from 31 documents (total 310 corpus positions)\n",
      "2019-04-24 17:02:04,958 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:04,962 : INFO : built Dictionary(208 unique tokens: ['basic', 'cli', 'command', 'docker', 'go']...) from 62 documents (total 634 corpus positions)\n",
      "2019-04-24 17:02:05,014 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,019 : INFO : built Dictionary(597 unique tokens: ['ainda', 'atraído', 'cada', 'ciência', 'dominado']...) from 58 documents (total 1108 corpus positions)\n",
      "2019-04-24 17:02:05,067 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,070 : INFO : built Dictionary(175 unique tokens: ['avail', 'detail', 'exactli', 'fix', 'green']...) from 17 documents (total 232 corpus positions)\n",
      "2019-04-24 17:02:05,082 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,086 : INFO : built Dictionary(123 unique tokens: ['hash', 'moment', 'realiz', 'server', 'tabl']...) from 42 documents (total 226 corpus positions)\n",
      "2019-04-24 17:02:05,105 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,110 : INFO : built Dictionary(349 unique tokens: ['face', 'financeiro', 'novo', 'outra', 'realment']...) from 40 documents (total 608 corpus positions)\n",
      "2019-04-24 17:02:05,132 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,135 : INFO : built Dictionary(73 unique tokens: ['agora', 'clickpag', 'facilitar', 'iniciativa', 'pagamento']...) from 12 documents (total 98 corpus positions)\n",
      "2019-04-24 17:02:05,144 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,147 : INFO : built Dictionary(187 unique tokens: ['aim', 'analysi', 'compani', 'consortium', 'cosmiq']...) from 17 documents (total 272 corpus positions)\n",
      "2019-04-24 17:02:05,163 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,167 : INFO : built Dictionary(378 unique tokens: ['artigo', 'aston', 'bond', 'brasil', 'canantech']...) from 33 documents (total 620 corpus positions)\n",
      "2019-04-24 17:02:05,188 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,190 : INFO : built Dictionary(118 unique tokens: ['appl', 'colleg', 'dilemma', 'drop', 'face']...) from 13 documents (total 154 corpus positions)\n",
      "2019-04-24 17:02:05,201 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,204 : INFO : built Dictionary(254 unique tokens: ['comum', 'corr', 'corredor', 'dizendo', 'fulano']...) from 29 documents (total 422 corpus positions)\n",
      "2019-04-24 17:02:05,254 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,260 : INFO : built Dictionary(910 unique tokens: ['appl', 'artifici', 'brain', 'exclus', 'insid']...) from 213 documents (total 2289 corpus positions)\n",
      "2019-04-24 17:02:05,538 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,541 : INFO : built Dictionary(421 unique tokens: ['hei', 'blog', 'deal', 'decid', 'final']...) from 111 documents (total 1136 corpus positions)\n",
      "2019-04-24 17:02:05,625 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,628 : INFO : built Dictionary(469 unique tokens: ['brain', 'eerili', 'encount', 'facebook', 'newsfe']...) from 143 documents (total 945 corpus positions)\n",
      "2019-04-24 17:02:05,722 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,724 : INFO : built Dictionary(232 unique tokens: ['bem', 'component', 'devido', 'dinheiro', 'empresa']...) from 21 documents (total 356 corpus positions)\n",
      "2019-04-24 17:02:05,746 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,750 : INFO : built Dictionary(425 unique tokens: ['act', 'code', 'deliv', 'exampl', 'gather']...) from 126 documents (total 889 corpus positions)\n",
      "2019-04-24 17:02:05,829 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,832 : INFO : built Dictionary(302 unique tokens: ['armário', 'dentro', 'lgbt', 'para', 'publicado']...) from 43 documents (total 528 corpus positions)\n",
      "2019-04-24 17:02:05,856 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,859 : INFO : built Dictionary(251 unique tokens: ['believ', 'common', 'hundr', 'lectur', 'make']...) from 43 documents (total 410 corpus positions)\n",
      "2019-04-24 17:02:05,882 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,885 : INFO : built Dictionary(316 unique tokens: ['ano', 'como', 'drasticament', 'experiência', 'habilidad']...) from 30 documents (total 567 corpus positions)\n",
      "2019-04-24 17:02:05,919 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:05,922 : INFO : built Dictionary(440 unique tokens: ['coder', 'develop', 'effici', 'import', 'learn']...) from 147 documents (total 964 corpus positions)\n",
      "2019-04-24 17:02:06,002 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,005 : INFO : built Dictionary(190 unique tokens: ['cada', 'crescimento', 'criada', 'destaca', 'digit']...) from 15 documents (total 297 corpus positions)\n",
      "2019-04-24 17:02:06,022 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,025 : INFO : built Dictionary(280 unique tokens: ['danish', 'reuter', 'siddiqui', 'uber', 'untouch']...) from 62 documents (total 548 corpus positions)\n",
      "2019-04-24 17:02:06,063 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,066 : INFO : built Dictionary(301 unique tokens: ['cheap', 'easi', 'gene', 'health', 'inform']...) from 35 documents (total 473 corpus positions)\n",
      "2019-04-24 17:02:06,085 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,089 : INFO : built Dictionary(143 unique tokens: ['arduino', 'better', 'cooper', 'michael', 'remind']...) from 37 documents (total 243 corpus positions)\n",
      "2019-04-24 17:02:06,111 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,114 : INFO : built Dictionary(314 unique tokens: ['arduino', 'crazi', 'gone', 'obviou', 'reason']...) from 71 documents (total 866 corpus positions)\n",
      "2019-04-24 17:02:06,158 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:06,160 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,162 : INFO : built Dictionary(102 unique tokens: ['americana', 'bebida', 'coca', 'cola', 'companhia']...) from 7 documents (total 128 corpus positions)\n",
      "2019-04-24 17:02:06,164 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:06,179 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,183 : INFO : built Dictionary(504 unique tokens: ['algun', 'aplicativo', 'campo', 'classificado', 'como']...) from 63 documents (total 966 corpus positions)\n",
      "2019-04-24 17:02:06,227 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,230 : INFO : built Dictionary(172 unique tokens: ['calendar', 'folk', 'mark', 'offici', 'appl']...) from 24 documents (total 319 corpus positions)\n",
      "2019-04-24 17:02:06,244 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,247 : INFO : built Dictionary(151 unique tokens: ['appl', 'auditorium', 'california', 'centric', 'civic']...) from 16 documents (total 248 corpus positions)\n",
      "2019-04-24 17:02:06,256 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,261 : INFO : built Dictionary(158 unique tokens: ['aplicação', 'baseia', 'com', 'corpo', 'entr']...) from 13 documents (total 225 corpus positions)\n",
      "2019-04-24 17:02:06,270 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:06,273 : INFO : built Dictionary(140 unique tokens: ['bissexuai', 'campanha', 'carolina', 'celebra', 'com']...) from 11 documents (total 187 corpus positions)\n",
      "2019-04-24 17:02:06,284 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,287 : INFO : built Dictionary(172 unique tokens: ['advanc', 'app', 'artifici', 'bui', 'carri']...) from 27 documents (total 309 corpus positions)\n",
      "2019-04-24 17:02:06,313 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,317 : INFO : built Dictionary(429 unique tokens: ['discuss', 'docker', 'ecosystem', 'end', 'split']...) from 73 documents (total 944 corpus positions)\n",
      "2019-04-24 17:02:06,369 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,371 : INFO : built Dictionary(105 unique tokens: ['cloud', 'develop', 'easi', 'gcp', 'googl']...) from 16 documents (total 214 corpus positions)\n",
      "2019-04-24 17:02:06,390 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,394 : INFO : built Dictionary(374 unique tokens: ['applic', 'background', 'data', 'develop', 'divers']...) from 58 documents (total 875 corpus positions)\n",
      "2019-04-24 17:02:06,436 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,438 : INFO : built Dictionary(167 unique tokens: ['amaz', 'associ', 'awesom', 'benefit', 'blog']...) from 21 documents (total 236 corpus positions)\n",
      "2019-04-24 17:02:06,459 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,464 : INFO : built Dictionary(395 unique tokens: ['bitcoin', 'blockchain', 'circa', 'gdp', 'global']...) from 60 documents (total 856 corpus positions)\n",
      "2019-04-24 17:02:06,506 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,508 : INFO : built Dictionary(236 unique tokens: ['billion', 'cdn', 'content', 'deliveri', 'disrupt']...) from 19 documents (total 385 corpus positions)\n",
      "2019-04-24 17:02:06,518 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:06,521 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,523 : INFO : built Dictionary(103 unique tokens: ['acessório', 'acompanhar', 'americano', 'chegada', 'durant']...) from 8 documents (total 133 corpus positions)\n",
      "2019-04-24 17:02:06,525 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:06,533 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:06,536 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,539 : INFO : built Dictionary(91 unique tokens: ['app', 'better', 'chat', 'commun', 'custom']...) from 8 documents (total 144 corpus positions)\n",
      "2019-04-24 17:02:06,541 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:06,552 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,555 : INFO : built Dictionary(303 unique tokens: ['aprendizado', 'barata', 'conseguir', 'criar', 'dar']...) from 31 documents (total 556 corpus positions)\n",
      "2019-04-24 17:02:06,578 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,581 : INFO : built Dictionary(220 unique tokens: ['art', 'classif', 'earlier', 'imag', 'implement']...) from 25 documents (total 364 corpus positions)\n",
      "2019-04-24 17:02:06,598 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,601 : INFO : built Dictionary(184 unique tokens: ['articl', 'ba', 'base', 'bdd', 'behaviour']...) from 29 documents (total 390 corpus positions)\n",
      "2019-04-24 17:02:06,617 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,619 : INFO : built Dictionary(96 unique tokens: ['amazon', 'aw', 'azur', 'cloud', 'custom']...) from 11 documents (total 139 corpus positions)\n",
      "2019-04-24 17:02:06,644 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,650 : INFO : built Dictionary(533 unique tokens: ['app', 'ascensão', 'do', 'espetacular', 'falar']...) from 69 documents (total 1059 corpus positions)\n",
      "2019-04-24 17:02:06,703 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:06,706 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,709 : INFO : built Dictionary(57 unique tokens: ['american', 'com', 'crosscultur', 'cultur', 'expect']...) from 9 documents (total 69 corpus positions)\n",
      "2019-04-24 17:02:06,713 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:06,721 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,724 : INFO : built Dictionary(126 unique tokens: ['acquisit', 'appl', 'artifici', 'base', 'compani']...) from 15 documents (total 202 corpus positions)\n",
      "2019-04-24 17:02:06,744 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,748 : INFO : built Dictionary(389 unique tokens: ['comparison', 'hourglass', 'pixabai', 'sourc', 'ariel']...) from 75 documents (total 728 corpus positions)\n",
      "2019-04-24 17:02:06,791 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,795 : INFO : built Dictionary(306 unique tokens: ['compani', 'date', 'facebook', 'fossbyt', 'impress']...) from 49 documents (total 541 corpus positions)\n",
      "2019-04-24 17:02:06,826 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,830 : INFO : built Dictionary(297 unique tokens: ['case', 'deep', 'hyperbol', 'imagin', 'learn']...) from 49 documents (total 635 corpus positions)\n",
      "2019-04-24 17:02:06,867 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,871 : INFO : built Dictionary(377 unique tokens: ['bon', 'crédito', 'divulgação', 'diz', 'inglê']...) from 72 documents (total 787 corpus positions)\n",
      "2019-04-24 17:02:06,917 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,921 : INFO : built Dictionary(106 unique tokens: ['argu', 'classic', 'code', 'concept', 'debat']...) from 11 documents (total 157 corpus positions)\n",
      "2019-04-24 17:02:06,929 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:06,931 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,933 : INFO : built Dictionary(27 unique tokens: ['blockchain', 'actual', 'chanc', 'clarif', 'know']...) from 3 documents (total 27 corpus positions)\n",
      "2019-04-24 17:02:06,936 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:06,942 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:06,950 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,954 : INFO : built Dictionary(141 unique tokens: ['architectur', 'came', 'complet', 'explain', 'greenfield']...) from 19 documents (total 211 corpus positions)\n",
      "2019-04-24 17:02:06,970 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:06,973 : INFO : built Dictionary(105 unique tokens: ['activ', 'dai', 'default', 'past', 'topic']...) from 44 documents (total 417 corpus positions)\n",
      "2019-04-24 17:02:07,010 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,014 : INFO : built Dictionary(119 unique tokens: ['closur', 'compil', 'develop', 'engin', 'java']...) from 21 documents (total 208 corpus positions)\n",
      "2019-04-24 17:02:07,028 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,031 : INFO : built Dictionary(164 unique tokens: ['bank', 'blockchain', 'btl', 'european', 'group']...) from 19 documents (total 273 corpus positions)\n",
      "2019-04-24 17:02:07,045 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,048 : INFO : built Dictionary(188 unique tokens: ['abil', 'aka', 'befuddl', 'imag', 'pictur']...) from 22 documents (total 263 corpus positions)\n",
      "2019-04-24 17:02:07,062 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,065 : INFO : built Dictionary(134 unique tokens: ['artifici', 'comput', 'evolv', 'intellig', 'know']...) from 23 documents (total 250 corpus positions)\n",
      "2019-04-24 17:02:07,095 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:07,101 : INFO : built Dictionary(766 unique tokens: ['banco', 'cada', 'companhia', 'dado', 'dedicam']...) from 112 documents (total 1518 corpus positions)\n",
      "2019-04-24 17:02:07,252 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,257 : INFO : built Dictionary(875 unique tokens: ['armi', 'artifici', 'better', 'build', 'coder']...) from 171 documents (total 2038 corpus positions)\n",
      "2019-04-24 17:02:07,447 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:07,448 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,449 : INFO : built Dictionary(31 unique tokens: ['applic', 'content', 'cross', 'design', 'mechan']...) from 2 documents (total 34 corpus positions)\n",
      "2019-04-24 17:02:07,451 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:07,454 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:07,455 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:07,459 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,463 : INFO : built Dictionary(93 unique tokens: ['aren', 'confirm', 'detail', 'dropbox', 'final']...) from 15 documents (total 131 corpus positions)\n",
      "2019-04-24 17:02:07,472 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,475 : INFO : built Dictionary(129 unique tokens: ['competência', 'existem', 'obrigatória', 'para', 'profissionai']...) from 17 documents (total 183 corpus positions)\n",
      "2019-04-24 17:02:07,486 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,489 : INFO : built Dictionary(191 unique tokens: ['centuri', 'com', 'criar', 'fez', 'film']...) from 19 documents (total 297 corpus positions)\n",
      "2019-04-24 17:02:07,513 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,518 : INFO : built Dictionary(425 unique tokens: ['busi', 'challeng', 'chang', 'daili', 'digit']...) from 64 documents (total 800 corpus positions)\n",
      "2019-04-24 17:02:07,561 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,564 : INFO : built Dictionary(208 unique tokens: ['associ', 'churn', 'cmo', 'contribut', 'demand']...) from 36 documents (total 312 corpus positions)\n",
      "2019-04-24 17:02:07,584 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,587 : INFO : built Dictionary(192 unique tokens: ['aris', 'best', 'cloud', 'comput', 'continu']...) from 53 documents (total 498 corpus positions)\n",
      "2019-04-24 17:02:07,635 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,640 : INFO : built Dictionary(517 unique tokens: ['android', 'best', 'dai', 'decid', 'decis']...) from 168 documents (total 1208 corpus positions)\n",
      "2019-04-24 17:02:07,765 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,768 : INFO : built Dictionary(308 unique tokens: ['atravé', 'centro', 'desenvolvimento', 'diferencia', 'digit']...) from 37 documents (total 487 corpus positions)\n",
      "2019-04-24 17:02:07,792 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,795 : INFO : built Dictionary(311 unique tokens: ['agent', 'competência', 'cuidar', 'da', 'entendemo']...) from 21 documents (total 568 corpus positions)\n",
      "2019-04-24 17:02:07,818 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,822 : INFO : built Dictionary(306 unique tokens: ['action', 'advanc', 'analyt', 'busi', 'cognit']...) from 41 documents (total 516 corpus positions)\n",
      "2019-04-24 17:02:07,850 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:07,853 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,856 : INFO : built Dictionary(17 unique tokens: ['advic', 'analyt', 'articl', 'avail', 'book']...) from 2 documents (total 21 corpus positions)\n",
      "2019-04-24 17:02:07,859 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:07,861 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:07,864 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:07,876 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,879 : INFO : built Dictionary(177 unique tokens: ['batalha', 'cinco', 'código', 'da', 'deveria']...) from 22 documents (total 279 corpus positions)\n",
      "2019-04-24 17:02:07,899 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,903 : INFO : built Dictionary(251 unique tokens: ['acabar', 'cartão', 'com', 'crédito', 'deu']...) from 33 documents (total 431 corpus positions)\n",
      "2019-04-24 17:02:07,925 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,928 : INFO : built Dictionary(166 unique tokens: ['compani', 'custom', 'depart', 'intens', 'resourc']...) from 37 documents (total 271 corpus positions)\n",
      "2019-04-24 17:02:07,955 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,958 : INFO : built Dictionary(129 unique tokens: ['case', 'content', 'instanc', 'packag', 'suppos']...) from 21 documents (total 306 corpus positions)\n",
      "2019-04-24 17:02:07,973 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:07,977 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:07,980 : INFO : built Dictionary(33 unique tokens: ['carro', 'espaço', 'mai', 'para', 'que']...) from 3 documents (total 37 corpus positions)\n",
      "2019-04-24 17:02:07,983 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:07,990 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:08,005 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,012 : INFO : built Dictionary(264 unique tokens: ['achiev', 'best', 'better', 'book', 'build']...) from 88 documents (total 560 corpus positions)\n",
      "2019-04-24 17:02:08,064 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:08,067 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,070 : INFO : built Dictionary(44 unique tokens: ['adipis', 'amet', 'consectetur', 'dolor', 'elit']...) from 3 documents (total 48 corpus positions)\n",
      "2019-04-24 17:02:08,071 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:08,076 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:08,081 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,087 : INFO : built Dictionary(108 unique tokens: ['cloud', 'converg', 'data', 'devic', 'differ']...) from 12 documents (total 161 corpus positions)\n",
      "2019-04-24 17:02:08,096 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,099 : INFO : built Dictionary(119 unique tokens: ['amazon', 'aw', 'consultoria', 'continua', 'divulgado']...) from 12 documents (total 193 corpus positions)\n",
      "2019-04-24 17:02:08,110 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,113 : INFO : built Dictionary(176 unique tokens: ['até', 'bilhõ', 'considerável', 'do', 'dobro']...) from 14 documents (total 266 corpus positions)\n",
      "2019-04-24 17:02:08,135 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,141 : INFO : built Dictionary(454 unique tokens: ['alv', 'ano', 'detalh', 'exam', 'fachada']...) from 46 documents (total 842 corpus positions)\n",
      "2019-04-24 17:02:08,180 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,185 : INFO : built Dictionary(149 unique tokens: ['applic', 'architectur', 'australia', 'cindi', 'coast']...) from 27 documents (total 210 corpus positions)\n",
      "2019-04-24 17:02:08,203 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,207 : INFO : built Dictionary(238 unique tokens: ['api', 'beta', 'cloud', 'googl', 'languag']...) from 46 documents (total 486 corpus positions)\n",
      "2019-04-24 17:02:08,231 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:08,234 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:08,237 : INFO : built Dictionary(25 unique tokens: ['appl', 'event', 'francisco', 'iphon', 'new']...) from 4 documents (total 33 corpus positions)\n",
      "2019-04-24 17:02:08,239 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:08,244 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:08,247 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:08,248 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,251 : INFO : built Dictionary(37 unique tokens: ['airpod', 'announc', 'appl', 'automat', 'connect']...) from 4 documents (total 49 corpus positions)\n",
      "2019-04-24 17:02:08,253 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:08,258 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:08,262 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:08,264 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,267 : INFO : built Dictionary(43 unique tokens: ['announc', 'appl', 'call', 'confirm', 'devic']...) from 4 documents (total 61 corpus positions)\n",
      "2019-04-24 17:02:08,269 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:08,273 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:08,280 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,284 : INFO : built Dictionary(164 unique tokens: ['announc', 'appl', 'event', 'francisco', 'inch']...) from 14 documents (total 250 corpus positions)\n",
      "2019-04-24 17:02:08,295 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:08,298 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,302 : INFO : built Dictionary(51 unique tokens: ['appl', 'big', 'compani', 'cult', 'date']...) from 3 documents (total 58 corpus positions)\n",
      "2019-04-24 17:02:08,305 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:08,310 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:08,350 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,359 : INFO : built Dictionary(852 unique tokens: ['adapt', 'appl', 'easili', 'greg', 'grin']...) from 185 documents (total 1770 corpus positions)\n",
      "2019-04-24 17:02:08,558 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,560 : INFO : built Dictionary(83 unique tokens: ['abstract', 'got', 'html', 'look', 'wai']...) from 18 documents (total 109 corpus positions)\n",
      "2019-04-24 17:02:08,569 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:08,572 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,575 : INFO : built Dictionary(17 unique tokens: ['activ', 'captur', 'credit', 'drupal', 'issu']...) from 3 documents (total 24 corpus positions)\n",
      "2019-04-24 17:02:08,578 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:08,581 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:08,583 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:08,589 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:08,592 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,596 : INFO : built Dictionary(114 unique tokens: ['aim', 'allow', 'app', 'auchenberg', 'code']...) from 8 documents (total 208 corpus positions)\n",
      "2019-04-24 17:02:08,600 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:08,628 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,634 : INFO : built Dictionary(412 unique tokens: ['compani', 'differ', 'digit', 'european', 'increas']...) from 68 documents (total 879 corpus positions)\n",
      "2019-04-24 17:02:08,733 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:08,739 : INFO : built Dictionary(817 unique tokens: ['action', 'busi', 'explor', 'gener', 'growth']...) from 182 documents (total 2075 corpus positions)\n",
      "2019-04-24 17:02:09,045 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,051 : INFO : built Dictionary(140 unique tokens: ['demand', 'game', 'new', 'park', 'spothero']...) from 19 documents (total 217 corpus positions)\n",
      "2019-04-24 17:02:09,074 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,078 : INFO : built Dictionary(101 unique tokens: ['ano', 'do', 'financeira', 'fundada', 'maior']...) from 12 documents (total 142 corpus positions)\n",
      "2019-04-24 17:02:09,089 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,095 : INFO : built Dictionary(127 unique tokens: ['bradesco', 'client', 'desta', 'nfc', 'partir']...) from 12 documents (total 149 corpus positions)\n",
      "2019-04-24 17:02:09,128 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,134 : INFO : built Dictionary(302 unique tokens: ['complex', 'configur', 'environ', 'fundament', 'internet']...) from 113 documents (total 935 corpus positions)\n",
      "2019-04-24 17:02:09,275 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,281 : INFO : built Dictionary(357 unique tokens: ['address', 'architect', 'area', 'aw', 'cloud']...) from 97 documents (total 797 corpus positions)\n",
      "2019-04-24 17:02:09,356 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,360 : INFO : built Dictionary(267 unique tokens: ['anniversari', 'best', 'busi', 'capabl', 'chang']...) from 50 documents (total 558 corpus positions)\n",
      "2019-04-24 17:02:09,396 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,401 : INFO : built Dictionary(318 unique tokens: ['acabam', 'ao', 'atend', 'brasil', 'cluster']...) from 26 documents (total 560 corpus positions)\n",
      "2019-04-24 17:02:09,426 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:09,429 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,432 : INFO : built Dictionary(79 unique tokens: ['coisa', 'com', 'da', 'do', 'grand']...) from 5 documents (total 97 corpus positions)\n",
      "2019-04-24 17:02:09,436 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:09,450 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,455 : INFO : built Dictionary(289 unique tokens: ['coolest', 'css', 'danni', 'date', 'develop']...) from 42 documents (total 450 corpus positions)\n",
      "2019-04-24 17:02:09,485 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,490 : INFO : built Dictionary(256 unique tokens: ['appl', 'critic', 'lost', 'think', 'touch']...) from 43 documents (total 387 corpus positions)\n",
      "2019-04-24 17:02:09,518 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,523 : INFO : built Dictionary(218 unique tokens: ['busi', 'citi', 'comedi', 'decid', 'group']...) from 54 documents (total 329 corpus positions)\n",
      "2019-04-24 17:02:09,559 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,566 : INFO : built Dictionary(304 unique tokens: ['ask', 'beat', 'includ', 'intrigu', 'introduct']...) from 60 documents (total 640 corpus positions)\n",
      "2019-04-24 17:02:09,625 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,629 : INFO : built Dictionary(268 unique tokens: ['artifici', 'coupl', 'deep', 'intellig', 'learn']...) from 58 documents (total 519 corpus positions)\n",
      "2019-04-24 17:02:09,682 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,688 : INFO : built Dictionary(159 unique tokens: ['evolv', 'ey', 'luck', 'superbug', 'want']...) from 32 documents (total 265 corpus positions)\n",
      "2019-04-24 17:02:09,711 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,716 : INFO : built Dictionary(226 unique tokens: ['acreditam', 'afirma', 'ano', 'apena', 'departamento']...) from 22 documents (total 376 corpus positions)\n",
      "2019-04-24 17:02:09,742 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:09,747 : INFO : built Dictionary(340 unique tokens: ['adoção', 'biometria', 'brasil', 'cada', 'certificação']...) from 33 documents (total 579 corpus positions)\n",
      "2019-04-24 17:02:09,794 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,803 : INFO : built Dictionary(568 unique tokens: ['atenção', 'carreira', 'coisa', 'da', 'distant']...) from 65 documents (total 974 corpus positions)\n",
      "2019-04-24 17:02:09,864 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,868 : INFO : built Dictionary(327 unique tokens: ['atualment', 'cerca', 'custo', 'desenvolvedora', 'empresa']...) from 39 documents (total 659 corpus positions)\n",
      "2019-04-24 17:02:09,904 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,909 : INFO : built Dictionary(145 unique tokens: ['ceo', 'event', 'gitlab', 'live', 'master']...) from 23 documents (total 237 corpus positions)\n",
      "2019-04-24 17:02:09,930 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,933 : INFO : built Dictionary(113 unique tokens: ['android', 'commun', 'enjoi', 'follow', 'member']...) from 18 documents (total 144 corpus positions)\n",
      "2019-04-24 17:02:09,949 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,953 : INFO : built Dictionary(134 unique tokens: ['anális', 'aristotl', 'aristótel', 'baseia', 'centena']...) from 11 documents (total 191 corpus positions)\n",
      "2019-04-24 17:02:09,962 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:09,965 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,969 : INFO : built Dictionary(25 unique tokens: ['approach', 'learn', 'map', 'mind', 'revolutionari']...) from 3 documents (total 31 corpus positions)\n",
      "2019-04-24 17:02:09,973 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:09,976 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:09,987 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:09,992 : INFO : built Dictionary(188 unique tokens: ['applic', 'build', 'heavili', 'involv', 'past']...) from 37 documents (total 317 corpus positions)\n",
      "2019-04-24 17:02:10,028 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:10,033 : INFO : built Dictionary(481 unique tokens: ['analítica', 'como', 'construção', 'disnei', 'década']...) from 53 documents (total 878 corpus positions)\n",
      "2019-04-24 17:02:10,124 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:10,132 : INFO : built Dictionary(522 unique tokens: ['dark', 'let', 'scrum', 'talk', 'oppress']...) from 272 documents (total 1540 corpus positions)\n",
      "2019-04-24 17:02:10,446 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:10,449 : INFO : built Dictionary(90 unique tokens: ['como', 'dividida', 'empresa', 'equip', 'são']...) from 10 documents (total 113 corpus positions)\n",
      "2019-04-24 17:02:10,458 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:10,461 : INFO : built Dictionary(180 unique tokens: ['administrativo', 'administração', 'alguma', 'alta', 'ano']...) from 23 documents (total 269 corpus positions)\n",
      "2019-04-24 17:02:10,482 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:10,486 : INFO : built Dictionary(180 unique tokens: ['android', 'app', 'code', 'dai', 'diseas']...) from 33 documents (total 345 corpus positions)\n",
      "2019-04-24 17:02:10,562 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:10,568 : INFO : built Dictionary(536 unique tokens: ['adapt', 'chang', 'cheaper', 'custom', 'easier']...) from 136 documents (total 1196 corpus positions)\n",
      "2019-04-24 17:02:10,707 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:10,711 : INFO : built Dictionary(178 unique tokens: ['com', 'fidelidad', 'inici', 'novo', 'nubank']...) from 20 documents (total 287 corpus positions)\n",
      "2019-04-24 17:02:10,731 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:10,735 : INFO : built Dictionary(127 unique tokens: ['automot', 'fast', 'move', 'olli', 'concept']...) from 18 documents (total 157 corpus positions)\n",
      "2019-04-24 17:02:10,746 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:10,749 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:10,753 : INFO : built Dictionary(103 unique tokens: ['atravé', 'brasil', 'comunicar', 'curitiba', 'dba']...) from 9 documents (total 126 corpus positions)\n",
      "2019-04-24 17:02:10,756 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:10,771 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:10,777 : INFO : built Dictionary(333 unique tokens: ['abrimo', 'aprend', 'brasil', 'campu', 'conectar']...) from 34 documents (total 505 corpus positions)\n",
      "2019-04-24 17:02:10,810 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:10,814 : INFO : built Dictionary(281 unique tokens: ['cover', 'familiar', 'fig', 'leaf', 'long']...) from 39 documents (total 558 corpus positions)\n",
      "2019-04-24 17:02:10,853 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:10,860 : INFO : built Dictionary(240 unique tokens: ['artifici', 'base', 'compani', 'deepmind', 'diseas']...) from 40 documents (total 439 corpus positions)\n",
      "2019-04-24 17:02:10,908 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:10,913 : INFO : built Dictionary(364 unique tokens: ['artifici', 'chang', 'crawford', 'impact', 'intellig']...) from 44 documents (total 569 corpus positions)\n",
      "2019-04-24 17:02:10,942 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:10,945 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:10,952 : INFO : built Dictionary(70 unique tokens: ['com', 'divulg', 'estratégica', 'mastercard', 'parceria']...) from 6 documents (total 84 corpus positions)\n",
      "2019-04-24 17:02:10,959 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:11,026 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,034 : INFO : built Dictionary(244 unique tokens: ['adher', 'adopt', 'bank', 'bitcoin', 'blockchain']...) from 29 documents (total 388 corpus positions)\n",
      "2019-04-24 17:02:11,077 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:11,080 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,084 : INFO : built Dictionary(31 unique tokens: ['custom', 'deliv', 'user', 'valu', 'know']...) from 3 documents (total 33 corpus positions)\n",
      "2019-04-24 17:02:11,089 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:11,094 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:11,114 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,124 : INFO : built Dictionary(347 unique tokens: ['acendendo', 'campu', 'chegar', 'conform', 'entrando']...) from 34 documents (total 627 corpus positions)\n",
      "2019-04-24 17:02:11,172 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,177 : INFO : built Dictionary(512 unique tokens: ['avaliamo', 'bpmn', 'com', 'criar', 'diagrama']...) from 89 documents (total 1387 corpus positions)\n",
      "2019-04-24 17:02:11,325 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,331 : INFO : built Dictionary(485 unique tokens: ['authent', 'base', 'relev', 'token', 'address']...) from 161 documents (total 1590 corpus positions)\n",
      "2019-04-24 17:02:11,517 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,521 : INFO : built Dictionary(239 unique tokens: ['announc', 'base', 'center', 'cloud', 'compani']...) from 28 documents (total 407 corpus positions)\n",
      "2019-04-24 17:02:11,546 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,551 : INFO : built Dictionary(253 unique tokens: ['agricultura', 'alcançass', 'atual', 'brasileira', 'campo']...) from 17 documents (total 364 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:11,579 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,582 : INFO : built Dictionary(300 unique tokens: ['good', 'iphon', 'look', 'appl', 'big']...) from 58 documents (total 573 corpus positions)\n",
      "2019-04-24 17:02:11,625 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:11,628 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,632 : INFO : built Dictionary(75 unique tokens: ['app', 'appl', 'includ', 'io', 'iwork']...) from 8 documents (total 174 corpus positions)\n",
      "2019-04-24 17:02:11,635 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:11,645 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,649 : INFO : built Dictionary(132 unique tokens: ['appl', 'design', 'io', 'ipad', 'iphon']...) from 16 documents (total 223 corpus positions)\n",
      "2019-04-24 17:02:11,670 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,675 : INFO : built Dictionary(335 unique tokens: ['appear', 'chang', 'commerc', 'drupal', 'ecommerc']...) from 58 documents (total 691 corpus positions)\n",
      "2019-04-24 17:02:11,727 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,730 : INFO : built Dictionary(140 unique tokens: ['acordo', 'alemão', 'americana', 'anunci', 'bayer']...) from 16 documents (total 214 corpus positions)\n",
      "2019-04-24 17:02:11,754 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,760 : INFO : built Dictionary(288 unique tokens: ['compani', 'friction', 'hidden', 'slow', 'sourc']...) from 56 documents (total 456 corpus positions)\n",
      "2019-04-24 17:02:11,792 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,799 : INFO : built Dictionary(143 unique tokens: ['adquiriu', 'atravé', 'capit', 'commerc', 'comércio']...) from 10 documents (total 196 corpus positions)\n",
      "2019-04-24 17:02:11,817 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,823 : INFO : built Dictionary(279 unique tokens: ['channel', 'exponenti', 'grown', 'market', 'multi']...) from 45 documents (total 465 corpus positions)\n",
      "2019-04-24 17:02:11,872 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,878 : INFO : built Dictionary(321 unique tokens: ['annual', 'build', 'celebr', 'confer', 'design']...) from 62 documents (total 745 corpus positions)\n",
      "2019-04-24 17:02:11,974 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:11,982 : INFO : built Dictionary(496 unique tokens: ['causal', 'mathemat', 'mean', 'repres', 'analysi']...) from 259 documents (total 1691 corpus positions)\n",
      "2019-04-24 17:02:12,332 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:12,339 : INFO : built Dictionary(1080 unique tokens: ['build', 'deliv', 'digit', 'fall', 'idea']...) from 330 documents (total 2764 corpus positions)\n",
      "2019-04-24 17:02:12,823 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:12,826 : INFO : built Dictionary(226 unique tokens: ['aglomeração', 'atenção', 'chama', 'fazem', 'fotógrafo']...) from 27 documents (total 350 corpus positions)\n",
      "2019-04-24 17:02:12,848 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:12,851 : INFO : built Dictionary(131 unique tokens: ['attitud', 'dualism', 'go', 'huge', 'interest']...) from 30 documents (total 172 corpus positions)\n",
      "2019-04-24 17:02:12,875 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:12,879 : INFO : built Dictionary(224 unique tokens: ['academ', 'analyt', 'annual', 'base', 'confer']...) from 31 documents (total 442 corpus positions)\n",
      "2019-04-24 17:02:12,904 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:12,907 : INFO : built Dictionary(131 unique tokens: ['desenvolvida', 'digit', 'digitalizar', 'documento', 'formato']...) from 12 documents (total 179 corpus positions)\n",
      "2019-04-24 17:02:12,928 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:12,933 : INFO : built Dictionary(488 unique tokens: ['absolutament', 'ajudam', 'algum', 'auxiliam', 'bot']...) from 54 documents (total 1063 corpus positions)\n",
      "2019-04-24 17:02:12,993 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:12,996 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:12,999 : INFO : built Dictionary(121 unique tokens: ['colaboração', 'com', 'commerc', 'contrato', 'empresa']...) from 6 documents (total 166 corpus positions)\n",
      "2019-04-24 17:02:13,005 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:13,024 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:13,030 : INFO : built Dictionary(271 unique tokens: ['acordo', 'agrícola', 'alemanha', 'aspirina', 'bayer']...) from 23 documents (total 412 corpus positions)\n",
      "2019-04-24 17:02:13,054 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:13,058 : INFO : built Dictionary(91 unique tokens: ['color', 'discuss', 'earlier', 'engag', 'have']...) from 12 documents (total 116 corpus positions)\n",
      "2019-04-24 17:02:13,065 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:13,068 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:13,071 : INFO : built Dictionary(42 unique tokens: ['access', 'blur', 'easili', 'face', 'identifi']...) from 4 documents (total 53 corpus positions)\n",
      "2019-04-24 17:02:13,074 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:13,080 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:13,085 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:13,089 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:13,092 : INFO : built Dictionary(88 unique tokens: ['adaptar', 'anunci', 'com', 'conteúdo', 'design']...) from 7 documents (total 108 corpus positions)\n",
      "2019-04-24 17:02:13,095 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:13,122 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:13,128 : INFO : built Dictionary(596 unique tokens: ['appl', 'compani', 'tech', 'think', 'wrong']...) from 98 documents (total 1010 corpus positions)\n",
      "2019-04-24 17:02:13,199 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:13,201 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:13,205 : INFO : built Dictionary(154 unique tokens: ['convergência', 'digit', 'atendimento', 'canal', 'financeira']...) from 9 documents (total 217 corpus positions)\n",
      "2019-04-24 17:02:13,208 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:13,223 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:13,227 : INFO : built Dictionary(218 unique tokens: ['app', 'digit', 'effort', 'expertis', 'financ']...) from 36 documents (total 422 corpus positions)\n",
      "2019-04-24 17:02:13,251 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:13,255 : INFO : built Dictionary(216 unique tokens: ['comércio', 'dificuldad', 'eletrônico', 'estoqu', 'lançou']...) from 22 documents (total 342 corpus positions)\n",
      "2019-04-24 17:02:13,275 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:13,278 : INFO : built Dictionary(277 unique tokens: ['atendimento', 'atividad', 'comércio', 'correio', 'diz']...) from 23 documents (total 457 corpus positions)\n",
      "2019-04-24 17:02:13,293 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:13,297 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:13,300 : INFO : built Dictionary(32 unique tokens: ['asp', 'build', 'client', 'construct', 'core']...) from 4 documents (total 35 corpus positions)\n",
      "2019-04-24 17:02:13,303 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:13,307 : WARNING : Couldn't get relevant sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:13,324 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:13,331 : INFO : built Dictionary(429 unique tokens: ['diz', 'java', 'modularizar', 'muito', 'plataforma']...) from 81 documents (total 1210 corpus positions)\n",
      "2019-04-24 17:02:13,402 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:13,405 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:13,407 : INFO : built Dictionary(52 unique tokens: ['absorvido', 'aprendendo', 'arian', 'com', 'conform']...) from 5 documents (total 61 corpus positions)\n",
      "2019-04-24 17:02:13,409 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:13,418 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:13,421 : INFO : built Dictionary(258 unique tokens: ['busi', 'intellig', 'que', 'representa', 'bastant']...) from 17 documents (total 389 corpus positions)\n",
      "2019-04-24 17:02:13,478 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:13,486 : INFO : built Dictionary(633 unique tokens: ['android', 'api', 'associ', 'come', 'cost']...) from 475 documents (total 2590 corpus positions)\n",
      "2019-04-24 17:02:14,328 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:14,331 : INFO : built Dictionary(190 unique tokens: ['bank', 'editor', 'guardian', 'monei', 'singl']...) from 33 documents (total 265 corpus positions)\n",
      "2019-04-24 17:02:14,346 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:14,348 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:14,351 : INFO : built Dictionary(51 unique tokens: ['america', 'andi', 'art', 'artist', 'captain']...) from 5 documents (total 66 corpus positions)\n",
      "2019-04-24 17:02:14,353 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:14,372 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:14,376 : INFO : built Dictionary(243 unique tokens: ['account', 'bank', 'branch', 'complet', 'credit']...) from 45 documents (total 678 corpus positions)\n",
      "2019-04-24 17:02:14,415 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:14,422 : INFO : built Dictionary(238 unique tokens: ['ahead', 'compani', 'look', 'salesforc', 'afternoon']...) from 33 documents (total 379 corpus positions)\n",
      "2019-04-24 17:02:14,450 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:14,454 : INFO : built Dictionary(265 unique tokens: ['android', 'avail', 'download', 'eason', 'jamal']...) from 59 documents (total 627 corpus positions)\n",
      "2019-04-24 17:02:14,499 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:14,504 : INFO : built Dictionary(287 unique tokens: ['articl', 'list', 'time', 'energi', 'idea']...) from 97 documents (total 514 corpus positions)\n",
      "2019-04-24 17:02:14,549 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:14,551 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:14,554 : INFO : built Dictionary(19 unique tokens: ['data', 'develop', 'differ', 'focus', 'previou']...) from 2 documents (total 25 corpus positions)\n",
      "2019-04-24 17:02:14,556 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:14,557 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:14,559 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:14,571 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:14,575 : INFO : built Dictionary(299 unique tokens: ['ago', 'decid', 'develop', 'hand', 'month']...) from 68 documents (total 561 corpus positions)\n",
      "2019-04-24 17:02:14,606 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:14,608 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:14,610 : INFO : built Dictionary(91 unique tokens: ['ainda', 'ano', 'armazenamento', 'cartõ', 'comprimir']...) from 9 documents (total 109 corpus positions)\n",
      "2019-04-24 17:02:14,611 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:14,619 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:14,622 : INFO : built Dictionary(105 unique tokens: ['bitcoin', 'constitut', 'feder', 'form', 'judg']...) from 12 documents (total 146 corpus positions)\n",
      "2019-04-24 17:02:14,672 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:14,680 : INFO : built Dictionary(807 unique tokens: ['bad', 'believ', 'bitcoin', 'fail', 'meet']...) from 260 documents (total 2265 corpus positions)\n",
      "2019-04-24 17:02:15,054 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,057 : INFO : built Dictionary(407 unique tokens: ['aprendizado', 'cognitiva', 'como', 'computação', 'forma']...) from 44 documents (total 735 corpus positions)\n",
      "2019-04-24 17:02:15,090 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,093 : INFO : built Dictionary(151 unique tokens: ['acionista', 'alienar', 'açõ', 'brasil', 'celebr']...) from 11 documents (total 236 corpus positions)\n",
      "2019-04-24 17:02:15,101 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:15,103 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,106 : INFO : built Dictionary(104 unique tokens: ['caminha', 'cidad', 'diariament', 'do', 'ela']...) from 8 documents (total 129 corpus positions)\n",
      "2019-04-24 17:02:15,108 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:15,122 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,126 : INFO : built Dictionary(291 unique tokens: ['debut', 'io', 'ipad', 'iphon', 'mac']...) from 47 documents (total 633 corpus positions)\n",
      "2019-04-24 17:02:15,147 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:15,149 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,150 : INFO : built Dictionary(56 unique tokens: ['alongsid', 'app', 'appl', 'collabor', 'featur']...) from 7 documents (total 94 corpus positions)\n",
      "2019-04-24 17:02:15,153 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:15,167 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,170 : INFO : built Dictionary(338 unique tokens: ['call', 'earli', 'exist', 'found', 'host']...) from 73 documents (total 572 corpus positions)\n",
      "2019-04-24 17:02:15,213 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,216 : INFO : built Dictionary(216 unique tokens: ['book', 'call', 'curt', 'dan', 'friend']...) from 46 documents (total 459 corpus positions)\n",
      "2019-04-24 17:02:15,232 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:15,235 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,238 : INFO : built Dictionary(24 unique tokens: ['busi', 'clear', 'depart', 'digit', 'plai']...) from 3 documents (total 28 corpus positions)\n",
      "2019-04-24 17:02:15,240 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:15,242 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:15,244 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:15,247 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:15,249 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,252 : INFO : built Dictionary(25 unique tokens: ['academ', 'algorithm', 'applic', 'evalu', 'implement']...) from 2 documents (total 25 corpus positions)\n",
      "2019-04-24 17:02:15,254 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:15,258 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:15,260 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:15,270 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:15,274 : INFO : built Dictionary(362 unique tokens: ['dez', 'documentário', 'empreendedor', 'escondido', 'netflix']...) from 43 documents (total 639 corpus positions)\n",
      "2019-04-24 17:02:15,297 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:15,299 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,301 : INFO : built Dictionary(47 unique tokens: ['capit', 'catalina', 'cisco', 'compani', 'enterpris']...) from 5 documents (total 51 corpus positions)\n",
      "2019-04-24 17:02:15,304 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:15,320 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,323 : INFO : built Dictionary(356 unique tokens: ['angular', 'complex', 'curv', 'danni', 'end']...) from 75 documents (total 686 corpus positions)\n",
      "2019-04-24 17:02:15,365 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:15,367 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,370 : INFO : built Dictionary(24 unique tokens: ['bank', 'build', 'monzo', 'scratch', 'avail']...) from 3 documents (total 26 corpus positions)\n",
      "2019-04-24 17:02:15,373 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:15,377 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:15,390 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,394 : INFO : built Dictionary(221 unique tokens: ['build', 'capabl', 'compani', 'develop', 'leadership']...) from 48 documents (total 683 corpus positions)\n",
      "2019-04-24 17:02:15,438 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,443 : INFO : built Dictionary(346 unique tokens: ['com', 'cultura', 'estratégia', 'ficar', 'fácil']...) from 42 documents (total 636 corpus positions)\n",
      "2019-04-24 17:02:15,479 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,484 : INFO : built Dictionary(524 unique tokens: ['acha', 'conceito', 'perda', 'precisa', 'que']...) from 64 documents (total 1040 corpus positions)\n",
      "2019-04-24 17:02:15,540 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,543 : INFO : built Dictionary(260 unique tokens: ['bank', 'blockchain', 'cash', 'custom', 'digit']...) from 35 documents (total 454 corpus positions)\n",
      "2019-04-24 17:02:15,594 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,599 : INFO : built Dictionary(500 unique tokens: ['anim', 'app', 'experi', 'intric', 'memor']...) from 274 documents (total 1846 corpus positions)\n",
      "2019-04-24 17:02:15,897 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:15,899 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,901 : INFO : built Dictionary(60 unique tokens: ['cada', 'com', 'configuraçõ', 'criar', 'diferent']...) from 9 documents (total 121 corpus positions)\n",
      "2019-04-24 17:02:15,904 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:15,909 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:15,911 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,913 : INFO : built Dictionary(50 unique tokens: ['amp', 'app', 'googl', 'mobil', 'result']...) from 6 documents (total 106 corpus positions)\n",
      "2019-04-24 17:02:15,915 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:15,921 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:15,923 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,925 : INFO : built Dictionary(37 unique tokens: ['aim', 'android', 'book', 'call', 'discov']...) from 7 documents (total 66 corpus positions)\n",
      "2019-04-24 17:02:15,928 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:15,934 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:15,936 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,940 : INFO : built Dictionary(40 unique tokens: ['agropecuário', 'aplicaçõ', 'armazenamento', 'captura', 'crie']...) from 2 documents (total 44 corpus positions)\n",
      "2019-04-24 17:02:15,946 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:15,949 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:15,951 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:15,965 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:15,970 : INFO : built Dictionary(476 unique tokens: ['aplicativo', 'criação', 'desafio', 'dispositivo', 'envolv']...) from 69 documents (total 905 corpus positions)\n",
      "2019-04-24 17:02:16,033 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,037 : INFO : built Dictionary(521 unique tokens: ['bank', 'blog', 'corner', 'financi', 'guess']...) from 101 documents (total 966 corpus positions)\n",
      "2019-04-24 17:02:16,094 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,096 : INFO : built Dictionary(115 unique tokens: ['matter', 'time', 'bug', 'contribut', 'core']...) from 20 documents (total 218 corpus positions)\n",
      "2019-04-24 17:02:16,106 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:16,109 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,111 : INFO : built Dictionary(119 unique tokens: ['aceleração', 'adicion', 'ano', 'aprov', 'combustívei']...) from 7 documents (total 159 corpus positions)\n",
      "2019-04-24 17:02:16,114 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:16,128 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,131 : INFO : built Dictionary(328 unique tokens: ['allo', 'app', 'assist', 'digit', 'eager']...) from 61 documents (total 553 corpus positions)\n",
      "2019-04-24 17:02:16,175 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,179 : INFO : built Dictionary(498 unique tokens: ['busi', 'life', 'dream', 'feel', 'imposs']...) from 149 documents (total 888 corpus positions)\n",
      "2019-04-24 17:02:16,269 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,273 : INFO : built Dictionary(517 unique tokens: ['chief', 'compani', 'contact', 'deliv', 'effici']...) from 110 documents (total 1820 corpus positions)\n",
      "2019-04-24 17:02:16,387 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,390 : INFO : built Dictionary(312 unique tokens: ['cash', 'hurt', 'spend', 'liter', 'good']...) from 42 documents (total 460 corpus positions)\n",
      "2019-04-24 17:02:16,406 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:16,409 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,411 : INFO : built Dictionary(108 unique tokens: ['com', 'constant', 'crescimento', 'da', 'empresa']...) from 6 documents (total 137 corpus positions)\n",
      "2019-04-24 17:02:16,413 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:16,448 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,454 : INFO : built Dictionary(560 unique tokens: ['applic', 'authent', 'build', 'get', 'java']...) from 218 documents (total 1829 corpus positions)\n",
      "2019-04-24 17:02:16,673 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,675 : INFO : built Dictionary(204 unique tokens: ['cover', 'devop', 'infrastructur', 'keynot', 'perform']...) from 26 documents (total 274 corpus positions)\n",
      "2019-04-24 17:02:16,687 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,690 : INFO : built Dictionary(208 unique tokens: ['enorm', 'ideia', 'inovadora', 'joven', 'muito']...) from 21 documents (total 306 corpus positions)\n",
      "2019-04-24 17:02:16,703 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,706 : INFO : built Dictionary(210 unique tokens: ['aumentada', 'estev', 'grand', 'nunca', 'próxima']...) from 18 documents (total 299 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:16,729 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,733 : INFO : built Dictionary(418 unique tokens: ['architectur', 'chang', 'cloud', 'gatewai', 'major']...) from 94 documents (total 1003 corpus positions)\n",
      "2019-04-24 17:02:16,797 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,800 : INFO : built Dictionary(204 unique tokens: ['build', 'compon', 'javascript', 'librari', 'popular']...) from 43 documents (total 556 corpus positions)\n",
      "2019-04-24 17:02:16,831 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,835 : INFO : built Dictionary(451 unique tokens: ['airbnb', 'algorithm', 'alok', 'compani', 'data']...) from 62 documents (total 929 corpus positions)\n",
      "2019-04-24 17:02:16,888 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,892 : INFO : built Dictionary(358 unique tokens: ['rimini', 'street', 'agil', 'anunci', 'atg']...) from 34 documents (total 754 corpus positions)\n",
      "2019-04-24 17:02:16,914 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,917 : INFO : built Dictionary(147 unique tokens: ['abil', 'benefit', 'develop', 'improv', 'major']...) from 20 documents (total 259 corpus positions)\n",
      "2019-04-24 17:02:16,937 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,941 : INFO : built Dictionary(264 unique tokens: ['android', 'avail', 'download', 'eason', 'jamal']...) from 59 documents (total 623 corpus positions)\n",
      "2019-04-24 17:02:16,971 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,974 : INFO : built Dictionary(126 unique tokens: ['client', 'io', 'neat', 'roll', 'server']...) from 14 documents (total 165 corpus positions)\n",
      "2019-04-24 17:02:16,983 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:16,988 : INFO : built Dictionary(56 unique tokens: ['apresentação', 'começar', 'como', 'compartilho', 'docker']...) from 12 documents (total 69 corpus positions)\n",
      "2019-04-24 17:02:17,015 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,020 : INFO : built Dictionary(372 unique tokens: ['analyt', 'googl', 'import', 'market', 'tool']...) from 96 documents (total 1122 corpus positions)\n",
      "2019-04-24 17:02:17,109 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,112 : INFO : built Dictionary(143 unique tokens: ['adob', 'aem', 'applic', 'feel', 'microservic']...) from 33 documents (total 404 corpus positions)\n",
      "2019-04-24 17:02:17,134 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,138 : INFO : built Dictionary(442 unique tokens: ['ano', 'ao', 'calçado', 'começ', 'empreendedor']...) from 69 documents (total 870 corpus positions)\n",
      "2019-04-24 17:02:17,180 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:17,183 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,184 : INFO : built Dictionary(33 unique tokens: ['ano', 'campo', 'com', 'construção', 'difusão']...) from 2 documents (total 38 corpus positions)\n",
      "2019-04-24 17:02:17,187 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:17,190 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:17,192 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:17,201 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,204 : INFO : built Dictionary(256 unique tokens: ['artifici', 'busi', 'came', 'featur', 'francisco']...) from 33 documents (total 375 corpus positions)\n",
      "2019-04-24 17:02:17,228 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,231 : INFO : built Dictionary(359 unique tokens: ['class', 'cmu', 'complet', 'cubr', 'end']...) from 100 documents (total 687 corpus positions)\n",
      "2019-04-24 17:02:17,285 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,288 : INFO : built Dictionary(357 unique tokens: ['alarmingli', 'charg', 'discoveri', 'establish', 'evalu']...) from 65 documents (total 639 corpus positions)\n",
      "2019-04-24 17:02:17,329 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,332 : INFO : built Dictionary(360 unique tokens: ['ey', 'provid', 'bureau', 'common', 'engrav']...) from 58 documents (total 584 corpus positions)\n",
      "2019-04-24 17:02:17,359 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,362 : INFO : built Dictionary(194 unique tokens: ['apresenta', 'balanço', 'dafiti', 'primeiro', 'semestr']...) from 17 documents (total 304 corpus positions)\n",
      "2019-04-24 17:02:17,375 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,378 : INFO : built Dictionary(185 unique tokens: ['artifici', 'diego', 'domin', 'facebook', 'googl']...) from 29 documents (total 313 corpus positions)\n",
      "2019-04-24 17:02:17,393 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,395 : INFO : built Dictionary(124 unique tokens: ['cloud', 'left', 'live', 'love', 'microsoft']...) from 14 documents (total 220 corpus positions)\n",
      "2019-04-24 17:02:17,409 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,413 : INFO : built Dictionary(226 unique tokens: ['anniversari', 'básico', 'contêin', 'edit', 'enterpris']...) from 49 documents (total 508 corpus positions)\n",
      "2019-04-24 17:02:17,440 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:17,443 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,446 : INFO : built Dictionary(74 unique tokens: ['analisar', 'apena', 'awr', 'brasil', 'como']...) from 5 documents (total 85 corpus positions)\n",
      "2019-04-24 17:02:17,448 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:17,460 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,463 : INFO : built Dictionary(188 unique tokens: ['accur', 'automat', 'brain', 'caption', 'googl']...) from 32 documents (total 417 corpus positions)\n",
      "2019-04-24 17:02:17,505 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,510 : INFO : built Dictionary(445 unique tokens: ['answer', 'ask', 'design', 'like', 'question']...) from 139 documents (total 1656 corpus positions)\n",
      "2019-04-24 17:02:17,652 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,654 : INFO : built Dictionary(92 unique tokens: ['amp', 'analyt', 'collect', 'compon', 'event']...) from 11 documents (total 147 corpus positions)\n",
      "2019-04-24 17:02:17,669 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,673 : INFO : built Dictionary(311 unique tokens: ['announc', 'excit', 'final', 'releas', 'todai']...) from 67 documents (total 699 corpus positions)\n",
      "2019-04-24 17:02:17,721 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,726 : INFO : built Dictionary(632 unique tokens: ['benitez', 'cinema', 'comunicação', 'estagiário', 'gael']...) from 88 documents (total 1159 corpus positions)\n",
      "2019-04-24 17:02:17,791 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,794 : INFO : built Dictionary(282 unique tokens: ['announc', 'atlanta', 'avail', 'confer', 'gener']...) from 47 documents (total 740 corpus positions)\n",
      "2019-04-24 17:02:17,824 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,827 : INFO : built Dictionary(276 unique tokens: ['annual', 'confer', 'corp', 'financi', 'industri']...) from 33 documents (total 579 corpus positions)\n",
      "2019-04-24 17:02:17,846 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,848 : INFO : built Dictionary(142 unique tokens: ['advanc', 'chang', 'iconographi', 'technolog', 'time']...) from 26 documents (total 189 corpus positions)\n",
      "2019-04-24 17:02:17,858 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,861 : INFO : built Dictionary(119 unique tokens: ['allo', 'confer', 'develop', 'earlier', 'googl']...) from 18 documents (total 187 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:17,878 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,881 : INFO : built Dictionary(309 unique tokens: ['ago', 'algorithm', 'announc', 'base', 'googl']...) from 41 documents (total 576 corpus positions)\n",
      "2019-04-24 17:02:17,898 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:17,900 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,903 : INFO : built Dictionary(20 unique tokens: ['android', 'desenvolvimento', 'io', 'multiplataforma', 'para']...) from 2 documents (total 30 corpus positions)\n",
      "2019-04-24 17:02:17,905 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:17,907 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:17,909 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:17,914 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,917 : INFO : built Dictionary(131 unique tokens: ['javascript', 'linux', 'onion', 'php', 'produc']...) from 14 documents (total 185 corpus positions)\n",
      "2019-04-24 17:02:17,931 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,934 : INFO : built Dictionary(246 unique tokens: ['contain', 'docker', 'futur', 'manag', 'open']...) from 45 documents (total 447 corpus positions)\n",
      "2019-04-24 17:02:17,956 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,959 : INFO : built Dictionary(114 unique tokens: ['bank', 'client', 'com', 'como', 'corporativa']...) from 11 documents (total 187 corpus positions)\n",
      "2019-04-24 17:02:17,969 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,972 : INFO : built Dictionary(190 unique tokens: ['dai', 'differ', 'launch', 'think', 'accompani']...) from 23 documents (total 293 corpus positions)\n",
      "2019-04-24 17:02:17,983 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,986 : INFO : built Dictionary(115 unique tokens: ['aim', 'assess', 'baidu', 'deep', 'deepbench']...) from 13 documents (total 187 corpus positions)\n",
      "2019-04-24 17:02:17,994 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:17,996 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:17,998 : INFO : built Dictionary(86 unique tokens: ['actuari', 'aetna', 'assum', 'clue', 'collect']...) from 7 documents (total 115 corpus positions)\n",
      "2019-04-24 17:02:18,000 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:18,008 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,011 : INFO : built Dictionary(131 unique tokens: ['ccn', 'coinupvot', 'write', 'accept', 'announc']...) from 16 documents (total 202 corpus positions)\n",
      "2019-04-24 17:02:18,021 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,024 : INFO : built Dictionary(152 unique tokens: ['custom', 'ecosystem', 'experi', 'manag', 'new']...) from 22 documents (total 269 corpus positions)\n",
      "2019-04-24 17:02:18,046 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,051 : INFO : built Dictionary(532 unique tokens: ['aberta', 'api', 'banco', 'bank', 'desenvolvedor']...) from 70 documents (total 1123 corpus positions)\n",
      "2019-04-24 17:02:18,108 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,110 : INFO : built Dictionary(241 unique tokens: ['acaba', 'acessarem', 'ajudar', 'anunciar', 'ao']...) from 23 documents (total 377 corpus positions)\n",
      "2019-04-24 17:02:18,125 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,128 : INFO : built Dictionary(204 unique tokens: ['analyt', 'ano', 'anális', 'atend', 'com']...) from 21 documents (total 326 corpus positions)\n",
      "2019-04-24 17:02:18,145 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,148 : INFO : built Dictionary(221 unique tokens: ['busi', 'event', 'honor', 'institut', 'larg']...) from 45 documents (total 392 corpus positions)\n",
      "2019-04-24 17:02:18,166 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:18,169 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,172 : INFO : built Dictionary(22 unique tokens: ['continu', 'digit', 'expand', 'offer', 'scandic']...) from 3 documents (total 27 corpus positions)\n",
      "2019-04-24 17:02:18,175 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:18,177 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:18,184 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,188 : INFO : built Dictionary(117 unique tokens: ['account', 'bank', 'cash', 'friend', 'go']...) from 10 documents (total 176 corpus positions)\n",
      "2019-04-24 17:02:18,201 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,205 : INFO : built Dictionary(261 unique tokens: ['charg', 'cio', 'compani', 'digit', 'increasingli']...) from 24 documents (total 489 corpus positions)\n",
      "2019-04-24 17:02:18,242 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,247 : INFO : built Dictionary(709 unique tokens: ['better', 'boot', 'icon', 'john', 'lewi']...) from 141 documents (total 1635 corpus positions)\n",
      "2019-04-24 17:02:18,372 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,374 : INFO : built Dictionary(250 unique tokens: ['digit', 'greater', 'immediaci', 'need', 'especi']...) from 43 documents (total 446 corpus positions)\n",
      "2019-04-24 17:02:18,401 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,406 : INFO : built Dictionary(329 unique tokens: ['big', 'busi', 'consum', 'cpg', 'domin']...) from 63 documents (total 620 corpus positions)\n",
      "2019-04-24 17:02:18,445 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,449 : INFO : built Dictionary(334 unique tokens: ['accord', 'ad', 'appl', 'launch', 'point']...) from 66 documents (total 578 corpus positions)\n",
      "2019-04-24 17:02:18,483 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,487 : INFO : built Dictionary(245 unique tokens: ['bettersoft', 'engin', 'softwar', 'sue', 'applic']...) from 70 documents (total 643 corpus positions)\n",
      "2019-04-24 17:02:18,521 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,524 : INFO : built Dictionary(109 unique tokens: ['appear', 'chess', 'complet', 'defeat', 'earlier']...) from 12 documents (total 144 corpus positions)\n",
      "2019-04-24 17:02:18,537 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,541 : INFO : built Dictionary(281 unique tokens: ['career', 'engin', 'grew', 'hand', 'launch']...) from 37 documents (total 544 corpus positions)\n",
      "2019-04-24 17:02:18,564 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,567 : INFO : built Dictionary(131 unique tokens: ['announc', 'cloud', 'comput', 'event', 'francisco']...) from 18 documents (total 242 corpus positions)\n",
      "2019-04-24 17:02:18,578 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,581 : INFO : built Dictionary(206 unique tokens: ['acaba', 'ainda', 'com', 'comércio', 'criação']...) from 20 documents (total 339 corpus positions)\n",
      "2019-04-24 17:02:18,594 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,596 : INFO : built Dictionary(119 unique tokens: ['blog', 'busi', 'busy', 'campbel', 'cloud']...) from 15 documents (total 163 corpus positions)\n",
      "2019-04-24 17:02:18,604 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:18,606 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,607 : INFO : built Dictionary(70 unique tokens: ['access', 'averag', 'blog', 'cayden', 'cross']...) from 6 documents (total 92 corpus positions)\n",
      "2019-04-24 17:02:18,610 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:18,622 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:18,626 : INFO : built Dictionary(256 unique tokens: ['applic', 'bring', 'capabl', 'cloud', 'continu']...) from 40 documents (total 546 corpus positions)\n",
      "2019-04-24 17:02:18,648 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,651 : INFO : built Dictionary(132 unique tokens: ['announc', 'better', 'creativ', 'custom', 'employe']...) from 17 documents (total 221 corpus positions)\n",
      "2019-04-24 17:02:18,664 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,666 : INFO : built Dictionary(185 unique tokens: ['best', 'blog', 'built', 'creat', 'cross']...) from 26 documents (total 324 corpus positions)\n",
      "2019-04-24 17:02:18,685 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,689 : INFO : built Dictionary(215 unique tokens: ['acceler', 'behavior', 'blog', 'content', 'cover']...) from 37 documents (total 492 corpus positions)\n",
      "2019-04-24 17:02:18,718 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,721 : INFO : built Dictionary(276 unique tokens: ['applic', 'best', 'experi', 'help', 'need']...) from 99 documents (total 668 corpus positions)\n",
      "2019-04-24 17:02:18,773 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,776 : INFO : built Dictionary(192 unique tokens: ['compani', 'databas', 'hold', 'kei', 'largest']...) from 28 documents (total 275 corpus positions)\n",
      "2019-04-24 17:02:18,788 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,790 : INFO : built Dictionary(130 unique tokens: ['attack', 'blog', 'ddo', 'denial', 'gigabit']...) from 19 documents (total 189 corpus positions)\n",
      "2019-04-24 17:02:18,828 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,834 : INFO : built Dictionary(693 unique tokens: ['chang', 'compani', 'competit', 'digit', 'edg']...) from 139 documents (total 1940 corpus positions)\n",
      "2019-04-24 17:02:18,966 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:18,968 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,970 : INFO : built Dictionary(28 unique tokens: ['abl', 'cloud', 'consult', 'engin', 'enthusiast']...) from 2 documents (total 31 corpus positions)\n",
      "2019-04-24 17:02:18,971 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:18,973 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:18,976 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:18,987 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:18,991 : INFO : built Dictionary(322 unique tokens: ['alexa', 'atop', 'citi', 'cosmopolitan', 'deliv']...) from 54 documents (total 482 corpus positions)\n",
      "2019-04-24 17:02:19,018 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,022 : INFO : built Dictionary(118 unique tokens: ['advanc', 'allow', 'app', 'automat', 'caption']...) from 12 documents (total 175 corpus positions)\n",
      "2019-04-24 17:02:19,036 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,040 : INFO : built Dictionary(131 unique tokens: ['advic', 'extra', 'includ', 'inform', 'insight']...) from 19 documents (total 227 corpus positions)\n",
      "2019-04-24 17:02:19,056 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,060 : INFO : built Dictionary(274 unique tokens: ['acordo', 'administrador', 'aluguel', 'ano', 'center']...) from 20 documents (total 467 corpus positions)\n",
      "2019-04-24 17:02:19,082 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,086 : INFO : built Dictionary(306 unique tokens: ['answer', 'ask', 'bank', 'biggest', 'challeng']...) from 56 documents (total 625 corpus positions)\n",
      "2019-04-24 17:02:19,130 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,136 : INFO : built Dictionary(391 unique tokens: ['baseada', 'conheça', 'custo', 'evitam', 'falha']...) from 43 documents (total 696 corpus positions)\n",
      "2019-04-24 17:02:19,175 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,179 : INFO : built Dictionary(262 unique tokens: ['believ', 'killer', 'probabl', 'prospect', 'read']...) from 32 documents (total 396 corpus positions)\n",
      "2019-04-24 17:02:19,220 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,227 : INFO : built Dictionary(626 unique tokens: ['ask', 'conduct', 'data', 'doubt', 'engin']...) from 200 documents (total 1646 corpus positions)\n",
      "2019-04-24 17:02:19,417 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:19,419 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,421 : INFO : built Dictionary(39 unique tokens: ['campina', 'fotografia', 'pela', 'que', 'sabia']...) from 3 documents (total 42 corpus positions)\n",
      "2019-04-24 17:02:19,424 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:19,427 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:19,429 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:19,434 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,438 : INFO : built Dictionary(131 unique tokens: ['meerkat', 'rememb', 'came', 'earli', 'particular']...) from 13 documents (total 171 corpus positions)\n",
      "2019-04-24 17:02:19,447 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,451 : INFO : built Dictionary(179 unique tokens: ['ano', 'artifici', 'até', 'científica', 'desd']...) from 20 documents (total 233 corpus positions)\n",
      "2019-04-24 17:02:19,471 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,475 : INFO : built Dictionary(472 unique tokens: ['client', 'companhia', 'estratégia', 'fidelização', 'multiproduto']...) from 63 documents (total 948 corpus positions)\n",
      "2019-04-24 17:02:19,543 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,549 : INFO : built Dictionary(453 unique tokens: ['android', 'espresso', 'framework', 'power', 'test']...) from 227 documents (total 1522 corpus positions)\n",
      "2019-04-24 17:02:19,741 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,743 : INFO : built Dictionary(196 unique tokens: ['bank', 'develop', 'ethereum', 'jpmorgan', 'mega']...) from 23 documents (total 321 corpus positions)\n",
      "2019-04-24 17:02:19,758 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,761 : INFO : built Dictionary(172 unique tokens: ['account', 'bank', 'new', 'onlin', 'product']...) from 22 documents (total 299 corpus positions)\n",
      "2019-04-24 17:02:19,773 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,776 : INFO : built Dictionary(108 unique tokens: ['announc', 'app', 'chatbot', 'line', 'march']...) from 16 documents (total 205 corpus positions)\n",
      "2019-04-24 17:02:19,795 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,799 : INFO : built Dictionary(281 unique tokens: ['aim', 'approach', 'develop', 'disciplin', 'engin']...) from 71 documents (total 726 corpus positions)\n",
      "2019-04-24 17:02:19,839 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,841 : INFO : built Dictionary(165 unique tokens: ['ambient', 'baixo', 'baseia', 'bioconstrução', 'construir']...) from 13 documents (total 223 corpus positions)\n",
      "2019-04-24 17:02:19,847 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:19,849 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,850 : INFO : built Dictionary(21 unique tokens: ['ag', 'chang', 'consult', 'custom', 'digit']...) from 3 documents (total 25 corpus positions)\n",
      "2019-04-24 17:02:19,852 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:19,855 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:19,873 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:19,877 : INFO : built Dictionary(398 unique tokens: ['abil', 'activ', 'assist', 'chore', 'complex']...) from 81 documents (total 1000 corpus positions)\n",
      "2019-04-24 17:02:19,940 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:19,942 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,944 : INFO : built Dictionary(47 unique tokens: ['allow', 'autonomi', 'brand', 'consum', 'embrac']...) from 7 documents (total 50 corpus positions)\n",
      "2019-04-24 17:02:19,946 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:19,973 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:19,978 : INFO : built Dictionary(472 unique tokens: ['articl', 'edit', 'mistak', 'note', 'point']...) from 297 documents (total 1304 corpus positions)\n",
      "2019-04-24 17:02:20,186 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,188 : INFO : built Dictionary(130 unique tokens: ['commerc', 'cria', 'encontrar', 'endeavor', 'entrar']...) from 12 documents (total 174 corpus positions)\n",
      "2019-04-24 17:02:20,202 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,205 : INFO : built Dictionary(343 unique tokens: ['destroi', 'interrupt', 'on', 'product', 'schedul']...) from 100 documents (total 600 corpus positions)\n",
      "2019-04-24 17:02:20,242 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,245 : INFO : built Dictionary(126 unique tokens: ['olá', 'ouvint', 'analisar', 'apreciar', 'dirigido']...) from 10 documents (total 151 corpus positions)\n",
      "2019-04-24 17:02:20,252 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:20,254 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,256 : INFO : built Dictionary(97 unique tokens: ['acquir', 'busi', 'cover', 'detail', 'emerg']...) from 6 documents (total 120 corpus positions)\n",
      "2019-04-24 17:02:20,259 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:20,268 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,271 : INFO : built Dictionary(180 unique tokens: ['accustom', 'amazon', 'devic', 'echo', 'like']...) from 24 documents (total 287 corpus positions)\n",
      "2019-04-24 17:02:20,283 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,285 : INFO : built Dictionary(129 unique tokens: ['anunci', 'feito', 'googl', 'pelo', 'pixel']...) from 12 documents (total 171 corpus positions)\n",
      "2019-04-24 17:02:20,292 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,294 : INFO : built Dictionary(126 unique tokens: ['agora', 'banco', 'desculpa', 'enem', 'enquanto']...) from 11 documents (total 158 corpus positions)\n",
      "2019-04-24 17:02:20,303 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,306 : INFO : built Dictionary(135 unique tokens: ['accuraci', 'anika', 'assembl', 'breast', 'cancer']...) from 17 documents (total 202 corpus positions)\n",
      "2019-04-24 17:02:20,316 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,319 : INFO : built Dictionary(177 unique tokens: ['austrália', 'cadeia', 'comida', 'fresca', 'mai']...) from 16 documents (total 281 corpus positions)\n",
      "2019-04-24 17:02:20,331 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,334 : INFO : built Dictionary(146 unique tokens: ['accentur', 'adob', 'america', 'announc', 'digit']...) from 12 documents (total 286 corpus positions)\n",
      "2019-04-24 17:02:20,346 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,349 : INFO : built Dictionary(220 unique tokens: ['ag', 'alto', 'artist', 'california', 'creat']...) from 30 documents (total 317 corpus positions)\n",
      "2019-04-24 17:02:20,366 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,369 : INFO : built Dictionary(220 unique tokens: ['ag', 'alto', 'artist', 'california', 'creat']...) from 30 documents (total 317 corpus positions)\n",
      "2019-04-24 17:02:20,389 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,393 : INFO : built Dictionary(421 unique tokens: ['ambient', 'assédio', 'caso', 'como', 'escancarado']...) from 47 documents (total 822 corpus positions)\n",
      "2019-04-24 17:02:20,428 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,431 : INFO : built Dictionary(190 unique tokens: ['app', 'asp', 'core', 'engin', 'googl']...) from 43 documents (total 581 corpus positions)\n",
      "2019-04-24 17:02:20,460 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,463 : INFO : built Dictionary(258 unique tokens: ['coolest', 'css', 'danni', 'date', 'develop']...) from 45 documents (total 411 corpus positions)\n",
      "2019-04-24 17:02:20,481 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,484 : INFO : built Dictionary(109 unique tokens: ['aren', 'chatbot', 'languag', 'learn', 'new']...) from 18 documents (total 160 corpus positions)\n",
      "2019-04-24 17:02:20,499 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,503 : INFO : built Dictionary(342 unique tokens: ['approach', 'automat', 'bath', 'butter', 'car']...) from 40 documents (total 512 corpus positions)\n",
      "2019-04-24 17:02:20,535 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,539 : INFO : built Dictionary(355 unique tokens: ['advanc', 'complex', 'enabl', 'learn', 'machin']...) from 54 documents (total 917 corpus positions)\n",
      "2019-04-24 17:02:20,587 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,590 : INFO : built Dictionary(346 unique tokens: ['bad', 'chanc', 'compani', 'delusion', 'lot']...) from 64 documents (total 675 corpus positions)\n",
      "2019-04-24 17:02:20,623 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,626 : INFO : built Dictionary(142 unique tokens: ['analysi', 'analyz', 'api', 'approach', 'bigqueri']...) from 17 documents (total 230 corpus positions)\n",
      "2019-04-24 17:02:20,637 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,640 : INFO : built Dictionary(210 unique tokens: ['como', 'compra', 'conseguiu', 'desconto', 'ingresso']...) from 21 documents (total 275 corpus positions)\n",
      "2019-04-24 17:02:20,651 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,654 : INFO : built Dictionary(113 unique tokens: ['ago', 'api', 'bot', 'littl', 'publish']...) from 19 documents (total 172 corpus positions)\n",
      "2019-04-24 17:02:20,668 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,671 : INFO : built Dictionary(241 unique tokens: ['activ', 'awai', 'commun', 'contribut', 'driven']...) from 35 documents (total 425 corpus positions)\n",
      "2019-04-24 17:02:20,695 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,699 : INFO : built Dictionary(272 unique tokens: ['afford', 'agenc', 'contributor', 'convinc', 'core']...) from 56 documents (total 546 corpus positions)\n",
      "2019-04-24 17:02:20,761 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:20,767 : INFO : built Dictionary(996 unique tokens: ['america', 'comput', 'corpor', 'decad', 'discoveri']...) from 192 documents (total 2323 corpus positions)\n",
      "2019-04-24 17:02:21,002 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,007 : INFO : built Dictionary(380 unique tokens: ['activ', 'ask', 'call', 'discours', 'engin']...) from 92 documents (total 696 corpus positions)\n",
      "2019-04-24 17:02:21,063 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,066 : INFO : built Dictionary(282 unique tokens: ['ask', 'call', 'engin', 'experi', 'femal']...) from 59 documents (total 491 corpus positions)\n",
      "2019-04-24 17:02:21,100 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,104 : INFO : built Dictionary(313 unique tokens: ['believ', 'firmli', 'hardest', 'name', 'scienc']...) from 87 documents (total 604 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:21,156 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,160 : INFO : built Dictionary(569 unique tokens: ['algun', 'ano', 'bimod', 'conceito', 'criou']...) from 78 documents (total 1091 corpus positions)\n",
      "2019-04-24 17:02:21,225 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,228 : INFO : built Dictionary(258 unique tokens: ['billion', 'celebr', 'commun', 'compani', 'coupl']...) from 40 documents (total 409 corpus positions)\n",
      "2019-04-24 17:02:21,247 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,250 : INFO : built Dictionary(241 unique tokens: ['acordo', 'anunci', 'aquisição', 'brasil', 'citibank']...) from 20 documents (total 389 corpus positions)\n",
      "2019-04-24 17:02:21,265 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,270 : INFO : built Dictionary(122 unique tokens: ['advisori', 'audienc', 'avail', 'bring', 'custom']...) from 13 documents (total 188 corpus positions)\n",
      "2019-04-24 17:02:21,290 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,294 : INFO : built Dictionary(286 unique tokens: ['applic', 'lot', 'slow', 'thing', 'explor']...) from 107 documents (total 794 corpus positions)\n",
      "2019-04-24 17:02:21,361 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,364 : INFO : built Dictionary(258 unique tokens: ['chief', 'commun', 'festiv', 'keith', 'kick']...) from 43 documents (total 444 corpus positions)\n",
      "2019-04-24 17:02:21,412 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,420 : INFO : built Dictionary(1151 unique tokens: ['ano', 'falamo', 'idad', 'isto', 'puta']...) from 214 documents (total 2785 corpus positions)\n",
      "2019-04-24 17:02:21,723 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,725 : INFO : built Dictionary(302 unique tokens: ['como', 'empresa', 'está', 'gestão', 'ideia']...) from 27 documents (total 477 corpus positions)\n",
      "2019-04-24 17:02:21,738 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,741 : INFO : built Dictionary(118 unique tokens: ['announc', 'busi', 'facebook', 'offici', 'product']...) from 21 documents (total 197 corpus positions)\n",
      "2019-04-24 17:02:21,758 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,761 : INFO : built Dictionary(244 unique tokens: ['busi', 'email', 'energi', 'invest', 'peopl']...) from 57 documents (total 454 corpus positions)\n",
      "2019-04-24 17:02:21,791 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,794 : INFO : built Dictionary(278 unique tokens: ['beauti', 'everybodi', 'look', 'want', 'dress']...) from 47 documents (total 434 corpus positions)\n",
      "2019-04-24 17:02:21,812 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:21,814 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,816 : INFO : built Dictionary(29 unique tokens: ['annual', 'awar', 'come', 'dai', 'lgbtq']...) from 2 documents (total 33 corpus positions)\n",
      "2019-04-24 17:02:21,818 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:21,820 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:21,822 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:21,824 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:21,826 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,829 : INFO : built Dictionary(22 unique tokens: ['adapt', 'agil', 'begin', 'point', 'scale']...) from 3 documents (total 22 corpus positions)\n",
      "2019-04-24 17:02:21,831 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:21,835 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:21,852 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,857 : INFO : built Dictionary(310 unique tokens: ['configur', 'docker', 'insan', 'network', 'overlai']...) from 116 documents (total 983 corpus positions)\n",
      "2019-04-24 17:02:21,946 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,948 : INFO : built Dictionary(175 unique tokens: ['appl', 'call', 'disk', 'hard', 'icloud']...) from 22 documents (total 278 corpus positions)\n",
      "2019-04-24 17:02:21,976 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:21,980 : INFO : built Dictionary(347 unique tokens: ['continu', 'discoveri', 'experi', 'explain', 'focu']...) from 72 documents (total 938 corpus positions)\n",
      "2019-04-24 17:02:22,036 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,040 : INFO : built Dictionary(368 unique tokens: ['artifici', 'como', 'comércio', 'criou', 'diferent']...) from 39 documents (total 639 corpus positions)\n",
      "2019-04-24 17:02:22,065 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:22,069 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,072 : INFO : built Dictionary(90 unique tokens: ['algoritmo', 'anunci', 'artifici', 'capaz', 'com']...) from 7 documents (total 118 corpus positions)\n",
      "2019-04-24 17:02:22,075 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:22,082 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,086 : INFO : built Dictionary(110 unique tokens: ['chip', 'goal', 'kickstart', 'million', 'pledg']...) from 13 documents (total 149 corpus positions)\n",
      "2019-04-24 17:02:22,100 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,104 : INFO : built Dictionary(166 unique tokens: ['built', 'chrome', 'come', 'develop', 'tool']...) from 63 documents (total 481 corpus positions)\n",
      "2019-04-24 17:02:22,134 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,138 : INFO : built Dictionary(174 unique tokens: ['américa', 'ao', 'brasil', 'dasa', 'diagnóstico']...) from 20 documents (total 297 corpus positions)\n",
      "2019-04-24 17:02:22,151 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,154 : INFO : built Dictionary(110 unique tokens: ['ad', 'analyt', 'featur', 'googl', 'new']...) from 17 documents (total 208 corpus positions)\n",
      "2019-04-24 17:02:22,169 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,172 : INFO : built Dictionary(217 unique tokens: ['android', 'announc', 'constraintlayout', 'googl', 'layout']...) from 33 documents (total 464 corpus positions)\n",
      "2019-04-24 17:02:22,204 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,208 : INFO : built Dictionary(463 unique tokens: ['approach', 'artifici', 'colleg', 'dartmouth', 'develop']...) from 70 documents (total 863 corpus positions)\n",
      "2019-04-24 17:02:22,253 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,256 : INFO : built Dictionary(303 unique tokens: ['act', 'afford', 'bii', 'care', 'chang']...) from 47 documents (total 594 corpus positions)\n",
      "2019-04-24 17:02:22,281 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,284 : INFO : built Dictionary(210 unique tokens: ['empresa', 'exclusiva', 'lançou', 'para', 'rede']...) from 26 documents (total 340 corpus positions)\n",
      "2019-04-24 17:02:22,297 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,300 : INFO : built Dictionary(271 unique tokens: ['abr', 'brasil', 'center', 'como', 'condução']...) from 20 documents (total 438 corpus positions)\n",
      "2019-04-24 17:02:22,315 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,318 : INFO : built Dictionary(377 unique tokens: ['adequada', 'advisor', 'automatizada', 'brasil', 'carteira']...) from 54 documents (total 759 corpus positions)\n",
      "2019-04-24 17:02:22,346 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,348 : INFO : built Dictionary(169 unique tokens: ['ano', 'bem', 'com', 'começando', 'dar']...) from 10 documents (total 247 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:22,353 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:22,355 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,357 : INFO : built Dictionary(30 unique tokens: ['cubo', 'especi', 'insper', 'muito', 'novembro']...) from 3 documents (total 35 corpus positions)\n",
      "2019-04-24 17:02:22,359 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:22,361 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:22,362 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:22,364 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:22,366 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,367 : INFO : built Dictionary(27 unique tokens: ['acquia', 'custom', 'digit', 'except', 'experi']...) from 3 documents (total 30 corpus positions)\n",
      "2019-04-24 17:02:22,369 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:22,372 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:22,376 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,378 : INFO : built Dictionary(132 unique tokens: ['anticip', 'belgium', 'close', 'comput', 'end']...) from 14 documents (total 198 corpus positions)\n",
      "2019-04-24 17:02:22,386 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,388 : INFO : built Dictionary(208 unique tokens: ['attract', 'chocol', 'develop', 'emphas', 'fountain']...) from 20 documents (total 274 corpus positions)\n",
      "2019-04-24 17:02:22,399 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,401 : INFO : built Dictionary(254 unique tokens: ['avail', 'awesom', 'code', 'danni', 'develop']...) from 40 documents (total 450 corpus positions)\n",
      "2019-04-24 17:02:22,436 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,442 : INFO : built Dictionary(897 unique tokens: ['ao', 'certa', 'costuma', 'dose', 'inconsequência']...) from 145 documents (total 1959 corpus positions)\n",
      "2019-04-24 17:02:22,606 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,609 : INFO : built Dictionary(329 unique tokens: ['desenvolv', 'geração', 'inovador', 'necessariament', 'não']...) from 35 documents (total 569 corpus positions)\n",
      "2019-04-24 17:02:22,630 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:22,632 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,636 : INFO : built Dictionary(75 unique tokens: ['air', 'ap', 'call', 'couch', 'horror']...) from 7 documents (total 92 corpus positions)\n",
      "2019-04-24 17:02:22,641 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:22,646 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:22,648 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,651 : INFO : built Dictionary(66 unique tokens: ['anunci', 'chrome', 'consumo', 'googl', 'incluir']...) from 4 documents (total 79 corpus positions)\n",
      "2019-04-24 17:02:22,653 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:22,658 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:22,667 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,671 : INFO : built Dictionary(203 unique tokens: ['analyt', 'behavior', 'busi', 'channel', 'cross']...) from 34 documents (total 325 corpus positions)\n",
      "2019-04-24 17:02:22,688 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:22,690 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,693 : INFO : built Dictionary(68 unique tokens: ['bastass', 'capaz', 'como', 'disnei', 'invent']...) from 6 documents (total 80 corpus positions)\n",
      "2019-04-24 17:02:22,695 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:22,701 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:22,703 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,705 : INFO : built Dictionary(71 unique tokens: ['auth', 'gsoc', 'hawk', 'mentor', 'project']...) from 9 documents (total 140 corpus positions)\n",
      "2019-04-24 17:02:22,708 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:22,714 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,716 : INFO : built Dictionary(99 unique tokens: ['compartilhar', 'contigo', 'ebook', 'enxugando', 'máquina']...) from 14 documents (total 148 corpus positions)\n",
      "2019-04-24 17:02:22,738 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,742 : INFO : built Dictionary(477 unique tokens: ['america', 'atop', 'ce', 'cloud', 'come']...) from 60 documents (total 1000 corpus positions)\n",
      "2019-04-24 17:02:22,806 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,810 : INFO : built Dictionary(346 unique tokens: ['articl', 'dzone', 'featur', 'guid', 'java']...) from 74 documents (total 855 corpus positions)\n",
      "2019-04-24 17:02:22,867 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,871 : INFO : built Dictionary(398 unique tokens: ['ant', 'cada', 'chamada', 'com', 'comprem']...) from 30 documents (total 704 corpus positions)\n",
      "2019-04-24 17:02:22,890 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:22,893 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,895 : INFO : built Dictionary(23 unique tokens: ['abstract', 'approach', 'arbitrarili', 'detect', 'duplic']...) from 2 documents (total 31 corpus positions)\n",
      "2019-04-24 17:02:22,898 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:22,900 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:22,903 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:22,909 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:22,911 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,913 : INFO : built Dictionary(95 unique tokens: ['ano', 'até', 'brasil', 'digit', 'encomendada']...) from 9 documents (total 129 corpus positions)\n",
      "2019-04-24 17:02:22,915 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:22,923 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,926 : INFO : built Dictionary(147 unique tokens: ['acreditam', 'algun', 'atividad', 'brasil', 'com']...) from 12 documents (total 198 corpus positions)\n",
      "2019-04-24 17:02:22,951 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:22,956 : INFO : built Dictionary(419 unique tokens: ['applic', 'assembl', 'cohes', 'commun', 'compon']...) from 138 documents (total 1126 corpus positions)\n",
      "2019-04-24 17:02:23,056 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,059 : INFO : built Dictionary(386 unique tokens: ['agosto', 'agência', 'eua', 'mcdonald', 'mê']...) from 46 documents (total 668 corpus positions)\n",
      "2019-04-24 17:02:23,090 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,094 : INFO : built Dictionary(214 unique tokens: ['debug', 'develop', 'essenti', 'skill', 'error']...) from 63 documents (total 489 corpus positions)\n",
      "2019-04-24 17:02:23,122 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,124 : INFO : built Dictionary(97 unique tokens: ['car', 'drive', 'get', 'hard', 'imag']...) from 13 documents (total 118 corpus positions)\n",
      "2019-04-24 17:02:23,137 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,140 : INFO : built Dictionary(125 unique tokens: ['ask', 'busi', 'case', 'decad', 'easiest']...) from 43 documents (total 194 corpus positions)\n",
      "2019-04-24 17:02:23,154 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:23,158 : INFO : built Dictionary(150 unique tokens: ['energia', 'eólica', 'foto', 'gera', 'limpa']...) from 13 documents (total 218 corpus positions)\n",
      "2019-04-24 17:02:23,180 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,184 : INFO : built Dictionary(389 unique tokens: ['algo', 'aplicação', 'burocrático', 'com', 'consumo']...) from 66 documents (total 1071 corpus positions)\n",
      "2019-04-24 17:02:23,233 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:23,236 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,239 : INFO : built Dictionary(18 unique tokens: ['better', 'browser', 'experi', 'latest', 'unsupport']...) from 4 documents (total 27 corpus positions)\n",
      "2019-04-24 17:02:23,241 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:23,244 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:23,257 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,262 : INFO : built Dictionary(261 unique tokens: ['ann', 'brian', 'ceo', 'chang', 'commun']...) from 30 documents (total 465 corpus positions)\n",
      "2019-04-24 17:02:23,292 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,296 : INFO : built Dictionary(327 unique tokens: ['futur', 'intellig', 'notion', 'resid', 'technolog']...) from 57 documents (total 575 corpus positions)\n",
      "2019-04-24 17:02:23,327 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,330 : INFO : built Dictionary(201 unique tokens: ['advanc', 'googl', 'latest', 'learn', 'littl']...) from 34 documents (total 363 corpus positions)\n",
      "2019-04-24 17:02:23,346 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:23,349 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,351 : INFO : built Dictionary(21 unique tokens: ['easier', 'histor', 'industri', 'new', 'technolog']...) from 2 documents (total 25 corpus positions)\n",
      "2019-04-24 17:02:23,354 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:23,357 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:23,359 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:23,365 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,368 : INFO : built Dictionary(127 unique tokens: ['annual', 'appl', 'big', 'blue', 'confer']...) from 16 documents (total 195 corpus positions)\n",
      "2019-04-24 17:02:23,379 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,381 : INFO : built Dictionary(88 unique tokens: ['deploi', 'earli', 'ibm', 'mac', 'track']...) from 16 documents (total 150 corpus positions)\n",
      "2019-04-24 17:02:23,395 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,398 : INFO : built Dictionary(259 unique tokens: ['bunnel', 'david', 'founder', 'late', 'macworld']...) from 35 documents (total 391 corpus positions)\n",
      "2019-04-24 17:02:23,415 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,417 : INFO : built Dictionary(129 unique tokens: ['appl', 'campu', 'centric', 'cupertino', 'event']...) from 15 documents (total 204 corpus positions)\n",
      "2019-04-24 17:02:23,430 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,433 : INFO : built Dictionary(119 unique tokens: ['app', 'appl', 'banner', 'compani', 'develop']...) from 11 documents (total 208 corpus positions)\n",
      "2019-04-24 17:02:23,444 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,450 : INFO : built Dictionary(129 unique tokens: ['appl', 'compani', 'comput', 'confer', 'deliv']...) from 18 documents (total 229 corpus positions)\n",
      "2019-04-24 17:02:23,472 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,475 : INFO : built Dictionary(280 unique tokens: ['bit', 'final', 'focuss', 'keep', 'littl']...) from 49 documents (total 582 corpus positions)\n",
      "2019-04-24 17:02:23,516 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,521 : INFO : built Dictionary(356 unique tokens: ['analyt', 'archiv', 'backup', 'best', 'busi']...) from 72 documents (total 1063 corpus positions)\n",
      "2019-04-24 17:02:23,581 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,583 : INFO : built Dictionary(153 unique tokens: ['browser', 'cloud', 'code', 'configur', 'edit']...) from 19 documents (total 356 corpus positions)\n",
      "2019-04-24 17:02:23,592 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:23,594 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,596 : INFO : built Dictionary(41 unique tokens: ['aaand', 'announc', 'appl', 'hear', 'octob']...) from 9 documents (total 55 corpus positions)\n",
      "2019-04-24 17:02:23,598 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:23,607 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,610 : INFO : built Dictionary(149 unique tokens: ['ibm', 'impress', 'pretti', 'report', 'stat']...) from 24 documents (total 238 corpus positions)\n",
      "2019-04-24 17:02:23,642 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,646 : INFO : built Dictionary(430 unique tokens: ['announc', 'august', 'host', 'move', 'pantheon']...) from 151 documents (total 1267 corpus positions)\n",
      "2019-04-24 17:02:23,784 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,790 : INFO : built Dictionary(303 unique tokens: ['access', 'best', 'checklist', 'fulfil', 'make']...) from 64 documents (total 549 corpus positions)\n",
      "2019-04-24 17:02:23,828 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:23,830 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,833 : INFO : built Dictionary(34 unique tokens: ['ao', 'aplicaçõ', 'bitcoin', 'básico', 'com']...) from 2 documents (total 35 corpus positions)\n",
      "2019-04-24 17:02:23,836 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:23,839 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:23,841 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:23,854 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,858 : INFO : built Dictionary(279 unique tokens: ['ag', 'ago', 'analyt', 'guess', 'imag']...) from 35 documents (total 536 corpus positions)\n",
      "2019-04-24 17:02:23,880 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,883 : INFO : built Dictionary(111 unique tokens: ['announc', 'baz', 'busi', 'cloud', 'commerci']...) from 11 documents (total 163 corpus positions)\n",
      "2019-04-24 17:02:23,896 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,899 : INFO : built Dictionary(211 unique tokens: ['choos', 'entrepreneur', 'larg', 'nowadai', 'offic']...) from 47 documents (total 311 corpus positions)\n",
      "2019-04-24 17:02:23,924 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,928 : INFO : built Dictionary(151 unique tokens: ['bank', 'creat', 'digit', 'head', 'intrigu']...) from 46 documents (total 308 corpus positions)\n",
      "2019-04-24 17:02:23,945 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:23,947 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,949 : INFO : built Dictionary(27 unique tokens: ['browser', 'com', 'email', 'privaci', 'salesforc']...) from 5 documents (total 33 corpus positions)\n",
      "2019-04-24 17:02:23,951 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:23,962 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,966 : INFO : built Dictionary(174 unique tokens: ['connect', 'feed', 'matter', 'mission', 'new']...) from 34 documents (total 450 corpus positions)\n",
      "2019-04-24 17:02:23,987 : WARNING : Input text is expected to have at least 10 sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:23,990 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:23,992 : INFO : built Dictionary(30 unique tokens: ['conjunto', 'crescimento', 'criar', 'diferent', 'forma']...) from 2 documents (total 33 corpus positions)\n",
      "2019-04-24 17:02:23,994 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:23,996 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:23,998 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:24,004 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,007 : INFO : built Dictionary(140 unique tokens: ['appl', 'bat', 'block', 'googl', 'mere']...) from 15 documents (total 170 corpus positions)\n",
      "2019-04-24 17:02:24,016 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,018 : INFO : built Dictionary(138 unique tokens: ['brasil', 'case', 'chegou', 'client', 'com']...) from 13 documents (total 205 corpus positions)\n",
      "2019-04-24 17:02:24,032 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,035 : INFO : built Dictionary(345 unique tokens: ['criou', 'receita', 'sua', 'uma', 'você']...) from 38 documents (total 595 corpus positions)\n",
      "2019-04-24 17:02:24,060 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,063 : INFO : built Dictionary(235 unique tokens: ['armazenar', 'comum', 'dado', 'muito', 'na']...) from 17 documents (total 335 corpus positions)\n",
      "2019-04-24 17:02:24,082 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,088 : INFO : built Dictionary(323 unique tokens: ['choos', 'date', 'decor', 'hous', 'impress']...) from 75 documents (total 688 corpus positions)\n",
      "2019-04-24 17:02:24,132 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,135 : INFO : built Dictionary(267 unique tokens: ['brick', 'code', 'compani', 'diomidi', 'explor']...) from 43 documents (total 546 corpus positions)\n",
      "2019-04-24 17:02:24,161 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,164 : INFO : built Dictionary(169 unique tokens: ['hack', 'immun', 'isn', 'like', 'softwar']...) from 27 documents (total 304 corpus positions)\n",
      "2019-04-24 17:02:24,174 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:24,177 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,179 : INFO : built Dictionary(25 unique tokens: ['best', 'click', 'cloud', 'compil', 'comput']...) from 2 documents (total 31 corpus positions)\n",
      "2019-04-24 17:02:24,181 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:24,184 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:24,187 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:24,197 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,200 : INFO : built Dictionary(178 unique tokens: ['convinc', 'mayb', 'need', 'smartwatch', 'accord']...) from 23 documents (total 283 corpus positions)\n",
      "2019-04-24 17:02:24,217 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,221 : INFO : built Dictionary(202 unique tokens: ['ask', 'attract', 'bound', 'cowork', 'employe']...) from 28 documents (total 309 corpus positions)\n",
      "2019-04-24 17:02:24,251 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,257 : INFO : built Dictionary(218 unique tokens: ['anniversari', 'appl', 'celebr', 'ipod', 'launch']...) from 20 documents (total 335 corpus positions)\n",
      "2019-04-24 17:02:24,278 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,282 : INFO : built Dictionary(146 unique tokens: ['atlassian', 'better', 'cloud', 'jira', 'recent']...) from 32 documents (total 259 corpus positions)\n",
      "2019-04-24 17:02:24,539 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,542 : INFO : built Dictionary(208 unique tokens: ['job', 'know', 'peopl', 'want', 'appl']...) from 22 documents (total 290 corpus positions)\n",
      "2019-04-24 17:02:24,567 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,573 : INFO : built Dictionary(321 unique tokens: ['bui', 'busi', 'devic', 'la', 'peopl']...) from 43 documents (total 648 corpus positions)\n",
      "2019-04-24 17:02:24,619 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,625 : INFO : built Dictionary(332 unique tokens: ['aka', 'basic', 'busi', 'engin', 'gist']...) from 66 documents (total 678 corpus positions)\n",
      "2019-04-24 17:02:24,686 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,691 : INFO : built Dictionary(360 unique tokens: ['action', 'alloc', 'bring', 'challeng', 'determin']...) from 57 documents (total 647 corpus positions)\n",
      "2019-04-24 17:02:24,725 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,729 : INFO : built Dictionary(179 unique tokens: ['aberto', 'experian', 'externo', 'hackathon', 'mê']...) from 18 documents (total 271 corpus positions)\n",
      "2019-04-24 17:02:24,741 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:24,744 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,747 : INFO : built Dictionary(163 unique tokens: ['ainda', 'alguma', 'atualizaçõ', 'coisa', 'completa']...) from 7 documents (total 243 corpus positions)\n",
      "2019-04-24 17:02:24,750 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:24,762 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,765 : INFO : built Dictionary(141 unique tokens: ['deepen', 'facebook', 'integr', 'messeng', 'option']...) from 20 documents (total 251 corpus positions)\n",
      "2019-04-24 17:02:24,782 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,786 : INFO : built Dictionary(276 unique tokens: ['anunci', 'api', 'chrome', 'equip', 'está']...) from 27 documents (total 503 corpus positions)\n",
      "2019-04-24 17:02:24,810 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,813 : INFO : built Dictionary(162 unique tokens: ['bring', 'enhanc', 'enterpris', 'featur', 'googl']...) from 28 documents (total 388 corpus positions)\n",
      "2019-04-24 17:02:24,831 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,834 : INFO : built Dictionary(197 unique tokens: ['googl', 'hardwar', 'solid', 'start', 'thing']...) from 28 documents (total 278 corpus positions)\n",
      "2019-04-24 17:02:24,871 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:24,876 : INFO : built Dictionary(827 unique tokens: ['acabado', 'ant', 'appl', 'artigo', 'bem']...) from 117 documents (total 2011 corpus positions)\n",
      "2019-04-24 17:02:25,070 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:25,075 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,089 : INFO : built Dictionary(139 unique tokens: ['advantag', 'android', 'announc', 'appl', 'avenu']...) from 9 documents (total 222 corpus positions)\n",
      "2019-04-24 17:02:25,095 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:25,109 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,115 : INFO : built Dictionary(104 unique tokens: ['panther', 'rememb', 'appl', 'arriv', 'fourth']...) from 11 documents (total 143 corpus positions)\n",
      "2019-04-24 17:02:25,124 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:25,128 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,132 : INFO : built Dictionary(31 unique tokens: ['direct', 'matt', 'ross', 'annalis', 'basso']...) from 3 documents (total 31 corpus positions)\n",
      "2019-04-24 17:02:25,137 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:25,144 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:25,151 : WARNING : Input text is expected to have at least 10 sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:25,154 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,158 : INFO : built Dictionary(107 unique tokens: ['atenção', 'autarquia', 'capitalização', 'complementar', 'comunicação']...) from 8 documents (total 149 corpus positions)\n",
      "2019-04-24 17:02:25,161 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:25,174 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,178 : INFO : built Dictionary(155 unique tokens: ['ad', 'deep', 'develop', 'languag', 'learn']...) from 17 documents (total 226 corpus positions)\n",
      "2019-04-24 17:02:25,195 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,199 : INFO : built Dictionary(219 unique tokens: ['acaba', 'banco', 'bilhõ', 'brasil', 'clinicweb']...) from 18 documents (total 342 corpus positions)\n",
      "2019-04-24 17:02:25,218 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,223 : INFO : built Dictionary(296 unique tokens: ['ambient', 'aqui', 'backend', 'blog', 'começamo']...) from 38 documents (total 539 corpus positions)\n",
      "2019-04-24 17:02:25,252 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,257 : INFO : built Dictionary(241 unique tokens: ['applic', 'blog', 'boot', 'confer', 'develop']...) from 27 documents (total 423 corpus positions)\n",
      "2019-04-24 17:02:25,287 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,292 : INFO : built Dictionary(337 unique tokens: ['adopt', 'agricultur', 'box', 'cross', 'develop']...) from 52 documents (total 642 corpus positions)\n",
      "2019-04-24 17:02:25,322 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:25,325 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,330 : INFO : built Dictionary(32 unique tokens: ['artifici', 'como', 'decisõ', 'está', 'ibm']...) from 2 documents (total 32 corpus positions)\n",
      "2019-04-24 17:02:25,333 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:25,338 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:25,341 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:25,349 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,355 : INFO : built Dictionary(149 unique tokens: ['litter', 'note', 'offic', 'post', 'aren']...) from 18 documents (total 208 corpus positions)\n",
      "2019-04-24 17:02:25,376 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,381 : INFO : built Dictionary(324 unique tokens: ['akin', 'finish', 'hunt', 'linear', 'path']...) from 58 documents (total 572 corpus positions)\n",
      "2019-04-24 17:02:25,434 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,440 : INFO : built Dictionary(506 unique tokens: ['abrir', 'anális', 'coisa', 'concorrent', 'da']...) from 76 documents (total 1148 corpus positions)\n",
      "2019-04-24 17:02:25,527 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,533 : INFO : built Dictionary(291 unique tokens: ['como', 'enterpris', 'entrou', 'game', 'googl']...) from 35 documents (total 585 corpus positions)\n",
      "2019-04-24 17:02:25,565 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,569 : INFO : built Dictionary(269 unique tokens: ['fragment', 'futur', 'head', 'platform', 'split']...) from 59 documents (total 400 corpus positions)\n",
      "2019-04-24 17:02:25,599 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,604 : INFO : built Dictionary(215 unique tokens: ['artifici', 'bengio', 'dedic', 'deep', 'enorm']...) from 29 documents (total 348 corpus positions)\n",
      "2019-04-24 17:02:25,632 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,639 : INFO : built Dictionary(316 unique tokens: ['elast', 'februari', 'follow', 'heya', 'pack']...) from 60 documents (total 545 corpus positions)\n",
      "2019-04-24 17:02:25,672 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,675 : INFO : built Dictionary(195 unique tokens: ['announc', 'attempt', 'base', 'better', 'bot']...) from 19 documents (total 280 corpus positions)\n",
      "2019-04-24 17:02:25,690 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,694 : INFO : built Dictionary(192 unique tokens: ['deep', 'learn', 'confer', 'data', 'dean']...) from 23 documents (total 327 corpus positions)\n",
      "2019-04-24 17:02:25,711 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,714 : INFO : built Dictionary(155 unique tokens: ['agência', 'ano', 'apresent', 'bilhão', 'bilhõ']...) from 17 documents (total 255 corpus positions)\n",
      "2019-04-24 17:02:25,726 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:25,729 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,733 : INFO : built Dictionary(83 unique tokens: ['acquir', 'announc', 'app', 'attempt', 'compani']...) from 8 documents (total 118 corpus positions)\n",
      "2019-04-24 17:02:25,736 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:25,749 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,753 : INFO : built Dictionary(237 unique tokens: ['belief', 'clock', 'cycl', 'near', 'open']...) from 39 documents (total 464 corpus positions)\n",
      "2019-04-24 17:02:25,780 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,783 : INFO : built Dictionary(188 unique tokens: ['acceler', 'ad', 'apach', 'cluster', 'databrick']...) from 39 documents (total 399 corpus positions)\n",
      "2019-04-24 17:02:25,805 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,809 : INFO : built Dictionary(123 unique tokens: ['brasil', 'comida', 'deliveri', 'está', 'lançar']...) from 16 documents (total 193 corpus positions)\n",
      "2019-04-24 17:02:25,819 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:25,822 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,825 : INFO : built Dictionary(18 unique tokens: ['digit', 'mean', 'term', 'transform', 'busi']...) from 3 documents (total 20 corpus positions)\n",
      "2019-04-24 17:02:25,827 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:25,830 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:25,832 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:25,849 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,856 : INFO : built Dictionary(339 unique tokens: ['architect', 'backend', 'microservic', 'recent', 'rest']...) from 67 documents (total 734 corpus positions)\n",
      "2019-04-24 17:02:25,920 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,924 : INFO : built Dictionary(285 unique tokens: ['kotlin', 'post', 'seri', 'click', 'design']...) from 70 documents (total 644 corpus positions)\n",
      "2019-04-24 17:02:25,987 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:25,992 : INFO : built Dictionary(159 unique tokens: ['backend', 'dripstat', 'intellij', 'kotlin', 'plugin']...) from 39 documents (total 296 corpus positions)\n",
      "2019-04-24 17:02:26,016 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,020 : INFO : built Dictionary(263 unique tokens: ['bunch', 'decid', 'font', 'night', 'reason']...) from 60 documents (total 479 corpus positions)\n",
      "2019-04-24 17:02:26,052 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:26,056 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,061 : INFO : built Dictionary(105 unique tokens: ['américa', 'diagnóstico', 'paulo', 'são', 'anális']...) from 8 documents (total 134 corpus positions)\n",
      "2019-04-24 17:02:26,065 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:26,087 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:26,091 : INFO : built Dictionary(384 unique tokens: ['bridg', 'brooklyn', 'builder', 'collabor', 'fellow']...) from 72 documents (total 746 corpus positions)\n",
      "2019-04-24 17:02:26,158 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,165 : INFO : built Dictionary(377 unique tokens: ['access', 'allow', 'applic', 'bring', 'compani']...) from 67 documents (total 662 corpus positions)\n",
      "2019-04-24 17:02:26,221 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,226 : INFO : built Dictionary(297 unique tokens: ['habit', 'meet', 'subtweet', 'terribl', 'associ']...) from 60 documents (total 470 corpus positions)\n",
      "2019-04-24 17:02:26,261 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,265 : INFO : built Dictionary(301 unique tokens: ['appl', 'loud', 'nike', 'wai', 'watch']...) from 44 documents (total 504 corpus positions)\n",
      "2019-04-24 17:02:26,294 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,297 : INFO : built Dictionary(132 unique tokens: ['appl', 'await', 'confirm', 'escap', 'event']...) from 27 documents (total 192 corpus positions)\n",
      "2019-04-24 17:02:26,318 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,322 : INFO : built Dictionary(256 unique tokens: ['digit', 'post', 'python', 'recognit', 'wai']...) from 54 documents (total 458 corpus positions)\n",
      "2019-04-24 17:02:26,353 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,358 : INFO : built Dictionary(277 unique tokens: ['excit', 'live', 'time', 'diamandi', 'exponenti']...) from 48 documents (total 383 corpus positions)\n",
      "2019-04-24 17:02:26,395 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,400 : INFO : built Dictionary(711 unique tokens: ['andar', 'avenida', 'empresa', 'funcionário', 'ocupa']...) from 95 documents (total 1378 corpus positions)\n",
      "2019-04-24 17:02:26,519 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,525 : INFO : built Dictionary(342 unique tokens: ['chang', 'fast', 'faster', 'technolog', 'world']...) from 70 documents (total 740 corpus positions)\n",
      "2019-04-24 17:02:26,583 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,588 : INFO : built Dictionary(367 unique tokens: ['doubt', 'fastest', 'grow', 'node', 'platform']...) from 73 documents (total 667 corpus positions)\n",
      "2019-04-24 17:02:26,641 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,644 : INFO : built Dictionary(165 unique tokens: ['april', 'call', 'flow', 'learn', 'merg']...) from 28 documents (total 302 corpus positions)\n",
      "2019-04-24 17:02:26,662 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,665 : INFO : built Dictionary(118 unique tokens: ['competit', 'leav', 'behav', 'like', 'mean']...) from 16 documents (total 178 corpus positions)\n",
      "2019-04-24 17:02:26,678 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,681 : INFO : built Dictionary(135 unique tokens: ['automat', 'classroom', 'cluster', 'companion', 'contain']...) from 16 documents (total 241 corpus positions)\n",
      "2019-04-24 17:02:26,695 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,698 : INFO : built Dictionary(128 unique tokens: ['announc', 'browser', 'edg', 'firefox', 'happi']...) from 14 documents (total 204 corpus positions)\n",
      "2019-04-24 17:02:26,718 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,723 : INFO : built Dictionary(335 unique tokens: ['brief', 'center', 'compani', 'crop', 'data']...) from 67 documents (total 638 corpus positions)\n",
      "2019-04-24 17:02:26,763 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,768 : INFO : built Dictionary(218 unique tokens: ['ano', 'até', 'baixa', 'brasileira', 'cidad']...) from 15 documents (total 315 corpus positions)\n",
      "2019-04-24 17:02:26,780 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,783 : INFO : built Dictionary(170 unique tokens: ['acaba', 'anunciar', 'connect', 'desenvolvendo', 'empresa']...) from 11 documents (total 299 corpus positions)\n",
      "2019-04-24 17:02:26,797 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:26,801 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,805 : INFO : built Dictionary(140 unique tokens: ['cenário', 'cidad', 'citi', 'coisa', 'com']...) from 7 documents (total 203 corpus positions)\n",
      "2019-04-24 17:02:26,808 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:26,821 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,825 : INFO : built Dictionary(260 unique tokens: ['apolog', 'babi', 'drug', 'facebook', 'gun']...) from 27 documents (total 383 corpus positions)\n",
      "2019-04-24 17:02:26,842 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:26,844 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,849 : INFO : built Dictionary(19 unique tokens: ['best', 'code', 'develop', 'experienc', 'isn']...) from 4 documents (total 22 corpus positions)\n",
      "2019-04-24 17:02:26,854 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:26,858 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:26,866 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,871 : INFO : built Dictionary(215 unique tokens: ['contact', 'daili', 'deem', 'dispos', 'ey']...) from 24 documents (total 312 corpus positions)\n",
      "2019-04-24 17:02:26,892 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,896 : INFO : built Dictionary(277 unique tokens: ['applic', 'arena', 'artifici', 'confer', 'discuss']...) from 37 documents (total 401 corpus positions)\n",
      "2019-04-24 17:02:26,920 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,924 : INFO : built Dictionary(252 unique tokens: ['atividad', 'brainstorm', 'campanha', 'client', 'criação']...) from 32 documents (total 413 corpus positions)\n",
      "2019-04-24 17:02:26,946 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,949 : INFO : built Dictionary(175 unique tokens: ['android', 'come', 'develop', 'eclips', 'goodby']...) from 20 documents (total 333 corpus positions)\n",
      "2019-04-24 17:02:26,963 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:26,966 : INFO : built Dictionary(114 unique tokens: ['articl', 'demonstr', 'docker', 'drupal', 'organ']...) from 39 documents (total 242 corpus positions)\n",
      "2019-04-24 17:02:26,999 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,006 : INFO : built Dictionary(498 unique tokens: ['articl', 'aspect', 'blog', 'code', 'conduct']...) from 123 documents (total 1042 corpus positions)\n",
      "2019-04-24 17:02:27,103 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,106 : INFO : built Dictionary(204 unique tokens: ['develop', 'end', 'gulp', 'mainstai', 'nowadai']...) from 43 documents (total 412 corpus positions)\n",
      "2019-04-24 17:02:27,136 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,140 : INFO : built Dictionary(165 unique tokens: ['attach', 'content', 'creat', 'drupal', 'field']...) from 61 documents (total 496 corpus positions)\n",
      "2019-04-24 17:02:27,183 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,188 : INFO : built Dictionary(360 unique tokens: ['articl', 'bring', 'challeng', 'china', 'deploi']...) from 57 documents (total 671 corpus positions)\n",
      "2019-04-24 17:02:27,226 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,229 : INFO : built Dictionary(272 unique tokens: ['applic', 'develop', 'keep', 'kotlin', 'open']...) from 66 documents (total 493 corpus positions)\n",
      "2019-04-24 17:02:27,267 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,271 : INFO : built Dictionary(305 unique tokens: ['ambient', 'cada', 'corporativo', 'ferramenta', 'investido']...) from 29 documents (total 481 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:27,292 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,295 : INFO : built Dictionary(260 unique tokens: ['app', 'busi', 'continu', 'dollar', 'find']...) from 40 documents (total 410 corpus positions)\n",
      "2019-04-24 17:02:27,317 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,321 : INFO : built Dictionary(264 unique tokens: ['acquia', 'dai', 'disappoint', 'engag', 'address']...) from 32 documents (total 360 corpus positions)\n",
      "2019-04-24 17:02:27,336 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,342 : INFO : built Dictionary(104 unique tokens: ['abil', 'best', 'case', 'condit', 'crux']...) from 31 documents (total 175 corpus positions)\n",
      "2019-04-24 17:02:27,364 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,368 : INFO : built Dictionary(374 unique tokens: ['actual', 'build', 'mean', 'microservic', 'answer']...) from 72 documents (total 752 corpus positions)\n",
      "2019-04-24 17:02:27,420 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,422 : INFO : built Dictionary(205 unique tokens: ['object', 'recogn', 'see', 'twice', 'algorithm']...) from 24 documents (total 339 corpus positions)\n",
      "2019-04-24 17:02:27,446 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,450 : INFO : built Dictionary(346 unique tokens: ['curv', 'hype', 'learn', 'machin', 'question']...) from 64 documents (total 594 corpus positions)\n",
      "2019-04-24 17:02:27,484 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,488 : INFO : built Dictionary(259 unique tokens: ['anuncia', 'companhia', 'digit', 'especializada', 'financeiro']...) from 19 documents (total 429 corpus positions)\n",
      "2019-04-24 17:02:27,506 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,509 : INFO : built Dictionary(193 unique tokens: ['challeng', 'chief', 'cloudera', 'commun', 'discuss']...) from 35 documents (total 363 corpus positions)\n",
      "2019-04-24 17:02:27,543 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,547 : INFO : built Dictionary(406 unique tokens: ['acquir', 'compani', 'competitor', 'custom', 'million']...) from 71 documents (total 1074 corpus positions)\n",
      "2019-04-24 17:02:27,607 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,609 : INFO : built Dictionary(60 unique tokens: ['android', 'linux', 'need', 'run', 'teeni']...) from 11 documents (total 66 corpus positions)\n",
      "2019-04-24 17:02:27,623 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,627 : INFO : built Dictionary(241 unique tokens: ['basic', 'box', 'drupal', 'handl', 'instal']...) from 46 documents (total 489 corpus positions)\n",
      "2019-04-24 17:02:27,664 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,668 : INFO : built Dictionary(345 unique tokens: ['access', 'ask', 'burg', 'compar', 'desktop']...) from 81 documents (total 986 corpus positions)\n",
      "2019-04-24 17:02:27,730 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,733 : INFO : built Dictionary(316 unique tokens: ['aceitação', 'ambient', 'artigo', 'bem', 'claro']...) from 48 documents (total 662 corpus positions)\n",
      "2019-04-24 17:02:27,765 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,769 : INFO : built Dictionary(249 unique tokens: ['black', 'chega', 'chegou', 'com', 'grupo']...) from 23 documents (total 438 corpus positions)\n",
      "2019-04-24 17:02:27,788 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,791 : INFO : built Dictionary(238 unique tokens: ['acceler', 'acquia', 'announc', 'author', 'avail']...) from 25 documents (total 486 corpus positions)\n",
      "2019-04-24 17:02:27,806 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:27,808 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,810 : INFO : built Dictionary(26 unique tokens: ['abil', 'author', 'builder', 'collect', 'content']...) from 2 documents (total 31 corpus positions)\n",
      "2019-04-24 17:02:27,812 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:27,815 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:27,817 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:27,832 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,836 : INFO : built Dictionary(566 unique tokens: ['blockchain', 'crescent', 'curiosidad', 'executivo', 'observando']...) from 76 documents (total 1014 corpus positions)\n",
      "2019-04-24 17:02:27,907 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:27,912 : INFO : built Dictionary(617 unique tokens: ['afin', 'correto', 'dado', 'gestão', 'informação']...) from 104 documents (total 1521 corpus positions)\n",
      "2019-04-24 17:02:28,022 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:28,024 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:28,026 : INFO : built Dictionary(50 unique tokens: ['américa', 'companhia', 'dasa', 'diagnóstica', 'diagnóstico']...) from 5 documents (total 64 corpus positions)\n",
      "2019-04-24 17:02:28,028 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:28,043 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:28,047 : INFO : built Dictionary(339 unique tokens: ['bui', 'dai', 'design', 'embrac', 'extend']...) from 50 documents (total 706 corpus positions)\n",
      "2019-04-24 17:02:28,084 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:28,087 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:28,091 : INFO : built Dictionary(108 unique tokens: ['com', 'dentro', 'discutirá', 'evento', 'feira']...) from 7 documents (total 125 corpus positions)\n",
      "2019-04-24 17:02:28,094 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:28,163 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:28,173 : INFO : built Dictionary(1176 unique tokens: ['case', 'gather', 'introduct', 'present', 'sens']...) from 245 documents (total 3447 corpus positions)\n",
      "2019-04-24 17:02:28,687 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:28,692 : INFO : built Dictionary(468 unique tokens: ['ago', 'backend', 'construct', 'consult', 'fail']...) from 112 documents (total 1162 corpus positions)\n",
      "2019-04-24 17:02:28,820 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:28,825 : INFO : built Dictionary(587 unique tokens: ['data', 'googl', 'led', 'log', 'number']...) from 177 documents (total 1625 corpus positions)\n",
      "2019-04-24 17:02:29,021 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,024 : INFO : built Dictionary(160 unique tokens: ['aplicativo', 'atendimento', 'client', 'digit', 'facebook']...) from 15 documents (total 249 corpus positions)\n",
      "2019-04-24 17:02:29,039 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,042 : INFO : built Dictionary(199 unique tokens: ['acceler', 'better', 'blog', 'brain', 'cross']...) from 20 documents (total 331 corpus positions)\n",
      "2019-04-24 17:02:29,058 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,061 : INFO : built Dictionary(164 unique tokens: ['analyt', 'autom', 'cape', 'compani', 'improv']...) from 17 documents (total 245 corpus positions)\n",
      "2019-04-24 17:02:29,073 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,076 : INFO : built Dictionary(148 unique tokens: ['apena', 'carro', 'citroën', 'cliqu', 'com']...) from 17 documents (total 215 corpus positions)\n",
      "2019-04-24 17:02:29,094 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,098 : INFO : built Dictionary(252 unique tokens: ['assum', 'candid', 'colleg', 'count', 'eastern']...) from 47 documents (total 423 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:29,120 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,123 : INFO : built Dictionary(109 unique tokens: ['chines', 'comemoram', 'dia', 'do', 'fato']...) from 10 documents (total 145 corpus positions)\n",
      "2019-04-24 17:02:29,143 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,150 : INFO : built Dictionary(274 unique tokens: ['believ', 'brand', 'conclud', 'consum', 'die']...) from 50 documents (total 442 corpus positions)\n",
      "2019-04-24 17:02:29,193 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,197 : INFO : built Dictionary(240 unique tokens: ['aim', 'base', 'bede', 'bodi', 'calori']...) from 34 documents (total 338 corpus positions)\n",
      "2019-04-24 17:02:29,220 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,224 : INFO : built Dictionary(323 unique tokens: ['ago', 'artifici', 'began', 'capit', 'firm']...) from 53 documents (total 607 corpus positions)\n",
      "2019-04-24 17:02:29,256 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:29,258 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,260 : INFO : built Dictionary(94 unique tokens: ['access', 'build', 'catch', 'daughter', 'flight']...) from 8 documents (total 127 corpus positions)\n",
      "2019-04-24 17:02:29,262 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:29,270 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,272 : INFO : built Dictionary(125 unique tokens: ['announc', 'base', 'bui', 'cloud', 'compani']...) from 16 documents (total 186 corpus positions)\n",
      "2019-04-24 17:02:29,284 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,288 : INFO : built Dictionary(249 unique tokens: ['acredito', 'ano', 'chover', 'comando', 'deu']...) from 14 documents (total 375 corpus positions)\n",
      "2019-04-24 17:02:29,305 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,308 : INFO : built Dictionary(246 unique tokens: ['articl', 'biggest', 'broadest', 'cultur', 'divers']...) from 32 documents (total 364 corpus positions)\n",
      "2019-04-24 17:02:29,325 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,328 : INFO : built Dictionary(85 unique tokens: ['antiqu', 'appreci', 'be', 'commun', 'cours']...) from 13 documents (total 134 corpus positions)\n",
      "2019-04-24 17:02:29,334 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:29,337 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,340 : INFO : built Dictionary(32 unique tokens: ['brainstorm', 'bring', 'good', 'great', 'idea']...) from 6 documents (total 40 corpus positions)\n",
      "2019-04-24 17:02:29,342 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:29,350 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,355 : INFO : built Dictionary(230 unique tokens: ['atravé', 'aumenta', 'cada', 'cognitiva', 'desenvolvimento']...) from 20 documents (total 315 corpus positions)\n",
      "2019-04-24 17:02:29,370 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,373 : INFO : built Dictionary(219 unique tokens: ['acquisit', 'announc', 'compani', 'creat', 'digit']...) from 26 documents (total 373 corpus positions)\n",
      "2019-04-24 17:02:29,390 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:29,393 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,397 : INFO : built Dictionary(26 unique tokens: ['abl', 'announc', 'bit', 'cheer', 'decemb']...) from 2 documents (total 27 corpus positions)\n",
      "2019-04-24 17:02:29,400 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:29,402 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:29,406 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:29,424 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,430 : INFO : built Dictionary(535 unique tokens: ['time', 'year', 'deal', 'collect', 'custom']...) from 81 documents (total 878 corpus positions)\n",
      "2019-04-24 17:02:29,487 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,491 : INFO : built Dictionary(704 unique tokens: ['américa', 'avançar', 'competitividad', 'desafio', 'desenvolvimento']...) from 68 documents (total 1615 corpus positions)\n",
      "2019-04-24 17:02:29,557 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:29,559 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,562 : INFO : built Dictionary(64 unique tokens: ['charg', 'hulu', 'movi', 'recommend', 'super']...) from 9 documents (total 74 corpus positions)\n",
      "2019-04-24 17:02:29,564 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:29,570 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,574 : INFO : built Dictionary(76 unique tokens: ['believ', 'drupal', 'hard', 'releas', 'world']...) from 13 documents (total 119 corpus positions)\n",
      "2019-04-24 17:02:29,583 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:29,585 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,588 : INFO : built Dictionary(59 unique tokens: ['busi', 'compani', 'cours', 'creat', 'establish']...) from 4 documents (total 87 corpus positions)\n",
      "2019-04-24 17:02:29,590 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:29,594 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:29,598 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:29,601 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,603 : INFO : built Dictionary(74 unique tokens: ['anunci', 'artifici', 'com', 'experimento', 'explorar']...) from 6 documents (total 95 corpus positions)\n",
      "2019-04-24 17:02:29,607 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:29,626 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,632 : INFO : built Dictionary(317 unique tokens: ['aspir', 'brain', 'build', 'evernot', 'second']...) from 53 documents (total 690 corpus positions)\n",
      "2019-04-24 17:02:29,661 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:29,663 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,665 : INFO : built Dictionary(18 unique tokens: ['get', 'languag', 'octob', 'peopl', 'read']...) from 4 documents (total 24 corpus positions)\n",
      "2019-04-24 17:02:29,668 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:29,672 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:29,689 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,693 : INFO : built Dictionary(402 unique tokens: ['area', 'cloud', 'fastest', 'googl', 'grow']...) from 72 documents (total 954 corpus positions)\n",
      "2019-04-24 17:02:29,746 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:29,749 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,752 : INFO : built Dictionary(123 unique tokens: ['accur', 'alta', 'aprendizado', 'baixa', 'capaz']...) from 9 documents (total 170 corpus positions)\n",
      "2019-04-24 17:02:29,755 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:29,775 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,780 : INFO : built Dictionary(559 unique tokens: ['ajudar', 'ano', 'ao', 'black', 'com']...) from 61 documents (total 1103 corpus positions)\n",
      "2019-04-24 17:02:29,836 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,840 : INFO : built Dictionary(161 unique tokens: ['do', 'estão', 'excel', 'gráfico', 'isso']...) from 22 documents (total 260 corpus positions)\n",
      "2019-04-24 17:02:29,852 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:29,855 : INFO : built Dictionary(112 unique tokens: ['cabral', 'continuar', 'cresceu', 'curti', 'dei']...) from 12 documents (total 163 corpus positions)\n",
      "2019-04-24 17:02:29,874 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,878 : INFO : built Dictionary(351 unique tokens: ['childthem', 'eat', 'function', 'overrid', 'postfoot']...) from 90 documents (total 702 corpus positions)\n",
      "2019-04-24 17:02:29,937 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:29,941 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,946 : INFO : built Dictionary(105 unique tokens: ['address', 'berlin', 'case', 'cto', 'docker']...) from 6 documents (total 132 corpus positions)\n",
      "2019-04-24 17:02:29,953 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:29,967 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:29,972 : INFO : built Dictionary(185 unique tokens: ['architect', 'certifi', 'salesforc', 'technic', 'want']...) from 34 documents (total 322 corpus positions)\n",
      "2019-04-24 17:02:30,000 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,005 : INFO : built Dictionary(299 unique tokens: ['gonna', 'love', 'stori', 'american', 'chequ']...) from 120 documents (total 569 corpus positions)\n",
      "2019-04-24 17:02:30,066 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,069 : INFO : built Dictionary(139 unique tokens: ['accord', 'aim', 'bank', 'blockchain', 'cev']...) from 21 documents (total 237 corpus positions)\n",
      "2019-04-24 17:02:30,083 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,086 : INFO : built Dictionary(79 unique tokens: ['acquir', 'announc', 'applic', 'cloud', 'environ']...) from 10 documents (total 127 corpus positions)\n",
      "2019-04-24 17:02:30,095 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,099 : INFO : built Dictionary(87 unique tokens: ['ad', 'bunch', 'check', 'cover', 'develop']...) from 16 documents (total 155 corpus positions)\n",
      "2019-04-24 17:02:30,109 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,113 : INFO : built Dictionary(118 unique tokens: ['data', 'invest', 'organ', 'return', 'scienc']...) from 18 documents (total 173 corpus positions)\n",
      "2019-04-24 17:02:30,140 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,146 : INFO : built Dictionary(468 unique tokens: ['accentur', 'ceo', 'competit', 'design', 'evenson']...) from 96 documents (total 956 corpus positions)\n",
      "2019-04-24 17:02:30,218 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,221 : INFO : built Dictionary(237 unique tokens: ['aviat', 'fatal', 'industri', 'miscommun', 'commun']...) from 47 documents (total 485 corpus positions)\n",
      "2019-04-24 17:02:30,258 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,262 : INFO : built Dictionary(371 unique tokens: ['ano', 'black', 'desd', 'está', 'evento']...) from 49 documents (total 670 corpus positions)\n",
      "2019-04-24 17:02:30,293 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:30,296 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,299 : INFO : built Dictionary(66 unique tokens: ['acordo', 'artifici', 'capaz', 'com', 'fazer']...) from 6 documents (total 81 corpus positions)\n",
      "2019-04-24 17:02:30,302 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:30,316 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,320 : INFO : built Dictionary(274 unique tokens: ['app', 'base', 'board', 'deal', 'kanban']...) from 73 documents (total 506 corpus positions)\n",
      "2019-04-24 17:02:30,368 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,373 : INFO : built Dictionary(359 unique tokens: ['design', 'exception', 'java', 'stream', 'api']...) from 73 documents (total 869 corpus positions)\n",
      "2019-04-24 17:02:30,436 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,441 : INFO : built Dictionary(640 unique tokens: ['compreend', 'envolv', 'liderança', 'não', 'principalment']...) from 76 documents (total 1203 corpus positions)\n",
      "2019-04-24 17:02:30,509 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,512 : INFO : built Dictionary(111 unique tokens: ['ajudava', 'atualiz', 'favorito', 'fila', 'googl']...) from 12 documents (total 149 corpus positions)\n",
      "2019-04-24 17:02:30,531 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,535 : INFO : built Dictionary(307 unique tokens: ['analysi', 'captur', 'collect', 'devic', 'john']...) from 40 documents (total 554 corpus positions)\n",
      "2019-04-24 17:02:30,564 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,566 : INFO : built Dictionary(139 unique tokens: ['microsoft', 'mobil', 'new', 'oper', 'past']...) from 20 documents (total 219 corpus positions)\n",
      "2019-04-24 17:02:30,582 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,588 : INFO : built Dictionary(227 unique tokens: ['atualment', 'chatbot', 'da', 'fort', 'mai']...) from 21 documents (total 359 corpus positions)\n",
      "2019-04-24 17:02:30,604 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,608 : INFO : built Dictionary(307 unique tokens: ['ainda', 'além', 'civilização', 'conseguiu', 'contato']...) from 35 documents (total 504 corpus positions)\n",
      "2019-04-24 17:02:30,632 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,635 : INFO : built Dictionary(261 unique tokens: ['architectur', 'develop', 'hype', 'industri', 'microservic']...) from 55 documents (total 691 corpus positions)\n",
      "2019-04-24 17:02:30,679 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,683 : INFO : built Dictionary(335 unique tokens: ['ag', 'bank', 'forgotten', 'help', 'imagin']...) from 40 documents (total 515 corpus positions)\n",
      "2019-04-24 17:02:30,710 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,714 : INFO : built Dictionary(236 unique tokens: ['algorithm', 'implement', 'beginn', 'get', 'start']...) from 96 documents (total 554 corpus positions)\n",
      "2019-04-24 17:02:30,781 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,784 : INFO : built Dictionary(339 unique tokens: ['data', 'descent', 'destruct', 'european', 'faulti']...) from 38 documents (total 597 corpus positions)\n",
      "2019-04-24 17:02:30,807 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:30,809 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,812 : INFO : built Dictionary(126 unique tokens: ['américa', 'anual', 'anunci', 'autenticação', 'biometria']...) from 8 documents (total 172 corpus positions)\n",
      "2019-04-24 17:02:30,815 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:30,822 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,825 : INFO : built Dictionary(74 unique tokens: ['amazon', 'ami', 'applic', 'design', 'environ']...) from 15 documents (total 115 corpus positions)\n",
      "2019-04-24 17:02:30,833 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,836 : INFO : built Dictionary(166 unique tokens: ['ano', 'anunci', 'att', 'atuação', 'banco']...) from 16 documents (total 259 corpus positions)\n",
      "2019-04-24 17:02:30,845 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:30,849 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,852 : INFO : built Dictionary(100 unique tokens: ['academia', 'animado', 'art', 'cinematográfica', 'ciência']...) from 7 documents (total 120 corpus positions)\n",
      "2019-04-24 17:02:30,855 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:30,866 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:30,872 : INFO : built Dictionary(207 unique tokens: ['alguma', 'até', 'class', 'com', 'criar']...) from 22 documents (total 422 corpus positions)\n",
      "2019-04-24 17:02:30,888 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,892 : INFO : built Dictionary(149 unique tokens: ['comput', 'featur', 'gain', 'get', 'imag']...) from 19 documents (total 212 corpus positions)\n",
      "2019-04-24 17:02:30,901 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,904 : INFO : built Dictionary(66 unique tokens: ['android', 'colleagu', 'develop', 'mention', 'present']...) from 12 documents (total 100 corpus positions)\n",
      "2019-04-24 17:02:30,922 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,925 : INFO : built Dictionary(380 unique tokens: ['benefit', 'brain', 'come', 'illustr', 'medit']...) from 50 documents (total 764 corpus positions)\n",
      "2019-04-24 17:02:30,961 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:30,965 : INFO : built Dictionary(236 unique tokens: ['best', 'bring', 'collabor', 'design', 'everydai']...) from 31 documents (total 473 corpus positions)\n",
      "2019-04-24 17:02:30,997 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,005 : INFO : built Dictionary(179 unique tokens: ['check', 'know', 'problem', 'right', 'spell']...) from 44 documents (total 337 corpus positions)\n",
      "2019-04-24 17:02:31,041 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,045 : INFO : built Dictionary(421 unique tokens: ['acabando', 'ainda', 'ano', 'construir', 'determinarão']...) from 42 documents (total 776 corpus positions)\n",
      "2019-04-24 17:02:31,081 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,085 : INFO : built Dictionary(288 unique tokens: ['chatbot', 'danni', 'excit', 'got', 'introduct']...) from 60 documents (total 535 corpus positions)\n",
      "2019-04-24 17:02:31,114 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:31,116 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,119 : INFO : built Dictionary(50 unique tokens: ['articl', 'decad', 'drupal', 'ecommerc', 'ecosystem']...) from 6 documents (total 77 corpus positions)\n",
      "2019-04-24 17:02:31,121 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:31,128 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,131 : INFO : built Dictionary(121 unique tokens: ['activ', 'bui', 'engag', 'internet', 'primari']...) from 15 documents (total 174 corpus positions)\n",
      "2019-04-24 17:02:31,141 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,144 : INFO : built Dictionary(158 unique tokens: ['argu', 'build', 'ceo', 'commerc', 'develop']...) from 16 documents (total 233 corpus positions)\n",
      "2019-04-24 17:02:31,155 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,158 : INFO : built Dictionary(136 unique tokens: ['build', 'come', 'detour', 'distribut', 'drupal']...) from 15 documents (total 246 corpus positions)\n",
      "2019-04-24 17:02:31,171 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,175 : INFO : built Dictionary(190 unique tokens: ['build', 'drupal', 'ecommerc', 'establish', 'ideal']...) from 29 documents (total 304 corpus positions)\n",
      "2019-04-24 17:02:31,192 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,194 : INFO : built Dictionary(167 unique tokens: ['advic', 'disingenu', 'drupal', 'ecommerc', 'histori']...) from 16 documents (total 300 corpus positions)\n",
      "2019-04-24 17:02:31,206 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,209 : INFO : built Dictionary(139 unique tokens: ['acquia', 'best', 'commerc', 'dedic', 'drupal']...) from 24 documents (total 218 corpus positions)\n",
      "2019-04-24 17:02:31,220 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,222 : INFO : built Dictionary(65 unique tokens: ['commerc', 'disclosur', 'drupal', 'import', 'person']...) from 12 documents (total 83 corpus positions)\n",
      "2019-04-24 17:02:31,233 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,237 : INFO : built Dictionary(379 unique tokens: ['adiantava', 'bermuda', 'camiseta', 'escuro', 'fala']...) from 37 documents (total 623 corpus positions)\n",
      "2019-04-24 17:02:31,260 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,263 : INFO : built Dictionary(183 unique tokens: ['contain', 'dai', 'flow', 'port', 'rotterdam']...) from 32 documents (total 312 corpus positions)\n",
      "2019-04-24 17:02:31,278 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,281 : INFO : built Dictionary(66 unique tokens: ['date', 'fanat', 'rejoic', 'abil', 'card']...) from 17 documents (total 100 corpus positions)\n",
      "2019-04-24 17:02:31,290 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,292 : INFO : built Dictionary(144 unique tokens: ['continu', 'grow', 'librari', 'popular', 'wordpress']...) from 24 documents (total 253 corpus positions)\n",
      "2019-04-24 17:02:31,307 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,310 : INFO : built Dictionary(157 unique tokens: ['antenna', 'applic', 'conductor', 'examin', 'flagship']...) from 20 documents (total 250 corpus positions)\n",
      "2019-04-24 17:02:31,318 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:31,321 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,324 : INFO : built Dictionary(22 unique tokens: ['brasileira', 'com', 'comentada', 'deficiência', 'inclusão']...) from 2 documents (total 32 corpus positions)\n",
      "2019-04-24 17:02:31,327 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:31,329 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:31,331 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:31,340 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,343 : INFO : built Dictionary(230 unique tokens: ['edg', 'fit', 'line', 'mainstream', 'ring']...) from 35 documents (total 348 corpus positions)\n",
      "2019-04-24 17:02:31,364 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,367 : INFO : built Dictionary(221 unique tokens: ['ceo', 'harder', 'busi', 'chang', 'compani']...) from 47 documents (total 434 corpus positions)\n",
      "2019-04-24 17:02:31,390 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:31,392 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,395 : INFO : built Dictionary(32 unique tokens: ['abstract', 'action', 'approach', 'directli', 'domain']...) from 2 documents (total 32 corpus positions)\n",
      "2019-04-24 17:02:31,398 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:31,400 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:31,402 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:31,420 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,426 : INFO : built Dictionary(667 unique tokens: ['assédio', 'beneficiar', 'cargo', 'com', 'istock']...) from 87 documents (total 1396 corpus positions)\n",
      "2019-04-24 17:02:31,501 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,503 : INFO : built Dictionary(147 unique tokens: ['adopt', 'android', 'dagger', 'depend', 'develop']...) from 34 documents (total 292 corpus positions)\n",
      "2019-04-24 17:02:31,525 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,529 : INFO : built Dictionary(356 unique tokens: ['afford', 'amp', 'balanc', 'googl', 'ignor']...) from 65 documents (total 656 corpus positions)\n",
      "2019-04-24 17:02:31,566 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,568 : INFO : built Dictionary(128 unique tokens: ['ago', 'choic', 'long', 'market', 'messag']...) from 22 documents (total 199 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:31,580 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,583 : INFO : built Dictionary(185 unique tokens: ['iniciei', 'jornada', 'minha', 'muuuuuito', 'para']...) from 22 documents (total 249 corpus positions)\n",
      "2019-04-24 17:02:31,593 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:31,595 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,598 : INFO : built Dictionary(93 unique tokens: ['big', 'bot', 'chatbot', 'compani', 'earlier']...) from 9 documents (total 137 corpus positions)\n",
      "2019-04-24 17:02:31,600 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:31,620 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,625 : INFO : built Dictionary(454 unique tokens: ['deep', 'develop', 'learn', 'research', 'sens']...) from 100 documents (total 836 corpus positions)\n",
      "2019-04-24 17:02:31,678 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:31,680 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,682 : INFO : built Dictionary(63 unique tokens: ['atualizado', 'carro', 'conceito', 'divulgação', 'emoçõ']...) from 6 documents (total 86 corpus positions)\n",
      "2019-04-24 17:02:31,685 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:31,718 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,727 : INFO : built Dictionary(711 unique tokens: ['celebr', 'educ', 'globe', 'scienc', 'week']...) from 135 documents (total 1573 corpus positions)\n",
      "2019-04-24 17:02:31,858 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,860 : INFO : built Dictionary(115 unique tokens: ['app', 'begin', 'come', 'googl', 'movi']...) from 13 documents (total 160 corpus positions)\n",
      "2019-04-24 17:02:31,867 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,870 : INFO : built Dictionary(81 unique tokens: ['ad', 'amazon', 'compar', 'content', 'get']...) from 12 documents (total 113 corpus positions)\n",
      "2019-04-24 17:02:31,884 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,889 : INFO : built Dictionary(261 unique tokens: ['assumpt', 'differ', 'oper', 'peopl', 'perform']...) from 52 documents (total 483 corpus positions)\n",
      "2019-04-24 17:02:31,912 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,915 : INFO : built Dictionary(113 unique tokens: ['black', 'chegam', 'começam', 'como', 'dia']...) from 10 documents (total 150 corpus positions)\n",
      "2019-04-24 17:02:31,925 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,929 : INFO : built Dictionary(180 unique tokens: ['atlanta', 'sept', 'adb', 'adob', 'corp']...) from 24 documents (total 336 corpus positions)\n",
      "2019-04-24 17:02:31,945 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,948 : INFO : built Dictionary(177 unique tokens: ['aceleração', 'aplicativo', 'com', 'condução', 'curva']...) from 18 documents (total 257 corpus positions)\n",
      "2019-04-24 17:02:31,965 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:31,968 : INFO : built Dictionary(453 unique tokens: ['ano', 'apesar', 'até', 'comemora', 'continua']...) from 52 documents (total 789 corpus positions)\n",
      "2019-04-24 17:02:32,009 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:32,015 : INFO : built Dictionary(321 unique tokens: ['almeida', 'antônio', 'anunci', 'anuncia', 'braga']...) from 17 documents (total 506 corpus positions)\n",
      "2019-04-24 17:02:32,075 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:32,086 : INFO : built Dictionary(987 unique tokens: ['centena', 'cm', 'concurr', 'eden', 'flag']...) from 194 documents (total 3404 corpus positions)\n",
      "2019-04-24 17:02:32,659 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:32,663 : INFO : built Dictionary(242 unique tokens: ['adopt', 'browser', 'look', 'novemb', 'thirti']...) from 47 documents (total 393 corpus positions)\n",
      "2019-04-24 17:02:32,694 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:32,697 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:32,700 : INFO : built Dictionary(27 unique tokens: ['browser', 'com', 'privaci', 'salesforc', 'statement']...) from 5 documents (total 31 corpus positions)\n",
      "2019-04-24 17:02:32,704 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:32,718 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:32,722 : INFO : built Dictionary(134 unique tokens: ['announc', 'bring', 'cloud', 'collabor', 'deeper']...) from 21 documents (total 256 corpus positions)\n",
      "2019-04-24 17:02:32,737 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:32,740 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:32,744 : INFO : built Dictionary(94 unique tokens: ['amazon', 'assistent', 'até', 'casa', 'como']...) from 8 documents (total 109 corpus positions)\n",
      "2019-04-24 17:02:32,747 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:32,759 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:32,762 : INFO : built Dictionary(238 unique tokens: ['artifici', 'ask', 'execut', 'intellig', 'compani']...) from 45 documents (total 349 corpus positions)\n",
      "2019-04-24 17:02:32,789 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:32,793 : INFO : built Dictionary(285 unique tokens: ['secret', 'tell', 'agre', 'biggest', 'complet']...) from 90 documents (total 550 corpus positions)\n",
      "2019-04-24 17:02:32,849 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:32,852 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:32,854 : INFO : built Dictionary(42 unique tokens: ['diagnos', 'diseas', 'emma', 'lawton', 'parkinson']...) from 5 documents (total 46 corpus positions)\n",
      "2019-04-24 17:02:32,857 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:32,867 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:32,871 : INFO : built Dictionary(215 unique tokens: ['coach', 'common', 'disguis', 'life', 'misconcept']...) from 40 documents (total 419 corpus positions)\n",
      "2019-04-24 17:02:32,906 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:32,911 : INFO : built Dictionary(493 unique tokens: ['numer', 'roman', 'pixabai', 'sourc', 'barri']...) from 120 documents (total 1066 corpus positions)\n",
      "2019-04-24 17:02:33,015 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,020 : INFO : built Dictionary(552 unique tokens: ['angelov', 'continu', 'develop', 'forward', 'framework']...) from 140 documents (total 1166 corpus positions)\n",
      "2019-04-24 17:02:33,125 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,128 : INFO : built Dictionary(369 unique tokens: ['architectur', 'base', 'consid', 'consider', 'decis']...) from 106 documents (total 835 corpus positions)\n",
      "2019-04-24 17:02:33,184 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,187 : INFO : built Dictionary(423 unique tokens: ['almoço', 'ano', 'assumiu', 'brasil', 'cargo']...) from 44 documents (total 732 corpus positions)\n",
      "2019-04-24 17:02:33,236 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,243 : INFO : built Dictionary(855 unique tokens: ['abstrato', 'arquitetura', 'artigo', 'caso', 'coisa']...) from 168 documents (total 2662 corpus positions)\n",
      "2019-04-24 17:02:33,464 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:33,466 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,468 : INFO : built Dictionary(111 unique tokens: ['adequado', 'caso', 'cegueira', 'com', 'diabética']...) from 8 documents (total 142 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:33,469 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:33,484 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,487 : INFO : built Dictionary(419 unique tokens: ['acceler', 'alan', 'boehm', 'challeng', 'coca']...) from 59 documents (total 810 corpus positions)\n",
      "2019-04-24 17:02:33,531 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,534 : INFO : built Dictionary(219 unique tokens: ['busi', 'consid', 'email', 'good', 'like']...) from 64 documents (total 443 corpus positions)\n",
      "2019-04-24 17:02:33,566 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,569 : INFO : built Dictionary(363 unique tokens: ['beta', 'bloomberg', 'cham', 'compani', 'creat']...) from 70 documents (total 566 corpus positions)\n",
      "2019-04-24 17:02:33,602 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,604 : INFO : built Dictionary(297 unique tokens: ['adoção', 'caminho', 'digit', 'mai', 'muito']...) from 17 documents (total 475 corpus positions)\n",
      "2019-04-24 17:02:33,615 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:33,617 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,619 : INFO : built Dictionary(49 unique tokens: ['book', 'command', 'egoless', 'establish', 'jerri']...) from 7 documents (total 57 corpus positions)\n",
      "2019-04-24 17:02:33,623 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:33,641 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,645 : INFO : built Dictionary(375 unique tokens: ['creep', 'develop', 'hover', 'project', 'scope']...) from 87 documents (total 968 corpus positions)\n",
      "2019-04-24 17:02:33,707 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:33,709 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,710 : INFO : built Dictionary(31 unique tokens: ['brasileira', 'brasileiro', 'commerc', 'consumo', 'disponibiliza']...) from 7 documents (total 47 corpus positions)\n",
      "2019-04-24 17:02:33,712 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:33,718 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,721 : INFO : built Dictionary(147 unique tokens: ['advoc', 'bring', 'comput', 'develop', 'devic']...) from 19 documents (total 261 corpus positions)\n",
      "2019-04-24 17:02:33,733 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,735 : INFO : built Dictionary(125 unique tokens: ['ad', 'artilleri', 'audiovisu', 'awai', 'call']...) from 12 documents (total 188 corpus positions)\n",
      "2019-04-24 17:02:33,746 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,749 : INFO : built Dictionary(241 unique tokens: ['casa', 'component', 'interessant', 'minha', 'rede']...) from 39 documents (total 426 corpus positions)\n",
      "2019-04-24 17:02:33,766 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:33,769 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,773 : INFO : built Dictionary(92 unique tokens: ['aka', 'android', 'anunci', 'baseada', 'coisa']...) from 6 documents (total 127 corpus positions)\n",
      "2019-04-24 17:02:33,775 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:33,781 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:33,783 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,786 : INFO : built Dictionary(84 unique tokens: ['aqui', 'assim', 'brasileira', 'causando', 'como']...) from 8 documents (total 101 corpus positions)\n",
      "2019-04-24 17:02:33,788 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:33,797 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,800 : INFO : built Dictionary(211 unique tokens: ['build', 'craig', 'go', 'heptio', 'industri']...) from 45 documents (total 333 corpus positions)\n",
      "2019-04-24 17:02:33,819 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,822 : INFO : built Dictionary(181 unique tokens: ['call', 'compon', 'contain', 'containerd', 'core']...) from 22 documents (total 293 corpus positions)\n",
      "2019-04-24 17:02:33,840 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,843 : INFO : built Dictionary(349 unique tokens: ['ainda', 'ano', 'coisa', 'consulta', 'da']...) from 27 documents (total 578 corpus positions)\n",
      "2019-04-24 17:02:33,860 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,863 : INFO : built Dictionary(161 unique tokens: ['depend', 'hack', 'home', 'kind', 'lot']...) from 19 documents (total 217 corpus positions)\n",
      "2019-04-24 17:02:33,870 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:33,872 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,873 : INFO : built Dictionary(17 unique tokens: ['activ', 'daili', 'duolingo', 'globe', 'languag']...) from 3 documents (total 25 corpus positions)\n",
      "2019-04-24 17:02:33,876 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:33,879 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:33,887 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,890 : INFO : built Dictionary(223 unique tokens: ['frustrat', 'look', 'respond', 'upset', 'view']...) from 33 documents (total 353 corpus positions)\n",
      "2019-04-24 17:02:33,903 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:33,906 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,907 : INFO : built Dictionary(81 unique tokens: ['bounc', 'chore', 'get', 'gmail', 'header']...) from 8 documents (total 133 corpus positions)\n",
      "2019-04-24 17:02:33,911 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:33,930 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,934 : INFO : built Dictionary(460 unique tokens: ['entertain', 'ordinari', 'peopl', 'seek', 'benjamin']...) from 101 documents (total 909 corpus positions)\n",
      "2019-04-24 17:02:33,992 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:33,994 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:33,995 : INFO : built Dictionary(54 unique tokens: ['hack', 'suffer', 'yahoo', 'account', 'august']...) from 7 documents (total 64 corpus positions)\n",
      "2019-04-24 17:02:33,997 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:34,012 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,016 : INFO : built Dictionary(249 unique tokens: ['highli', 'intentservic', 'known', 'lesser', 'like']...) from 63 documents (total 625 corpus positions)\n",
      "2019-04-24 17:02:34,057 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,060 : INFO : built Dictionary(201 unique tokens: ['activ', 'android', 'app', 'compos', 'fragment']...) from 53 documents (total 504 corpus positions)\n",
      "2019-04-24 17:02:34,096 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,100 : INFO : built Dictionary(394 unique tokens: ['big', 'challeng', 'data', 'engin', 'expand']...) from 104 documents (total 1020 corpus positions)\n",
      "2019-04-24 17:02:34,183 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,187 : INFO : built Dictionary(832 unique tokens: ['acontecendo', 'agora', 'ano', 'como', 'depoi']...) from 132 documents (total 2174 corpus positions)\n",
      "2019-04-24 17:02:34,334 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,336 : INFO : built Dictionary(209 unique tokens: ['abc', 'arbit', 'facebook', 'factcheck', 'fake']...) from 24 documents (total 339 corpus positions)\n",
      "2019-04-24 17:02:34,353 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,357 : INFO : built Dictionary(313 unique tokens: ['ano', 'anunciado', 'bueno', 'cercado', 'companhia']...) from 28 documents (total 472 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:34,373 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,375 : INFO : built Dictionary(89 unique tokens: ['desktop', 'explain', 'guid', 'help', 'record']...) from 22 documents (total 187 corpus positions)\n",
      "2019-04-24 17:02:34,388 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,391 : INFO : built Dictionary(239 unique tokens: ['agipag', 'agiplan', 'anunci', 'banco', 'baratear']...) from 19 documents (total 386 corpus positions)\n",
      "2019-04-24 17:02:34,402 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:34,404 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,406 : INFO : built Dictionary(93 unique tokens: ['adição', 'apresent', 'arduino', 'desenvolvimento', 'fundação']...) from 8 documents (total 125 corpus positions)\n",
      "2019-04-24 17:02:34,408 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:34,416 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,418 : INFO : built Dictionary(154 unique tokens: ['banco', 'brasil', 'cartão', 'caso', 'central']...) from 13 documents (total 234 corpus positions)\n",
      "2019-04-24 17:02:34,429 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,433 : INFO : built Dictionary(245 unique tokens: ['ameaça', 'ao', 'banco', 'brasília', 'cartão']...) from 29 documents (total 436 corpus positions)\n",
      "2019-04-24 17:02:34,450 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:34,453 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,455 : INFO : built Dictionary(149 unique tokens: ['ano', 'final', 'que', 'ainda', 'depoi']...) from 8 documents (total 192 corpus positions)\n",
      "2019-04-24 17:02:34,457 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:34,472 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,475 : INFO : built Dictionary(288 unique tokens: ['api', 'applic', 'build', 'capabl', 'decoupl']...) from 46 documents (total 621 corpus positions)\n",
      "2019-04-24 17:02:34,501 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:34,504 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,507 : INFO : built Dictionary(118 unique tokens: ['arm', 'curso', 'dar', 'desenvolvemo', 'desenvolvimento']...) from 8 documents (total 201 corpus positions)\n",
      "2019-04-24 17:02:34,510 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:34,522 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,526 : INFO : built Dictionary(223 unique tokens: ['amber', 'colleg', 'composit', 'date', 'dublin']...) from 36 documents (total 412 corpus positions)\n",
      "2019-04-24 17:02:34,542 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,545 : INFO : built Dictionary(71 unique tokens: ['brief', 'includ', 'secret', 'spot', 'trend']...) from 15 documents (total 111 corpus positions)\n",
      "2019-04-24 17:02:34,554 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,556 : INFO : built Dictionary(189 unique tokens: ['abocanhando', 'adquirida', 'andrea', 'daniel', 'digitai']...) from 13 documents (total 267 corpus positions)\n",
      "2019-04-24 17:02:34,565 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:34,567 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,570 : INFO : built Dictionary(106 unique tokens: ['bmw', 'conceito', 'detalh', 'divulg', 'holoact']...) from 9 documents (total 139 corpus positions)\n",
      "2019-04-24 17:02:34,572 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:34,587 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,591 : INFO : built Dictionary(427 unique tokens: ['ao', 'apó', 'banco', 'central', 'confirmar']...) from 40 documents (total 881 corpus positions)\n",
      "2019-04-24 17:02:34,617 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:34,619 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,621 : INFO : built Dictionary(78 unique tokens: ['acima', 'além', 'artifici', 'casa', 'criada']...) from 6 documents (total 106 corpus positions)\n",
      "2019-04-24 17:02:34,623 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:34,642 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,646 : INFO : built Dictionary(498 unique tokens: ['built', 'conglomer', 'door', 'german', 'headquart']...) from 93 documents (total 860 corpus positions)\n",
      "2019-04-24 17:02:34,694 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:34,696 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,698 : INFO : built Dictionary(91 unique tokens: ['agora', 'apresentar', 'batata', 'bebida', 'brasil']...) from 6 documents (total 104 corpus positions)\n",
      "2019-04-24 17:02:34,700 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:34,704 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:34,707 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,709 : INFO : built Dictionary(42 unique tokens: ['américa', 'anunci', 'aquisição', 'bahia', 'capit']...) from 3 documents (total 44 corpus positions)\n",
      "2019-04-24 17:02:34,711 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:34,713 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:34,715 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:34,720 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,723 : INFO : built Dictionary(179 unique tokens: ['anunci', 'atuai', 'com', 'commerc', 'contou']...) from 15 documents (total 252 corpus positions)\n",
      "2019-04-24 17:02:34,737 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,739 : INFO : built Dictionary(187 unique tokens: ['awai', 'easi', 'share', 'straight', 'tell']...) from 53 documents (total 343 corpus positions)\n",
      "2019-04-24 17:02:34,766 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,769 : INFO : built Dictionary(291 unique tokens: ['attempt', 'clean', 'cure', 'fling', 'kid']...) from 63 documents (total 626 corpus positions)\n",
      "2019-04-24 17:02:34,806 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,809 : INFO : built Dictionary(212 unique tokens: ['adventur', 'android', 'avail', 'close', 'codelab']...) from 47 documents (total 505 corpus positions)\n",
      "2019-04-24 17:02:34,831 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,833 : INFO : built Dictionary(53 unique tokens: ['make', 'map', 'sens', 'technolog', 'architectur']...) from 10 documents (total 73 corpus positions)\n",
      "2019-04-24 17:02:34,845 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,850 : INFO : built Dictionary(449 unique tokens: ['achar', 'certo', 'errado', 'está', 'mude']...) from 42 documents (total 804 corpus positions)\n",
      "2019-04-24 17:02:34,878 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,881 : INFO : built Dictionary(212 unique tokens: ['enthusiasm', 'flush', 'goal', 'optim', 'set']...) from 22 documents (total 316 corpus positions)\n",
      "2019-04-24 17:02:34,899 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,902 : INFO : built Dictionary(125 unique tokens: ['awai', 'cobertura', 'java', 'maven', 'notic']...) from 63 documents (total 602 corpus positions)\n",
      "2019-04-24 17:02:34,935 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,938 : INFO : built Dictionary(132 unique tokens: ['autom', 'build', 'docker', 'follow', 'label']...) from 37 documents (total 265 corpus positions)\n",
      "2019-04-24 17:02:34,953 : WARNING : Input text is expected to have at least 10 sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:34,955 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,957 : INFO : built Dictionary(83 unique tokens: ['acessibilidad', 'adicion', 'ajudar', 'cadeira', 'com']...) from 7 documents (total 97 corpus positions)\n",
      "2019-04-24 17:02:34,960 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:34,965 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:34,967 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:34,969 : INFO : built Dictionary(23 unique tokens: ['collabor', 'compani', 'devop', 'import', 'increasingli']...) from 2 documents (total 29 corpus positions)\n",
      "2019-04-24 17:02:34,973 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:34,975 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:34,977 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:35,008 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,017 : INFO : built Dictionary(570 unique tokens: ['asid', 'clean', 'coupl', 'dai', 'digit']...) from 136 documents (total 1359 corpus positions)\n",
      "2019-04-24 17:02:35,130 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,135 : INFO : built Dictionary(742 unique tokens: ['boot', 'progress', 'angular', 'code', 'react']...) from 205 documents (total 1972 corpus positions)\n",
      "2019-04-24 17:02:35,295 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,297 : INFO : built Dictionary(161 unique tokens: ['bui', 'control', 'dai', 'direct', 'experi']...) from 18 documents (total 232 corpus positions)\n",
      "2019-04-24 17:02:35,314 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,318 : INFO : built Dictionary(486 unique tokens: ['dai', 'drop', 'eat', 'great', 'happen']...) from 76 documents (total 776 corpus positions)\n",
      "2019-04-24 17:02:35,361 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,364 : INFO : built Dictionary(318 unique tokens: ['ago', 'better', 'develop', 'huge', 'node']...) from 67 documents (total 605 corpus positions)\n",
      "2019-04-24 17:02:35,394 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,396 : INFO : built Dictionary(207 unique tokens: ['api', 'artifici', 'categori', 'choic', 'contain']...) from 28 documents (total 404 corpus positions)\n",
      "2019-04-24 17:02:35,414 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,416 : INFO : built Dictionary(165 unique tokens: ['accord', 'ago', 'coca', 'cola', 'fanfar']...) from 26 documents (total 271 corpus positions)\n",
      "2019-04-24 17:02:35,436 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,440 : INFO : built Dictionary(309 unique tokens: ['constitu', 'era', 'expect', 'govern', 'great']...) from 52 documents (total 598 corpus positions)\n",
      "2019-04-24 17:02:35,470 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,473 : INFO : built Dictionary(240 unique tokens: ['acabando', 'aconteceu', 'ano', 'blog', 'com']...) from 22 documents (total 389 corpus positions)\n",
      "2019-04-24 17:02:35,488 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,491 : INFO : built Dictionary(256 unique tokens: ['adotam', 'agora', 'bomba', 'cerca', 'cobrança']...) from 31 documents (total 438 corpus positions)\n",
      "2019-04-24 17:02:35,509 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,512 : INFO : built Dictionary(113 unique tokens: ['american', 'coke', 'consum', 'have', 'smile']...) from 18 documents (total 174 corpus positions)\n",
      "2019-04-24 17:02:35,531 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,534 : INFO : built Dictionary(247 unique tokens: ['articl', 'browser', 'code', 'custom', 'design']...) from 72 documents (total 754 corpus positions)\n",
      "2019-04-24 17:02:35,580 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,583 : INFO : built Dictionary(228 unique tokens: ['crm', 'emerg', 'expect', 'gear', 'kick']...) from 36 documents (total 394 corpus positions)\n",
      "2019-04-24 17:02:35,603 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,606 : INFO : built Dictionary(144 unique tokens: ['amaz', 'gadget', 'go', 'year', 'activ']...) from 24 documents (total 184 corpus positions)\n",
      "2019-04-24 17:02:35,622 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,626 : INFO : built Dictionary(260 unique tokens: ['anniversari', 'celebr', 'consum', 'edit', 'electron']...) from 36 documents (total 432 corpus positions)\n",
      "2019-04-24 17:02:35,651 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,655 : INFO : built Dictionary(350 unique tokens: ['alejandro', 'apaixonado', 'argentino', 'comunicação', 'desafio']...) from 50 documents (total 671 corpus positions)\n",
      "2019-04-24 17:02:35,692 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,695 : INFO : built Dictionary(325 unique tokens: ['ago', 'continu', 'ensur', 'follow', 'introduc']...) from 53 documents (total 815 corpus positions)\n",
      "2019-04-24 17:02:35,735 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,738 : INFO : built Dictionary(238 unique tokens: ['hack', 'proud', 'quarterli', 'releas', 'report']...) from 54 documents (total 479 corpus positions)\n",
      "2019-04-24 17:02:35,767 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,770 : INFO : built Dictionary(262 unique tokens: ['chang', 'decid', 'major', 'medium', 'busi']...) from 59 documents (total 450 corpus positions)\n",
      "2019-04-24 17:02:35,802 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,805 : INFO : built Dictionary(387 unique tokens: ['awai', 'build', 'cross', 'deepmind', 'king']...) from 65 documents (total 648 corpus positions)\n",
      "2019-04-24 17:02:35,858 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,862 : INFO : built Dictionary(796 unique tokens: ['alli', 'america', 'best', 'desper', 'donald']...) from 123 documents (total 1455 corpus positions)\n",
      "2019-04-24 17:02:35,962 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,965 : INFO : built Dictionary(366 unique tokens: ['account', 'anniversari', 'birth', 'call', 'cathol']...) from 54 documents (total 499 corpus positions)\n",
      "2019-04-24 17:02:35,991 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:35,994 : INFO : built Dictionary(343 unique tokens: ['agil', 'long', 'plan', 'possibl', 'term']...) from 65 documents (total 759 corpus positions)\n",
      "2019-04-24 17:02:36,031 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,034 : INFO : built Dictionary(155 unique tokens: ['bock', 'cafeteria', 'call', 'compani', 'cultur']...) from 16 documents (total 219 corpus positions)\n",
      "2019-04-24 17:02:36,042 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:36,044 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,046 : INFO : built Dictionary(40 unique tokens: ['ce', 'challeng', 'design', 'experi', 'lover']...) from 6 documents (total 43 corpus positions)\n",
      "2019-04-24 17:02:36,048 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:36,051 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:36,053 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:36,063 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,067 : INFO : built Dictionary(395 unique tokens: ['aquisição', 'boa', 'estratégia', 'exist', 'por']...) from 50 documents (total 758 corpus positions)\n",
      "2019-04-24 17:02:36,099 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,101 : INFO : built Dictionary(161 unique tokens: ['announc', 'chapter', 'excit', 'futur', 'new']...) from 27 documents (total 251 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:36,114 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,117 : INFO : built Dictionary(164 unique tokens: ['acordo', 'cognitiva', 'com', 'como', 'computação']...) from 14 documents (total 217 corpus positions)\n",
      "2019-04-24 17:02:36,123 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:36,125 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,127 : INFO : built Dictionary(107 unique tokens: ['ainda', 'ano', 'estão', 'novo', 'resoluçõ']...) from 7 documents (total 133 corpus positions)\n",
      "2019-04-24 17:02:36,130 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:36,135 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:36,137 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,139 : INFO : built Dictionary(49 unique tokens: ['ajudam', 'aumentando', 'aumentar', 'contínua', 'deploi']...) from 2 documents (total 64 corpus positions)\n",
      "2019-04-24 17:02:36,140 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:36,143 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:36,145 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:36,150 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,153 : INFO : built Dictionary(172 unique tokens: ['alimentado', 'ampla', 'aplicaçõ', 'ble', 'coisa']...) from 10 documents (total 264 corpus positions)\n",
      "2019-04-24 17:02:36,162 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,165 : INFO : built Dictionary(161 unique tokens: ['acesso', 'ant', 'banco', 'concentravam', 'criando']...) from 13 documents (total 229 corpus positions)\n",
      "2019-04-24 17:02:36,180 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,184 : INFO : built Dictionary(289 unique tokens: ['custom', 'declin', 'destin', 'disnei', 'face']...) from 50 documents (total 553 corpus positions)\n",
      "2019-04-24 17:02:36,212 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,214 : INFO : built Dictionary(126 unique tokens: ['atualizar', 'derivado', 'devem', 'seu', 'sistema']...) from 11 documents (total 226 corpus positions)\n",
      "2019-04-24 17:02:36,230 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,233 : INFO : built Dictionary(297 unique tokens: ['android', 'build', 'past', 'stuff', 'year']...) from 63 documents (total 549 corpus positions)\n",
      "2019-04-24 17:02:36,259 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:36,262 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,264 : INFO : built Dictionary(76 unique tokens: ['adob', 'assistent', 'demonstr', 'ediçõ', 'essa']...) from 9 documents (total 100 corpus positions)\n",
      "2019-04-24 17:02:36,267 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:36,281 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,287 : INFO : built Dictionary(272 unique tokens: ['agil', 'busi', 'cogniz', 'digit', 'economi']...) from 26 documents (total 590 corpus positions)\n",
      "2019-04-24 17:02:36,301 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:36,304 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,306 : INFO : built Dictionary(25 unique tokens: ['face', 'function', 'iot', 'largest', 'let']...) from 3 documents (total 29 corpus positions)\n",
      "2019-04-24 17:02:36,307 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:36,311 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:36,323 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,328 : INFO : built Dictionary(471 unique tokens: ['algoritmo', 'analisar', 'astronômica', 'computacion', 'computacionai']...) from 53 documents (total 926 corpus positions)\n",
      "2019-04-24 17:02:36,364 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,367 : INFO : built Dictionary(158 unique tokens: ['aprovação', 'cabeada', 'dado', 'eletricista', 'eletrônico']...) from 15 documents (total 263 corpus positions)\n",
      "2019-04-24 17:02:36,378 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,381 : INFO : built Dictionary(221 unique tokens: ['acordo', 'client', 'com', 'comércio', 'criador']...) from 15 documents (total 331 corpus positions)\n",
      "2019-04-24 17:02:36,394 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,397 : INFO : built Dictionary(189 unique tokens: ['acquisit', 'analyt', 'beef', 'compani', 'engag']...) from 18 documents (total 297 corpus positions)\n",
      "2019-04-24 17:02:36,419 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,424 : INFO : built Dictionary(377 unique tokens: ['articl', 'claudio', 'peer', 'review', 'ribeiro']...) from 123 documents (total 1007 corpus positions)\n",
      "2019-04-24 17:02:36,510 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,513 : INFO : built Dictionary(533 unique tokens: ['busi', 'growth', 'market', 'mobil', 'world']...) from 80 documents (total 1224 corpus positions)\n",
      "2019-04-24 17:02:36,573 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,576 : INFO : built Dictionary(299 unique tokens: ['post', 'psycholog', 'seri', 'understand', 'user']...) from 63 documents (total 680 corpus positions)\n",
      "2019-04-24 17:02:36,618 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,622 : INFO : built Dictionary(325 unique tokens: ['best', 'commun', 'new', 'php', 'releas']...) from 89 documents (total 715 corpus positions)\n",
      "2019-04-24 17:02:36,675 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,677 : INFO : built Dictionary(126 unique tokens: ['ambient', 'android', 'aplicativo', 'com', 'como']...) from 10 documents (total 185 corpus positions)\n",
      "2019-04-24 17:02:36,687 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,690 : INFO : built Dictionary(289 unique tokens: ['conceito', 'conhecido', 'desenvolvimento', 'develop', 'do']...) from 31 documents (total 459 corpus positions)\n",
      "2019-04-24 17:02:36,705 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,708 : INFO : built Dictionary(118 unique tokens: ['acaba', 'aconteceu', 'apresentada', 'bebendo', 'ce']...) from 11 documents (total 151 corpus positions)\n",
      "2019-04-24 17:02:36,727 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,731 : INFO : built Dictionary(314 unique tokens: ['develop', 'framework', 'languag', 'platform', 'regardless']...) from 116 documents (total 848 corpus positions)\n",
      "2019-04-24 17:02:36,794 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:36,796 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,799 : INFO : built Dictionary(87 unique tokens: ['aplicação', 'capturar', 'client', 'consiga', 'corretament']...) from 6 documents (total 110 corpus positions)\n",
      "2019-04-24 17:02:36,801 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:36,818 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,822 : INFO : built Dictionary(403 unique tokens: ['allegi', 'club', 'ecommerc', 'experi', 'fan']...) from 67 documents (total 831 corpus positions)\n",
      "2019-04-24 17:02:36,868 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,871 : INFO : built Dictionary(341 unique tokens: ['apena', 'caso', 'cota', 'deputado', 'descobriu']...) from 40 documents (total 537 corpus positions)\n",
      "2019-04-24 17:02:36,904 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:36,909 : INFO : built Dictionary(607 unique tokens: ['acquia', 'begin', 'blog', 'come', 'far']...) from 128 documents (total 1323 corpus positions)\n",
      "2019-04-24 17:02:37,017 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:37,021 : INFO : built Dictionary(317 unique tokens: ['barata', 'estimar', 'exemplo', 'fluído', 'nem']...) from 37 documents (total 670 corpus positions)\n",
      "2019-04-24 17:02:37,053 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,056 : INFO : built Dictionary(280 unique tokens: ['car', 'chip', 'cloud', 'cyclist', 'design']...) from 32 documents (total 476 corpus positions)\n",
      "2019-04-24 17:02:37,076 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,080 : INFO : built Dictionary(176 unique tokens: ['brasil', 'coca', 'cola', 'criar', 'design']...) from 24 documents (total 246 corpus positions)\n",
      "2019-04-24 17:02:37,090 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:37,092 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,094 : INFO : built Dictionary(27 unique tokens: ['applic', 'aw', 'cluster', 'contain', 'creat']...) from 2 documents (total 32 corpus positions)\n",
      "2019-04-24 17:02:37,097 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:37,099 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:37,101 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:37,107 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,110 : INFO : built Dictionary(123 unique tokens: ['new', 'plan', 'review', 'round', 'time']...) from 37 documents (total 206 corpus positions)\n",
      "2019-04-24 17:02:37,120 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:37,123 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,125 : INFO : built Dictionary(24 unique tokens: ['activ', 'analyt', 'answer', 'app', 'billion']...) from 2 documents (total 26 corpus positions)\n",
      "2019-04-24 17:02:37,126 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:37,128 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:37,131 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:37,141 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,144 : INFO : built Dictionary(282 unique tokens: ['career', 'choic', 'embark', 'new', 'reflect']...) from 67 documents (total 494 corpus positions)\n",
      "2019-04-24 17:02:37,173 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,176 : INFO : built Dictionary(151 unique tokens: ['abril', 'inaugurada', 'incubadora', 'localizada', 'maior']...) from 16 documents (total 214 corpus positions)\n",
      "2019-04-24 17:02:37,185 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,187 : INFO : built Dictionary(139 unique tokens: ['anunciando', 'aumentada', 'baidu', 'busca', 'chinê']...) from 10 documents (total 188 corpus positions)\n",
      "2019-04-24 17:02:37,197 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,200 : INFO : built Dictionary(165 unique tokens: ['acquir', 'agre', 'announc', 'crashlyt', 'develop']...) from 29 documents (total 288 corpus positions)\n",
      "2019-04-24 17:02:37,230 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,235 : INFO : built Dictionary(474 unique tokens: ['right', 'start', 'tettra', 'assumpt', 'custom']...) from 127 documents (total 1123 corpus positions)\n",
      "2019-04-24 17:02:37,353 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,358 : INFO : built Dictionary(993 unique tokens: ['bring', 'convert', 'high', 'organ', 'traffic']...) from 301 documents (total 3022 corpus positions)\n",
      "2019-04-24 17:02:37,736 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,739 : INFO : built Dictionary(195 unique tokens: ['airbnb', 'announc', 'came', 'compani', 'design']...) from 33 documents (total 314 corpus positions)\n",
      "2019-04-24 17:02:37,779 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,784 : INFO : built Dictionary(569 unique tokens: ['articl', 'googl', 'million', 'number', 'send']...) from 187 documents (total 1635 corpus positions)\n",
      "2019-04-24 17:02:37,932 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,934 : INFO : built Dictionary(258 unique tokens: ['avançar', 'brin', 'cofundador', 'econômico', 'ef']...) from 25 documents (total 471 corpus positions)\n",
      "2019-04-24 17:02:37,955 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,958 : INFO : built Dictionary(380 unique tokens: ['aid', 'drank', 'intend', 'kool', 'microservic']...) from 44 documents (total 666 corpus positions)\n",
      "2019-04-24 17:02:37,986 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:37,990 : INFO : built Dictionary(473 unique tokens: ['acessar', 'adaptado', 'basta', 'blog', 'caso']...) from 46 documents (total 1102 corpus positions)\n",
      "2019-04-24 17:02:38,028 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,031 : INFO : built Dictionary(281 unique tokens: ['aplicado', 'compartilho', 'depoi', 'embarcado', 'implementar']...) from 26 documents (total 543 corpus positions)\n",
      "2019-04-24 17:02:38,046 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,048 : INFO : built Dictionary(122 unique tokens: ['internet', 'retail', 'samsung', 'take', 'thing']...) from 16 documents (total 201 corpus positions)\n",
      "2019-04-24 17:02:38,056 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:38,058 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,060 : INFO : built Dictionary(93 unique tokens: ['américa', 'assinado', 'companhia', 'comprar', 'confirm']...) from 7 documents (total 122 corpus positions)\n",
      "2019-04-24 17:02:38,063 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:38,071 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,074 : INFO : built Dictionary(152 unique tokens: ['commun', 'deliveri', 'hero', 'issu', 'littl']...) from 23 documents (total 241 corpus positions)\n",
      "2019-04-24 17:02:38,091 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,094 : INFO : built Dictionary(388 unique tokens: ['ag', 'comput', 'long', 'model', 'newer']...) from 55 documents (total 580 corpus positions)\n",
      "2019-04-24 17:02:38,120 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,122 : INFO : built Dictionary(133 unique tokens: ['até', 'bilhõ', 'conectado', 'eletrônico', 'equipamento']...) from 17 documents (total 182 corpus positions)\n",
      "2019-04-24 17:02:38,142 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,146 : INFO : built Dictionary(347 unique tokens: ['api', 'terrifi', 'version', 'angri', 'basic']...) from 70 documents (total 798 corpus positions)\n",
      "2019-04-24 17:02:38,191 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,198 : INFO : built Dictionary(363 unique tokens: ['activ', 'colocar', 'layout', 'lista', 'passo']...) from 71 documents (total 928 corpus positions)\n",
      "2019-04-24 17:02:38,258 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,261 : INFO : built Dictionary(331 unique tokens: ['base', 'classifi', 'compani', 'differ', 'engin']...) from 85 documents (total 666 corpus positions)\n",
      "2019-04-24 17:02:38,303 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,305 : INFO : built Dictionary(132 unique tokens: ['board', 'new', 'offer', 'opportun', 'pricei']...) from 17 documents (total 171 corpus positions)\n",
      "2019-04-24 17:02:38,328 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,331 : INFO : built Dictionary(543 unique tokens: ['decad', 'devic', 'enhanc', 'feel', 'function']...) from 99 documents (total 1110 corpus positions)\n",
      "2019-04-24 17:02:38,415 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,419 : INFO : built Dictionary(523 unique tokens: ['acquisit', 'compani', 'differ', 'integr', 'merger']...) from 98 documents (total 1346 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:38,672 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,676 : INFO : built Dictionary(278 unique tokens: ['benefit', 'concept', 'consensu', 'familiar', 'implement']...) from 108 documents (total 873 corpus positions)\n",
      "2019-04-24 17:02:38,751 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,754 : INFO : built Dictionary(262 unique tokens: ['ago', 'base', 'capabl', 'common', 'content']...) from 59 documents (total 593 corpus positions)\n",
      "2019-04-24 17:02:38,778 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:38,780 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,782 : INFO : built Dictionary(22 unique tokens: ['architectur', 'design', 'end', 'godbolt', 'micah']...) from 3 documents (total 28 corpus positions)\n",
      "2019-04-24 17:02:38,783 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:38,787 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:38,789 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:38,791 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,793 : INFO : built Dictionary(22 unique tokens: ['gui', 'op', 'configur', 'like', 'screw']...) from 6 documents (total 25 corpus positions)\n",
      "2019-04-24 17:02:38,795 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:38,804 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,807 : INFO : built Dictionary(149 unique tokens: ['anniversari', 'drush', 'mark', 'week', 'year']...) from 31 documents (total 223 corpus positions)\n",
      "2019-04-24 17:02:38,830 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,834 : INFO : built Dictionary(413 unique tokens: ['cloud', 'googl', 'microsoft', 'pivot', 'privileg']...) from 98 documents (total 780 corpus positions)\n",
      "2019-04-24 17:02:38,883 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:38,885 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,887 : INFO : built Dictionary(199 unique tokens: ['arduino', 'bloco', 'com', 'do', 'elemento']...) from 9 documents (total 302 corpus positions)\n",
      "2019-04-24 17:02:38,890 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:38,895 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:38,897 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,900 : INFO : built Dictionary(42 unique tokens: ['ação', 'colocá', 'fala', 'ideia', 'muito']...) from 6 documents (total 49 corpus positions)\n",
      "2019-04-24 17:02:38,902 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:38,912 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,915 : INFO : built Dictionary(227 unique tokens: ['acquia', 'adob', 'episerv', 'favor', 'forrest']...) from 32 documents (total 425 corpus positions)\n",
      "2019-04-24 17:02:38,948 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:38,953 : INFO : built Dictionary(474 unique tokens: ['blockchain', 'ceo', 'coin', 'compani', 'founder']...) from 127 documents (total 1135 corpus positions)\n",
      "2019-04-24 17:02:39,064 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:39,066 : INFO : built Dictionary(159 unique tokens: ['learn', 'quest', 'sitepoint', 'visit', 'problem']...) from 39 documents (total 275 corpus positions)\n",
      "2019-04-24 17:02:39,078 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:39,080 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:39,083 : INFO : built Dictionary(24 unique tokens: ['acquia', 'base', 'cloud', 'content', 'deliveri']...) from 3 documents (total 29 corpus positions)\n",
      "2019-04-24 17:02:39,085 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:39,088 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:39,120 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:39,125 : INFO : built Dictionary(517 unique tokens: ['bot', 'build', 'camilo', 'chat', 'facebook']...) from 267 documents (total 2072 corpus positions)\n",
      "2019-04-24 17:02:39,433 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:39,436 : INFO : built Dictionary(411 unique tokens: ['acceler', 'agil', 'bank', 'citigroup', 'describ']...) from 100 documents (total 811 corpus positions)\n",
      "2019-04-24 17:02:39,477 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:39,479 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:39,482 : INFO : built Dictionary(67 unique tokens: ['ano', 'anterior', 'aumento', 'bilhão', 'brasil']...) from 9 documents (total 101 corpus positions)\n",
      "2019-04-24 17:02:39,484 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:39,491 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:39,493 : INFO : built Dictionary(129 unique tokens: ['brasil', 'espanhol', 'euro', 'geraram', 'grupo']...) from 15 documents (total 213 corpus positions)\n",
      "2019-04-24 17:02:39,515 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:39,519 : INFO : built Dictionary(659 unique tokens: ['ainda', 'ano', 'aplicar', 'açõ', 'começ']...) from 74 documents (total 1294 corpus positions)\n",
      "2019-04-24 17:02:39,576 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:39,578 : INFO : built Dictionary(172 unique tokens: ['anybodi', 'extrovert', 'salesperson', 'sell', 'stereotyp']...) from 22 documents (total 249 corpus positions)\n",
      "2019-04-24 17:02:39,592 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:39,595 : INFO : built Dictionary(245 unique tokens: ['author', 'blockchain', 'director', 'distribut', 'follow']...) from 39 documents (total 430 corpus positions)\n",
      "2019-04-24 17:02:39,614 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:39,617 : INFO : built Dictionary(289 unique tokens: ['artifici', 'flourish', 'intellig', 'market', 'technolog']...) from 39 documents (total 485 corpus positions)\n",
      "2019-04-24 17:02:39,636 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:39,638 : INFO : built Dictionary(115 unique tokens: ['applic', 'architectur', 'depend', 'ebook', 'free']...) from 12 documents (total 184 corpus positions)\n",
      "2019-04-24 17:02:39,646 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:39,649 : INFO : built Dictionary(107 unique tokens: ['advisor', 'barbarian', 'blockchain', 'constitut', 'fintech']...) from 14 documents (total 149 corpus positions)\n",
      "2019-04-24 17:02:39,692 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:39,699 : INFO : built Dictionary(735 unique tokens: ['peopl', 'process', 'stream', 'cqr', 'event']...) from 256 documents (total 2487 corpus positions)\n",
      "2019-04-24 17:02:40,006 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:40,008 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:40,010 : INFO : built Dictionary(92 unique tokens: ['actelion', 'bilhõ', 'biotecnologia', 'chri', 'cisão']...) from 6 documents (total 114 corpus positions)\n",
      "2019-04-24 17:02:40,012 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:40,138 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:40,151 : INFO : built Dictionary(1152 unique tokens: ['agil', 'chapter', 'lai', 'learn', 'practition']...) from 636 documents (total 6145 corpus positions)\n",
      "2019-04-24 17:02:43,223 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,226 : INFO : built Dictionary(237 unique tokens: ['deadlin', 'deliv', 'design', 'develop', 'disciplin']...) from 54 documents (total 448 corpus positions)\n",
      "2019-04-24 17:02:43,251 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:43,254 : INFO : built Dictionary(132 unique tokens: ['amiga', 'atenta', 'como', 'conversa', 'delicada']...) from 10 documents (total 178 corpus positions)\n",
      "2019-04-24 17:02:43,262 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,264 : INFO : built Dictionary(104 unique tokens: ['ainda', 'extremament', 'gent', 'geral', 'machista']...) from 12 documents (total 126 corpus positions)\n",
      "2019-04-24 17:02:43,277 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,280 : INFO : built Dictionary(384 unique tokens: ['como', 'entrevista', 'garota', 'kaol', 'luta']...) from 57 documents (total 705 corpus positions)\n",
      "2019-04-24 17:02:43,316 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,319 : INFO : built Dictionary(218 unique tokens: ['brows', 'desktop', 'domin', 'earli', 'metaphor']...) from 44 documents (total 407 corpus positions)\n",
      "2019-04-24 17:02:43,340 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,343 : INFO : built Dictionary(82 unique tokens: ['adapt', 'calcul', 'class', 'convert', 'differ']...) from 22 documents (total 157 corpus positions)\n",
      "2019-04-24 17:02:43,355 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,358 : INFO : built Dictionary(265 unique tokens: ['ainda', 'clássica', 'compartilhar', 'contemporânea', 'editori']...) from 33 documents (total 366 corpus positions)\n",
      "2019-04-24 17:02:43,382 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,386 : INFO : built Dictionary(450 unique tokens: ['agora', 'ainda', 'apena', 'artigo', 'author']...) from 46 documents (total 920 corpus positions)\n",
      "2019-04-24 17:02:43,426 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,430 : INFO : built Dictionary(317 unique tokens: ['awesom', 'caught', 'collect', 'coupl', 'danni']...) from 55 documents (total 534 corpus positions)\n",
      "2019-04-24 17:02:43,462 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,467 : INFO : built Dictionary(345 unique tokens: ['barcelona', 'cerca', 'ciência', 'coisa', 'com']...) from 29 documents (total 513 corpus positions)\n",
      "2019-04-24 17:02:43,493 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,496 : INFO : built Dictionary(277 unique tokens: ['author', 'career', 'chamber', 'director', 'follow']...) from 55 documents (total 413 corpus positions)\n",
      "2019-04-24 17:02:43,521 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,525 : INFO : built Dictionary(139 unique tokens: ['announc', 'avail', 'behalf', 'bintrai', 'boot']...) from 27 documents (total 243 corpus positions)\n",
      "2019-04-24 17:02:43,540 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,544 : INFO : built Dictionary(309 unique tokens: ['abordagen', 'artifici', 'artigo', 'cauteloso', 'com']...) from 25 documents (total 498 corpus positions)\n",
      "2019-04-24 17:02:43,576 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,580 : INFO : built Dictionary(428 unique tokens: ['ceo', 'fit', 'grow', 'issu', 'market']...) from 173 documents (total 1058 corpus positions)\n",
      "2019-04-24 17:02:43,722 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,726 : INFO : built Dictionary(296 unique tokens: ['apach', 'base', 'cloud', 'graph', 'ibm']...) from 43 documents (total 603 corpus positions)\n",
      "2019-04-24 17:02:43,749 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:43,751 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,753 : INFO : built Dictionary(42 unique tokens: ['curi', 'franklin', 'goodal', 'heard', 'jane']...) from 5 documents (total 45 corpus positions)\n",
      "2019-04-24 17:02:43,755 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:43,757 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:43,759 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:43,763 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:43,765 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,767 : INFO : built Dictionary(27 unique tokens: ['abstract', 'desir', 'engin', 'express', 'flourish']...) from 2 documents (total 31 corpus positions)\n",
      "2019-04-24 17:02:43,770 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:43,773 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:43,775 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:43,787 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,792 : INFO : built Dictionary(559 unique tokens: ['amiga', 'author', 'betti', 'como', 'consultor']...) from 69 documents (total 970 corpus positions)\n",
      "2019-04-24 17:02:43,830 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,833 : INFO : built Dictionary(181 unique tokens: ['backup', 'cloud', 'code', 'com', 'compani']...) from 21 documents (total 265 corpus positions)\n",
      "2019-04-24 17:02:43,847 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,850 : INFO : built Dictionary(229 unique tokens: ['brilliant', 'washington', 'women', 'girl', 'littl']...) from 30 documents (total 383 corpus positions)\n",
      "2019-04-24 17:02:43,878 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,882 : INFO : built Dictionary(550 unique tokens: ['googl', 'improv', 'rank', 'search', 'seo']...) from 126 documents (total 1117 corpus positions)\n",
      "2019-04-24 17:02:43,963 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:43,965 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,967 : INFO : built Dictionary(87 unique tokens: ['como', 'film', 'foto', 'menina', 'na']...) from 7 documents (total 109 corpus positions)\n",
      "2019-04-24 17:02:43,969 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:43,981 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:43,984 : INFO : built Dictionary(215 unique tokens: ['architectur', 'call', 'command', 'cqr', 'driven']...) from 58 documents (total 517 corpus positions)\n",
      "2019-04-24 17:02:44,020 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,024 : INFO : built Dictionary(367 unique tokens: ['acontec', 'brasil', 'campu', 'da', 'décima']...) from 30 documents (total 638 corpus positions)\n",
      "2019-04-24 17:02:44,042 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,045 : INFO : built Dictionary(133 unique tokens: ['anunci', 'anális', 'baixo', 'buscador', 'custo']...) from 10 documents (total 170 corpus positions)\n",
      "2019-04-24 17:02:44,054 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,056 : INFO : built Dictionary(160 unique tokens: ['bit', 'choos', 'cloud', 'googl', 'littl']...) from 17 documents (total 286 corpus positions)\n",
      "2019-04-24 17:02:44,070 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,073 : INFO : built Dictionary(170 unique tokens: ['account', 'belong', 'bill', 'central', 'cloud']...) from 33 documents (total 432 corpus positions)\n",
      "2019-04-24 17:02:44,094 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,097 : INFO : built Dictionary(158 unique tokens: ['develop', 'eclips', 'id', 'java', 'popular']...) from 37 documents (total 344 corpus positions)\n",
      "2019-04-24 17:02:44,115 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,118 : INFO : built Dictionary(202 unique tokens: ['agosto', 'applic', 'build', 'cloud', 'deliv']...) from 23 documents (total 367 corpus positions)\n",
      "2019-04-24 17:02:44,140 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,143 : INFO : built Dictionary(400 unique tokens: ['ago', 'amazon', 'book', 'fake', 'achiev']...) from 84 documents (total 728 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:44,187 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,191 : INFO : built Dictionary(227 unique tokens: ['como', 'dia', 'falou', 'hoje', 'no']...) from 22 documents (total 363 corpus positions)\n",
      "2019-04-24 17:02:44,202 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,205 : INFO : built Dictionary(98 unique tokens: ['bad', 'biggest', 'dry', 'ey', 'trend']...) from 16 documents (total 124 corpus positions)\n",
      "2019-04-24 17:02:44,217 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,221 : INFO : built Dictionary(231 unique tokens: ['blog', 'box', 'complet', 'easi', 'far']...) from 40 documents (total 433 corpus positions)\n",
      "2019-04-24 17:02:44,253 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,259 : INFO : built Dictionary(385 unique tokens: ['accur', 'base', 'critic', 'data', 'decis']...) from 93 documents (total 979 corpus positions)\n",
      "2019-04-24 17:02:44,344 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,350 : INFO : built Dictionary(471 unique tokens: ['ago', 'api', 'approach', 'articl', 'deeper']...) from 280 documents (total 2234 corpus positions)\n",
      "2019-04-24 17:02:44,733 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,735 : INFO : built Dictionary(221 unique tokens: ['author', 'boston', 'chairman', 'courtesi', 'execut']...) from 39 documents (total 315 corpus positions)\n",
      "2019-04-24 17:02:44,756 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,760 : INFO : built Dictionary(498 unique tokens: ['baixo', 'commerc', 'crescimento', 'desd', 'digit']...) from 63 documents (total 867 corpus positions)\n",
      "2019-04-24 17:02:44,806 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,810 : INFO : built Dictionary(400 unique tokens: ['agenc', 'best', 'execut', 'improv', 'know']...) from 64 documents (total 770 corpus positions)\n",
      "2019-04-24 17:02:44,852 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,855 : INFO : built Dictionary(114 unique tokens: ['advoc', 'app', 'auto', 'brandon', 'busi']...) from 11 documents (total 177 corpus positions)\n",
      "2019-04-24 17:02:44,867 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,871 : INFO : built Dictionary(366 unique tokens: ['apoiado', 'conceito', 'farm', 'inaugurar', 'março']...) from 36 documents (total 641 corpus positions)\n",
      "2019-04-24 17:02:44,894 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,897 : INFO : built Dictionary(259 unique tokens: ['aparelho', 'aplicativo', 'irão', 'não', 'pessoa']...) from 29 documents (total 432 corpus positions)\n",
      "2019-04-24 17:02:44,926 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:44,930 : INFO : built Dictionary(427 unique tokens: ['awai', 'center', 'cloud', 'data', 'decid']...) from 81 documents (total 988 corpus positions)\n",
      "2019-04-24 17:02:45,008 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,013 : INFO : built Dictionary(140 unique tokens: ['alta', 'aprendizado', 'baixa', 'capaz', 'equip']...) from 13 documents (total 188 corpus positions)\n",
      "2019-04-24 17:02:45,027 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,031 : INFO : built Dictionary(169 unique tokens: ['brand', 'contributor', 'drupal', 'emerg', 'largest']...) from 33 documents (total 327 corpus positions)\n",
      "2019-04-24 17:02:45,057 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,061 : INFO : built Dictionary(437 unique tokens: ['balanço', 'companhia', 'deram', 'divulgação', 'do']...) from 67 documents (total 1004 corpus positions)\n",
      "2019-04-24 17:02:45,109 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:45,112 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,113 : INFO : built Dictionary(61 unique tokens: ['abil', 'basic', 'class', 'creat', 'data']...) from 6 documents (total 81 corpus positions)\n",
      "2019-04-24 17:02:45,116 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:45,125 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,128 : INFO : built Dictionary(285 unique tokens: ['belo', 'bicicleta', 'cada', 'ciclista', 'estão']...) from 43 documents (total 481 corpus positions)\n",
      "2019-04-24 17:02:45,153 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,156 : INFO : built Dictionary(349 unique tokens: ['breve', 'coisa', 'ficha', 'papel', 'passado']...) from 32 documents (total 595 corpus positions)\n",
      "2019-04-24 17:02:45,183 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,187 : INFO : built Dictionary(261 unique tokens: ['good', 'know', 'rate', 'retent', 'measur']...) from 83 documents (total 658 corpus positions)\n",
      "2019-04-24 17:02:45,254 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,258 : INFO : built Dictionary(544 unique tokens: ['come', 'compani', 'cost', 'crack', 'custom']...) from 105 documents (total 1169 corpus positions)\n",
      "2019-04-24 17:02:45,349 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,354 : INFO : built Dictionary(319 unique tokens: ['arduino', 'artigo', 'atravé', 'com', 'como']...) from 43 documents (total 762 corpus positions)\n",
      "2019-04-24 17:02:45,393 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,396 : INFO : built Dictionary(192 unique tokens: ['criada', 'código', 'foi', 'golang', 'googl']...) from 18 documents (total 276 corpus positions)\n",
      "2019-04-24 17:02:45,416 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,421 : INFO : built Dictionary(317 unique tokens: ['continu', 'expert', 'infant', 'let', 'monitor']...) from 57 documents (total 570 corpus positions)\n",
      "2019-04-24 17:02:45,452 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,455 : INFO : built Dictionary(109 unique tokens: ['access', 'dai', 'globe', 'googl', 'inform']...) from 16 documents (total 176 corpus positions)\n",
      "2019-04-24 17:02:45,465 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,468 : INFO : built Dictionary(189 unique tokens: ['alto', 'client', 'com', 'commerc', 'comércio']...) from 15 documents (total 286 corpus positions)\n",
      "2019-04-24 17:02:45,485 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,489 : INFO : built Dictionary(345 unique tokens: ['acostumado', 'celular', 'com', 'computador', 'diariament']...) from 42 documents (total 689 corpus positions)\n",
      "2019-04-24 17:02:45,517 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,521 : INFO : built Dictionary(134 unique tokens: ['artifici', 'built', 'core', 'crm', 'debut']...) from 21 documents (total 214 corpus positions)\n",
      "2019-04-24 17:02:45,552 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,557 : INFO : built Dictionary(503 unique tokens: ['bank', 'credit', 'custom', 'determin', 'experi']...) from 112 documents (total 1273 corpus positions)\n",
      "2019-04-24 17:02:45,663 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,666 : INFO : built Dictionary(143 unique tokens: ['like', 'look', 'strategi', 'stun', 'acquir']...) from 15 documents (total 194 corpus positions)\n",
      "2019-04-24 17:02:45,682 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,686 : INFO : built Dictionary(194 unique tokens: ['announc', 'api', 'avail', 'cloud', 'distribut']...) from 26 documents (total 411 corpus positions)\n",
      "2019-04-24 17:02:45,714 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,719 : INFO : built Dictionary(433 unique tokens: ['antecipadament', 'app', 'assin', 'disponível', 'esta']...) from 50 documents (total 782 corpus positions)\n",
      "2019-04-24 17:02:45,765 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:45,770 : INFO : built Dictionary(235 unique tokens: ['browser', 'develop', 'differ', 'recent', 'reliabl']...) from 36 documents (total 438 corpus positions)\n",
      "2019-04-24 17:02:45,803 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,807 : INFO : built Dictionary(282 unique tokens: ['acid', 'announc', 'avail', 'beta', 'cake']...) from 28 documents (total 506 corpus positions)\n",
      "2019-04-24 17:02:45,836 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,840 : INFO : built Dictionary(242 unique tokens: ['blog', 'distribut', 'drupal', 'investor', 'nasdaq']...) from 52 documents (total 549 corpus positions)\n",
      "2019-04-24 17:02:45,877 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,880 : INFO : built Dictionary(78 unique tokens: ['code', 'develop', 'discuss', 'document', 'great']...) from 26 documents (total 139 corpus positions)\n",
      "2019-04-24 17:02:45,903 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,909 : INFO : built Dictionary(339 unique tokens: ['applic', 'attend', 'colleagu', 'discuss', 'driven']...) from 73 documents (total 684 corpus positions)\n",
      "2019-04-24 17:02:45,976 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:45,979 : INFO : built Dictionary(270 unique tokens: ['ago', 'build', 'decad', 'defi', 'engin']...) from 58 documents (total 504 corpus positions)\n",
      "2019-04-24 17:02:46,020 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,024 : INFO : built Dictionary(260 unique tokens: ['align', 'area', 'bank', 'busi', 'current']...) from 53 documents (total 526 corpus positions)\n",
      "2019-04-24 17:02:46,054 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,057 : INFO : built Dictionary(99 unique tokens: ['design', 'excit', 'wai', 'want', 'year']...) from 15 documents (total 150 corpus positions)\n",
      "2019-04-24 17:02:46,068 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,072 : INFO : built Dictionary(131 unique tokens: ['commit', 'github', 'histori', 'look', 'make']...) from 43 documents (total 241 corpus positions)\n",
      "2019-04-24 17:02:46,092 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,095 : INFO : built Dictionary(148 unique tokens: ['acquisit', 'amazon', 'bank', 'capit', 'comment']...) from 17 documents (total 220 corpus positions)\n",
      "2019-04-24 17:02:46,110 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,114 : INFO : built Dictionary(247 unique tokens: ['announc', 'best', 'controversi', 'explor', 'interest']...) from 33 documents (total 403 corpus positions)\n",
      "2019-04-24 17:02:46,143 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,147 : INFO : built Dictionary(339 unique tokens: ['android', 'app', 'build', 'call', 'cross']...) from 84 documents (total 784 corpus positions)\n",
      "2019-04-24 17:02:46,194 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:46,197 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,198 : INFO : built Dictionary(23 unique tokens: ['applic', 'block', 'busi', 'custom', 'drive']...) from 2 documents (total 25 corpus positions)\n",
      "2019-04-24 17:02:46,201 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:46,204 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:46,207 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:46,212 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,216 : INFO : built Dictionary(156 unique tokens: ['automotiva', 'carro', 'desenvolvendo', 'dirig', 'empresa']...) from 15 documents (total 212 corpus positions)\n",
      "2019-04-24 17:02:46,230 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,233 : INFO : built Dictionary(191 unique tokens: ['android', 'articl', 'certif', 'exam', 'experi']...) from 31 documents (total 352 corpus positions)\n",
      "2019-04-24 17:02:46,253 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,256 : INFO : built Dictionary(157 unique tokens: ['concept', 'debt', 'idea', 'introduc', 'learn']...) from 21 documents (total 243 corpus positions)\n",
      "2019-04-24 17:02:46,278 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,281 : INFO : built Dictionary(229 unique tokens: ['android', 'api', 'began', 'devic', 'graphic']...) from 74 documents (total 608 corpus positions)\n",
      "2019-04-24 17:02:46,331 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,334 : INFO : built Dictionary(207 unique tokens: ['atento', 'caminho', 'cardoso', 'cobrar', 'companhia']...) from 16 documents (total 311 corpus positions)\n",
      "2019-04-24 17:02:46,353 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,357 : INFO : built Dictionary(265 unique tokens: ['como', 'exceçõ', 'forma', 'framework', 'introdução']...) from 51 documents (total 607 corpus positions)\n",
      "2019-04-24 17:02:46,388 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:46,391 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,394 : INFO : built Dictionary(86 unique tokens: ['aprendizagem', 'artifici', 'duet', 'experimento', 'googl']...) from 8 documents (total 104 corpus positions)\n",
      "2019-04-24 17:02:46,397 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:46,424 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,429 : INFO : built Dictionary(570 unique tokens: ['innov', 'isn', 'list', 'new', 'summari']...) from 134 documents (total 1269 corpus positions)\n",
      "2019-04-24 17:02:46,532 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,536 : INFO : built Dictionary(324 unique tokens: ['aceitação', 'anunciaram', 'coisa', 'colaboração', 'conectado']...) from 24 documents (total 611 corpus positions)\n",
      "2019-04-24 17:02:46,566 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,570 : INFO : built Dictionary(493 unique tokens: ['channel', 'fatigu', 'market', 'stage', 'suffer']...) from 115 documents (total 1154 corpus positions)\n",
      "2019-04-24 17:02:46,646 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,648 : INFO : built Dictionary(166 unique tokens: ['copi', 'exist', 'file', 'fragment', 'mechan']...) from 20 documents (total 259 corpus positions)\n",
      "2019-04-24 17:02:46,659 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:46,661 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,663 : INFO : built Dictionary(23 unique tokens: ['analyt', 'decad', 'gartner', 'long', 'magic']...) from 2 documents (total 26 corpus positions)\n",
      "2019-04-24 17:02:46,665 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:46,668 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:46,670 : WARNING : Couldn't get relevant sentences.\n",
      "2019-04-24 17:02:46,681 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,685 : INFO : built Dictionary(274 unique tokens: ['experi', 'initi', 'introduct', 'maco', 'previous']...) from 59 documents (total 540 corpus positions)\n",
      "2019-04-24 17:02:46,712 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,714 : INFO : built Dictionary(68 unique tokens: ['advanc', 'articl', 'career', 'chanc', 'help']...) from 10 documents (total 87 corpus positions)\n",
      "2019-04-24 17:02:46,723 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,725 : INFO : built Dictionary(191 unique tokens: ['aberta', 'aceleradora', 'acelerar', 'coisa', 'corporaçõ']...) from 18 documents (total 330 corpus positions)\n",
      "2019-04-24 17:02:46,738 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,740 : INFO : built Dictionary(108 unique tokens: ['amazon', 'call', 'chat', 'chime', 'conferenc']...) from 10 documents (total 157 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-24 17:02:46,764 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,768 : INFO : built Dictionary(532 unique tokens: ['begin', 'code', 'direct', 'effort', 'februari']...) from 109 documents (total 1344 corpus positions)\n",
      "2019-04-24 17:02:46,864 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,867 : INFO : built Dictionary(349 unique tokens: ['busi', 'chase', 'deal', 'financi', 'hour']...) from 39 documents (total 585 corpus positions)\n",
      "2019-04-24 17:02:46,888 : WARNING : Input text is expected to have at least 10 sentences.\n",
      "2019-04-24 17:02:46,890 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-24 17:02:46,893 : INFO : built Dictionary(18 unique tokens: ['acquia', 'award', 'categori', 'compris', 'global']...) from 2 documents (total 28 corpus positions)\n",
      "2019-04-24 17:02:46,896 : WARNING : Input corpus is expected to have at least 10 documents.\n",
      "2019-04-24 17:02:46,898 : WARNING : Please add more sentences to the text. The number of reachable nodes is below 3\n",
      "2019-04-24 17:02:46,900 : WARNING : Couldn't get relevant sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "article_Summary = list(map(lambda x:summary(x),df_articles_influence['text'].values))\n",
    "new_areticle_texts = list(map(lambda x:pre_process(x),article_Summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2944, 38109)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newFeatures = vectorizer.fit_transform(article_Summary)\n",
    "newFeatures.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# pca = PCA(n_components=500, svd_solver='full')\n",
    "pca = TruncatedSVD(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(newFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reducedFeatures = pca.fit_transform(newFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reducedFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2944, 500)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reducedFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newFeatures = reducedFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling part\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from  sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = newFeatures\n",
    "y = df_articles_influence['Popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=46)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangyufan/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "randomForest = RandomForestRegressor(random_state=42)\n",
    "randomForest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.09921961799341"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForestPredict = randomForest.predict(X_test)\n",
    "randomForest_mse = mean_squared_error(y_test, randomForestPredict)\n",
    "randomForestMSE = np.sqrt(randomForest_mse)\n",
    "randomForestMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1>Find users you may like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a user follows an authur(article), the system will recommend several users that he/she may like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>personId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userRegion</th>\n",
       "      <th>userCountry</th>\n",
       "      <th>Preference_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1465413895</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>344280948527967603</td>\n",
       "      <td>-3167637573980064150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1466034457</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-4205346868684833897</td>\n",
       "      <td>-1387464358334758758</td>\n",
       "      <td>5111485313337394011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1460566517</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>4761910285123871012</td>\n",
       "      <td>-108842214936804958</td>\n",
       "      <td>-9137723263631808218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1463360064</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-6255158415883847921</td>\n",
       "      <td>6013226412048763966</td>\n",
       "      <td>7846471679835395183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1463357802</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-5181489804915739633</td>\n",
       "      <td>-1443636648652872475</td>\n",
       "      <td>-2256095188093371416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>1462445527</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>1738052593226421681</td>\n",
       "      <td>8615245686887763683</td>\n",
       "      <td>-7910123701795213363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1462445529</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>1738052593226421681</td>\n",
       "      <td>8615245686887763683</td>\n",
       "      <td>-7910123701795213363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1466013645</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>1854874463930846880</td>\n",
       "      <td>2318971825420092215</td>\n",
       "      <td>4175613295207725786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>1462381714</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>1738052593226421681</td>\n",
       "      <td>6013226412048763966</td>\n",
       "      <td>5796685774598185282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>1465539000</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-709287718034731589</td>\n",
       "      <td>3285541426833936337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>1464633461</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>1959495508923903948</td>\n",
       "      <td>2653698047369148236</td>\n",
       "      <td>-8903496970590476068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>1464806867</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-7463305179076477879</td>\n",
       "      <td>-2726721797588771398</td>\n",
       "      <td>6852263164867911264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>1465823234</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>8657408509986329668</td>\n",
       "      <td>6003902177042843076</td>\n",
       "      <td>6107089621846415848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>1465577245</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-5148591903395022444</td>\n",
       "      <td>-2979881261169775358</td>\n",
       "      <td>6661249173876371595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>1465576604</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-5148591903395022444</td>\n",
       "      <td>670878778036881163</td>\n",
       "      <td>5145119242847801856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>1460550577</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>1114791714656282929</td>\n",
       "      <td>-2820994773540913369</td>\n",
       "      <td>2082534594284775882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>1464881404</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>7277161137091492767</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>1185607126054010002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>1464882034</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>7277161137091492767</td>\n",
       "      <td>3891637997717104548</td>\n",
       "      <td>4240699853832706755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>1464879868</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>880612740433495828</td>\n",
       "      <td>6013226412048763966</td>\n",
       "      <td>3831181614891772761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>1464881599</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>3306277069425849869</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>1185607126054010002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>1464881842</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-7463305179076477879</td>\n",
       "      <td>7774613525190730745</td>\n",
       "      <td>7176458023900062217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>1464882330</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-2683134512107439488</td>\n",
       "      <td>-4627026983118548639</td>\n",
       "      <td>-1493555408238884876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>1464094524</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-8742648016180281673</td>\n",
       "      <td>8237333675050684529</td>\n",
       "      <td>5576613154774630041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>1462588417</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-1901742495252324928</td>\n",
       "      <td>3375381077362025672</td>\n",
       "      <td>-1271644409296578508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>1465126854</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-4765711818183276269</td>\n",
       "      <td>-1443636648652872475</td>\n",
       "      <td>-261539783637799977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>1465826658</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>5206308811707978799</td>\n",
       "      <td>-4165818767652094649</td>\n",
       "      <td>8965425132432451710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>1465825716</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>5843362068320522769</td>\n",
       "      <td>1037187242736800310</td>\n",
       "      <td>-9058533905149194582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>1463141330</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>626121253933491500</td>\n",
       "      <td>22763587941636338</td>\n",
       "      <td>7771032409693098654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>1464613454</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-6980020268309524947</td>\n",
       "      <td>692689608292948411</td>\n",
       "      <td>8836515145740663066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>1459875188</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-4463029741564307314</td>\n",
       "      <td>9091970136990402395</td>\n",
       "      <td>-3760305501069661206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71051</th>\n",
       "      <td>1481747588</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-1878128207048892154</td>\n",
       "      <td>6644119361202586331</td>\n",
       "      <td>6500890420368531287</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; Win64; x64) Apple...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71088</th>\n",
       "      <td>1487246069</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>1469580151036142903</td>\n",
       "      <td>-3196433790714486571</td>\n",
       "      <td>-8481296671501180768</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71118</th>\n",
       "      <td>1481631662</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-1878128207048892154</td>\n",
       "      <td>-35428957105270993</td>\n",
       "      <td>1201006018778052621</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71143</th>\n",
       "      <td>1481735512</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>2282385028752844581</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>-390041621245303564</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71149</th>\n",
       "      <td>1488308005</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>4109618890343020064</td>\n",
       "      <td>3891637997717104548</td>\n",
       "      <td>-7416795577834806518</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71208</th>\n",
       "      <td>1469462073</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-559964548932224920</td>\n",
       "      <td>-3390049372067052505</td>\n",
       "      <td>9133258750087835933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71253</th>\n",
       "      <td>1481746563</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>6569463984699537820</td>\n",
       "      <td>3302556033962996625</td>\n",
       "      <td>3773944108952253856</td>\n",
       "      <td>Android - Native Mobile App</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71372</th>\n",
       "      <td>1482167208</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>7065704533945771463</td>\n",
       "      <td>3938645257702379823</td>\n",
       "      <td>-5900190159705334723</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71414</th>\n",
       "      <td>1482321929</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-1663441888197894674</td>\n",
       "      <td>-1602833675167376798</td>\n",
       "      <td>-790936212620854905</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71484</th>\n",
       "      <td>1482261965</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>1580124381109623727</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>-47033132540303420</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71521</th>\n",
       "      <td>1482798887</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>672199059798181601</td>\n",
       "      <td>7527226129639571966</td>\n",
       "      <td>-8349959724684684992</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71564</th>\n",
       "      <td>1482774768</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>672199059798181601</td>\n",
       "      <td>-3203894957285229214</td>\n",
       "      <td>811955987407933531</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>ON</td>\n",
       "      <td>CA</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71576</th>\n",
       "      <td>1482751128</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-1415040208471067980</td>\n",
       "      <td>-331066625167168067</td>\n",
       "      <td>4090754668108556992</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71636</th>\n",
       "      <td>1483017605</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>2930191803881821526</td>\n",
       "      <td>2754566407772265068</td>\n",
       "      <td>-7945576473420652773</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71641</th>\n",
       "      <td>1483203554</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>3716124214746295857</td>\n",
       "      <td>2959376686327377624</td>\n",
       "      <td>-9014332646409316809</td>\n",
       "      <td>Mozilla/5.0 (X11; Fedora; Linux x86_64) AppleW...</td>\n",
       "      <td>PR</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71740</th>\n",
       "      <td>1483375987</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-8934199835393138432</td>\n",
       "      <td>3217014177234377440</td>\n",
       "      <td>1655398135522594967</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71759</th>\n",
       "      <td>1483709230</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-8314629309720421219</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>-8149705308202373712</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71772</th>\n",
       "      <td>1482777553</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-8992803137960175254</td>\n",
       "      <td>1560134519462672730</td>\n",
       "      <td>5924955095978491164</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71833</th>\n",
       "      <td>1483678274</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>1220948775534529013</td>\n",
       "      <td>2416280733544962613</td>\n",
       "      <td>7833475850187327120</td>\n",
       "      <td>Android - Native Mobile App</td>\n",
       "      <td>NJ</td>\n",
       "      <td>US</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71856</th>\n",
       "      <td>1483978716</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>2384931701643938149</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>2003640115228344885</td>\n",
       "      <td>Android - Native Mobile App</td>\n",
       "      <td>NY</td>\n",
       "      <td>US</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71942</th>\n",
       "      <td>1484356712</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>5930806521893160184</td>\n",
       "      <td>2416280733544962613</td>\n",
       "      <td>-7576733427435825093</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6...</td>\n",
       "      <td>?</td>\n",
       "      <td>US</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71943</th>\n",
       "      <td>1484357049</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>5037403311832115000</td>\n",
       "      <td>2416280733544962613</td>\n",
       "      <td>-7576733427435825093</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6...</td>\n",
       "      <td>?</td>\n",
       "      <td>US</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71970</th>\n",
       "      <td>1484911614</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-2386148284399181873</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>-5167461849230317561</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71985</th>\n",
       "      <td>1485436992</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>8424505741986577894</td>\n",
       "      <td>7392990465409599343</td>\n",
       "      <td>4467376371602647239</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72022</th>\n",
       "      <td>1485795057</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>2321412363020240814</td>\n",
       "      <td>6013226412048763966</td>\n",
       "      <td>8310906696171015235</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72050</th>\n",
       "      <td>1487597704</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-6872546942144599345</td>\n",
       "      <td>-1393866732742189886</td>\n",
       "      <td>-6350745898785551312</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72137</th>\n",
       "      <td>1484667841</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-3191013159715472435</td>\n",
       "      <td>-534549863526737439</td>\n",
       "      <td>-5643454536515310292</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72154</th>\n",
       "      <td>1485427731</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-3900870368325485697</td>\n",
       "      <td>3938645257702379823</td>\n",
       "      <td>-6277253600739582448</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72168</th>\n",
       "      <td>1485427217</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>-3900870368325485697</td>\n",
       "      <td>1895326251577378793</td>\n",
       "      <td>7094126669811309285</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72176</th>\n",
       "      <td>1485428430</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>5484061377044071389</td>\n",
       "      <td>-2785363955043455312</td>\n",
       "      <td>-1351563543679373051</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1407 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp eventType            contentId             personId  \\\n",
       "3      1465413895    FOLLOW   310515487419366995   344280948527967603   \n",
       "69     1466034457    FOLLOW -4205346868684833897 -1387464358334758758   \n",
       "78     1460566517    FOLLOW  4761910285123871012  -108842214936804958   \n",
       "257    1463360064    FOLLOW -6255158415883847921  6013226412048763966   \n",
       "259    1463357802    FOLLOW -5181489804915739633 -1443636648652872475   \n",
       "277    1462445527    FOLLOW  1738052593226421681  8615245686887763683   \n",
       "280    1462445529    FOLLOW  1738052593226421681  8615245686887763683   \n",
       "388    1466013645    FOLLOW  1854874463930846880  2318971825420092215   \n",
       "516    1462381714    FOLLOW  1738052593226421681  6013226412048763966   \n",
       "709    1465539000    FOLLOW   310515487419366995  -709287718034731589   \n",
       "830    1464633461    FOLLOW  1959495508923903948  2653698047369148236   \n",
       "974    1464806867    FOLLOW -7463305179076477879 -2726721797588771398   \n",
       "1082   1465823234    FOLLOW  8657408509986329668  6003902177042843076   \n",
       "1170   1465577245    FOLLOW -5148591903395022444 -2979881261169775358   \n",
       "1192   1465576604    FOLLOW -5148591903395022444   670878778036881163   \n",
       "1210   1460550577    FOLLOW  1114791714656282929 -2820994773540913369   \n",
       "1334   1464881404    FOLLOW  7277161137091492767 -1032019229384696495   \n",
       "1391   1464882034    FOLLOW  7277161137091492767  3891637997717104548   \n",
       "1398   1464879868    FOLLOW   880612740433495828  6013226412048763966   \n",
       "1412   1464881599    FOLLOW  3306277069425849869 -1032019229384696495   \n",
       "1425   1464881842    FOLLOW -7463305179076477879  7774613525190730745   \n",
       "1434   1464882330    FOLLOW -2683134512107439488 -4627026983118548639   \n",
       "1549   1464094524    FOLLOW -8742648016180281673  8237333675050684529   \n",
       "2026   1462588417    FOLLOW -1901742495252324928  3375381077362025672   \n",
       "2098   1465126854    FOLLOW -4765711818183276269 -1443636648652872475   \n",
       "2144   1465826658    FOLLOW  5206308811707978799 -4165818767652094649   \n",
       "2166   1465825716    FOLLOW  5843362068320522769  1037187242736800310   \n",
       "2333   1463141330    FOLLOW   626121253933491500    22763587941636338   \n",
       "2362   1464613454    FOLLOW -6980020268309524947   692689608292948411   \n",
       "2522   1459875188    FOLLOW -4463029741564307314  9091970136990402395   \n",
       "...           ...       ...                  ...                  ...   \n",
       "71051  1481747588    FOLLOW -1878128207048892154  6644119361202586331   \n",
       "71088  1487246069    FOLLOW  1469580151036142903 -3196433790714486571   \n",
       "71118  1481631662    FOLLOW -1878128207048892154   -35428957105270993   \n",
       "71143  1481735512    FOLLOW  2282385028752844581  3609194402293569455   \n",
       "71149  1488308005    FOLLOW  4109618890343020064  3891637997717104548   \n",
       "71208  1469462073    FOLLOW  -559964548932224920 -3390049372067052505   \n",
       "71253  1481746563    FOLLOW  6569463984699537820  3302556033962996625   \n",
       "71372  1482167208    FOLLOW  7065704533945771463  3938645257702379823   \n",
       "71414  1482321929    FOLLOW -1663441888197894674 -1602833675167376798   \n",
       "71484  1482261965    FOLLOW  1580124381109623727  3609194402293569455   \n",
       "71521  1482798887    FOLLOW   672199059798181601  7527226129639571966   \n",
       "71564  1482774768    FOLLOW   672199059798181601 -3203894957285229214   \n",
       "71576  1482751128    FOLLOW -1415040208471067980  -331066625167168067   \n",
       "71636  1483017605    FOLLOW  2930191803881821526  2754566407772265068   \n",
       "71641  1483203554    FOLLOW  3716124214746295857  2959376686327377624   \n",
       "71740  1483375987    FOLLOW -8934199835393138432  3217014177234377440   \n",
       "71759  1483709230    FOLLOW -8314629309720421219  3609194402293569455   \n",
       "71772  1482777553    FOLLOW -8992803137960175254  1560134519462672730   \n",
       "71833  1483678274    FOLLOW  1220948775534529013  2416280733544962613   \n",
       "71856  1483978716    FOLLOW  2384931701643938149 -1032019229384696495   \n",
       "71942  1484356712    FOLLOW  5930806521893160184  2416280733544962613   \n",
       "71943  1484357049    FOLLOW  5037403311832115000  2416280733544962613   \n",
       "71970  1484911614    FOLLOW -2386148284399181873  3609194402293569455   \n",
       "71985  1485436992    FOLLOW  8424505741986577894  7392990465409599343   \n",
       "72022  1485795057    FOLLOW  2321412363020240814  6013226412048763966   \n",
       "72050  1487597704    FOLLOW -6872546942144599345 -1393866732742189886   \n",
       "72137  1484667841    FOLLOW -3191013159715472435  -534549863526737439   \n",
       "72154  1485427731    FOLLOW -3900870368325485697  3938645257702379823   \n",
       "72168  1485427217    FOLLOW -3900870368325485697  1895326251577378793   \n",
       "72176  1485428430    FOLLOW  5484061377044071389 -2785363955043455312   \n",
       "\n",
       "                 sessionId                                          userAgent  \\\n",
       "3     -3167637573980064150                                                NaN   \n",
       "69     5111485313337394011                                                NaN   \n",
       "78    -9137723263631808218                                                NaN   \n",
       "257    7846471679835395183                                                NaN   \n",
       "259   -2256095188093371416                                                NaN   \n",
       "277   -7910123701795213363                                                NaN   \n",
       "280   -7910123701795213363                                                NaN   \n",
       "388    4175613295207725786                                                NaN   \n",
       "516    5796685774598185282                                                NaN   \n",
       "709    3285541426833936337                                                NaN   \n",
       "830   -8903496970590476068                                                NaN   \n",
       "974    6852263164867911264                                                NaN   \n",
       "1082   6107089621846415848                                                NaN   \n",
       "1170   6661249173876371595                                                NaN   \n",
       "1192   5145119242847801856                                                NaN   \n",
       "1210   2082534594284775882                                                NaN   \n",
       "1334   1185607126054010002                                                NaN   \n",
       "1391   4240699853832706755                                                NaN   \n",
       "1398   3831181614891772761                                                NaN   \n",
       "1412   1185607126054010002                                                NaN   \n",
       "1425   7176458023900062217                                                NaN   \n",
       "1434  -1493555408238884876                                                NaN   \n",
       "1549   5576613154774630041                                                NaN   \n",
       "2026  -1271644409296578508                                                NaN   \n",
       "2098   -261539783637799977                                                NaN   \n",
       "2144   8965425132432451710                                                NaN   \n",
       "2166  -9058533905149194582                                                NaN   \n",
       "2333   7771032409693098654                                                NaN   \n",
       "2362   8836515145740663066                                                NaN   \n",
       "2522  -3760305501069661206                                                NaN   \n",
       "...                    ...                                                ...   \n",
       "71051  6500890420368531287  Mozilla/5.0 (Windows NT 6.1; Win64; x64) Apple...   \n",
       "71088 -8481296671501180768  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2...   \n",
       "71118  1201006018778052621  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "71143  -390041621245303564  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "71149 -7416795577834806518  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "71208  9133258750087835933                                                NaN   \n",
       "71253  3773944108952253856                        Android - Native Mobile App   \n",
       "71372 -5900190159705334723  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
       "71414  -790936212620854905  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1...   \n",
       "71484   -47033132540303420  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "71521 -8349959724684684992  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1...   \n",
       "71564   811955987407933531  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "71576  4090754668108556992  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
       "71636 -7945576473420652773  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
       "71641 -9014332646409316809  Mozilla/5.0 (X11; Fedora; Linux x86_64) AppleW...   \n",
       "71740  1655398135522594967  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "71759 -8149705308202373712  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "71772  5924955095978491164  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "71833  7833475850187327120                        Android - Native Mobile App   \n",
       "71856  2003640115228344885                        Android - Native Mobile App   \n",
       "71942 -7576733427435825093  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6...   \n",
       "71943 -7576733427435825093  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6...   \n",
       "71970 -5167461849230317561  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "71985  4467376371602647239  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
       "72022  8310906696171015235  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
       "72050 -6350745898785551312  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "72137 -5643454536515310292  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2...   \n",
       "72154 -6277253600739582448  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
       "72168  7094126669811309285  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2...   \n",
       "72176 -1351563543679373051  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "\n",
       "      userRegion userCountry  Preference_level  \n",
       "3            NaN         NaN               4.0  \n",
       "69           NaN         NaN               4.0  \n",
       "78           NaN         NaN               4.0  \n",
       "257          NaN         NaN               4.0  \n",
       "259          NaN         NaN               4.0  \n",
       "277          NaN         NaN               4.0  \n",
       "280          NaN         NaN               4.0  \n",
       "388          NaN         NaN               4.0  \n",
       "516          NaN         NaN               4.0  \n",
       "709          NaN         NaN               4.0  \n",
       "830          NaN         NaN               4.0  \n",
       "974          NaN         NaN               4.0  \n",
       "1082         NaN         NaN               4.0  \n",
       "1170         NaN         NaN               4.0  \n",
       "1192         NaN         NaN               4.0  \n",
       "1210         NaN         NaN               4.0  \n",
       "1334         NaN         NaN               4.0  \n",
       "1391         NaN         NaN               4.0  \n",
       "1398         NaN         NaN               4.0  \n",
       "1412         NaN         NaN               4.0  \n",
       "1425         NaN         NaN               4.0  \n",
       "1434         NaN         NaN               4.0  \n",
       "1549         NaN         NaN               4.0  \n",
       "2026         NaN         NaN               4.0  \n",
       "2098         NaN         NaN               4.0  \n",
       "2144         NaN         NaN               4.0  \n",
       "2166         NaN         NaN               4.0  \n",
       "2333         NaN         NaN               4.0  \n",
       "2362         NaN         NaN               4.0  \n",
       "2522         NaN         NaN               4.0  \n",
       "...          ...         ...               ...  \n",
       "71051         SP          BR               4.0  \n",
       "71088         MG          BR               4.0  \n",
       "71118         MG          BR               4.0  \n",
       "71143         SP          BR               4.0  \n",
       "71149         SP          BR               4.0  \n",
       "71208        NaN         NaN               4.0  \n",
       "71253         SP          BR               4.0  \n",
       "71372         SP          BR               4.0  \n",
       "71414         SP          BR               4.0  \n",
       "71484         SP          BR               4.0  \n",
       "71521         SP          BR               4.0  \n",
       "71564         ON          CA               4.0  \n",
       "71576         MG          BR               4.0  \n",
       "71636         MG          BR               4.0  \n",
       "71641         PR          BR               4.0  \n",
       "71740         SP          BR               4.0  \n",
       "71759         SP          BR               4.0  \n",
       "71772         SP          BR               4.0  \n",
       "71833         NJ          US               4.0  \n",
       "71856         NY          US               4.0  \n",
       "71942          ?          US               4.0  \n",
       "71943          ?          US               4.0  \n",
       "71970         SP          BR               4.0  \n",
       "71985         SP          BR               4.0  \n",
       "72022         SP          BR               4.0  \n",
       "72050         MG          BR               4.0  \n",
       "72137         MG          BR               4.0  \n",
       "72154         SP          BR               4.0  \n",
       "72168         SP          BR               4.0  \n",
       "72176         SP          BR               4.0  \n",
       "\n",
       "[1407 rows x 9 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventType_Follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eventType_Follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>personId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userRegion</th>\n",
       "      <th>userCountry</th>\n",
       "      <th>Preference_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1465413895</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>344280948527967603</td>\n",
       "      <td>-3167637573980064150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69449</th>\n",
       "      <td>1486646178</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>4876769046116846438</td>\n",
       "      <td>344280948527967603</td>\n",
       "      <td>-6738042183545495282</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp eventType            contentId            personId  \\\n",
       "3      1465413895    FOLLOW   310515487419366995  344280948527967603   \n",
       "69449  1486646178    FOLLOW  4876769046116846438  344280948527967603   \n",
       "\n",
       "                 sessionId                                          userAgent  \\\n",
       "3     -3167637573980064150                                                NaN   \n",
       "69449 -6738042183545495282  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "\n",
       "      userRegion userCountry  Preference_level  \n",
       "3            NaN         NaN               4.0  \n",
       "69449         MG          BR               4.0  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_temp = eventType_Follow.loc[eventType_Follow['personId'] == 344280948527967603]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_list = df_users.loc[df_users['contentId'] == 310515487419366995]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_list = user_list.loc[user_list['personId'] != 344280948527967603]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>personId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userRegion</th>\n",
       "      <th>userCountry</th>\n",
       "      <th>Preference_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32241</th>\n",
       "      <td>1465411835</td>\n",
       "      <td>COMMENT CREATED</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-3500661007957156229</td>\n",
       "      <td>1335241234835338187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>1465397293</td>\n",
       "      <td>COMMENT CREATED</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3621737643587579081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6974</th>\n",
       "      <td>1465397453</td>\n",
       "      <td>COMMENT CREATED</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1130272294246983140</td>\n",
       "      <td>2631864456530402479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1465539000</td>\n",
       "      <td>COMMENT CREATED</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-709287718034731589</td>\n",
       "      <td>3285541426833936337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9340</th>\n",
       "      <td>1465401803</td>\n",
       "      <td>COMMENT CREATED</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>1899177452305284666</td>\n",
       "      <td>8862752102171960091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7054</th>\n",
       "      <td>1465513287</td>\n",
       "      <td>COMMENT CREATED</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>3413008167249007087</td>\n",
       "      <td>1073600550561679603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7058</th>\n",
       "      <td>1465513288</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>3413008167249007087</td>\n",
       "      <td>1073600550561679603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32211</th>\n",
       "      <td>1465411835</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-3500661007957156229</td>\n",
       "      <td>1335241234835338187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6978</th>\n",
       "      <td>1465397454</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1130272294246983140</td>\n",
       "      <td>2631864456530402479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>1465539000</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-709287718034731589</td>\n",
       "      <td>3285541426833936337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7002</th>\n",
       "      <td>1465397293</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3621737643587579081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9327</th>\n",
       "      <td>1465401803</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>1899177452305284666</td>\n",
       "      <td>8862752102171960091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1465413879</td>\n",
       "      <td>BOOKMARK</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>1143207167886864524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25388</th>\n",
       "      <td>1465762177</td>\n",
       "      <td>BOOKMARK</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>4946304010805340284</td>\n",
       "      <td>-8400431429655089062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24700</th>\n",
       "      <td>1465558284</td>\n",
       "      <td>BOOKMARK</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1578287561410088674</td>\n",
       "      <td>-5128977248257411641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>1465397278</td>\n",
       "      <td>BOOKMARK</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3621737643587579081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673</th>\n",
       "      <td>1465476237</td>\n",
       "      <td>BOOKMARK</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-5603024664917721129</td>\n",
       "      <td>5773124361916769245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>1465538891</td>\n",
       "      <td>BOOKMARK</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-709287718034731589</td>\n",
       "      <td>3285541426833936337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16464</th>\n",
       "      <td>1465555403</td>\n",
       "      <td>BOOKMARK</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1443636648652872475</td>\n",
       "      <td>-3976301106281818872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31709</th>\n",
       "      <td>1465441698</td>\n",
       "      <td>BOOKMARK</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>1623838599684589103</td>\n",
       "      <td>6171857147535807357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1465413954</td>\n",
       "      <td>BOOKMARK</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-8763398617720485024</td>\n",
       "      <td>1395789369402380392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33295</th>\n",
       "      <td>1465565846</td>\n",
       "      <td>LIKE</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>1895326251577378793</td>\n",
       "      <td>-831865528880170726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6951</th>\n",
       "      <td>1465397412</td>\n",
       "      <td>LIKE</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1130272294246983140</td>\n",
       "      <td>2631864456530402479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25380</th>\n",
       "      <td>1465762176</td>\n",
       "      <td>LIKE</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>4946304010805340284</td>\n",
       "      <td>-8400431429655089062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24593</th>\n",
       "      <td>1465558284</td>\n",
       "      <td>LIKE</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1578287561410088674</td>\n",
       "      <td>-5128977248257411641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5698</th>\n",
       "      <td>1465476238</td>\n",
       "      <td>LIKE</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-5603024664917721129</td>\n",
       "      <td>5773124361916769245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16468</th>\n",
       "      <td>1465555402</td>\n",
       "      <td>LIKE</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1443636648652872475</td>\n",
       "      <td>-3976301106281818872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41885</th>\n",
       "      <td>1468026215</td>\n",
       "      <td>LIKE</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>881856221521045800</td>\n",
       "      <td>2563642580723079752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1465413946</td>\n",
       "      <td>LIKE</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-8763398617720485024</td>\n",
       "      <td>1395789369402380392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1465413867</td>\n",
       "      <td>LIKE</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>3609194402293569455</td>\n",
       "      <td>1143207167886864524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20116</th>\n",
       "      <td>1465407089</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>627408625947732191</td>\n",
       "      <td>-2060499994429429341</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31710</th>\n",
       "      <td>1465441608</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>1623838599684589103</td>\n",
       "      <td>6171857147535807357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31708</th>\n",
       "      <td>1465441608</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>1623838599684589103</td>\n",
       "      <td>6171857147535807357</td>\n",
       "      <td>Android - Native Mobile App</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25407</th>\n",
       "      <td>1465572029</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>7948079555216525045</td>\n",
       "      <td>7216612964602324985</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_3...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25431</th>\n",
       "      <td>1465572029</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>7948079555216525045</td>\n",
       "      <td>7216612964602324985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43220</th>\n",
       "      <td>1469802783</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>3472075810981614387</td>\n",
       "      <td>-6949613824284014260</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25381</th>\n",
       "      <td>1465762121</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>4946304010805340284</td>\n",
       "      <td>-8400431429655089062</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>RJ</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32215</th>\n",
       "      <td>1465411633</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-3500661007957156229</td>\n",
       "      <td>1335241234835338187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41886</th>\n",
       "      <td>1468025987</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>881856221521045800</td>\n",
       "      <td>2563642580723079752</td>\n",
       "      <td>Android - Native Mobile App</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32208</th>\n",
       "      <td>1465411632</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-3500661007957156229</td>\n",
       "      <td>1335241234835338187</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35828</th>\n",
       "      <td>1469109146</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>4063400901401648079</td>\n",
       "      <td>2909993685488923248</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6957</th>\n",
       "      <td>1465396622</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-5527145562136413747</td>\n",
       "      <td>3192880191028684629</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5...</td>\n",
       "      <td>RJ</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20094</th>\n",
       "      <td>1465405282</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>6574579966911353978</td>\n",
       "      <td>-4955852924885592789</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16438</th>\n",
       "      <td>1465556208</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1130272294246983140</td>\n",
       "      <td>3915619990954748125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20101</th>\n",
       "      <td>1465407701</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>7308881151087125462</td>\n",
       "      <td>-6110753172213420868</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32101</th>\n",
       "      <td>1465503714</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-4491909192209964776</td>\n",
       "      <td>-3501927457068402540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32104</th>\n",
       "      <td>1465503714</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-4491909192209964776</td>\n",
       "      <td>-3501927457068402540</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32110</th>\n",
       "      <td>1465506536</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1251984896177895077</td>\n",
       "      <td>-5668457755385241471</td>\n",
       "      <td>Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:46....</td>\n",
       "      <td>MG</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32204</th>\n",
       "      <td>1465409822</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>1899224753659027997</td>\n",
       "      <td>1708977135910218598</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37100</th>\n",
       "      <td>1469479622</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-5527145562136413747</td>\n",
       "      <td>-7075418167979716771</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5...</td>\n",
       "      <td>RJ</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32206</th>\n",
       "      <td>1465411311</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>6921649833761206472</td>\n",
       "      <td>4688537671787969555</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20100</th>\n",
       "      <td>1465407021</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>627408625947732191</td>\n",
       "      <td>-2060499994429429341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32210</th>\n",
       "      <td>1465411234</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3621737643587579081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32212</th>\n",
       "      <td>1465411234</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3621737643587579081</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...</td>\n",
       "      <td>NY</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32213</th>\n",
       "      <td>1465409822</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>1899224753659027997</td>\n",
       "      <td>1708977135910218598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32238</th>\n",
       "      <td>1465408376</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-8632760515877149847</td>\n",
       "      <td>-526804249137711866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32244</th>\n",
       "      <td>1465411311</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>6921649833761206472</td>\n",
       "      <td>4688537671787969555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33310</th>\n",
       "      <td>1465565775</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>1895326251577378793</td>\n",
       "      <td>-831865528880170726</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33365</th>\n",
       "      <td>1465565729</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>1895326251577378793</td>\n",
       "      <td>-831865528880170726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67675</th>\n",
       "      <td>1486561039</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>3005175913610348223</td>\n",
       "      <td>736177961079848957</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>SP</td>\n",
       "      <td>BR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp        eventType           contentId             personId  \\\n",
       "32241  1465411835  COMMENT CREATED  310515487419366995 -3500661007957156229   \n",
       "6997   1465397293  COMMENT CREATED  310515487419366995 -1032019229384696495   \n",
       "6974   1465397453  COMMENT CREATED  310515487419366995 -1130272294246983140   \n",
       "705    1465539000  COMMENT CREATED  310515487419366995  -709287718034731589   \n",
       "9340   1465401803  COMMENT CREATED  310515487419366995  1899177452305284666   \n",
       "7054   1465513287  COMMENT CREATED  310515487419366995  3413008167249007087   \n",
       "7058   1465513288           FOLLOW  310515487419366995  3413008167249007087   \n",
       "32211  1465411835           FOLLOW  310515487419366995 -3500661007957156229   \n",
       "6978   1465397454           FOLLOW  310515487419366995 -1130272294246983140   \n",
       "709    1465539000           FOLLOW  310515487419366995  -709287718034731589   \n",
       "7002   1465397293           FOLLOW  310515487419366995 -1032019229384696495   \n",
       "9327   1465401803           FOLLOW  310515487419366995  1899177452305284666   \n",
       "25     1465413879         BOOKMARK  310515487419366995  3609194402293569455   \n",
       "25388  1465762177         BOOKMARK  310515487419366995  4946304010805340284   \n",
       "24700  1465558284         BOOKMARK  310515487419366995 -1578287561410088674   \n",
       "6988   1465397278         BOOKMARK  310515487419366995 -1032019229384696495   \n",
       "5673   1465476237         BOOKMARK  310515487419366995 -5603024664917721129   \n",
       "708    1465538891         BOOKMARK  310515487419366995  -709287718034731589   \n",
       "16464  1465555403         BOOKMARK  310515487419366995 -1443636648652872475   \n",
       "31709  1465441698         BOOKMARK  310515487419366995  1623838599684589103   \n",
       "27     1465413954         BOOKMARK  310515487419366995 -8763398617720485024   \n",
       "33295  1465565846             LIKE  310515487419366995  1895326251577378793   \n",
       "6951   1465397412             LIKE  310515487419366995 -1130272294246983140   \n",
       "25380  1465762176             LIKE  310515487419366995  4946304010805340284   \n",
       "24593  1465558284             LIKE  310515487419366995 -1578287561410088674   \n",
       "5698   1465476238             LIKE  310515487419366995 -5603024664917721129   \n",
       "16468  1465555402             LIKE  310515487419366995 -1443636648652872475   \n",
       "41885  1468026215             LIKE  310515487419366995   881856221521045800   \n",
       "43     1465413946             LIKE  310515487419366995 -8763398617720485024   \n",
       "36     1465413867             LIKE  310515487419366995  3609194402293569455   \n",
       "...           ...              ...                 ...                  ...   \n",
       "20116  1465407089             VIEW  310515487419366995   627408625947732191   \n",
       "31710  1465441608             VIEW  310515487419366995  1623838599684589103   \n",
       "31708  1465441608             VIEW  310515487419366995  1623838599684589103   \n",
       "25407  1465572029             VIEW  310515487419366995  7948079555216525045   \n",
       "25431  1465572029             VIEW  310515487419366995  7948079555216525045   \n",
       "43220  1469802783             VIEW  310515487419366995  3472075810981614387   \n",
       "25381  1465762121             VIEW  310515487419366995  4946304010805340284   \n",
       "32215  1465411633             VIEW  310515487419366995 -3500661007957156229   \n",
       "41886  1468025987             VIEW  310515487419366995   881856221521045800   \n",
       "32208  1465411632             VIEW  310515487419366995 -3500661007957156229   \n",
       "35828  1469109146             VIEW  310515487419366995  4063400901401648079   \n",
       "6957   1465396622             VIEW  310515487419366995 -5527145562136413747   \n",
       "20094  1465405282             VIEW  310515487419366995  6574579966911353978   \n",
       "16438  1465556208             VIEW  310515487419366995 -1130272294246983140   \n",
       "20101  1465407701             VIEW  310515487419366995  7308881151087125462   \n",
       "32101  1465503714             VIEW  310515487419366995 -4491909192209964776   \n",
       "32104  1465503714             VIEW  310515487419366995 -4491909192209964776   \n",
       "32110  1465506536             VIEW  310515487419366995 -1251984896177895077   \n",
       "32204  1465409822             VIEW  310515487419366995  1899224753659027997   \n",
       "37100  1469479622             VIEW  310515487419366995 -5527145562136413747   \n",
       "32206  1465411311             VIEW  310515487419366995  6921649833761206472   \n",
       "20100  1465407021             VIEW  310515487419366995   627408625947732191   \n",
       "32210  1465411234             VIEW  310515487419366995 -1032019229384696495   \n",
       "32212  1465411234             VIEW  310515487419366995 -1032019229384696495   \n",
       "32213  1465409822             VIEW  310515487419366995  1899224753659027997   \n",
       "32238  1465408376             VIEW  310515487419366995 -8632760515877149847   \n",
       "32244  1465411311             VIEW  310515487419366995  6921649833761206472   \n",
       "33310  1465565775             VIEW  310515487419366995  1895326251577378793   \n",
       "33365  1465565729             VIEW  310515487419366995  1895326251577378793   \n",
       "67675  1486561039             VIEW  310515487419366995  3005175913610348223   \n",
       "\n",
       "                 sessionId                                          userAgent  \\\n",
       "32241  1335241234835338187                                                NaN   \n",
       "6997   3621737643587579081                                                NaN   \n",
       "6974   2631864456530402479                                                NaN   \n",
       "705    3285541426833936337                                                NaN   \n",
       "9340   8862752102171960091                                                NaN   \n",
       "7054   1073600550561679603                                                NaN   \n",
       "7058   1073600550561679603                                                NaN   \n",
       "32211  1335241234835338187                                                NaN   \n",
       "6978   2631864456530402479                                                NaN   \n",
       "709    3285541426833936337                                                NaN   \n",
       "7002   3621737643587579081                                                NaN   \n",
       "9327   8862752102171960091                                                NaN   \n",
       "25     1143207167886864524                                                NaN   \n",
       "25388 -8400431429655089062                                                NaN   \n",
       "24700 -5128977248257411641                                                NaN   \n",
       "6988   3621737643587579081                                                NaN   \n",
       "5673   5773124361916769245                                                NaN   \n",
       "708    3285541426833936337                                                NaN   \n",
       "16464 -3976301106281818872                                                NaN   \n",
       "31709  6171857147535807357                                                NaN   \n",
       "27     1395789369402380392                                                NaN   \n",
       "33295  -831865528880170726                                                NaN   \n",
       "6951   2631864456530402479                                                NaN   \n",
       "25380 -8400431429655089062                                                NaN   \n",
       "24593 -5128977248257411641                                                NaN   \n",
       "5698   5773124361916769245                                                NaN   \n",
       "16468 -3976301106281818872                                                NaN   \n",
       "41885  2563642580723079752                                                NaN   \n",
       "43     1395789369402380392                                                NaN   \n",
       "36     1143207167886864524                                                NaN   \n",
       "...                    ...                                                ...   \n",
       "20116 -2060499994429429341  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
       "31710  6171857147535807357                                                NaN   \n",
       "31708  6171857147535807357                        Android - Native Mobile App   \n",
       "25407  7216612964602324985  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_3...   \n",
       "25431  7216612964602324985                                                NaN   \n",
       "43220 -6949613824284014260  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "25381 -8400431429655089062  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "32215  1335241234835338187                                                NaN   \n",
       "41886  2563642580723079752                        Android - Native Mobile App   \n",
       "32208  1335241234835338187  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
       "35828  2909993685488923248  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "6957   3192880191028684629  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5...   \n",
       "20094 -4955852924885592789  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "16438  3915619990954748125                                                NaN   \n",
       "20101 -6110753172213420868  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5...   \n",
       "32101 -3501927457068402540                                                NaN   \n",
       "32104 -3501927457068402540  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "32110 -5668457755385241471  Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:46....   \n",
       "32204  1708977135910218598  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "37100 -7075418167979716771  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5...   \n",
       "32206  4688537671787969555  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n",
       "20100 -2060499994429429341                                                NaN   \n",
       "32210  3621737643587579081                                                NaN   \n",
       "32212  3621737643587579081  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...   \n",
       "32213  1708977135910218598                                                NaN   \n",
       "32238  -526804249137711866                                                NaN   \n",
       "32244  4688537671787969555                                                NaN   \n",
       "33310  -831865528880170726  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4...   \n",
       "33365  -831865528880170726                                                NaN   \n",
       "67675   736177961079848957  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
       "\n",
       "      userRegion userCountry  Preference_level  \n",
       "32241        NaN         NaN               5.0  \n",
       "6997         NaN         NaN               5.0  \n",
       "6974         NaN         NaN               5.0  \n",
       "705          NaN         NaN               5.0  \n",
       "9340         NaN         NaN               5.0  \n",
       "7054         NaN         NaN               5.0  \n",
       "7058         NaN         NaN               4.0  \n",
       "32211        NaN         NaN               4.0  \n",
       "6978         NaN         NaN               4.0  \n",
       "709          NaN         NaN               4.0  \n",
       "7002         NaN         NaN               4.0  \n",
       "9327         NaN         NaN               4.0  \n",
       "25           NaN         NaN               3.0  \n",
       "25388        NaN         NaN               3.0  \n",
       "24700        NaN         NaN               3.0  \n",
       "6988         NaN         NaN               3.0  \n",
       "5673         NaN         NaN               3.0  \n",
       "708          NaN         NaN               3.0  \n",
       "16464        NaN         NaN               3.0  \n",
       "31709        NaN         NaN               3.0  \n",
       "27           NaN         NaN               3.0  \n",
       "33295        NaN         NaN               2.0  \n",
       "6951         NaN         NaN               2.0  \n",
       "25380        NaN         NaN               2.0  \n",
       "24593        NaN         NaN               2.0  \n",
       "5698         NaN         NaN               2.0  \n",
       "16468        NaN         NaN               2.0  \n",
       "41885        NaN         NaN               2.0  \n",
       "43           NaN         NaN               2.0  \n",
       "36           NaN         NaN               2.0  \n",
       "...          ...         ...               ...  \n",
       "20116         SP          BR               1.0  \n",
       "31710        NaN         NaN               1.0  \n",
       "31708         MG          BR               1.0  \n",
       "25407         SP          BR               1.0  \n",
       "25431        NaN         NaN               1.0  \n",
       "43220         SP          BR               1.0  \n",
       "25381         RJ          BR               1.0  \n",
       "32215        NaN         NaN               1.0  \n",
       "41886         MG          BR               1.0  \n",
       "32208         SP          BR               1.0  \n",
       "35828         MG          BR               1.0  \n",
       "6957          RJ          BR               1.0  \n",
       "20094         SP          BR               1.0  \n",
       "16438        NaN         NaN               1.0  \n",
       "20101         SP          BR               1.0  \n",
       "32101        NaN         NaN               1.0  \n",
       "32104         SP          BR               1.0  \n",
       "32110         MG          BR               1.0  \n",
       "32204         SP          BR               1.0  \n",
       "37100         RJ          BR               1.0  \n",
       "32206         SP          BR               1.0  \n",
       "20100        NaN         NaN               1.0  \n",
       "32210        NaN         NaN               1.0  \n",
       "32212         NY          US               1.0  \n",
       "32213        NaN         NaN               1.0  \n",
       "32238        NaN         NaN               1.0  \n",
       "32244        NaN         NaN               1.0  \n",
       "33310         SP          BR               1.0  \n",
       "33365        NaN         NaN               1.0  \n",
       "67675         SP          BR               1.0  \n",
       "\n",
       "[128 rows x 9 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_list = user_list.sort_values('Preference_level', ascending=False)\n",
    "\n",
    "user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = user_list['personId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3500661007957156229, -1032019229384696495, -1130272294246983140,\n",
       "        -709287718034731589,  1899177452305284666,  3413008167249007087,\n",
       "        3609194402293569455,  4946304010805340284, -1578287561410088674])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n = personId ; m = contentId\n",
    "\n",
    "# recommend top 10 users you may like\n",
    "\n",
    "def Recommend_users_youmaylike(n, m):\n",
    "    \n",
    "\n",
    "    user_list = df_users.loc[df_users['contentId'] == m]\n",
    "    \n",
    "    user_list = user_list.loc[user_list['personId'] != n]\n",
    "    \n",
    "    user_list = user_list.sort_values('Preference_level', ascending=False)\n",
    "    \n",
    "    result = user_list['personId'].unique()\n",
    "    \n",
    "    recommendation_results = result[0:9]\n",
    "    \n",
    "    return recommendation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3295609019604191449,  3007736603136734729,  8189031666388954162,\n",
       "        6947583688031316012, -3230911339419872436,  1874422396201148365,\n",
       "       -2406209330529428019, -2979537012405607453, -3620817660824718175])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recommend_users_youmaylike(2653698047369148236, 1959495508923903948)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_friendship = pd.read_csv(\"friendship.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User A</th>\n",
       "      <th>User B</th>\n",
       "      <th>Friend (follow each other)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2653698047369148236</td>\n",
       "      <td>-3295609019604191449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2653698047369148236</td>\n",
       "      <td>3007736603136734729</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2653698047369148236</td>\n",
       "      <td>8189031666388954162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2653698047369148236</td>\n",
       "      <td>6947583688031316012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2653698047369148236</td>\n",
       "      <td>-3230911339419872436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                User A               User B  Friend (follow each other)\n",
       "0  2653698047369148236 -3295609019604191449                           1\n",
       "1  2653698047369148236  3007736603136734729                           1\n",
       "2  2653698047369148236  8189031666388954162                           0\n",
       "3  2653698047369148236  6947583688031316012                           1\n",
       "4  2653698047369148236 -3230911339419872436                           0"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_friendship.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "a = df_friendship['Friend (follow each other)']\n",
    "\n",
    "b = np.sum(a)\n",
    "\n",
    "score = b/10\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
